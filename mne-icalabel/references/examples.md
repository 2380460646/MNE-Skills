# Mne-Icalabel - Examples

**Pages:** 17

---

## API#

**URL:** https://mne.tools/mne-icalabel/stable/api/index.html

**Contents:**
- API#
- Most-used function#
- Models#
- Features#
- Annotating Components#

This is the application programming interface (API) reference for classes (CamelCase names) and functions (underscore_case names) of MNE-ICALabel.

The most commonly used function is mne_icalabel.label_components() which takes an mne instance (mne.io.Raw, mne.Epochs) and its ICA decomposition to label the components using the specified method/model.

label_components(inst, ica, method)

Automatically label the ICA components with the selected method.

On top of the available models, mne-icalabel provides a set of functions to extract features from ICA instance and Raw / Epochs instances using MNE-Python. Those features can then be used to train new models.

get_topomaps(ica[, picks, res, ...])

Generate an array of scalp topographies for the picked components.

Finally, to facilitate annotation of the ICA components, we provide an API that conforms to the derivative standard of BIDS for EEG data to write the annotations to a TSV file.

mark_component(component, fname, method, ...)

Mark a component with a label.

write_components_tsv(ica, fname)

Write channels tsv file for ICA components.

In addition, as of version 0.3, we have introduced a beta-version of a GUI that assists in annotated ICA components. This was heavily inspired by the annotation process in ICLabel.

label_ica_components(inst, ica[, show, block])

Launch the IC labelling GUI.

mne_icalabel.label_components

---

## Examples#

**URL:** https://mne.tools/mne-icalabel/stable/generated/examples/index.html

**Contents:**
- Examples#

Examples demonstrating ICA labeling for artifact correction, or annotating ICA components.

Repairing artifacts with ICA automatically using ICLabel Model

Labeling ICA components with a GUI

Download all examples in Python source code: examples_python.zip

Download all examples in Jupyter notebooks: examples_jupyter.zip

Gallery generated by Sphinx-Gallery

mne_icalabel.gui.label_ica_components

Repairing artifacts with ICA automatically using ICLabel Model

---

## ICLabel#

**URL:** https://mne.tools/mne-icalabel/stable/api/iclabel.html

**Contents:**
- ICLabel#
- Architecture#
- API#
- Cite#

This is the model originally available for EEGLab. The model was ported from matconvnet using pytorch or Microsoft onnxruntime.

ICLabel is designed to classify ICs fitted with an extended infomax ICA decomposition algorithm on EEG datasets referenced to a common average and filtered between (1, 100) Hz. It is possible to run ICLabel on datasets that do not meet those specification, but the classification performance might be negatively impacted. Moreover, the ICLabel paper did not study the effects of these preprocessing steps.

The model has three inputs: image (topomap), psd, and autocorrelation features. To encourage generalization, the image feature is rotated and negated, thus quadrupling the feature. After 3 convolutional layer with a ReLu activation, the 3 features are concatenated for the final layer.

iclabel_label_components(inst, ica[, ...])

Label the provided ICA components with the ICLabel neural network.

get_iclabel_features(inst, ica)

Generate the features for ICLabel neural network.

run_iclabel(images, psds, autocorr[, backend])

Run the ICLabel network on the provided set of features.

If you use ICLabel, please also cite the original paper[1].

Luca Pion-Tonachini, Ken Kreutz-Delgado, and Scott Makeig. Iclabel: an automated electroencephalographic independent component classifier, dataset, and website. NeuroImage, 198:181–197, September 2019. doi:10.1016/j.neuroimage.2019.05.026.

---

## Labeling ICA components with a GUI#

**URL:** https://mne.tools/mne-icalabel/stable/generated/examples/10_gui_label_components.html

**Contents:**
- Labeling ICA components with a GUI#
- Preprocess and run ICA on the data#
- Annotate ICA components with the GUI#
- Save the labeled components#

Go to the end to download the full example code.

This tutorial covers how to label ICA components with a GUI.

Similar to mne-qt-browser, we require the users to install a specific version of Qt. Our installation pip install mne-icalabel[gui] will not install any specific Qt version. Therefore, one can install Qt5 through either PyQt5 or PySide2 or a more modern Qt6 through either PyQt6 or PySide6 depending on their system. The users should install this separately to use the GUI functionality. See: https://www.riverbankcomputing.com/software/pyqt/ for more info on installing.

The GUI is still in active development, and may contain bugs, or changes without deprecation in future versions.

Load in some sample data

Before labeling components with the GUI, one needs to filter the data and then fit the ICA instance. Afterwards, one can run the GUI using the Raw data object and the fitted ICA instance.

The GUI will modify the ICA instance in place, and add the labels of each component to the labels_ attribute. The GUI will show features of the ICA components similar to the mne.viz.plot_ica_properties() function. It will also provide an interface to label each ICA component into one of seven categories:

For more information on annotating ICA components, we suggest reading through the tutorial from ICLabel (https://labeling.ucsd.edu/tutorial/about).

After the GUI labels, save the components using the write_components_tsv function. This will save the ICA annotations to disc in BIDS-Derivative for EEG data format.

Note: BIDS-EEG-Derivatives is not fully specified, so this functionality may change in the future without notice.

Total running time of the script: (0 minutes 2.653 seconds)

Estimated memory usage: 276 MB

Download Jupyter notebook: 10_gui_label_components.ipynb

Download Python source code: 10_gui_label_components.py

Download zipped: 10_gui_label_components.zip

Gallery generated by Sphinx-Gallery

Repairing artifacts with ICA automatically using ICLabel Model

---

## MEGNet#

**URL:** https://mne.tools/mne-icalabel/stable/api/megnet.html

**Contents:**
- MEGNet#
- Architecture#
- API#
- Cite#

MEGNet is an automated ICA-based artifact removal system for MEG using spatiotemporal convolutional neural networks. MEGNEt classifies ICs in the following categories:

'brain/other': Brain activity or other non-artifact activity.

'eye movement': Eye movements, such as saccades.

'heart beat': Cardiac activity.

'eye blink': Eye blinks.

The MEGNet architecture consists of three subnetworks:

2D CNN for spatial maps: Processes the topographic maps with 8 convolutional layers to extract spatial features from the magnetic flux patterns.

1D CNN for time courses: Processes 60-second epochs with 15-second overlaps using 5 convolutional layers to capture temporal dynamics.

Dense merge network: Combines the learned representations from both CNNs through concatenation and outputs probabilities for four classes: eye-blink (EB), saccade (SA), cardiac (CA), and non-artifact (NA).

The model uses PReLU activation and He uniform initialization, with batch normalization applied differently in spatial and temporal subnetworks based on automated hyperparameter optimization.

megnet_label_components(raw, ica)

Label the provided ICA components with the MEGnet neural network.

get_megnet_features(raw, ica)

Extract time series and topomaps for each ICA component.

If you use ICLaMEGNETbel, please also cite the original paper[1].

Alex H. Treacher, Prabhat Garg, Elizabeth Davenport, Ryan Godwin, Amy Proskovec, Leonardo Guimaraes Bezerra, Gowtham Murugesan, Ben Wagner, Christopher T. Whitlow, Joel D. Stitzel, Joseph A. Maldjian, and Albert A. Montillo. Megnet: automatic ica-based artifact removal for meg using spatiotemporal convolutional neural networks. NeuroImage, 241:118402, 2021. doi:https://doi.org/10.1016/j.neuroimage.2021.118402.

---

## mne_icalabel.annotation.mark_component#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.annotation.mark_component.html

**Contents:**
- mne_icalabel.annotation.mark_component#

Mark a component with a label.

The component to mark.

The filename for the BIDS filepath.

The method to use. Must be ‘manual’, or one of [‘iclabel’].

The label of the ICA component. Must be one of [‘brain’, ‘muscle artifact’, ‘eye blink’, ‘heart beat’, ‘line noise’, ‘channel noise’, ‘other’].

The annotating author.

Whether to raise an error if label is not an accepted value. Default is True.

Storage of ICA annotations as a .tsv file is currently experimental in the context of BIDS-EEG Derivatives. The API and functionality is subject to change as the community converges on the specification of BIDS-Derivatives.

mne_icalabel.features.get_topomaps

mne_icalabel.annotation.write_components_tsv

---

## mne_icalabel.annotation.write_components_tsv#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.annotation.write_components_tsv.html

**Contents:**
- mne_icalabel.annotation.write_components_tsv#

Write channels tsv file for ICA components.

Will create an accompanying JSON sidecar to explain the additional columns created in the channels tsv file for the ICA component labeling.

An instance of the fitted ICA.

Components are stored in a .tsv file essentially in the same manner as channels.tsv files for BIDS-EEG data. For more information, see the BIDS specification for EEG channels metadata.

Storage of ICA annotations as a .tsv file is currently experimental in the context of BIDS-EEG Derivatives. The API and functionality is subject to change as the community converges on the specification of BIDS-Derivatives.

mne_icalabel.annotation.mark_component

mne_icalabel.gui.label_ica_components

---

## mne_icalabel.features.get_topomaps#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.features.get_topomaps.html

**Contents:**
- mne_icalabel.features.get_topomaps#

Generate an array of scalp topographies for the picked components.

MNE ICA decomposition.

Indices of the independent components (ICs) to select. If an integer, represents the index of the IC to pick. Multiple ICs can be selected using a list of int or a slice. The indices are 0-indexed, so picks=1 will pick the second IC: ICA001. None (default) will pick all independent components in the order fitted.

The resolution of the square topographic map (in pixels).

The image interpolation to be used. All matplotlib options are accepted.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Dictionary of ICs topographic maps for each channel type.

mne_icalabel.label_components

mne_icalabel.annotation.mark_component

---

## mne_icalabel.gui.label_ica_components#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.gui.label_ica_components.html

**Contents:**
- mne_icalabel.gui.label_ica_components#
- Examples using mne_icalabel.gui.label_ica_components#

Launch the IC labelling GUI.

Raw or Epochs instance used to fit the ICA decomposition.

The ICA object fitted on inst.

Show the GUI if True.

Whether to halt program execution until the figure is closed.

The graphical user interface (GUI) window.

Labeling ICA components with a GUI

mne_icalabel.annotation.write_components_tsv

---

## mne_icalabel.iclabel.get_iclabel_features#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.iclabel.get_iclabel_features.html

**Contents:**
- mne_icalabel.iclabel.get_iclabel_features#

Generate the features for ICLabel neural network.

MNE Raw/Epoch instance with data array in Volts.

MNE ICA decomposition.

The topoplot feature.

The autocorrelations feature. Depending on the length of the raw data passed in, different methods of computing autocorrelation will be used. See Pion-Tonachini et al.[1] for details.

Luca Pion-Tonachini, Ken Kreutz-Delgado, and Scott Makeig. Iclabel: an automated electroencephalographic independent component classifier, dataset, and website. NeuroImage, 198:181–197, September 2019. doi:10.1016/j.neuroimage.2019.05.026.

---

## mne_icalabel.iclabel.iclabel_label_components#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.iclabel.iclabel_label_components.html

**Contents:**
- mne_icalabel.iclabel.iclabel_label_components#

Label the provided ICA components with the ICLabel neural network.

ICLabel is designed to classify ICs fitted with an extended infomax ICA decomposition algorithm on EEG datasets referenced to a common average and filtered between [1., 100.] Hz. It is possible to run ICLabel on datasets that do not meet those specification, but the classification performance might be negatively impacted. Moreover, the ICLabel paper did not study the effects of these preprocessing steps.

ICLabel uses 3 features:

Topographic maps, based on the ICA decomposition.

Power Spectral Density (PSD), based on the ICA decomposition and the provided instance.

Autocorrelation, based on the ICA decomposition and the provided instance.

For more information, see Pion-Tonachini et al.[1].

Instance used to fit the ICA decomposition. The instance should be referenced to a common average and bandpass filtered between 1 and 100 Hz.

ICA decomposition of the provided instance. The ICA decomposition should use the extended infomax method.

Whether to modify the ica instance in place by adding the automatic annotations to the labels_ property. By default True.

Backend to use to run ICLabel. If None, returns the first available backend in the order torch, onnx.

The estimated corresponding predicted probabilities of output classes for each independent component. Columns are ordered with 'brain', 'muscle artifact', 'eye blink', 'heart beat', 'line noise', 'channel noise', 'other'.

Luca Pion-Tonachini, Ken Kreutz-Delgado, and Scott Makeig. Iclabel: an automated electroencephalographic independent component classifier, dataset, and website. NeuroImage, 198:181–197, September 2019. doi:10.1016/j.neuroimage.2019.05.026.

---

## mne_icalabel.iclabel.run_iclabel#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.iclabel.run_iclabel.html

**Contents:**
- mne_icalabel.iclabel.run_iclabel#

Run the ICLabel network on the provided set of features.

The features are un-formatted and are as-returned by get_iclabel_features. For more information, see Pion-Tonachini et al.[1].

The power spectral density features.

The autocorrelation features.

Backend to use to run ICLabel. If None, returns the first available backend in the order torch, onnx.

The predicted numerical probability values for all labels in ICLabel output. Columns are ordered with 'Brain', 'Muscle', 'Eye', 'Heart', 'Line Noise', 'Channel Noise', and 'Other'.

Luca Pion-Tonachini, Ken Kreutz-Delgado, and Scott Makeig. Iclabel: an automated electroencephalographic independent component classifier, dataset, and website. NeuroImage, 198:181–197, September 2019. doi:10.1016/j.neuroimage.2019.05.026.

---

## mne_icalabel.label_components#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.label_components.html

**Contents:**
- mne_icalabel.label_components#
- Examples using mne_icalabel.label_components#

Automatically label the ICA components with the selected method.

The data instance used to fit the ICA instance.

The fitted ICA instance.

The proposed method for labeling components. Must be one of: 'iclabel', 'megnet'.

A dictionary with the following fields:

Estimated predicted probability of the output class for each independent component.

The corresponding string label of each class in 'y_pred'.

Please refer to the following function for additional information on each method:

'iclabel': iclabel_label_components()

'megnet': megnet_label_components()

Repairing artifacts with ICA automatically using ICLabel Model

mne_icalabel.features.get_topomaps

---

## mne_icalabel.megnet.get_megnet_features#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.megnet.get_megnet_features.html

**Contents:**
- mne_icalabel.megnet.get_megnet_features#

Extract time series and topomaps for each ICA component.

MEGNet uses topomaps from BrainStorm exported as 120x120x3 RGB images. Thus, we need to replicate the ‘appearance’/’look’ of a BrainStorm topomap.

Raw MEG recording used to fit the ICA decomposition. The raw instance should be bandpass filtered between 1 and 100 Hz and notch filtered at 50 or 60 Hz to remove line noise, and downsampled to 250 Hz.

ICA decomposition of the provided instance. The ICA decomposition should use the infomax method.

The time series for each ICA component.

The topomap RGB images for each ICA component.

---

## mne_icalabel.megnet.megnet_label_components#

**URL:** https://mne.tools/mne-icalabel/stable/generated/api/mne_icalabel.megnet.megnet_label_components.html

**Contents:**
- mne_icalabel.megnet.megnet_label_components#

Label the provided ICA components with the MEGnet neural network.

For more information, see Treacher et al.[1].

Raw MEG recording used to fit the ICA decomposition. The raw instance should be bandpass filtered between 1 and 100 Hz and notch filtered at 50 or 60 Hz to remove line noise, and downsampled to 250 Hz.

ICA decomposition of the provided instance. The ICA decomposition should use the infomax method.

The estimated corresponding predicted probabilities of output classes for each independent component. Columns are ordered with 'brain/other', 'eye movement', 'heart beat', 'eye blink'.

Alex H. Treacher, Prabhat Garg, Elizabeth Davenport, Ryan Godwin, Amy Proskovec, Leonardo Guimaraes Bezerra, Gowtham Murugesan, Ben Wagner, Christopher T. Whitlow, Joel D. Stitzel, Joseph A. Maldjian, and Albert A. Montillo. Megnet: automatic ica-based artifact removal for meg using spatiotemporal convolutional neural networks. NeuroImage, 241:118402, 2021. doi:https://doi.org/10.1016/j.neuroimage.2021.118402.

---

## MNE-ICALabel#

**URL:** https://mne.tools/mne-icalabel/stable/

**Contents:**
- MNE-ICALabel#
- Contents#

mne-icalabel is a Python package for labeling independent components that stem from an Independent Component Analysis (ICA).

Scalp electroencephalography (EEG) and magnetoencephalography (MEG) analysis is typically very noisy and contains various non-neural signals, such as heartbeat artifacts. Independent Component Analysis (ICA) is a common procedure to remove these artifacts. However, removing artifacts requires manual annotation of ICA components, which is subject to human error and very laborious when operating on large datasets.

The first few versions of mne-icalabel replicated the popular ICLabel model for Python (previously only available in MATLAB’s EEGLab). In future versions, the package aims to develop more robust models that build upon the ICLabel model.

We encourage you to use the package for your research and also build on top with relevant Pull Requests (PR). See our examples for walk-throughs of how to use the package and see our contributing guide for contributions.

mne-icalabel is licensed under the BSD license. A full copy of the license can be found on GitHub. See our Changelog for a full list of changes.

---

## Repairing artifacts with ICA automatically using ICLabel Model#

**URL:** https://mne.tools/mne-icalabel/stable/generated/examples/00_iclabel.html

**Contents:**
- Repairing artifacts with ICA automatically using ICLabel Model#
- Example: EOG and ECG artifact repair#
  - Visualizing the artifacts#
  - Filtering to remove slow drifts#
  - Fitting and plotting the ICA solution#
  - Selecting ICA components automatically#
    - Extract Labels and Reconstruct Raw Data#
- References#

Go to the end to download the full example code.

This tutorial covers automatically repairing signals using ICA with the ICLabel model[1], which originates in EEGLab. For conceptual background on ICA, see this scikit-learn tutorial. For a basic understanding of how to use ICA to remove artifacts, see the tutorial in MNE-Python.

ICLabel is designed to classify ICs fitted with an extended infomax ICA decomposition algorithm on EEG datasets referenced to a common average and filtered between [1., 100.] Hz. It is possible to run ICLabel on datasets that do not meet those specification, but the classification performance might be negatively impacted. Moreover, the ICLabel paper did not study the effects of these preprocessing steps.

This example involves running the ICA Infomax algorithm, which requires scikit-learn to be installed. Please install this optional dependency before running the example.

We begin as always by importing the necessary Python modules and loading some example data. Because ICA can be computationally intense, we’ll also crop the data to 60 seconds; and to save ourselves from repeatedly typing mne.preprocessing we’ll directly import a few functions and classes from that submodule.

Before applying ICA (or any artifact repair strategy), be sure to observe the artifacts in your data to make sure you choose the right repair tool. Sometimes the right tool is no tool at all — if the artifacts are small enough you may not even need to repair them to get good analysis results. See Overview of artifact detection for guidance on detecting and visualizing various types of artifact.

Let’s begin by visualizing the artifacts that we want to repair. In this dataset they are big enough to see easily in the raw data:

Before we run the ICA, an important step is filtering the data to remove low-frequency drifts, which can negatively affect the quality of the ICA fit. The slow drifts are problematic because they reduce the independence of the assumed-to-be-independent sources (e.g., during a slow upward drift, the neural, heartbeat, blink, and other muscular sources will all tend to have higher values), making it harder for the algorithm to find an accurate solution. A high-pass filter with 1 Hz cutoff frequency is recommended. However, because filtering is a linear operation, the ICA solution found from the filtered signal can be applied to the unfiltered signal (see [2] for more information), so we’ll keep a copy of the unfiltered Raw object around so we can apply the ICA solution to it later.

Ignoring the time domain

The ICA algorithms implemented in MNE-Python find patterns across channels, but ignore the time domain. This means you can compute ICA on discontinuous Epochs or Evoked objects (not just continuous Raw objects), or only use every Nth sample by passing the decim parameter to ICA.fit().

Epochs used for fitting ICA should not be baseline-corrected. Because cleaning the data via ICA may introduce DC offsets, we suggest to baseline correct your data after cleaning (and not before), should you require baseline correction.

Now we’re ready to set up and fit the ICA. Since we know (from observing our raw data) that the EOG and ECG artifacts are fairly strong, we would expect those artifacts to be captured in the first few dimensions of the PCA decomposition that happens before the ICA. Therefore, we probably don’t need a huge number of components to do a good job of isolating our artifacts (though it is usually preferable to include more components for a more accurate solution). As a first guess, we’ll run ICA with n_components=15 (use only the first 15 PCA components to compute the ICA decomposition) — a very small number given that our data has 59 good EEG channels, but with the advantage that it will run quickly and we will able to tell easily whether it worked or not (because we already know what the EOG / ECG artifacts should look like).

ICA fitting is not deterministic (e.g., the components may get a sign flip on different runs, or may not always be returned in the same order), so we’ll also specify a random seed so that we get identical results each time this tutorial is built by our web servers.

Before fitting ICA, we will apply a common average referencing, to comply with the ICLabel requirements.

We will use the ‘extended infomax’ method for fitting the ICA, to comply with the ICLabel requirements. ICLabel was not tested with other ICA decomposition algorithm, but its performance and accuracy should not be impacted by the algorithm.

Some optional parameters that we could have passed to the fit method include decim (to use only every Nth sample in computing the ICs, which can yield a considerable speed-up) and reject (for providing a rejection dictionary for maximum acceptable peak-to-peak amplitudes for each channel type, just like we used when creating epoched data in the Overview of MEG/EEG analysis with MNE-Python tutorial).

Now we can examine the ICs to see what they captured. plot_sources will show the time series of the ICs. Note that in our call to plot_sources we can use the original, unfiltered Raw object:

Here we can pretty clearly see that the first component (ICA000) captures the EOG signal quite well (for more info on visually identifying Independent Components, this EEGLAB tutorial is a good resource). We can also visualize the scalp field distribution of each component using plot_components. These are interpolated based on the values in the ICA mixing matrix:

We can also plot some diagnostics of IC using plot_properties:

Now that we’ve explored what components need to be removed, we can apply the automatic ICA component labeling algorithm, which will assign a probability value for each component being one of:

The output of the ICLabel label_components function produces predicted probability values for each of these classes in that order. See [1] for full details.

We can extract the labels of each component and exclude non-brain classified components, keeping ‘brain’ and ‘other’. “Other” is a catch-all that for non-classifiable components. We will stay on the side of caution and assume we cannot blindly remove these.

Now that the exclusions have been set, we can reconstruct the sensor signals with artifacts removed using the apply method (remember, we’re applying the ICA solution from the filtered data to the original unfiltered signal). Plotting the original raw data alongside the reconstructed data shows that the heartbeat and blink artifacts are repaired.

Luca Pion-Tonachini, Ken Kreutz-Delgado, and Scott Makeig. Iclabel: an automated electroencephalographic independent component classifier, dataset, and website. NeuroImage, 198:181–197, September 2019. doi:10.1016/j.neuroimage.2019.05.026.

Irene Winkler, Stefan Debener, Klaus-Robert Müller, and Michael Tangermann. On the influence of high-pass filtering on ICA-based artifact reduction in EEG-ERP. In Proceedings of EMBC-2015, 4101–4105. Milan, 2015. IEEE. doi:10.1109/EMBC.2015.7319296.

Total running time of the script: (1 minutes 10.859 seconds)

Estimated memory usage: 518 MB

Download Jupyter notebook: 00_iclabel.ipynb

Download Python source code: 00_iclabel.py

Download zipped: 00_iclabel.zip

Gallery generated by Sphinx-Gallery

Labeling ICA components with a GUI

---
