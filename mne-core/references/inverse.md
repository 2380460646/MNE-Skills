# Mne-Core - Inverse

**Pages:** 515

---

## Algorithms and other implementation details#

**URL:** https://mne.tools/stable/documentation/implementation.html

**Contents:**
- Algorithms and other implementation details#
- Internal representation (units)#
- Floating-point precision#
- Supported channel types#
- Supported data formats#
- Supported formats for digitized 3D locations#
- Memory-efficient I/O#
  - Preloading continuous (raw) data#
  - Preloading epoched data#
  - Loading data explicitly#

This page describes some of the technical details of MNE-Python implementation.

Irrespective of the units used in your manufacturer’s format, when importing data, MNE-Python will always convert measurements to the same standard units. Thus the in-memory representation of data are always in:

Volts (eeg, eog, seeg, emg, ecg, bio, ecog, dbs)

Teslas (magnetometers)

Teslas/meter (gradiometers)

Amperes*meter (dipole fits, minimum-norm estimates, etc.)

Moles/liter (“molar”; fNIRS data: oxyhemoglobin (hbo), deoxyhemoglobin (hbr))

Arbitrary units (various derived unitless quantities)

Note, however, that most MNE-Python plotting functions will scale the data when plotted to yield nice-looking axis annotations in a sensible range; for example, mne.io.Raw.plot_psd() will convert teslas to femtoteslas (fT) and volts to microvolts (µV) when plotting MEG and EEG data.

The units used in internal data representation are particularly important to remember when extracting data from MNE-Python objects and manipulating it outside MNE-Python (e.g., when using methods like get_data() or to_data_frame() to convert data to NumPy arrays or Pandas DataFrames for analysis or plotting with other Python modules).

MNE-Python performs all computation in memory using the double-precision 64-bit floating point format. This means that the data is typecast into float64 format as soon as it is read into memory. The reason for this is that operations such as filtering and preprocessing are more accurate when using the 64-bit format. However, for backward compatibility, MNE-Python writes .fif files in a 32-bit format by default. This reduces file size when saving data to disk, but beware that saving intermediate results to disk and re-loading them from disk later may lead to loss in precision. If you would like to ensure 64-bit precision, there are two possibilities:

Chain the operations in memory and avoid saving intermediate results.

Save intermediate results but change the dtype used for saving, by using the fmt parameter of mne.io.Raw.save() (or mne.Epochs.save(), etc). However, note that this may render the .fif files unreadable in software packages other than MNE-Python.

Channel types are represented in MNE-Python with shortened or abbreviated names. This page lists all supported channel types, their abbreviated names, and the measurement unit used to represent data of that type. Where channel types occur in two or more sub-types, the sub-type abbreviations are given in parentheses. More information about measurement units is given in the Internal representation (units) section.

scalp electroencephalography (EEG)

Magnetoencephalography (magnetometers)

Magnetoencephalography (gradiometers)

Electrocardiography (ECG)

Stereotactic EEG channels

Deep brain stimulation (DBS)

Electrocorticography (ECoG)

Functional near-infrared spectroscopy (oxyhemoglobin)

Functional near-infrared spectroscopy (deoxyhemoglobin)

Electromyography (EMG)

Electrooculography (EOG)

Miscellaneous biological channels (e.g., skin conductance)

stimulus (a.k.a. trigger) channels

respiration monitoring channel

continuous head position indicator (HPI) coil channels

Flux excitation channel

Internal Active Shielding data (Triux systems only?)

System status channel information (Triux systems only)

Galvanic skin response

Reference Magnetometers

Goodness of fit (GOF)

Continuous-wave functional near-infrared spectroscopy (CW-fNIRS) (CW amplitude)

Frequency-domain near-infrared spectroscopy (FD-NIRS AC amplitude)

Frequency-domain near-infrared spectroscopy (FD-NIRS phase)

Functional near-infrared spectroscopy (optical density)

Current source density

Volts per square meter

Eye-tracking (gaze position)

Eye-tracking (pupil size)

When MNE-Python loads sensor data, the data are stored in a Python object of type mne.io.Raw. Specialized loading functions are provided for the raw data file formats from a variety of equipment manufacturers. All raw data input/output functions in MNE-Python are found in mne.io and start with read_raw_*; see the documentation for each reader function for more info on reading specific file types.

As seen in the table below, there are also a few formats defined by other neuroimaging analysis software packages that are supported (EEGLAB, FieldTrip). Like the equipment-specific loading functions, these will also return an object of class Raw; additional functions are available for reading data that has already been epoched or averaged (see table).

mne.io.read_raw_artemis123()

4-D Neuroimaging / BTi

mne.io.read_raw_bti()

mne.io.read_raw_ctf()

mne.io.read_raw_fif()

mne.io.read_raw_fil()

mne.io.read_raw_kit(), mne.read_epochs_kit()

mne.io.read_raw_fieldtrip(), mne.read_epochs_fieldtrip(), mne.read_evoked_fieldtrip()

mne.io.read_raw_brainvision()

mne.io.read_raw_bdf()

mne.io.read_raw_cnt()

mne.io.read_raw_edf()

mne.io.read_raw_eeglab(), mne.read_epochs_eeglab()

mne.io.read_raw_egi()

mne.io.read_raw_egi()

mne.io.read_raw_eximia()

mne.io.read_raw_gdf()

mne.io.read_raw_nicolet()

mne.io.read_raw_persyst()

mne.io.read_raw_nirx()

mne.io.read_raw_boxy()

SR eyelink ASCII files

mne.io.read_raw_eyelink()

More details are provided in the tutorials in the Reading data for different recording systems section.

MNE-Python can load 3D point locations obtained by digitization systems. Such files allow to obtain a montage that can then be added to Raw objects with the set_montage(). See the documentation for each reader function for more info on reading specific file types.

mne.channels.read_dig_fif()

mne.channels.read_dig_polhemus_isotrak()

mne.channels.read_dig_egi()

mne.channels.read_dig_hpts()

mne.channels.read_dig_captrak()

mne.channels.read_dig_curry()

mne.channels.read_dig_dat()

To load Polhemus FastSCAN files you can use montage.

It is also possible to make a montage from arrays with mne.channels.make_dig_montage().

MNE-Python can read data on-demand using the preload option provided in raw reading functions. For example:

Filtering, resampling and dropping or selecting channels does not work with preload=False.

Similarly, epochs can also be be read from disk on-demand. For example:

When preload=False, the epochs data is loaded from the disk on-demand. Note that preload=False for epochs will work even if the raw object has been loaded with preload=True. Preloading is also supported for mne.read_epochs().

This comes with a caveat. When preload=False, data rejection based on peak-to-peak thresholds is executed when the data is loaded from disk, not when the Epochs object is created.

To explicitly reject artifacts with preload=False, use the function mne.Epochs.drop_bad().

To load the data if preload=False was initially selected, use the functions mne.io.Raw.load_data() and mne.Epochs.load_data().

If you just want your raw data as a Numpy array to work with it in a different framework you can use slicing syntax:

In short, data repair using spherical spline interpolation [1] consists of the following steps:

Project the good and bad electrodes onto a unit sphere

Compute a mapping matrix that maps \(N\) good channels to \(M\) bad channels

Use this mapping matrix to compute interpolated data in the bad channels

Spherical splines assume that the potential \(V(\boldsymbol{r_i})\) at any point \(\boldsymbol{r_i}\) on the surface of the sphere can be represented by:

where the \(C = (c_{1}, ..., c_{N})^{T}\) are constants which must be estimated. The function \(g_{m}(\cdot)\) of order \(m\) is given by:

where \(P_{n}(x)\) are Legendre polynomials of order \(n\).

To estimate the constants \(C\), we must solve the following two equations simultaneously:

where \(G_{ss} \in R^{N \times N}\) is a matrix whose entries are \(G_{ss}[i, j] = g_{m}(cos(\boldsymbol{r_i}, \boldsymbol{r_j}))\) and \(X \in R^{N \times 1}\) are the potentials \(V(\boldsymbol{r_i})\) measured at the good channels. \(T_{s} = (1, 1, ..., 1)^\top\) is a column vector of dimension \(N\). Equation (2) is the matrix formulation of Equation (1) and equation (3) is like applying an average reference to the data. From equation (2) and (3), we get:

\(C_{i}\) is the same as matrix \({\begin{bmatrix} {T_s}^{T} && 0 \\ T_s && G_{ss} \end{bmatrix}}^{-1}\) but with its first column deleted, therefore giving a matrix of dimension \((N + 1) \times N\).

Now, to estimate the potentials \(\hat{X} \in R^{M \times 1}\) at the bad channels, we have to do:

where \(G_{ds} \in R^{M \times N}\) computes \(g_{m}(\boldsymbol{r_i}, \boldsymbol{r_j})\) between the bad and good channels. \(T_{d} = (1, 1, ..., 1)^\top\) is a column vector of dimension \(M\). Plugging in equation (4) in (5), we get

To interpolate bad channels, one can simply do:

and the bad channel will be fixed.

MNE-Python’s implementation of Maxwell filtering is described in the Signal-space separation (SSS) and Maxwell filtering tutorial.

The Signal-Space Projection (SSP) is one approach to rejection of external disturbances in software. The section presents some relevant details of this method. For practical examples of how to use SSP for artifact rejection, see Repairing artifacts with SSP.

Unlike many other noise-cancellation approaches, SSP does not require additional reference sensors to record the disturbance fields. Instead, SSP relies on the fact that the magnetic field distributions generated by the sources in the brain have spatial distributions sufficiently different from those generated by external noise sources. Furthermore, it is implicitly assumed that the linear space spanned by the significant external noise patterns has a low dimension.

Without loss of generality we can always decompose any \(n\)-channel measurement \(b(t)\) into its signal and noise components as

Further, if we know that \(b_n(t)\) is well characterized by a few field patterns \(b_1 \dotso b_m\), we can express the disturbance as

where the columns of \(U\) constitute an orthonormal basis for \(b_1 \dotso b_m\), \(c_n(t)\) is an \(m\)-component column vector, and the error term \(e(t)\) is small and does not exhibit any consistent spatial distributions over time, i.e., \(C_e = E \{e e^\top\} = I\). Subsequently, we will call the column space of \(U\) the noise subspace. The basic idea of SSP is that we can actually find a small basis set \(b_1 \dotso b_m\) such that the conditions described above are satisfied. We can now construct the orthogonal complement operator

and apply it to \(b(t)\) in Equation (6) yielding

since \(P_{\perp}b_n(t) = P_{\perp}(Uc_n(t) + e(t)) \approx 0\) and \(P_{\perp}b_{s}(t) \approx b_{s}(t)\). The projection operator \(P_{\perp}\) is called the signal-space projection operator and generally provides considerable rejection of noise, suppressing external disturbances by a factor of 10 or more. The effectiveness of SSP depends on two factors:

The basis set \(b_1 \dotso b_m\) should be able to characterize the disturbance field patterns completely and

The angles between the noise subspace space spanned by \(b_1 \dotso b_m\) and the signal vectors \(b_s(t)\) should be as close to \(\pi / 2\) as possible.

If the first requirement is not satisfied, some noise will leak through because \(P_{\perp}b_n(t) \neq 0\). If the any of the brain signal vectors \(b_s(t)\) is close to the noise subspace not only the noise but also the signal will be attenuated by the application of \(P_{\perp}\) and, consequently, there might by little gain in signal-to-noise ratio.

Since the signal-space projection modifies the signal vectors originating in the brain, it is necessary to apply the projection to the forward solution in the course of inverse computations.

For more information on SSP, please consult the references listed in Tesche et al.[2], Uusitalo and Ilmoniemi[3].

As described above, application of SSP requires the estimation of the signal vectors \(b_1 \dotso b_m\) constituting the noise subspace. The most common approach, also implemented in mne.compute_proj_raw() is to compute a covariance matrix of empty room data, compute its eigenvalue decomposition, and employ the eigenvectors corresponding to the highest eigenvalues as basis for the noise subspace. It is also customary to use a separate set of vectors for magnetometers and gradiometers in the Vectorview system.

The EEG average reference is the mean signal over all the sensors. It is typical in EEG analysis to subtract the average reference from all the sensor signals \(b^{1}(t), ..., b^{n}(t)\). That is:

where the noise term \(b_{n}^{j}(t)\) is given by

Thus, the projector vector \(P_{\perp}\) will be given by \(P_{\perp}=\frac{1}{n}[1, 1, ..., 1]\)

When applying SSP, the signal of interest can also be sometimes removed. Therefore, it’s always a good idea to check how much the effect of interest is reduced by applying SSP. SSP might remove both the artifact and signal of interest.

The watershed algorithm [Segonne et al., 2004] is part of the FreeSurfer software. The name of the program is mri_watershed. Its use in the MNE environment is facilitated by the script mne watershed_bem.

After mne watershed_bem has completed, the following files appear in the subject’s bem/watershed directory:

<subject>_brain_surface contains the brain surface triangulation.

<subject>_inner_skull_surface contains the inner skull triangulation.

<subject>_outer_skull_surface contains the outer skull triangulation.

<subject>_outer_skin_surface contains the scalp triangulation.

All of these surfaces are in the FreeSurfer format. In addition, there will be a file called bem/watershed/ws.mgz which contains the brain MRI volume. Furthermore, mne watershed_bem script converts the scalp surface to fif format and saves the result to bem/<subject>-head.fif.

This method depends on the availablily of MRI data acquired with a multi-echo FLASH sequence at two flip angles (5 and 30 degrees). These data can be acquired separately from the MPRAGE data employed in FreeSurfer cortical reconstructions but it is strongly recommended that they are collected at the same time with the MPRAGEs or at least with the same scanner. For easy co-registration, the images should have FOV, matrix, slice thickness, gap, and slice orientation as the MPRAGE data. For information on suitable pulse sequences, see Fischl et al.[4].

Creation of the BEM meshes using this method involves the following steps:

Creating a synthetic 5-degree flip angle FLASH volume, register it with the MPRAGE data, and run the segmentation and meshing program. This step is accomplished by running the script mne flash_bem.

Inspecting the meshes with tkmedit, see Inspecting the meshes.

Different methods can be employed for the creation of the individual surfaces. For example, it may turn out that the watershed algorithm produces are better quality skin surface than the segmentation approach based on the FLASH images. If this is the case, outer_skin.surf can set to point to the corresponding watershed output file while the other surfaces can be picked from the FLASH segmentation data.

Since all images comprising the multi-echo FLASH data are contained in a single series, it is necessary to organize the images according to the echoes before proceeding to the BEM surface reconstruction. This can be accomplished by using dcm2niix or the MNE-C tool mne_organize_dicom if necessary, then use mne.bem.convert_flash_mris().

The BEM surface segmentation and tessellation is automated with the script mne flash_bem. It assumes that a FreeSurfer reconstruction for this subject is already in place.

Before running mne flash_bem do the following:

Create symbolic links from the directories containing the 5-degree and 30-degree flip angle FLASH series to flash05 and flash30, respectively:

ln -s <FLASH 5 series dir> flash05

ln -s <FLASH 30 series dir> flash30

Some partition formats (e.g. FAT32) do not support symbolic links. In this case, copy the file to the appropriate series:

cp <FLASH 5 series dir> flash05

cp <FLASH 30 series dir> flash30

Set the SUBJECTS_DIR and SUBJECT environment variables or pass the --subjects-dir and --subject options to mne flash_bem

If mne flash_bem is run with the --noflash30 option, the flash30 directory is not needed, i.e., only the 5-degree flip angle flash data are employed.

It may take a while for mne flash_bem to complete. It uses the FreeSurfer directory structure under $SUBJECTS_DIR/$SUBJECT. The script encapsulates the following processing steps:

It creates an mgz file corresponding to each of the eight echoes in each of the FLASH directories in mri/flash. The files will be called mef <flip-angle>_<echo-number>.mgz.

If the unwarp=True option is specified, run grad_unwarp and produce files mef <flip-angle>_<echo-number>u.mgz. These files will be then used in the following steps.

It creates parameter maps in mri/flash/parameter_maps using mri_ms_fitparms.

It creates a synthetic 5-degree flip angle volume in mri/flash/parameter_maps/flash5.mgz using mri_synthesize.

Using fsl_rigid_register, it creates a registered 5-degree flip angle volume mri/flash/parameter_maps/flash5_reg.mgz by registering mri/flash/parameter_maps/flash5.mgz to the T1 volume under mri.

Using mri_convert, it converts the flash5_reg volume to COR format under mri/flash5. If necessary, the T1 and brain volumes are also converted into the COR format.

It runs mri_make_bem_surfaces to create the BEM surface tessellations.

It creates the directory bem/flash, moves the tri-format tringulations there and creates the corresponding FreeSurfer surface files in the same directory.

The COR format volumes created by mne flash_bem are removed.

If the --noflash30 option is specified to mne flash_bem, steps 3 and 4 in the above are replaced by averaging over the different echo times in 5-degree flip angle data.

It is advisable to check the validity of the BEM meshes before using them. This can be done with:

the --view option of mne flash_bem

calling mne.viz.plot_bem() directly

Using FreeSurfer tools tkmedit or freeview

Coordinate systems in MNE-Python

In some MNE-Python objects (e.g., Forward, SourceSpaces, etc), information about the coordinate frame is encoded as a constant integer value. The meaning of those integers is determined in the source code.

The coordinate systems used in MNE software (and FreeSurfer) and their relationships are depicted in MEG/EEG and MRI coordinate systems. Except for the sensor coordinates, all of the coordinate systems are Cartesian and have the “RAS” (Right-Anterior-Superior) orientation, i.e., the \(x\) axis points to the right, the \(y\) axis to the front, and the \(z\) axis up.

MEG/EEG and MRI coordinate systems#

The coordinate transforms present in the fif files in MNE and the FreeSurfer files as well as those set to fixed values are indicated with \(T_x\), where \(x\) identifies the transformation.

The coordinate systems related to MEG/EEG data are:

This is a coordinate system defined with help of the fiducial landmarks (nasion and the two auricular points). In fif files, EEG electrode locations are given in this coordinate system. In addition, the head digitization data acquired in the beginning of an MEG, MEG/EEG, or EEG acquisition are expressed in head coordinates. For details, see MEG/EEG and MRI coordinate systems.

This is a coordinate system tied to the MEG device. The relationship of the Device and Head coordinates is determined during an MEG measurement by feeding current to three to five head-position indicator (HPI) coils and by determining their locations with respect to the MEG sensor array from the magnetic fields they generate.

Each MEG sensor has a local coordinate system defining the orientation and location of the sensor. With help of this coordinate system, the numerical integration data needed for the computation of the magnetic field can be expressed conveniently as discussed in Coil geometry information. The channel information data in the fif files contain the information to specify the coordinate transformation between the coordinates of each sensor and the MEG device coordinates.

The coordinate systems related to MRI data are:

Surface RAS coordinates

The FreeSurfer surface data are expressed in this coordinate system. The origin of this coordinate system is at the center of the conformed FreeSurfer MRI volumes (usually 256 x 256 x 256 isotropic 1-mm3 voxels) and the axes are oriented along the axes of this volume. The BEM surface and the locations of the sources in the source space are usually expressed in this coordinate system in the fif files. In this manual, the Surface RAS coordinates are usually referred to as MRI coordinates unless there is need to specifically discuss the different MRI-related coordinate systems.

This coordinate system has axes identical to the Surface RAS coordinates but the location of the origin is different and defined by the original MRI data, i.e. , the origin is in a scanner-dependent location. There is hardly any need to refer to this coordinate system explicitly in the analysis with the MNE software. However, since the Talairach coordinates, discussed below, are defined with respect to RAS coordinates rather than the Surface RAS coordinates, the RAS coordinate system is implicitly involved in the transformation between Surface RAS coordinates and the two Talairach coordinate systems.

MNI Talairach coordinates

The definition of this coordinate system is discussed, e.g., in https://imaging.mrc-cbu.cam.ac.uk/imaging/MniTalairach. This transformation is determined during the FreeSurfer reconstruction process. These coordinates are in MNI305 space.

FreeSurfer Talairach coordinates

The problem with the MNI Talairach coordinates is that the linear MNI Talairach transform does not match the brains completely to the Talairach brain. This is probably because the Talairach atlas brain is a rather odd shape, and as a result, it is difficult to match a standard brain to the atlas brain using an affine transform. As a result, the MNI brains are slightly larger (in particular higher, deeper and longer) than the Talairach brain. The differences are larger as you get further from the middle of the brain, towards the outside. The FreeSurfer Talairach coordinates mitigate this problem by additing a an additional transformation, defined separately for negative and positive MNI Talairach \(z\) coordinates. These two transformations, denoted by \(T_-\) and \(T_+\) in MEG/EEG and MRI coordinate systems, are fixed as discussed in https://imaging.mrc-cbu.cam.ac.uk/imaging/MniTalairach (Approach 2).

The different coordinate systems are related by coordinate transformations depicted in MEG/EEG and MRI coordinate systems. The arrows and coordinate transformation symbols (\(T_x\)) indicate the transformations actually present in the FreeSurfer files. Generally,

where \(x_k\), \(y_k\),and \(z_k\) are the location coordinates in two coordinate systems, \(T_{12}\) is the coordinate transformation from coordinate system “1” to “2”, \(x_0\), \(y_0\), and \(z_0\) is the location of the origin of coordinate system “1” in coordinate system “2”, and \(R_{jk}\) are the elements of the rotation matrix relating the two coordinate systems. The coordinate transformations are present in different files produced by FreeSurfer and MNE. The fixed transformations \(T_-\) and \(T_+\) are:

This section does not discuss the transformation between the MRI voxel indices and the different MRI coordinates. However, it is important to note that in FreeSurfer, MNE, as well as in Neuromag software an integer voxel coordinate corresponds to the location of the center of a voxel. Detailed information on the FreeSurfer MRI systems can be found at https://surfer.nmr.mgh.harvard.edu/fswiki/CoordinateSystems. The symbols \(T_x\) are defined in MEG/EEG and MRI coordinate systems.

\(T_{s_1}\dots T_{s_n}\)

Channel information in files containing \(T_1\).

nibabel.freesurfer.mghformat.MGHImage

mri/transforms/talairach.xfm

Hardcoded in software

Hardcoded in software.

Hardcoded in software

Hardcoded in software.

The head coordinate system#

The MEG/EEG head coordinate system employed in the MNE software is a right-handed Cartesian coordinate system. The direction of \(x\) axis is from left to right, that of \(y\) axis to the front, and the \(z\) axis thus points up.

The \(x\) axis of the head coordinate system passes through the two periauricular or preauricular points digitized before acquiring the data with positive direction to the right. The \(y\) axis passes through the nasion and is normal to the \(x\) axis. The \(z\) axis points up according to the right-hand rule and is normal to the \(xy\) plane.

The origin of the MEG device coordinate system is device dependent. Its origin is located approximately at the center of a sphere which fits the occipital section of the MEG helmet best with \(x\) axis axis going from left to right and \(y\) axis pointing front. The \(z\) axis is, again, normal to the \(xy\) plane with positive direction up.

The above definition is identical to that of the Neuromag MEG/EEG (head) coordinate system. However, in 4-D Neuroimaging and CTF MEG systems the head coordinate frame definition is different. The origin of the coordinate system is at the midpoint of the left and right auricular points. The \(x\) axis passes through the nasion and the origin with positive direction to the front. The \(y\) axis is perpendicular to the \(x\) axis on the and lies in the plane defined by the three fiducial landmarks, positive direction from right to left. The \(z\) axis is normal to the plane of the landmarks, pointing up. Note that in this convention the auricular points are not necessarily located on \(y\) coordinate axis. The file conversion utilities take care of these idiosyncrasies and convert all coordinate information to the MNE software head coordinate frame.

The fif format source space files containing the dipole locations and orientations are created with mne.setup_source_space().

In addition to source spaces confined to a surface, the MNE software provides some support for three-dimensional source spaces bounded by a surface as well as source spaces comprised of discrete, arbitrarily located source points. The mne.setup_volume_source_space() utility assists in generating such source spaces.

See The Boundary Element Model (BEM).

The following topology checks are performed during the creation of BEM models:

The completeness of each surface is confirmed by calculating the total solid angle subtended by all triangles from a point inside the triangulation. The result should be very close to \(4 \pi\). If the result is \(-4 \pi\) instead, it is conceivable that the ordering of the triangle vertices is incorrect and the --swap option should be specified.

The correct ordering of the surfaces is verified by checking that the surfaces are inside each other as expected. This is accomplished by checking that the sum solid angles subtended by triangles of a surface \(S_k\) at all vertices of another surface \(S_p\) which is supposed to be inside it equals \(4 \pi\). Naturally, this check is applied only if the model has more than one surface. Since the surface relations are transitive, it is enough to check that the outer skull surface is inside the skin surface and that the inner skull surface is inside the outer skull one.

The extent of each of the triangulated volumes is checked. If the extent is smaller than 50mm, an error is reported. This may indicate that the vertex coordinates have been specified in meters instead of millimeters.

The utility mne.make_bem_solution() computes the geometry information for BEM.

This Section explains the presentation of MEG detection coil geometry information the approximations used for different detection coils in MNE software. Two pieces of information are needed to characterize the detectors:

The location and orientation a local coordinate system for each detector.

A unique identifier, which has an one-to-one correspondence to the geometrical description of the coil.

MNE ships with several coil geometry configurations. They can be found in mne/data. See Plotting sensor layouts of MEG systems for a comparison between different coil geometries, and Implemented coil geometries for detailed information regarding the files describing Neuromag coil geometries.

The sensor coordinate system is completely characterized by the location of its origin and the direction cosines of three orthogonal unit vectors pointing to the directions of the x, y, and z axis. In fact, the unit vectors contain redundant information because the orientation can be uniquely defined with three angles. The measurement fif files list these data in MEG device coordinates. Transformation to the MEG head coordinate frame can be easily accomplished by applying the device-to-head coordinate transformation matrix available in the data files provided that the head-position indicator was used. Optionally, the MNE software forward calculation applies another coordinate transformation to the head-coordinate data to bring the coil locations and orientations to the MRI coordinate system.

If \(r_0\) is a row vector for the origin of the local sensor coordinate system and \(e_x\), \(e_y\), and \(e_z\) are the row vectors for the three orthogonal unit vectors, all given in device coordinates, a location of a point \(r_C\) in sensor coordinates is transformed to device coordinates (\(r_D\)) by

The forward calculation in the MNE software computes the signals detected by each MEG sensor for three orthogonal dipoles at each source space location. This requires specification of the conductor model, the location and orientation of the dipoles, and the location and orientation of each MEG sensor as well as its coil geometry.

The output of each SQUID sensor is a weighted sum of the magnetic fluxes threading the loops comprising the detection coil. Since the flux threading a coil loop is an integral of the magnetic field component normal to the coil plane, the output of the k th MEG channel, \(b_k\) can be approximated by:

where \(r_{kp}\) are a set of \(N_k\) integration points covering the pickup coil loops of the sensor, \(B(r_{kp})\) is the magnetic field due to the current sources calculated at \(r_{kp}\), \(n_{kp}\) are the coil normal directions at these points, and \(w_{kp}\) are the weights associated to the integration points. This formula essentially presents numerical integration of the magnetic field over the pickup loops of sensor \(k\).

There are three accuracy levels for the numerical integration expressed above. The simple accuracy means the simplest description of the coil. This accuracy is not used in the MNE forward calculations. The normal or recommended accuracy typically uses two integration points for planar gradiometers, one in each half of the pickup coil and four evenly distributed integration points for magnetometers. This is the default accuracy used by MNE. If the --accurate option is specified, the forward calculation typically employs a total of eight integration points for planar gradiometers and sixteen for magnetometers. Detailed information about the integration points is given in the next section.

This section describes the coil geometries currently implemented in MNE. The coil types fall in two general categories:

Axial gradiometers and planar gradiometers and

Planar magnetometers.

For axial sensors, the z axis of the local coordinate system is parallel to the field component detected, i.e., normal to the coil plane.For circular coils, the orientation of the x and y axes on the plane normal to the z axis is irrelevant. In the square coils employed in the Vectorview (TM) system the x axis is chosen to be parallel to one of the sides of the magnetometer coil. For planar sensors, the z axis is likewise normal to the coil plane and the x axis passes through the centerpoints of the two coil loops so that the detector gives a positive signal when the normal field component increases along the x axis.

Normal coil descriptions lists the parameters of the normal coil geometry descriptions Accurate coil descriptions lists the accurate descriptions. For simple accuracy, please consult the coil definition file, see The coil definition file. The columns of the tables contain the following data:

The number identifying the coil id. This number is used in the coil descriptions found in the FIF files.

Description of the coil.

Number of integration points used

The locations of the integration points in sensor coordinates.

Weights assigned to the field values at the integration points. Some formulas are listed instead of the numerical values to demonstrate the principle of the calculation. For example, in the normal coil descriptions of the planar gradiometers the weights are inverses of the baseline of the gradiometer to show that the output is in T/m.

The coil geometry information is stored in the file mne/data/coil_def.dat, which is automatically created by the MNE-C utility mne_list_coil_def.

Neuromag-122 planar gradiometer

Vectorview type 1 planar gradiometer

Vectorview type 2 planar gradiometer

Vectorview type 1 magnetometer

(+/-6.45, +/-6.45, 0.3)mm

Vectorview type 2 magnetometer

(+/-6.45, +/-6.45, 0.3)mm

Vectorview type 3 magnetometer

(+/-5.25, +/-5.25, 0.3)mm

An ideal point magnetometer

Magnes WH magnetometer

(+/-5.75, +/-5.75, 0.0)mm

Magnes WH 3600 axial gradiometer

(+/-4.5, +/-4.5, 0.0)mm (+/-4.5, +/-4.5, 50.0)mm

Magnes reference magnetometer

(+/-7.5, +/-7.5, 0.0)mm

Magnes reference gradiometer measuring diagonal gradients

(+/-20, +/-20, 0.0)mm (+/-20, +/-20, 135)mm

Magnes reference gradiometer measuring off-diagonal gradients

(87.5, +/-20, 0.0)mm (47.5, +/-20, 0.0)mm (-87.5, +/-20, 0.0)mm (-47.5, +/-20, 0.0)mm

CTF 275 axial gradiometer

(+/-4.5, +/-4.5, 0.0)mm (+/-4.5, +/-4.5, 50.0)mm

CTF reference magnetometer

CTF reference gradiometer measuring diagonal gradients

(+/-8.6, +/-8.6, 0.0)mm (+/-8.6, +/-8.6, 78.6)mm

If a plus-minus sign occurs in several coordinates, all possible combinations have to be included.

Neuromag-122 planar gradiometer

Vectorview type 1 planar gradiometer

Vectorview type 2 planar gradiometer

Vectorview type 1 magnetometer

(+/-6.45, +/-6.45, 0.3)mm

Vectorview type 2 magnetometer

(+/-6.45, +/-6.45, 0.3)mm

Vectorview type 3 magnetometer

(+/-5.25, +/-5.25, 0.3)mm

Magnes WH magnetometer

(+/-5.75, +/-5.75, 0.0)mm

Magnes WH 3600 axial gradiometer

(+/-4.5, +/-4.5, 0.0)mm (+/-4.5, +/-4.5, 0.0)mm

Magnes reference gradiometer measuring diagonal gradients

(+/-20, +/-20, 0.0)mm (+/-20, +/-20, 135)mm

Magnes reference gradiometer measuring off-diagonal gradients

(87.5, +/-20, 0.0)mm (47.5, +/-20, 0.0)mm (-87.5, +/-20, 0.0)mm (-47.5, +/-20, 0.0)mm

CTF 275 axial gradiometer

(+/-4.5, +/-4.5, 0.0)mm (+/-4.5, +/-4.5, 50.0)mm

CTF reference magnetometer

CTF 275 reference gradiometer measuring diagonal gradients

(+/-8.6, +/-8.6, 0.0)mm (+/-8.6, +/-8.6, 78.6)mm

CTF 275 reference gradiometer measuring off-diagonal gradients

(47.8, +/-8.5, 0.0)mm (30.8, +/-8.5, 0.0)mm (-47.8, +/-8.5, 0.0)mm (-30.8, +/-8.5, 0.0)mm

MIT KIT system axial gradiometer

(+/-3.875, +/-3.875, 0.0)mm (+/-3.875, +/-3.875, 0.0)mm

The coil geometry information is stored in the text file $MNE_ROOT/share/mne/coil_def.dat. In this file, any lines starting with the pound sign (#) are comments. A coil definition starts with a description line containing the following fields:

<class>: A number indicating class of this coil.

<id>: Coil ID value. This value is listed in the first column of Tables Normal coil descriptions and Accurate coil descriptions.

<accuracy>: The coil representation accuracy. Possible values and their meanings are listed in Coil representation accuracies.

<np>: Number of integration points in this representation.

<size/m>: The size of the coil. For circular coils this is the diameter of the coil and for square ones the side length of the square. This information is mainly included to facilitate drawing of the coil geometry. It should not be employed to infer a coil approximation for the forward calculations.

<baseline/m>: The baseline of a this kind of a coil. This will be zero for magnetometer coils. This information is mainly included to facilitate drawing of the coil geometry. It should not be employed to infer a coil approximation for the forward calculations.

<description>: Short description of this kind of a coil. If the description contains several words, it is enclosed in quotes.

The simplest representation available

The standard or normal representation (see Normal coil descriptions)

The most accurate representation available (see Accurate coil descriptions)

Each coil description line is followed by one or more integration point lines, consisting of seven numbers:

<weight>: Gives the weight for this integration point (last column in Tables Normal coil descriptions and Accurate coil descriptions).

<x/m> <y/m> <z/m>: Indicates the location of the integration point (fourth column in Tables Normal coil descriptions and Accurate coil descriptions).

<nx> <ny> <nz>: Components of a unit vector indicating the field component to be selected. Note that listing a separate unit vector for each integration points allows the implementation of curved coils and coils with the gradiometer loops tilted with respect to each other.

Examples on how to compute the forward solution in MNE-Python using mne.make_forward_solution() can be found Compute forward solution and Computing the forward solution.

Accounting for noise cancellation in MNE-Python is accomplished in mne.io.Raw.apply_gradient_compensation(). See Brainstorm CTF phantom dataset tutorial for an example.

CTF and 4D Neuroimaging data may have been subjected to noise cancellation employing the data from the reference sensor array. Even though these sensor are rather far away from the brain sources, mne.make_forward_solution() takes them into account in the computations. If the data file has software gradient compensation activated, it computes the field of at the reference sensors in addition to the main MEG sensor array and computes a compensated forward solution.

In MNE-Python, different sphere models can be specified through mne.make_sphere_model(). The default model has the following structure:

Relative outer radius

Although it is not BEM model per se the sphere structure describes the head geometry so it can be passed as bem parameter in MNE-Python functions such as mne.fit_dipole(), mne.viz.plot_alignment() or mne.make_forward_solution().

Sphere-model examples in MNE-Python

For examples of using the sphere model when computing the forward model (using mne.make_forward_solution()), see Brainstorm CTF phantom dataset tutorial, Brainstorm Elekta phantom dataset tutorial, and Alignment without MRI.

When the sphere model is employed, the computation of the EEG solution can be substantially accelerated by using approximation methods described by Mosher [5], Zhang [6], and Berg [7]. mne.make_forward_solution() approximates the solution with three dipoles in a homogeneous sphere whose locations and amplitudes are determined by minimizing the cost function:

where \(r_1,\dotsc,r_m\) and \(\mu_1,\dotsc,\mu_m\) are the locations and amplitudes of the approximating dipoles and \(V_{true}\) and \(V_{approx}\) are the potential distributions given by the true and approximative formulas, respectively. It can be shown that this integral can be expressed in closed form using an expansion of the potentials in spherical harmonics. The formula is evaluated for the most superficial dipoles, i.e., those lying just inside the inner skull surface.

One possibility to make a grand average over several runs of a experiment is to average the data across runs and average the forward solutions accordingly. For this purpose, mne.average_forward_solutions() computes a weighted average of several forward solutions. The function averages both MEG and EEG forward solutions. Usually the EEG forward solution is identical across runs because the electrode locations do not change.

This section describes the mathematical details of the calculation of minimum-norm estimates. In Bayesian sense, the ensuing current distribution is the maximum a posteriori (MAP) estimate under the following assumptions:

The viable locations of the currents are constrained to the cortex. Optionally, the current orientations can be fixed to be normal to the cortical mantle.

The amplitudes of the currents have a Gaussian prior distribution with a known source covariance matrix.

The measured data contain additive noise with a Gaussian distribution with a known covariance matrix. The noise is not correlated over time.

Computing the inverse operator is accomplished using mne.minimum_norm.make_inverse_operator() and mne.minimum_norm.apply_inverse(). The use of these functions is presented in the tutorial Source localization with MNE, dSPM, sLORETA, and eLORETA.

The measured data in the source estimation procedure consists of MEG and EEG data, recorded on a total of N channels. The task is to estimate a total of \(Q\) strengths of sources located on the cortical mantle. If the number of source locations is \(P\), \(Q = P\) for fixed-orientation sources and \(Q = 3P\) if the source orientations are unconstrained. The regularized linear inverse operator following from regularized maximal likelihood of the above probabilistic model is given by the \(Q \times N\) matrix

where \(G\) is the gain matrix relating the source strengths to the measured MEG/EEG data, \(C\) is the data noise-covariance matrix and \(R'\) is the source covariance matrix. The dimensions of these matrices are \(N \times Q\), \(N \times N\), and \(Q \times Q\), respectively. The \(Q \times 1\) source-strength vector is obtained by multiplying the \(Q \times 1\) data vector by \(Q\).

The expected value of the current amplitudes at time t is then given by \(\hat{j}(t) = Mx(t)\), where \(x(t)\) is a vector containing the measured MEG and EEG data values at time t.

For computational convenience, the linear inverse operator is not computed explicitly. See Computation of the solution for mathematical details, and Calculating the inverse operator for a detailed example.

The a priori variance of the currents is, in practice, unknown. We can express this by writing \(R' = R/ \lambda^2 = R \lambda^{-2}\), which yields the inverse operator

where the unknown current amplitude is now interpreted in terms of the regularization parameter \(\lambda^2\). Larger \(\lambda^2\) values correspond to spatially smoother and weaker current amplitudes, whereas smaller \(\lambda^2\) values lead to the opposite.

We can arrive at the regularized linear inverse operator also by minimizing a cost function \(S\) with respect to the estimated current \(\hat{j}\) (given the measurement vector \(x\) at any given time \(t\)) as

where the first term consists of the difference between the whitened measured data (see Whitening and scaling) and those predicted by the model while the second term is a weighted-norm of the current estimate. It is seen that, with increasing \(\lambda^2\), the source term receive more weight and larger discrepancy between the measured and predicted data is tolerable.

The MNE software employs data whitening so that a ‘whitened’ inverse operator assumes the form

is the spatially whitened gain matrix. We arrive at the whitened inverse operator equation (13) by making the substitution for \(G\) from (14) in (12) as

The expected current values are

knowing (13) and taking

as the whitened measurement vector at time t. The spatial whitening operator \(C^{-^1/_2}\) is obtained with the help of the eigenvalue decomposition \(C = U_C \Lambda_C^2 U_C^\top\) as \(C^{-^1/_2} = \Lambda_C^{-1} U_C^\top\). In the MNE software the noise-covariance matrix is stored as the one applying to raw data. To reflect the decrease of noise due to averaging, this matrix, \(C_0\), is scaled by the number of averages, \(L\), i.e., \(C = C_0 / L\).

When EEG data are included, the gain matrix \(G\) needs to be average referenced when computing the linear inverse operator \(M\). This is incorporated during creating the spatial whitening operator \(C^{-^1/_2}\), which includes any projectors on the data. EEG data average reference (using a projector) is mandatory for source modeling and is checked when calculating the inverse operator.

As shown above, regularization of the inverse solution is equivalent to a change in the variance of the current amplitudes in the Bayesian a priori distribution.

A convenient choice for the source-covariance matrix \(R\) is such that \(\text{trace}(\tilde{G} R \tilde{G}^\top) / \text{trace}(I) = 1\). With this choice we can approximate \(\lambda^2 \sim 1/\rm{SNR}^2\), where SNR is the (amplitude) signal-to-noise ratio of the whitened data.

The definition of the signal to noise-ratio/ \(\lambda^2\) relationship given above works nicely for the whitened forward solution. In the un-whitened case scaling with the trace ratio \(\text{trace}(GRG^\top) / \text{trace}(C)\) does not make sense, since the diagonal elements summed have, in general, different units of measure. For example, the MEG data are expressed in T or T/m whereas the unit of EEG is Volts.

See Computing a covariance matrix for example of noise covariance computation and whitening.

Since finite amount of data is usually available to compute an estimate of the noise-covariance matrix \(C\), the smallest eigenvalues of its estimate are usually inaccurate and smaller than the true eigenvalues. Depending on the seriousness of this problem, the following quantities can be affected:

The model data predicted by the current estimate,

Estimates of signal-to-noise ratios, which lead to estimates of the required regularization, see Regularization,

The estimated current values, and

The noise-normalized estimates, see Noise normalization.

Fortunately, the latter two are least likely to be affected due to regularization of the estimates. However, in some cases especially the EEG part of the noise-covariance matrix estimate can be deficient, i.e., it may possess very small eigenvalues and thus regularization of the noise-covariance matrix is advisable.

Historically, the MNE software accomplishes the regularization by replacing a noise-covariance matrix estimate \(C\) with

where the index \(k\) goes across the different channel groups (MEG planar gradiometers, MEG axial gradiometers and magnetometers, and EEG), \(\varepsilon_k\) are the corresponding regularization factors, \(\bar{\sigma_k}\) are the average variances across the channel groups, and \(I^{(k)}\) are diagonal matrices containing ones at the positions corresponding to the channels contained in each channel group.

See How should I regularize the covariance matrix? for details on computing and regularizing the channel covariance matrix.

The most straightforward approach to calculate the MNE is to employ the expression of the original or whitened inverse operator directly. However, for computational convenience we prefer to take another route, which employs the singular-value decomposition (SVD) of the matrix

where the superscript \(^1/_2\) indicates a square root of \(R\). For a diagonal matrix, one simply takes the square root of \(R\) while in the more general case one can use the Cholesky factorization \(R = R_C R_C^\top\) and thus \(R^{^1/_2} = R_C\).

Combining the SVD from (17) with the inverse equation (12) it is easy to show that

where the elements of the diagonal matrix \(\Gamma\) are simply

From our expected current equation (15) and our whitened measurement equation (16), if we take

we can see that the expression for the expected current is just

where \(\bar{v_k} = R^{^1/_2} v_k\), with \(v_k\) being the \(k\) th column of \(V\). It is thus seen that the current estimate is a weighted sum of the “weighted” eigenleads \(v_k\).

It is easy to see that \(w(t) \propto \sqrt{L}\). To maintain the relation \((\tilde{G} R \tilde{G}^\top) / \text{trace}(I) = 1\) when \(L\) changes we must have \(R \propto 1/L\). With this approach, \(\lambda_k\) is independent of \(L\) and, for fixed \(\lambda\), we see directly that \(j(t)\) is independent of \(L\).

The minimum-norm estimate is computed using this procedure in mne.minimum_norm.make_inverse_operator(), and its usage is illustrated in Calculating the inverse operator.

Noise normalization serves three purposes:

It converts the expected current value into a dimensionless statistical test variable. Thus the resulting time and location dependent values are often referred to as dynamic statistical parameter maps (dSPM).

It reduces the location bias of the estimates. In particular, the tendency of the MNE to prefer superficial currents is eliminated.

The width of the point-spread function becomes less dependent on the source location on the cortical mantle. The point-spread is defined as the MNE resulting from the signals coming from a point current source (a current dipole) located at a certain point on the cortex.

In practice, noise normalization is implemented as a division by the square root of the estimated variance of each voxel. In computing these noise normalization factors, it’s convenient to reuse our “weighted eigenleads” definition from equation (15) in matrix form as

Noise-normalized linear estimates introduced by Dale et al. [8] require division of the expected current amplitude by its variance. In practice, this requires the computation of the diagonal elements of the following matrix, using SVD equation (13) and (22):

Because we only care about the diagonal entries here, we can find the variances for each source as

Under the conditions expressed at the end of Computation of the solution, it follows that the t-statistic values associated with fixed-orientation sources) are thus proportional to \(\sqrt{L}\) while the F-statistic employed with free-orientation sources is proportional to \(L\), correspondingly.

The MNE software usually computes the square roots of the F-statistic to be displayed on the inflated cortical surfaces. These are also proportional to \(\sqrt{L}\).

sLORETA [9] estimates the current variances as the diagonal entries of the resolution matrix, which is the product of the inverse and forward operators. In other words, the diagonal entries of (using (18), (14), and (17))

Because \(R\) is diagonal and we only care about the diagonal entries, we can find our variance estimates as

While dSPM and sLORETA solve for noise normalization weights \(\sigma^2_k\) that are applied to standard minimum-norm estimates \(\hat{j}(t)\), eLORETA [10] instead solves for a source covariance matrix \(R\) that achieves zero localization bias. For fixed-orientation solutions the resulting matrix \(R\) will be a diagonal matrix, and for free-orientation solutions it will be a block-diagonal matrix with \(3 \times 3\) blocks.

In [10] eq. 2.13 states that the following system of equations can be used to find the weights, \(\forall i \in {1, ..., P}\) (note that here we represent the equations from that paper using our notation):

And an iterative algorithm can be used to find the values for the weights \(r_i\) that satisfy these equations as:

Initialize identity weights.

Compute \(N= \left( GRG^\top + \lambda^2C \right)^{-1}\).

Holding \(N\) fixed, compute new weights \(r_i = \left[ G_i^\top N G_i \right]^{-^1/_2}\).

Using new weights, go to step (2) until convergence.

In particular, for step (2) we can use our substitution from (14) as:

Then defining \(\tilde{N}\) as the whitened version of \(N\), i.e., the regularized pseudoinverse of \(\tilde{G}R\tilde{G}^\top\), we can compute \(N\) as:

In step (3) we left and right multiply with subsets of \(G\), but making the substitution (14) we see that we equivalently compute:

For convenience, we thus never need to compute \(N\) itself but can instead compute the whitened version \(\tilde{N}\).

Under noiseless conditions the SNR is infinite and thus leads to \(\lambda^2 = 0\) and the minimum-norm estimate explains the measured data perfectly. Under realistic conditions, however, \(\lambda^2 > 0\) and there is a misfit between measured data and those predicted by the MNE. Comparison of the predicted data, here denoted by \(x(t)\), and measured one can give valuable insight on the correctness of the regularization applied.

In the SVD approach we easily find

where the diagonal matrix \(\Pi\) has elements \(\pi_k = \lambda_k \gamma_k\) The predicted data is thus expressed as the weighted sum of the ‘recolored eigenfields’ in \(C^{^1/_2} U\).

If the add_dists=True option was used in source space creation, the source space file will contain Cortical Patch Statistics (CPS) for each vertex of the cortical surface. The CPS provide information about the source space point closest to it as well as the distance from the vertex to this source space point. The vertices for which a given source space point is the nearest one define the cortical patch associated with with the source space point. Once these data are available, it is straightforward to compute the following cortical patch statistics for each source location \(d\):

The average over the normals of at the vertices in a patch, \(\bar{n_d}\),

The areas of the patches, \(A_d\), and

The average deviation of the vertex normals in a patch from their average, \(\sigma_d\), given in degrees.

use_cps parameter in mne.convert_forward_solution(), and mne.minimum_norm.make_inverse_operator() controls whether to use cortical patch statistics (CPS) to define normal orientations or not (see Cortical surface reconstruction with FreeSurfer).

The principal sources of MEG and EEG signals are generally believed to be postsynaptic currents in the cortical pyramidal neurons. Since the net primary current associated with these microscopic events is oriented normal to the cortical mantle, it is reasonable to use the cortical normal orientation as a constraint in source estimation. In addition to allowing completely free source orientations, the MNE software implements three orientation constraints based of the surface normal data:

Source orientation can be rigidly fixed to the surface normal direction by specifying fixed=True in mne.minimum_norm.make_inverse_operator(). If cortical patch statistics are available the average normal over each patch, \(\bar{n_d}\), are used to define the source orientation. Otherwise, the vertex normal at the source space location is employed.

A location independent or fixed loose orientation constraint (fLOC) can be employed by specifying fixed=False and loose=1.0 when calling mne.minimum_norm.make_inverse_operator() (see Loose dipole orientations). In this approach, a source coordinate system based on the local surface orientation at the source location is employed. By default, the three columns of the gain matrix G, associated with a given source location, are the fields of unit dipoles pointing to the directions of the \(x\), \(y\), and \(z\) axis of the coordinate system employed in the forward calculation (usually the MEG head coordinate frame). For LOC the orientation is changed so that the first two source components lie in the plane normal to the surface normal at the source location and the third component is aligned with it. Thereafter, the variance of the source components tangential to the cortical surface are reduced by a factor defined by the --loose option.

A variable loose orientation constraint (vLOC) can be employed by specifying fixed=False and loose parameters when calling mne.minimum_norm.make_inverse_operator() (see Limiting orientations, but not fixing them). This is similar to fLOC except that the value given with the loose parameter will be multiplied by \(\sigma_d\), defined above.

The minimum-norm estimates have a bias towards superficial currents. This tendency can be alleviated by adjusting the source covariance matrix \(R\) to favor deeper source locations. In the depth weighting scheme employed in MNE analyze, the elements of \(R\) corresponding to the \(p\) th source location are be scaled by a factor

where \(g_{1p}\), \(g_{2p}\), and \(g_{3p}\) are the three columns of \(G\) corresponding to source location \(p\) and \(\gamma\) is the order of the depth weighting, which is specified via the depth option in mne.minimum_norm.make_inverse_operator().

It is often the case that the epoch to be analyzed is a linear combination over conditions rather than one of the original averages computed. As stated above, the noise-covariance matrix computed is originally one corresponding to raw data. Therefore, it has to be scaled correctly to correspond to the actual or effective number of epochs in the condition to be analyzed. In general, we have

where \(L_{eff}\) is the effective number of averages. To calculate \(L_{eff}\) for an arbitrary linear combination of conditions

we make use of the the fact that the noise-covariance matrix

An important special case of the above is a weighted average, where

Instead of a weighted average, one often computes a weighted sum, a simplest case being a difference or sum of two categories. For a difference \(w_1 = 1\) and \(w_2 = -1\) and thus

Interestingly, the same holds for a sum, where \(w_1 = w_2 = 1\). Generalizing, for any combination of sums and differences, where \(w_i = 1\) or \(w_i = -1\), \(i = 1 \dotso n\), we have

Morphing examples in MNE-Python

Examples of morphing in MNE-Python include this tutorial on surface source estimation or these examples on surface and volumetric source estimation.

Modern neuroimaging techniques, such as source reconstruction or fMRI analyses, make use of advanced mathematical models and hardware to map brain activity patterns into a subject-specific anatomical brain space. This enables the study of spatio-temporal brain activity. The representation of spatio-temporal brain data is often mapped onto the anatomical brain structure to relate functional and anatomical maps. Thereby activity patterns are overlaid with anatomical locations that supposedly produced the activity. Anatomical MR images are often used as such or are transformed into an inflated surface representations to serve as “canvas” for the visualization.

In order to compute group-level statistics, data representations across subjects must be morphed to a common frame, such that anatomically and functional similar structures are represented at the same spatial location for all subjects equally. Since brains vary, morphing comes into play to tell us how the data produced by subject A would be represented on the brain of subject B (and vice-versa).

The MNE software accomplishes morphing with help of morphing maps. The morphing is performed with help of the registered spherical surfaces (lh.sphere.reg and rh.sphere.reg ) which must be produced in FreeSurfer. A morphing map is a linear mapping from cortical surface values in subject A (\(x^{(A)}\)) to those in another subject B (\(x^{(B)}\))

where \(M^{(AB)}\) is a sparse matrix with at most three nonzero elements on each row. These elements are determined as follows. First, using the aligned spherical surfaces, for each vertex \(x_j^{(B)}\), find the triangle \(T_j^{(A)}\) on the spherical surface of subject A which contains the location \(x_j^{(B)}\). Next, find the numbers of the vertices of this triangle and set the corresponding elements on the j th row of \(M^{(AB)}\) so that \(x_j^{(B)}\) will be a linear interpolation between the triangle vertex values reflecting the location \(x_j^{(B)}\) within the triangle \(T_j^{(A)}\).

It follows from the above definition that in general

i.e., the mapping is almost a bijection.

The current estimates are normally defined only in a decimated grid which is a sparse subset of the vertices in the triangular tessellation of the cortical surface. Therefore, any sparse set of values is distributed to neighboring vertices to make the visualized results easily understandable. This procedure has been traditionally called smoothing but a more appropriate name might be smudging or blurring in accordance with similar operations in image processing programs.

In MNE software terms, smoothing of the vertex data is an iterative procedure, which produces a blurred image \(x^{(N)}\) from the original sparse image \(x^{(0)}\) by applying in each iteration step a sparse blurring matrix:

On each row \(j\) of the matrix \(S^{(p)}\) there are \(N_j^{(p - 1)}\) nonzero entries whose values equal \(1/N_j^{(p - 1)}\). Here \(N_j^{(p - 1)}\) is the number of immediate neighbors of vertex \(j\) which had non-zero values at iteration step \(p - 1\). Matrix \(S^{(p)}\) thus assigns the average of the non-zero neighbors as the new value for vertex \(j\). One important feature of this procedure is that it tends to preserve the amplitudes while blurring the surface image.

Once the indices non-zero vertices in \(x^{(0)}\) and the topology of the triangulation are fixed the matrices \(S^{(p)}\) are fixed and independent of the data. Therefore, it would be in principle possible to construct a composite blurring matrix

However, it turns out to be computationally more effective to do blurring with an iteration. The above formula for \(S^{(N)}\) also shows that the smudging (smoothing) operation is linear.

This section describes the mathematical formulation and application of Generalized Eigendecomposition (GED), often used in spatial filtering and source separation algorithms, such as mne.decoding.CSP, mne.decoding.SPoC, mne.decoding.SSD and mne.decoding.XdawnTransformer.

The core principle of GED is to find a set of channel weights (spatial filter) that maximizes the ratio of signal power between two data features. These features are defined by the researcher and are represented by two covariance matrices: a “signal” matrix \(S\) and a “reference” matrix \(R\). For example, \(S\) could be the covariance of data from a task time interval, and \(S\) could be the covariance from a baseline time interval. For more details see [11].

A few definitions first: Let \(n \in \mathbb{N}^+\) be a number of channels. Let \(\text{Symm}_n(\mathbb{R}) \subset M_n(\mathbb{R})\) be a vector space of real symmetric matrices. Let \(S^n_+, S^n_{++} \subset \text{Symm}_n(\mathbb{R})\) be sets of real positive semidefinite and positive definite matrices, respectively. Let \(S, R \in S^n_+\) be covariance matrices estimated from electrophysiological data \(X_S \in M_{n \times t_S}(\mathbb{R})\) and \(X_R \in M_{n \times t_R}(\mathbb{R})\).

GED (or simultaneous diagonalization by congruence) of \(S\) and \(R\) is possible when \(R\) is full rank (and thus \(R \in S^n_{++}\)):

where \(W \in M_n(\mathbb{R})\) is an invertible matrix of eigenvectors of \((S, R)\) and \(D\) is a diagonal matrix of eigenvalues \(\lambda_i\).

Each eigenvector \(\mathbf{w} \in W\) is a spatial filter that solves an optimization problem of the form:

That is, using spatial filters \(W\) on time-series \(X \in M_{n \times t}(\mathbb{R})\):

results in “activation” time-series \(A\) of the estimated “sources”, such that the ratio of their variances, \(\frac{\text{Var}(\mathbf{w}^T X_S)}{\text{Var}(\mathbf{w}^T X_R)} = \frac{\mathbf{w}^T S \mathbf{w}}{\mathbf{w}^T R \mathbf{w}}\), is sequentially maximized spatial filters \(\mathbf{w}_i\), sorted according to \(\lambda_i\).

Unfortunately, \(R\) might not be full rank depending on the data \(X_R\) (for example due to average reference, removed PCA/ICA components, etc.). In such cases, GED can be performed on \(S\) and \(R\) in the principal subspace \(Q = \operatorname{Im}(C_{ref}) \subset \mathbb{R}^n\) of some reference covariance \(C_{ref}\) (in Common Spatial Pattern (CSP) algorithm, for example, \(C_{ref}=\frac{1}{2}(S+R)\) and GED is performed on S and R’=S+R).

More formally: Let \(r \leq n\) be a rank of \(C \in S^n_+\). Let \(Q=\operatorname{Im}(C_{ref})\) be a principal subspace of \(C_{ref}\). Let \(P \in M_{n \times r}(\mathbb{R})\) be an isometry formed by orthonormal basis of \(Q\). Let \(f:S^n_+ \to S^r_+\), \(A \mapsto P^t A P\) be a “restricting” map, that restricts quadratic form \(q_A:\mathbb{R}^n \to \mathbb{R}\) to \(q_{A|_Q}:\mathbb{R}^n \to \mathbb{R}\) (in practical terms, \(q_A\) maps spatial filters to variance of the spatially filtered data \(X_A\)).

Then, the GED of \(S\) and \(R\) in the principal subspace \(Q\) of \(C_{ref}\) is performed as follows:

\(S\) and \(R\) are transformed to \(S_Q = f(S) = P^t S P\) and \(R_Q = f(R) = P^t R P\), such that \(S_Q\) and \(R_Q\) are matrix representations of restricted \(q_{S|_Q}\) and \(q_{R|_Q}\).

GED is performed on \(S_Q\) and \(R_Q\): \(S_Q W_Q = R_Q W_Q D\).

Eigenvectors \(W_Q\) of \((S_Q, R_Q)\) are transformed back to \(\mathbb{R}^n\) by \(W = P W_Q \in \mathbb{R}^{n \times r}\) to obtain \(r\) spatial filters.

Note that the solution to the original optimization problem is preserved:

In addition to restriction, \(q_S\) and \(q_R\) can be rescaled based on the whitened \(C_{ref}\). In this case the whitening map \(f_{wh}:S^n_+ \to S^r_+\), \(A \mapsto P_{wh}^t A P_{wh}\) transforms \(A\) into matrix representation of \(q_{A|Q}\) rescaled according to \(\Lambda^{-1/2}\), where \(\Lambda\) is a diagonal matrix of eigenvalues of \(C_{ref}\) and so \(P_{wh} = P \Lambda^{-1/2}\).

In MNE-Python, the matrix \(P\) of the restricting map can be obtained using

while \(P_{wh}\) using:

François M. Perrin, Jacques Pernier, Olivier M. Bertrand, and Jean Franćois Echallier. Spherical splines for scalp potential and current density mapping. Electroencephalography and Clinical Neurophysiology, 72(2):184–187, 1989. doi:10.1016/0013-4694(89)90180-6.

Claudia D. Tesche, Mikko A. Uusitalo, Risto J. Ilmoniemi, Minna Huotilainen, Matti J. Kajola, and Oili L. M. Salonen. Signal-space projections of MEG data characterize both distributed and well-localized neuronal sources. Electroencephalography and Clinical Neurophysiology, 95(3):189–200, 1995. doi:10.1016/0013-4694(95)00064-6.

Mikko A. Uusitalo and Risto J. Ilmoniemi. Signal-space projection method for separating MEG or EEG into components. Medical & Biological Engineering & Computing, 35(2):135–140, 1997. doi:10.1007/BF02534144.

Bruce Fischl, David H. Salat, André J.W. van der Kouwe, Nikos Makris, Florent Ségonne, Brian T. Quinn, and Anders M. Dale. Sequence-independent segmentation of magnetic resonance images. NeuroImage, 23:S69–S84, 2004. doi:10.1016/j.neuroimage.2004.07.016.

John C. Mosher, Richard M. Leahy, and Paul S. Lewis. EEG and MEG: forward solutions for inverse methods. IEEE Transactions on Biomedical Engineering, 46(3):245–259, 1999. doi:10.1109/10.748978.

Zhi Zhang. A fast method to compute surface potentials generated by dipoles within multilayer anisotropic spheres. Physics in Medicine and Biology, 40(3):335–349, 1995. doi:10.1088/0031-9155/40/3/001.

Patrick Berg and Michael Scherg. A fast method for forward computation of multiple-shell spherical head models. Electroencephalography and Clinical Neurophysiology, 90(1):58–64, 1994. doi:10.1016/0013-4694(94)90113-9.

Anders M. Dale, Bruce Fischl, and Martin I. Sereno. Cortical surface-based analysis: I. segmentation and surface reconstruction. NeuroImage, 9(2):179–194, 1999. doi:10.1006/nimg.1998.0395.

Roberto D. Pascual-Marqui. Standardized low-resolution brain electromagnetic tomography (sLORETA): technical details. Methods and Findings in Experimental and Clinical Pharmacology, 24(D):5–12, 2002. URL: https://pubmed.ncbi.nlm.nih.gov/12575463/.

Roberto D. Pascual-Marqui, Dietrich Lehmann, Martha Koukkou, Kieko Kochi, Peter Anderer, Bernd Saletu, Hideaki Tanaka, Koichi Hirata, E. Roy John, Leslie Prichep, Rolando Biscay-Lirio, and Toshihiko Kinoshita. Assessing interactions in the brain with exact low-resolution electromagnetic tomography. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 369(1952):3768–3784, 2011. doi:10.1098/rsta.2011.0081.

Michael X Cohen. A tutorial on generalized eigendecomposition for denoising, contrast enhancement, and dimension reduction in multichannel electrophysiology. NeuroImage, 247:118809, 2022. doi:10.1016/j.neuroimage.2021.118809.

---

## Command line tools using Python#

**URL:** https://mne.tools/stable/generated/commands.html

**Contents:**
- Command line tools using Python#
- mne anonymize#
  - Anonymize raw fif file.#
    - Options#
    - Examples#
- mne browse_raw#
  - Browse raw data.#
    - Options#
    - Examples#
- mne bti2fiff#

Usage: mne anonymize [options]

show program’s version number and exit

show this help message and exit

Name of file to modify.

Name of anonymized output file.`anon-` prefix is added to FILE if not given

Keep the HIS tag (not advised)

Move dates in file backwards by this many days.

Overwrite input file.

To anonymize other file types call mne.io.anonymize_info() on their Info objects and resave to disk.

Usage: mne browse_raw raw [options]

show program’s version number and exit

show this help message and exit

Input raw FIF file (can also be specified directly as an argument without the –raw prefix)

Disable all projectors

Time window for plotting (s)

Initial start time for plotting

Number of channels to plot at a time

Order to use for grouping during plotting (‘type’ or ‘original’)

Preload raw data (for faster navigation)

Show projection options dialog

Allow loading MaxShield processed data

Display high-pass filter corner frequency

Display low-pass filter corner frequency

Display filtering IIR order (or 0 to use FIR)

Enable trace clipping mode. Can be ‘clamp’, ‘transparent’, a float, or ‘none’.

Enable filtering cHPI signals.

Plot in butterfly mode

Enable verbose mode (printing of log messages).

This uses mne.io.read_raw() so it supports the same formats (without keyword arguments).

Usage: mne bti2fiff [options]

show program’s version number and exit

show this help message and exit

Input config file name

Name of the resulting fiff file

Compensatory rotation about Neuromag x axis, deg

Default translation, meter

Currently direct inclusion of reference channel weights is not supported. Please use ‘mne_create_comp_data’ to include the weights or use the low level functions from this module to include them by yourself.

The informed guess for the 4D name is E31 for the ECG channel and E63, E63 for the EOG channels. Please check and adjust if those channels are present in your dataset but ‘ECG 01’ and ‘EOG 01’, ‘EOG 02’ don’t appear in the channel names of the raw object.

Usage: mne clean_eog_ecg [options]

show program’s version number and exit

show this help message and exit

Suppress mne_process_raw output

Usage: mne compare_fiff <file_a> <file_b>

show program’s version number and exit

show this help message and exit

Usage: mne compute_proj_ecg [options]

show program’s version number and exit

show this help message and exit

Time before event in seconds

Time after event in seconds

Number of SSP vectors for gradiometers

Number of SSP vectors for magnetometers

Number of SSP vectors for EEG

Filter low cut-off frequency in Hz

Filter high cut-off frequency in Hz

Filter low cut-off frequency in Hz used for ECG event detection

Filter high cut-off frequency in Hz used for ECG event detection

Temporary file used during computation (to save memory)

Compute SSP after averaging

Use SSP projections from a fif file.

Number of taps to use for filtering

Number of jobs to run in parallel

Channel to use for ECG detection (Required if no ECG found)

Gradiometers rejection parameter in fT/cm (peak to peak amplitude)

Magnetometers rejection parameter in fT (peak to peak amplitude)

EEG rejection parameter in µV (peak to peak amplitude)

EOG rejection parameter in µV (peak to peak amplitude)

Add EEG average reference proj

Exclude the SSP projectors currently in the fiff file

Text file containing bad channels list (one per line)

raw file to use for event detection

Start artifact detection after tstart seconds

QRS detection threshold. Between 0 and 1. Can also be ‘auto’ for automatic selection

Usage: mne compute_proj_eog [options]

show program’s version number and exit

show this help message and exit

Time before event in seconds

Time after event in seconds

Number of SSP vectors for gradiometers

Number of SSP vectors for magnetometers

Number of SSP vectors for EEG

Filter low cut-off frequency in Hz

Filter high cut-off frequency in Hz

Filter low cut-off frequency in Hz used for EOG event detection

Filter high cut-off frequency in Hz used for EOG event detection

Temporary file used during computation (to save memory)

Compute SSP after averaging

Use SSP projections from a fif file.

Number of taps to use for filtering

Number of jobs to run in parallel

Gradiometers rejection parameter in fT/cm (peak to peak amplitude)

Magnetometers rejection parameter in fT (peak to peak amplitude)

EEG rejection parameter in µV (peak to peak amplitude)

EOG rejection parameter in µV (peak to peak amplitude)

Add EEG average reference proj

Exclude the SSP projectors currently in the fiff file

Text file containing bad channels list (one per line)

raw file to use for event detection

Start artifact detection after tstart seconds

Custom EOG channel(s), comma separated

to exclude ECG artifacts from projection computation.

Usage: mne coreg [options]

show program’s version number and exit

show this help message and exit

FIFF file with digitizer data for coregistration

The opacity of the head surface, in the range [0, 1].

Use a high-resolution head surface.

Use a low-resolution head surface.

Head<->MRI transform FIF file (“-trans.fif”)

Interaction style to use, can be “trackball” or “terrain”.

Enable verbose mode (printing of log messages).

Usage: mne flash_bem [options]

show program’s version number and exit

show this help message and exit

The 30-degree flip angle data. If no argument do not use flash30. If arguments are given, them as file names.

Path to the multiecho flash 5 images. Can be one file or one per echo.

Set if the Flash MRI images have already been registered with the T1.mgz file.

Run grad_unwarp with -unwarp <type> option on each of the converted data sets

Write over existing .surf files in bem folder

Show BEM model in 3D for visual inspection

Use copies instead of symlinks for surfaces

This program assumes that FreeSurfer and MNE are installed and sourced properly.

This function extracts the BEM surfaces (outer skull, inner skull, and outer skin) from multiecho FLASH MRI data with spin angles of 5 and 30 degrees. The multiecho FLASH data can be input as .mgz or .nii files. This function assumes that the Freesurfer segmentation of the subject has been completed. In particular, the T1.mgz and brain.mgz MRI volumes should be, as usual, in the subject’s mri directory.

Usage: mne freeview_bem_surfaces [options]

show program’s version number and exit

show this help message and exit

Method used to generate the BEM model. Can be flash or watershed.

Usage: mne kit2fiff [options]

show program’s version number and exit

show this help message and exit

Headshape points file name

Colon Separated Stimulus Trigger Channels

Threshold value for trigger channels

Name of the resulting fiff file

Set logging level for terminal output to debug

Use without arguments to invoke GUI:

Usage: mne make_scalp_surfaces [options]

show program’s version number and exit

show this help message and exit

Overwrite previously computed surface

The name of the subject

The MRI file to process using mkheadsurf.

Force creation of the surface even if it has some topological defects.

Threshold value to use with the MRI.

Disable medium and sparse decimations (dense only)

Enable verbose mode (printing of log messages).

Usage: mne prepare_bem_model [options]

show program’s version number and exit

show this help message and exit

The name of the file containing the triangulations of the BEM surfaces and the conductivities of the compartments. The standard ending for this file is -bem.fif.

The name of the resulting file containing BEM solution (geometry matrix). It uses the linear collocation approach. The file should end with -bem-sof.fif.

Enable verbose mode (printing of log messages).

Usage: mne report [options]

show program’s version number and exit

show this help message and exit

Path to folder who MNE-Report must be created

File from which info dictionary is to be read

File from which noise covariance is to be read

Time at which baseline correction starts for evokeds

Time at which baseline correction stops for evokeds

The subjects directory

Do not open MNE-Report in browser

Overwrite html report if it already exists

Number of jobs to run in parallel

Integer factor used to decimate BEM plots

Image format to use (can be ‘png’ or ‘svg’)

Enable verbose mode (printing of log messages).

Before getting started with mne report, make sure the files you want to render follow the filename conventions defined by MNE:

Filename convention (ends with)

-raw.fif(.gz), -raw_sss.fif(.gz), -raw_tsss.fif(.gz), _meg.fif(.gz), _eeg.fif(.gz), _ieeg.fif(.gz)

To generate a barebones report from all the *.fif files in the sample dataset, invoke the following command in a system (e.g., Bash) shell:

On successful creation of the report, it will open the HTML in a new tab in the browser. To disable this, use the --no-browser option.

TO generate a report for a single subject, give the SUBJECT name and the SUBJECTS_DIR and this will generate the MRI slices (with BEM contours overlaid on top if available):

To properly render trans and covariance files, add the measurement information:

To render whitened evoked files with baseline correction, add the noise covariance file:

To generate the report in parallel:

For help on all the available options, do:

Usage: mne setup_forward_model [options]

show program’s version number and exit

show this help message and exit

Subject name (required)

Output file name. Use a name <dir>/<name>-bem.fif

The surface ico downsampling to use, e.g. 5=20484, 4=5120, 3=1280. If None, no subsampling is applied.

Defines the brain compartment conductivity. The default value is 0.3 S/m.

Defines the skull compartment conductivity. The default value is 0.006 S/m.

Defines the scalp compartment conductivity. The default value is 0.3 S/m.

Use a single compartment model (brain only) instead a three layer one (scalp, skull, and brain). If this flag is specified, the options –skullc and –scalpc are irrelevant.

Enable verbose mode (printing of log messages).

Usage: mne setup_source_space [options]

show program’s version number and exit

show this help message and exit

Subject name (required)

Output file name. Use a name <dir>/<name>-src.fif

morph the source space to this subject

The surface to use. (default to white)

Specifies the approximate grid spacing of the source space in mm. (default to 7mm)

use the recursively subdivided icosahedron to create the source space.

use the recursively subdivided octahedron to create the source space.

The number of jobs to run in parallel (default 1). Requires the joblib package. Will use at most 2 jobs (one for each hemisphere).

Add distances. Can be “True”, “False”, or “patch” to only compute cortical patch statistics (like the –cps option in MNE-C)

to write over existing files

Enable verbose mode (printing of log messages).

Usage: mne show_fiff <file>

show program’s version number and exit

show this help message and exit

provide information about this tag

show the byte offset of each tag

Usage: mne show_info <file>

show program’s version number and exit

show this help message and exit

Usage: mne surf2bem [options]

show program’s version number and exit

show this help message and exit

Surface in Freesurfer format

Surface Id (e.g. 4 for head surface)

show program’s version number and exit

show this help message and exit

Show additional developer module information

Use ASCII instead of unicode symbols

Disable MNE-Python remote version checking.

Usage: mne watershed_bem [options]

show program’s version number and exit

show this help message and exit

Subject name (required)

Write over existing files

Specify the –atlas option for mri_watershed

Specify the –brain_atlas option for mri_watershed

Change the preflood height

Use copies instead of symlinks for surfaces

Whether or not to pass the -T1 flag (can be true, false, 0, or 1). By default it takes the same value as gcaatlas.

The filename for the brainmask output file relative to the $SUBJECTS_DIR/$SUBJECT/bem/watershed/ directory.

Enable verbose mode (printing of log messages).

Usage: mne what fname [fname2 ...]

show program’s version number and exit

show this help message and exit

Migrating from other analysis software

---

## Connectivity Estimation#

**URL:** https://mne.tools/stable/api/connectivity.html

**Contents:**
- Connectivity Estimation#

As of 0.24, connectivity functionality has been moved to the separate package mne_connectivity.

mne.time_frequency.tfr.morlet

---

## Covariance computation#

**URL:** https://mne.tools/stable/api/covariance.html

**Contents:**
- Covariance computation#

Covariance(data, names, bads, projs, nfree)

Noise covariance matrix.

compute_covariance(epochs[, ...])

Estimate noise covariance matrix from epochs.

compute_raw_covariance(raw[, tmin, tmax, ...])

Estimate noise covariance matrix from a continuous segment of raw data.

cov.compute_whitener(noise_cov[, info, ...])

Compute whitening matrix.

cov.prepare_noise_cov(noise_cov, info[, ...])

Prepare noise covariance matrix.

cov.regularize(cov, info[, mag, grad, eeg, ...])

Regularize noise covariance matrix.

compute_rank(inst[, rank, scalings, info, ...])

Compute the rank of data or noise covariance.

make_ad_hoc_cov(info[, std, verbose])

Create an ad hoc noise covariance.

read_cov(fname[, verbose])

Read a noise covariance from a FIF file.

write_cov(fname, cov, *[, overwrite, verbose])

Write a noise covariance matrix.

---

## Datasets#

**URL:** https://mne.tools/stable/api/datasets.html

**Contents:**
- Datasets#

Functions for fetching remote datasets.

See Datasets Overview for more information.

fetch_dataset(dataset_params[, processor, ...])

Fetch an MNE-compatible dataset using pooch.

Check for presence of a dataset.

brainstorm.bst_auditory.data_path([path, ...])

Get path to local copy of brainstorm (bst_auditory) dataset.

brainstorm.bst_resting.data_path([path, ...])

Get path to local copy of brainstorm (bst_resting) dataset.

brainstorm.bst_raw.data_path([path, ...])

Get path to local copy of brainstorm (bst_raw) dataset.

default_path(*[, verbose])

Get the default MNE_DATA path.

eegbci.load_data(subjects, runs, *[, path, ...])

Get paths to local copies of EEGBCI dataset files.

eegbci.standardize(raw)

Standardize channel positions and names.

fetch_aparc_sub_parcellation([subjects_dir, ...])

Fetch the modified subdivided aparc parcellation.

fetch_fsaverage([subjects_dir, verbose])

Fetch and update fsaverage.

fetch_hcp_mmp_parcellation([subjects_dir, ...])

Fetch the HCP-MMP parcellation.

fetch_infant_template(age[, subjects_dir, ...])

Fetch and update an infant MRI template.

fetch_phantom(kind[, subjects_dir, verbose])

Fetch and update a phantom subject.

fnirs_motor.data_path([path, force_update, ...])

Get path to local copy of fnirs_motor dataset.

hf_sef.data_path([dataset, path, ...])

Get path to local copy of the high frequency SEF dataset.

kiloword.data_path([path, force_update, ...])

Get path to local copy of the kiloword dataset.

limo.load_data(subject[, path, ...])

Fetch subjects epochs data for the LIMO data set.

misc.data_path([path, force_update, ...])

Get path to local copy of misc dataset.

mtrf.data_path([path, force_update, ...])

Get path to local copy of mtrf dataset.

multimodal.data_path([path, force_update, ...])

Get path to local copy of multimodal dataset.

opm.data_path([path, force_update, ...])

Get path to local copy of opm dataset.

sleep_physionet.age.fetch_data(subjects[, ...])

Get paths to local copies of PhysioNet Polysomnography dataset files.

sleep_physionet.temazepam.fetch_data(subjects)

Get paths to local copies of PhysioNet Polysomnography dataset files.

sample.data_path([path, force_update, ...])

Get path to local copy of sample dataset.

somato.data_path([path, force_update, ...])

Get path to local copy of somato dataset.

spm_face.data_path([path, force_update, ...])

Get path to local copy of spm dataset.

ucl_opm_auditory.data_path([path, ...])

Get path to local copy of ucl_opm_auditory dataset.

visual_92_categories.data_path([path, ...])

Get path to local copy of visual_92_categories dataset.

phantom_kit.data_path([path, force_update, ...])

Get path to local copy of phantom_kit dataset.

phantom_4dbti.data_path([path, ...])

Get path to local copy of phantom_4dbti dataset.

phantom_kernel.data_path([path, ...])

Get path to local copy of phantom_kernel dataset.

refmeg_noise.data_path([path, force_update, ...])

Get path to local copy of refmeg_noise dataset.

ssvep.data_path([path, force_update, ...])

Get path to local copy of ssvep dataset.

erp_core.data_path([path, force_update, ...])

Get path to local copy of erp_core dataset.

epilepsy_ecog.data_path([path, ...])

Get path to local copy of epilepsy_ecog dataset.

eyelink.data_path([path, force_update, ...])

Get path to local copy of eyelink dataset.

mne.export.export_raw

mne.datasets.fetch_dataset

---

## Datasets Overview#

**URL:** https://mne.tools/stable/documentation/datasets.html

**Contents:**
- Datasets Overview#
- Sample#
  - Contents of the data set#
- UCL OPM Auditory#
- Brainstorm#
  - Auditory#
  - Resting state#
  - Median nerve#
- SPM faces#
- EEGBCI motor imagery#

Contributing datasets to MNE-Python

Do not hesitate to contact MNE-Python developers on the MNE Forum to discuss the possibility of adding more publicly available datasets.

All the dataset fetchers are available in mne.datasets. To download any of the datasets, use the data_path (fetches full dataset) or the load_data (fetches dataset partially) functions.

All fetchers will check the default download location first to see if the dataset is already on your computer, and only download it if necessary. The default download location is also configurable; see the documentation of any of the data_path functions for more information.

mne.datasets.sample.data_path()

These data were acquired with the Neuromag Vectorview system at MGH/HMS/MIT Athinoula A. Martinos Center Biomedical Imaging. EEG data from a 60-channel electrode cap was acquired simultaneously with the MEG. The original MRI data set was acquired with a Siemens 1.5 T Sonata scanner using an MPRAGE sequence.

These data are provided solely for the purpose of getting familiar with the MNE software. The data should not be used to evaluate the performance of the MEG or MRI system employed.

In this experiment, checkerboard patterns were presented to the subject into the left and right visual field, interspersed by tones to the left or right ear. The interval between the stimuli was 750 ms. Occasionally a smiley face was presented at the center of the visual field. The subject was asked to press a key with the right index finger as soon as possible after the appearance of the face.

Response to left-ear auditory stimulus

Response to right-ear auditory stimulus

Response to left visual field stimulus

Response to right visual field stimulus

Response to the smiley face

Response triggered by the button press

The sample data set contains two main directories: MEG/sample (the MEG/EEG data) and subjects/sample (the MRI reconstructions). In addition to subject sample, the MRI surface reconstructions from another subject, morph, are provided to demonstrate morphing capabilities.

sample/audvis_raw.fif

A template script for off-line averaging

A template script for the computation of a noise-covariance matrix

Directory for the forward modelling data

BEM surface segmentation data computed with the watershed algorithm

Inner skull surface for BEM

Outer skull surface for BEM

Skin surface in fif format for mne_analyze visualizations

Surface reconstructions

The T1-weighted MRI data employed in visualizations

The following preprocessing steps have been already accomplished in the sample data set:

The MRI surface reconstructions have been computed using the FreeSurfer software.

The BEM surfaces have been created with the watershed algorithm, see Using the watershed algorithm.

The sample dataset is distributed with fsaverage for convenience.

mne.datasets.ucl_opm_auditory.data_path().

A basic auditory evoked field experiment using an OPM setup from FIL at UCL. See [1] for details.

Preprocessing optically pumped magnetometer (OPM) MEG data

Dataset fetchers for three Brainstorm tutorials are available. Users must agree to the license terms of these datasets before downloading them. These files are recorded in a CTF 275 system and are provided in native CTF format (.ds files).

mne.datasets.brainstorm.bst_raw.data_path().

Details about the data can be found at the Brainstorm auditory dataset tutorial.

Working with CTF data: the Brainstorm auditory dataset: Partially replicates the original Brainstorm tutorial.

mne.datasets.brainstorm.bst_resting.data_path()

Details can be found at the Brainstorm resting state dataset tutorial.

Compute envelope correlations in source space

mne.datasets.brainstorm.bst_raw.data_path()

Details can be found at the Brainstorm median nerve dataset tutorial.

Brainstorm raw (median nerve) dataset

mne.datasets.spm_face.data_path()

The SPM faces dataset contains EEG, MEG and fMRI recordings on face perception.

From raw data to dSPM on SPM Faces dataset Full pipeline including artifact removal, epochs averaging, forward model computation and source reconstruction using dSPM on the contrast: “faces - scrambled”.

mne.datasets.eegbci.load_data()

The EEGBCI dataset is documented in [2] and on the PhysioNet documentation page. The data set is available at PhysioNet [3]. It contains 64-channel EEG recordings from 109 subjects and 14 runs on each subject in EDF+ format. The recordings were made using the BCI2000 system. To load a subject, do:

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

mne.datasets.somato.data_path()

This dataset contains somatosensory data with event-related synchronizations (ERS) and desynchronizations (ERD).

Frequency and time-frequency sensor analysis

Compute source power using DICS beamformer

Explore event-related dynamics for specific frequency bands

mne.datasets.multimodal.data_path()

This dataset contains a single subject recorded at Otaniemi (Aalto University) with auditory, visual, and somatosensory stimuli.

Getting averaging info from .fif files

mne.datasets.fnirs_motor.data_path()

This dataset contains a single subject recorded at Macquarie University. It has optodes placed over the motor cortex. There are three conditions:

tapping the left thumb to fingers

tapping the right thumb to fingers

a control where nothing happens

The tapping lasts 5 seconds, and there are 30 trials of each condition.

Preprocessing functional near-infrared spectroscopy (fNIRS) data

mne.datasets.hf_sef.data_path()

This dataset contains somatosensory evoked fields (median nerve stimulation) with thousands of epochs. It was recorded with an Elekta TRIUX MEG device at a sampling frequency of 3 kHz. The dataset is suitable for investigating high-frequency somatosensory responses. Data from two subjects are included with MRI images in DICOM format and FreeSurfer reconstructions.

high-frequency SEF responses.

mne.datasets.visual_92_categories.data_path().

This dataset is recorded using a 306-channel Neuromag vectorview system.

Experiment consisted in the visual presentation of 92 images of human, animal and inanimate objects either natural or artificial [4]. Given the high number of conditions this dataset is well adapted to an approach based on Representational Similarity Analysis (RSA).

Representational Similarity Analysis (RSA): Partially replicates the results from [4].

mne.datasets.mtrf.data_path().

This dataset contains 128 channel EEG as well as natural speech stimulus features, which is also available here.

The experiment consisted of subjects listening to natural speech. The dataset contains several feature representations of the speech stimulus, suitable for using to fit continuous regression models of neural activity. More details and a description of the package can be found in [5].

Receptive Field Estimation and Prediction: Partially replicates the results from [5].

mne.datasets.kiloword.data_path().

This dataset consists of averaged EEG data from 75 subjects performing a lexical decision task on 960 English words [6]. The words are richly annotated, and can be used for e.g. multiple regression estimation of EEG correlates of printed word processing.

mne.datasets.phantom_kit.data_path().

This dataset was obtained with a phantom on a KIT system at Macquarie University in Sydney, Australia.

KIT phantom dataset tutorial

mne.datasets.phantom_4dbti.data_path().

This dataset was obtained with a phantom on a 4D Neuroimaging / BTi system at the MEG center in La Timone hospital in Marseille.

4D Neuroimaging/BTi phantom dataset tutorial

mne.datasets.phantom_kernel.data_path().

This dataset was obtained with a Neuromag phantom in a Kernel Flux (720-sensor) system at ILABS at the University of Washington. Only 7 out of 42 possible modules were active for testing purposes, yielding 121 channels of data with limited coverage (mostly occipital and parietal).

Kernel OPM phantom data

mne.datasets.opm.data_path()

OPM data acquired using an Elekta DACQ, simply piping the data into Elekta magnetometer channels. The FIF files thus appear to come from a TRIUX system that is only acquiring a small number of magnetometer channels instead of the whole array.

The OPM coil_type is custom, requiring a custom coil_def.dat. The new coil_type is 9999.

OPM co-registration differs a bit from the typical SQUID-MEG workflow. No -trans.fif file is needed for the OPMs, the FIF files include proper sensor locations in MRI coordinates and no digitization of RPA/LPA/Nasion. Thus the MEG<->Head coordinate transform is taken to be an identity matrix (i.e., everything is in MRI coordinates), even though this mis-identifies the head coordinate frame (which is defined by the relationship of the LPA, RPA, and Nasion).

Median nerve stimulation: trigger value 257.

Magnetic trigger (in OPM measurement only): trigger value 260. 1 second before the median nerve stimulation, a magnetic trigger is piped into the MSR. This was to be able to check the synchronization between OPMs retrospectively, as each sensor runs on an independent clock. Synchronization turned out to be satisfactory.

Optically pumped magnetometer (OPM) data

Compute source power spectral density (PSD) of VectorView and OPM data

mne.datasets.sleep_physionet.age.fetch_data() mne.datasets.sleep_physionet.temazepam.fetch_data()

The sleep PhysioNet database contains 197 whole-night PolySomnoGraphic sleep recordings, containing EEG, EOG, chin EMG, and event markers. Some records also contain respiration and body temperature. Corresponding hypnograms (sleep patterns) were manually scored by well-trained technicians according to the Rechtschaffen and Kales manual, and are also available. If you use these data please cite [7] and [3].

Sleep stage classification from polysomnography (PSG) data

mne.datasets.refmeg_noise.data_path().

This dataset was obtained with a 4D Neuroimaging / BTi system at the University Clinic - Erlangen, Germany. There are powerful bursts of external magnetic noise throughout the recording, which make it a good example for automatic noise removal techniques.

Find MEG reference channel artifacts

These datasets are used for specific purposes in the documentation and in general are not useful for separate analyses.

mne.datasets.fetch_fsaverage()

For convenience, we provide a function to separately download and extract the (or update an existing) fsaverage subject. See also the background information on fsaverage.

EEG forward operator with a template MRI

mne.datasets.fetch_infant_template()

This function will download an infant template MRI from [8] along with MNE-specific files.

mne.datasets.misc.data_path(). Data exists at /ecog/.

This dataset contains a sample electrocorticography (ECoG) dataset. It includes two grids of electrodes and ten shaft electrodes with simulated motor data (actual data pending availability).

How to convert 3D electrode positions to a 2D image: Demonstrates how to project a 3D electrode location onto a 2D image, a common procedure in ECoG analyses.

Locating intracranial electrode contacts: Demonstrates how to use a graphical user interface to locate electrode contacts as well as warp them to a common atlas.

mne.datasets.misc.data_path(). Data exists at /seeg/.

This dataset contains a sample stereoelectroencephalography (sEEG) dataset. It includes 21 shaft electrodes during a two-choice movement task on a keyboard.

Locating intracranial electrode contacts: Demonstrates how to use a graphical user interface to locate electrode contacts as well as warp them to a common atlas.

Working with sEEG data: Demonstrates ways to plot sEEG anatomy and results.

mne.datasets.limo.load_data().

In the original LIMO experiment (see [9]), participants performed a two-alternative forced choice task, discriminating between two face stimuli. Subjects discriminated the same two faces during the whole experiment. The critical manipulation consisted of the level of noise added to the face-stimuli during the task, making the faces more or less discernible to the observer.

The presented faces varied across a noise-signal (or phase-coherence) continuum spanning from 0 to 100% in increasing steps of 10%. In other words, faces with high phase-coherence (e.g., 90%) were easy to identify, while faces with low phase-coherence (e.g., 10%) were hard to identify and by extension hard to discriminate.

Single trial linear regression analysis with the LIMO dataset: Explores data from a single subject of the LIMO dataset and demonstrates how to fit a single trial linear regression using the information contained in the metadata of the individual datasets.

mne.datasets.erp_core.data_path()

The original ERP CORE dataset [10] contains data from 40 participants who completed 6 EEG experiments, carefully crafted to evoke 7 well-known event-related potential (ERP) components.

Currently, the MNE-Python ERP CORE dataset only provides data from one participant (subject 001) of the Flankers paradigm, which elicits the lateralized readiness potential (LRP) and error-related negativity (ERN). The data provided is not the original data from the ERP CORE dataset, but rather a slightly modified version, designed to demonstrate the Epochs metadata functionality. For example, we already set the references and montage correctly, and stored events as Annotations. Data is provided in FIFF format.

Auto-generating Epochs metadata: Learn how to auto-generate Epochs metadata, and visualize the error-related negativity (ERN) ERP component.

mne.datasets.ssvep.data_path()

This is a simple example dataset with frequency tagged visual stimulation: N=2 participants observed checkerboards patterns inverting with a constant frequency of either 12.0 Hz of 15.0 Hz. 10 trials of 20.0 s length each. 32 channels wet EEG was recorded.

Data format: BrainVision .eeg/.vhdr/.vmrk files organized according to BIDS standard.

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

mne.datasets.eyelink.data_path()

Two small example datasets of eye-tracking data from SR Research EyeLink.

mne.datasets.eyelink.data_path(). Data exists at /eeg-et/.

Contains both EEG (EGI) and eye-tracking (ASCII format) data recorded from a pupillary light reflex experiment, stored in separate files. 1 participant fixated on the screen while short light flashes appeared. Event onsets were recorded by a photodiode attached to the screen and were sent to both the EEG and eye-tracking systems.

Working with eye tracker data in MNE-Python

mne.datasets.eyelink.data_path(). Data exists at /freeviewing/.

Contains eye-tracking data (ASCII format) from 1 participant who was free-viewing a video of a natural scene. In some videos, the natural scene was pixelated such that the people in the scene were unrecognizable.

Plotting eye-tracking heatmaps in MNE-Python

Robert A. Seymour, Nicholas Alexander, Stephanie Mellor, George C. O’Neill, Tim M. Tierney, Gareth R. Barnes, and Eleanor A. Maguire. Interference suppression techniques for OPM-based MEG: Opportunities and challenges. NeuroImage, 247:118834, February 2022. doi:10.1016/j.neuroimage.2021.118834.

Gerwin Schalk, Dennis J. McFarland, Thilo Hinterberger, Niels Birbaumer, and Jonathan R. Wolpaw. BCI2000: a general-purpose brain-computer interface (BCI) system. IEEE Transactions on Biomedical Engineering, 51(6):1034–1043, 2004. doi:10.1109/TBME.2004.827072.

Ary L. Goldberger, Luis A. N. Amaral, Leon Glass, Jeffrey M. Hausdorff, Plamen Ch. Ivanov, Roger G. Mark, Joseph E. Mietus, George B. Moody, Chung-Kang Peng, and H. Eugene Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation, 2000. doi:10.1161/01.CIR.101.23.e215.

Radoslaw Martin Cichy, Dimitrios Pantazis, and Aude Oliva. Resolving human object recognition in space and time. Nature Neuroscience, 17(3):455–462, 2014. doi:10.1038/nn.3635.

Michael J. Crosse, Giovanni M. Di Liberto, Adam Bednar, and Edmund C. Lalor. The multivariate temporal response function (mTRF) toolbox: a MATLAB toolbox for relating neural signals to continuous stimuli. Frontiers in Human Neuroscience, 2016. doi:10.3389/fnhum.2016.00604.

Stéphane Dufau, Jonathan Grainger, Katherine J. Midgley, and Phillip J. Holcomb. A thousand words are worth a picture: snapshots of printed-word processing in an event-related potential megastudy. Psychological Science, 26(12):1887–1897, 2015. doi:10.1177/0956797615603934.

B. Kemp, A. H. Zwinderman, B. Tuk, H. A. C. Kamphuisen, and J. J. L. Oberyé. Analysis of a sleep-dependent neuronal feedback loop: the slow-wave microcontinuity of the EEG. IEEE Transactions on Biomedical Engineering, 47(9):1185–1194, 2000. doi:10.1109/10.867928.

Christian O’Reilly, Eric Larson, John E. Richards, and Mayada Elsabbagh. Structural templates for imaging EEG cortical sources in infants. NeuroImage, 227:117682, 2021. doi:10.1016/j.neuroimage.2020.117682.

Guillaume A. Rousselet, Carl M. Gaspar, Cyril R. Pernet, Jesse S. Husk, Patrick J. Bennett, and Allison B. Sekuler. Healthy aging delays scalp EEG sensitivity to noise in a face discrimination task. Frontiers in Psychology, 1(19):1–14, 2010. doi:10.3389/fpsyg.2010.00019.

Emily S. Kappenman, Jaclyn L. Farrens, Wendy Zhang, Andrew X. Stewart, and Steven J. Luck. ERP CORE: an open resource for human event-related potential research. NeuroImage, 225:117465, 2021. doi:10.1016/j.neuroimage.2020.117465.

Command line tools using Python

---

## Design philosophy#

**URL:** https://mne.tools/stable/documentation/design_philosophy.html

**Contents:**
- Design philosophy#
- Interactive versus scripted analysis#
- Integration with the scientific python stack#
- Submodule-based organization#
- (Mostly) unified API#
- In-place operation#

MNE-Python has some great interactive plotting abilities that can help you explore your data, and there are a few GUI-like interactive plotting commands (like browsing through the raw data and clicking to mark bad channels, or click-and-dragging to annotate bad temporal spans). But in general it is not possible to use MNE-Python to mouse-click your way to a finished, publishable analysis. MNE-Python works best when you assemble your analysis pipeline into one or more Python scripts. On the plus side, your scripts act as a record of everything you did in your analysis, making it easy to tweak your analysis later and/or share it with others (including your future self).

MNE-Python also integrates well with other standard scientific Python libraries. For example, MNE-Python objects underlyingly store their data in NumPy arrays, making it easy to apply custom algorithms or pass your data into one of scikit-learn’s machine learning pipelines. MNE-Python’s 2-D plotting functions also return matplotlib Figure objects, and the 3D plotting functions return mne.viz.Figure3D classes with a .plotter attribute pointing to pyvista.Plotter instances, so you can customize your MNE-Python plots using any of matplotlib or PyVista’s plotting commands. The intent is that MNE-Python will get most neuroscientists 90% of the way to their desired analysis goal, and other packages can get them over the finish line.

A useful-to-know organizing principle is that MNE-Python objects and functions are separated into submodules. This can help you discover related functions if you’re using an editor that supports tab-completion. For example, you can type mne.preprocessing.<TAB> to see all the functions in the preprocessing submodule; similarly for visualization functions (mne.viz), functions for reading and writing data (mne.io), statistics (mne.stats), etc. This also helps save keystrokes — instead of:

you can import submodules directly, and use just the submodule name to access its functions:

Whenever possible, we’ve tried to provide a unified API for the different data classes. For example, the Raw, Epochs, Evoked, and SourceEstimate classes all have a plot() method that can typically be called with no parameters specified and still yield an informative plot of the data. Similarly, they all have the methods copy(), crop(), resample() and save() with similar or identical method signatures. The sensor-level classes also all have an info attribute containing an Info object, which keeps track of channel names and types, applied filters, projectors, etc. See The Info data structure for more info.

Because neuroimaging datasets can be quite large, MNE-Python tries very hard to avoid making unnecessary copies of your data behind-the-scenes. To further improve memory efficiency, many object methods operate in-place (and silently return their object to allow method chaining). In-place operation may lead you to frequent use of the copy() method during interactive, exploratory analysis — so you can try out different preprocessing approaches or parameter settings without having to re-load the data each time — but it can also be a big memory-saver when applying a finished script to dozens of subjects’ worth of data.

Algorithms and other implementation details

---

## Documentation overview#

**URL:** https://mne.tools/stable/documentation/index.html

**Contents:**
- Documentation overview#

If you haven’t already installed MNE-Python, please take a look at our installation guides. Please also kindly find some resources for Getting started with Python if you need to.

The documentation for MNE-Python is divided into four main sections:

The Tutorials provide narrative explanations, sample code, and expected output for the most common MNE-Python analysis tasks. The emphasis is on thorough explanations that get new users up to speed quickly, at the expense of covering only a limited number of topics.

The How-to Examples provides working code samples demonstrating various analysis and visualization techniques. These examples often lack the narrative explanations seen in the tutorials, but can be a useful way to discover new analysis or plotting ideas, or to see how a particular technique you’ve read about can be applied using MNE-Python.

The Glossary provides short definitions of MNE-Python-specific vocabulary and general neuroimaging concepts. The glossary is often a good place to look if you don’t understand a term or acronym used somewhere else in the documentation.

The API reference provides documentation for the classes, functions and methods in the MNE-Python codebase. This is the same information that is rendered when running help(mne.<function_name>) in an interactive Python session, or when typing mne.<function_name>? in an IPython session or Jupyter notebook.

The rest of the MNE-Python documentation pages (parts outside of the four categories above) are shown in the navigation menu, including the list of example datasets, implementation details, and more. Documentation for the related C and MATLAB tools are available here:

MNE-MATLAB (repository)

Overview of the MNE tools suite

---

## Events#

**URL:** https://mne.tools/stable/api/events.html

**Contents:**
- Events#

Annotations(onset, duration, description[, ...])

Annotation object for annotating segments of raw data.

Parser for Elekta data acquisition settings.

concatenate_events(events, first_samps, ...)

Concatenate event lists to be compatible with concatenate_raws.

count_events(events[, ids])

find_events(raw[, stim_channel, output, ...])

Find events from raw file.

find_stim_steps(raw[, pad_start, pad_stop, ...])

Find all steps in data from a stim channel.

make_fixed_length_events(raw[, id, start, ...])

Make a set of events separated by a fixed duration.

make_fixed_length_epochs(raw[, duration, ...])

Divide continuous raw data into equal-sized consecutive epochs.

merge_events(events, ids, new_id[, ...])

Merge a set of events.

Parse a config file (like .ave and .cov files).

pick_events(events[, include, exclude, step])

read_annotations(fname[, sfreq, ...])

Read annotations from a file.

read_events(filename[, include, exclude, ...])

Read events from fif or text file.

write_events(filename, events, *[, ...])

Write events to file.

concatenate_epochs(epochs_list[, ...])

Concatenate a list of Epochs into one Epochs object.

events_from_annotations(raw[, event_id, ...])

Get events and event_id from an Annotations object.

annotations_from_events(events, sfreq[, ...])

Convert an event array to an Annotations object.

count_annotations(annotations)

IO with fif files containing events.

define_target_events(events, reference_id, ...)

Define new events by co-occurrence of existing events.

match_event_names(event_names, keys, *[, ...])

Search a collection of event names for matching (sub-)groups of events.

shift_time_events(events, ids, tshift, sfreq)

Shift a set of events.

Tools for working with epoched data.

average_movements(epochs[, head_pos, ...])

Average data using Maxwell filtering, transforming using head positions.

combine_event_ids(epochs, old_event_ids, ...)

Collapse event_ids from an epochs instance into a new event_id.

equalize_epoch_counts(epochs_list[, method, ...])

Equalize the number of trials in multiple Epochs or EpochsTFR instances.

make_metadata(events, event_id, tmin, tmax, ...)

Automatically generate metadata for use with mne.Epochs from events.

mne.transforms.read_ras_mni_t

---

## File I/O#

**URL:** https://mne.tools/stable/api/file_io.html

**Contents:**
- File I/O#

channel_type(info, idx)

channel_indices_by_type(info[, picks, exclude])

Get indices of channels by type.

get_head_surf(subject[, source, ...])

Load the subject head surface.

get_meg_helmet_surf(info[, trans, ...])

Load the MEG helmet associated with the MEG sensors.

get_volume_labels_from_aseg(mgz_fname[, ...])

Return a list of names and colors of segmented volumes.

get_volume_labels_from_src(src, subject, ...)

Return a list of Label of segmented volumes included in the src space.

Parse a config file (like .ave and .cov files).

read_labels_from_annot(subject[, parc, ...])

Read labels from a FreeSurfer annotation file.

read_bem_solution(fname, *[, verbose])

Read the BEM solution from a file.

read_bem_surfaces(fname[, patch_stats, ...])

Read the BEM surfaces from a FIF file.

read_cov(fname[, verbose])

Read a noise covariance from a FIF file.

read_dipole(fname[, verbose])

Read a dipole object from a file.

read_epochs(fname[, proj, preload, verbose])

Read epochs from a fif file.

read_epochs_kit(input_fname, events[, ...])

Reader function for Ricoh/KIT epochs files.

read_epochs_eeglab(input_fname[, events, ...])

Reader function for EEGLAB epochs files.

read_epochs_fieldtrip(fname, info[, ...])

Load epoched data from a FieldTrip preprocessing structure.

read_events(filename[, include, exclude, ...])

Read events from fif or text file.

read_evokeds(fname[, condition, baseline, ...])

Read evoked dataset(s).

read_evoked_besa(fname[, verbose])

Reader function for BESA .avr or .mul files.

read_evoked_fieldtrip(fname, info[, ...])

Load evoked data from a FieldTrip timelocked structure.

read_evokeds_mff(fname[, condition, ...])

Read averaged MFF file as EvokedArray or list of EvokedArray.

read_freesurfer_lut([fname])

Read a Freesurfer-formatted LUT.

read_forward_solution(fname[, include, ...])

Read a forward solution a.k.a.

read_label(filename[, subject, color, verbose])

Read FreeSurfer Label file.

read_morph_map(subject_from, subject_to[, ...])

read_proj(fname, *[, verbose])

Read projections from a FIF file.

read_reject_parameters(fname)

Read rejection parameters from .cov or .ave config file.

read_source_estimate(fname[, subject])

Read a source estimate object.

read_source_spaces(fname[, patch_stats, verbose])

Read the source spaces from a FIF file.

read_surface(fname[, read_metadata, ...])

Load a Freesurfer surface mesh in triangular format.

read_trans(fname[, return_all, verbose])

Read a -trans.fif file.

read_tri(fname_in[, swap, verbose])

Read triangle definitions from an ascii file.

write_labels_to_annot(labels[, subject, ...])

Create a FreeSurfer annotation from a list of labels.

write_bem_solution(fname, bem[, overwrite, ...])

Write a BEM model with solution.

write_bem_surfaces(fname, surfs[, ...])

Write BEM surfaces to a FIF file.

write_head_bem(fname, rr, tris[, ...])

Write a head surface to a FIF file.

write_cov(fname, cov, *[, overwrite, verbose])

Write a noise covariance matrix.

write_events(filename, events, *[, ...])

Write events to file.

write_evokeds(fname, evoked, *[, ...])

Write an evoked dataset to a file.

write_forward_solution(fname, fwd[, ...])

Write forward solution to a file.

write_label(filename, label[, verbose])

Write a FreeSurfer label.

write_proj(fname, projs, *[, overwrite, verbose])

Write projections to a FIF file.

write_source_spaces(fname, src, *[, ...])

Write source spaces to a file.

write_surface(fname, coords, faces[, ...])

Write a triangular Freesurfer surface mesh.

write_trans(fname, trans, *[, overwrite, ...])

Write a transformation FIF file.

Try to determine the type of the FIF file.

io.read_info(fname[, verbose])

Read measurement info from a file.

io.write_info(fname, info, *[, data_type, ...])

Write measurement info in fif file.

io.show_fiff(fname[, indent, read_limit, ...])

Show FIFF information.

io.get_channel_type_constants([include_defaults])

Return all known channel types, and associated FIFF constants.

BaseEpochs(info, data, events[, event_id, ...])

Abstract base class for Epochs-type classes.

---

## Forward Modeling#

**URL:** https://mne.tools/stable/api/forward.html

**Contents:**
- Forward Modeling#

Forward class to represent info from forward solution.

SourceSpaces(source_spaces[, info])

Represent a list of source space.

add_source_space_distances(src[, ...])

Compute inter-source distances along the cortical surface.

apply_forward(fwd, stc, info[, start, stop, ...])

Project source space currents to sensor space using a forward operator.

apply_forward_raw(fwd, stc, info[, start, ...])

Project source space currents to sensor space using a forward operator.

average_forward_solutions(fwds[, weights, ...])

Average forward solutions.

convert_forward_solution(fwd[, surf_ori, ...])

Convert forward solution between different source orientations.

decimate_surface(points, triangles, n_triangles)

Decimate surface data.

dig_mri_distances(info, trans, subject[, ...])

Compute distances between head shape points and the scalp surface.

forward.compute_depth_prior(forward, info[, ...])

Compute depth prior for depth weighting.

forward.compute_orient_prior(forward[, ...])

Compute orientation prior.

forward.restrict_forward_to_label(fwd, labels)

Restrict forward operator to labels.

forward.restrict_forward_to_stc(fwd, stc[, ...])

Restrict forward operator to active sources in a source estimate.

make_bem_model(subject[, ico, conductivity, ...])

Create a BEM model for a subject.

make_bem_solution(surfs, *[, solver, verbose])

Create a BEM solution using the linear collocation approach.

make_forward_dipole(dipole, bem, info[, ...])

Convert dipole object to source estimate and calculate forward operator.

make_forward_solution(info, trans, src, bem)

Calculate a forward solution for a subject.

make_field_map(evoked[, trans, subject, ...])

Compute surface maps used for field display in 3D.

make_sphere_model([r0, head_radius, info, ...])

Create a spherical model for forward solution calculation.

morph_source_spaces(src_from, subject_to[, ...])

Morph an existing source space to a different subject.

read_bem_surfaces(fname[, patch_stats, ...])

Read the BEM surfaces from a FIF file.

read_forward_solution(fname[, include, ...])

Read a forward solution a.k.a.

read_trans(fname[, return_all, verbose])

Read a -trans.fif file.

read_source_spaces(fname[, patch_stats, verbose])

Read the source spaces from a FIF file.

read_surface(fname[, read_metadata, ...])

Load a Freesurfer surface mesh in triangular format.

sensitivity_map(fwd[, projs, ch_type, mode, ...])

Compute sensitivity map.

setup_source_space(subject[, spacing, ...])

Set up bilateral hemisphere surface-based source space with subsampling.

setup_volume_source_space([subject, pos, ...])

Set up a volume source space with grid spacing or discrete source space.

surface.complete_surface_info(surf[, ...])

Complete surface information.

surface.read_curvature(filepath[, binary])

Load in curvature values from the ?h.curv file.

Use a custom coil definition file.

write_bem_surfaces(fname, surfs[, ...])

Write BEM surfaces to a FIF file.

write_trans(fname, trans, *[, overwrite, ...])

Write a transformation FIF file.

fit_sphere_to_headshape(info[, dig_kinds, ...])

Fit a sphere to the headshape points to determine head center.

get_fitting_dig(info[, dig_kinds, ...])

Get digitization points suitable for sphere fitting.

make_watershed_bem(subject[, subjects_dir, ...])

Create BEM surfaces using the FreeSurfer watershed algorithm.

make_flash_bem(subject[, overwrite, show, ...])

Create 3-Layer BEM model from prepared flash MRI images.

make_scalp_surfaces(subject[, subjects_dir, ...])

Create surfaces of the scalp and neck.

convert_flash_mris(subject[, flash30, ...])

Synthesize the flash 5 files for use with make_flash_bem.

distance_to_bem(pos, bem[, trans, verbose])

Calculate the distance of positions to inner skull surface.

mne.coreg.Coregistration

---

## Glossary#

**URL:** https://mne.tools/stable/documentation/glossary.html

**Contents:**
- Glossary#

The Glossary provides short definitions of vocabulary specific to MNE-Python and general neuroimaging concepts. If you think a term is missing, please consider creating a new issue or opening a pull request to add it.

An annotation is defined by an onset, a duration, and a textual description. It can contain information about the experiment, but also details on signals marked by a human such as bad data segments, sleep stages, sleep events (spindles, K-complex), and so on. An Annotations object is a container for multiple annotations, which is available as the annotations attribute of Raw objects. See Annotations for the class definition and Parsing events from raw data for a short tutorial. See also events.

A beamformer is a popular source estimation approach that uses a set of spatial filters (beamformer weights) to compute time courses of sources at predefined locations. See beamformer.Beamformer for the class definition. See also LCMV.

BEM is the acronym for boundary element method or boundary element model. Both are related to the definion of the conductor model in the forward model computation. The boundary element model consists of surfaces such as the inner skull, outer skull, and outer skin (scalp) that define compartments of tissues of the head. You can compute the BEM surfaces with bem.make_watershed_bem() or bem.make_flash_bem(). See Head model and forward computation for a usage demo.

Channels refer to MEG sensors, EEG electrodes or other sensors such as EOG, ECG, sEEG, ECoG, etc. Channels usually have a type (such as gradiometer), and a unit (such as T/m) used e.g. for plotting. See also data channels and non-data channels.

Many functions in MNE-Python operate on “data channels” by default. These are channels that contain electrophysiological data from the brain, as opposed to other channel types such as EOG, ECG, stimulus/trigger, or acquisition system status data (see non-data channels). The set of channels considered “data channels” in MNE contains the following types (together with scale factors for plotting):

'mag': Magnetometers (scaled by 1e+15 to plot in fT)

'grad': Gradiometers (scaled by 1e+13 to plot in fT/cm)

'eeg': EEG (scaled by 1e+06 to plot in µV)

'csd': Current source density (scaled by 1000 to plot in mV/m²)

'seeg': sEEG (scaled by 1000 to plot in mV)

'ecog': ECoG (scaled by 1e+06 to plot in µV)

'dbs': DBS (scaled by 1e+06 to plot in µV)

'hbo': Oxyhemoglobin (scaled by 1e+06 to plot in µM)

'hbr': Deoxyhemoglobin (scaled by 1e+06 to plot in µM)

'fnirs_cw_amplitude': fNIRS (CW amplitude) (scaled by 1 to plot in V)

'fnirs_fd_ac_amplitude': fNIRS (FD AC amplitude) (scaled by 1 to plot in V)

'fnirs_fd_phase': fNIRS (FD phase) (scaled by 1 to plot in rad)

'fnirs_od': fNIRS (OD) (scaled by 1 to plot in V)

The part of a signal that stays constant over time. The “DC offset” of electrophysiological signals is often dealt with by high-pass filtering or by subtracting some suitable baseline.

Dynamic Imaging of Coherent Sources is a method for computing source power in different frequency bands. See Compute source power using DICS beamformer and beamformer.make_dics() for more details.

Digitization is a procedure of recording the head shape and locations of fiducial coils (or HPI) and/or EEG electrodes on the head. They are represented as a set of points in 3D space. See Reading sensor digitization files and Supported formats for digitized 3D locations.

An equivalent current dipole (ECD) is an approximate representation of post-synaptic activity in a small cortical region. The intracellular currents that give rise to measurable EEG/MEG signals are thought to originate in populations of cortical pyramidal neurons aligned perpendicularly to the cortical surface. Because the length of such current sources is very small relative to the distance between the cortex and the EEG/MEG sensors, the fields measured by these techniques are well approximated by (i.e., equivalent to) fields generated by idealized point sources (dipoles) located on the cortical surface.

Dynamic statistical parametric mapping (dSPM) gives a noise-normalized minimum-norm estimate at a given source location. It is calculated by dividing the activity estimate at each source location by the baseline standard deviation of the noise.

eLORETA and sLORETA (exact and standardized low resolution brain electromagnetic tomography) are linear source estimation techniques like dSPM and MNE. sLORETA outputs standardized values (like dSPM), while eLORETA generates normalized current estimates. See minimum_norm.apply_inverse(), Source localization with MNE, dSPM, sLORETA, and eLORETA, and Compute sLORETA inverse solution on raw data.

Epochs (sometimes called “trials” in other software packages) are equal-length segments of data extracted from continuous data. Usually, epochs are extracted around stimulus events or responses, though sometimes sequential or overlapping epochs are used (e.g., for analysis of resting-state activity). See Epochs for the class definition and The Epochs data structure: discontinuous data for a narrative overview.

Events correspond to specific time points in raw data, such as triggers, experimental condition events, etc. MNE-Python represents events with integers stored in NumPy arrays of shape (n_events, 3). The first column contains the event onset (in samples) with first_samp included. The last column contains the event code. The second column contains the signal value of the immediately preceding sample, and reflects the fact that event arrays sometimes originate from analog voltage channels (“trigger channels” or “stim channels”). In most cases, the second column is all zeros and can be ignored. Event arrays can be created with mne.make_fixed_length_events(), mne.read_events(), and mne.find_events(). See Parsing events from raw data for a short tutorial. See also annotations.

Evoked data are obtained by averaging epochs. Typically, an evoked object is constructed for each subject and each condition, but it can also be obtained by averaging a list of evoked objects over different subjects. See EvokedArray for the class definition and The Evoked data structure: evoked/averaged data for a narrative overview.

Fiducials are objects placed in the field of view of an imaging system to act as known spatial references that are easy to localize. In neuroimaging, fiducials are often placed on anatomical landmarks such as the nasion (NAS) or left/right preauricular points (LPA and RPA).

These known reference locations are used to define a coordinate system for localizing sensors (hence NAS, LPA and RPA are often called “cardinal points” because they define the cardinal directions of the head coordinate system). The cardinal points are also useful when co-registering measurements in different coordinate systems (such as aligning EEG sensor locations to an MRI of the head).

Due to the common neuroimaging practice of placing fiducial objects on anatomical landmarks, the terms “fiducial”, “anatomical landmark”, and “cardinal point” are often (erroneously) used interchangeably.

The first_samp attribute of Raw objects is an integer representing the number of time samples that passed between the onset of the hardware acquisition system and the time when data recording started. This approach to sample numbering is a peculiarity of VectorView MEG systems, but for consistency it is present in all Raw objects regardless of the source of the data. In other words, first_samp will be 0 in Raw objects loaded from non-VectorView data files. See also last_samp.

The forward solution is a linear operator capturing the relationship between each dipole location in the source space and the corresponding field distribution measured by the sensors (the “lead field matrix”). Calculating a forward solution requires a conductivity model of the head, which encapsulates the geometries and electrical conductivities of the different tissue compartments (see boundary element model and bem.ConductorModel). For information about the Forward object and the data it stores, see mne.Forward.

A FreeSurfer lookup table (LUT) provides a mapping between a given volumetric atlas or surface label name, its integer value (e.g., in aparc+aseg.mgz), and its standard color (see the FreeSurfer wiki for more information). Custom LUTs can be also be created from different surface parcellations, see for example this comment about HCPMMP.

Global Field Power (GFP) is a measure of the (non-)uniformity of the electromagnetic field at the sensors. It is typically calculated as the standard deviation of the sensor values at each time point. Thus, it is a one-dimensional time series capturing the spatial variability of the signal across sensor locations.

Hierarchical event descriptors (HED) are tags that use keywords separated by slashes (/) to describe different types of experimental events (for example, stimulus/circle/red/left and stimulus/circle/blue/left). These tags can be used to group experimental events and select event types for analysis.

Head position indicators (HPI, sometimes cHPI for continuous head position indicators) are small coils attached to a subject’s head during MEG acquisition. Each coil emits a sinusoidal signal of a different frequency, which is picked up by the MEG sensors and can be used to infer the head position. With cHPI, the sinusoidal signals are typically set at frequencies above any neural signal of interest, and thus can be removed after head position correction via low-pass filtering. See Extracting and visualizing subject head movement.

A “measurement info” (or short “info”) object is a collection of metadata related to Raw, Epochs, or Evoked objects. It contains channel locations and types, sampling frequency, preprocessing history such as filters, etc. See The Info data structure for a narrative overview.

The inverse operator is an \(M \times N\) matrix (\(M\) source locations by \(N\) sensors) that, when applied to the sensor signals, yields estimates of the brain activity that gave rise to the observed sensor signals. Inverse operators are available for the linear inverse methods MNE, dSPM, sLORETA, and eLORETA. See minimum_norm.apply_inverse().

A Label refers to a defined region in the cortex, often called a region of interest (ROI) in the literature. Labels can be defined anatomically (based on the physical structure of the cortex) or functionally (based on cortical responses to specific stimuli). See also ROI.

The last_samp attribute of Raw objects is an integer representing the number of time samples that passed between the start and end of data recording. This approach to sample numbering is a peculiarity of VectorView MEG systems, but for consistency it is present in all Raw objects regardless of the source of the data. See also first_samp.

A Layout gives sensor positions in two dimensions (defined by x, y, width, and height values for each sensor). It is primarily used for illustrative purposes (i.e., making diagrams of approximate sensor positions in cartoons of the head, so-called topographies or topomaps). See also montage.

Linearly constrained minimum variance beamformer attempt to estimate activity for a given source while suppressing cross-talk from other regions (beamformer.make_lcmv()). See also beamformer.

A method to display pixel-wise activity within some volume by finding the maximum value along a vector from the viewer to the pixel (i.e., along the vector pependicular to the view plane).

Minimum-norm estimation (MNE) can be used to generate a distributed map of activation on a source space (usually on a cortical surface). MNE uses a linear inverse operator to project sensor measurements into the source space. The inverse operator is computed from the forward solution for a subject and an estimate of the noise covariance of sensor measurements.

EEG channel names and relative positions of sensors on the scalp. While layouts are 2D locations, montages are 3D locations. A montage can also contain locations for HPI points, fiducial points, or extra head shape points. See DigMontage for the class definition. See also layout.

Morphing refers to the operation of transferring source estimates from one anatomy to another. It is known as realignment in the fMRI literature. This operation is necessary for group studies to get the data into a common space for statistical analysis. See Morphing and averaging source estimates for more details.

The noise covariance is a matrix that contains the covariance between data channels. It is a square matrix with shape n_channels \(\times\) n_channels. It is especially useful when working with multiple sensor types (e.g. EEG and MEG). In practice, the matrix is estimated from baseline periods or empty room measurements, and it also provides a noise model that can be used for subsequent analysis (like source imaging).

All types of channels other than data channels. The set of channels considered “non-data channels” in MNE contains the following types (together with scale factors for plotting):

'eog': EOG (scaled by 1e+06 to plot in µV)

'ecg': ECG (scaled by 1e+06 to plot in µV)

'resp': Respiration monitoring channel

'emg': EMG (scaled by 1e+06 to plot in µV)

'ref_meg': Reference Magnetometers (scaled by 1e+15 to plot in fT)

'misc': misc (scaled by 1 to plot in AU)

'chpi': Continuous head position indicator (HPI) coil channels

'exci': Flux excitation channel

'ias': Internal Active Shielding data (Triux systems)

'syst': System status channel information (Triux systems)

'bio': BIO (scaled by 1e+06 to plot in µV)

'temperature': Temperature (scaled by 1 to plot in C)

'gsr': Galvanic skin response (scaled by 1 to plot in S)

'gof': Goodness of fit (scaled by 1 to plot in GOF)

'dipole': Dipole (scaled by 1e+09 to plot in nAm)

'eyegaze': Eye-tracking (Gaze position) (scaled by 1 to plot in rad)

'pupil': Eye-tracking (Pupil size) (scaled by 1000 to plot in mm)

'whitened': Whitened data (scaled by 1 to plot in Z)

An optically pumped magnetometer (OPM) is a type of magnetometer that uses a laser passing through a gas (e.g., rubidium) to sense magnetic fluctuations. OPMs can operate near room temperature.

Something that acts like a path in a file system. This can be a str or a pathlib.Path.

An integer that is the index of a channel in the measurement info. It allows to obtain the information on a channel in the list of channels available in info['chs'].

A projector, also referred to as Signal Space Projection (SSP), defines a linear operation applied spatially to EEG or MEG data. A matrix multiplication of an SSP projector with the data will reduce the rank of the data by projecting it to a lower-dimensional subspace. Such projections are typically applied to both the data and the forward operator when performing source localization. Note that EEG average referencing can be done using such a projection operator. Projectors are stored alongside data in the measurement info in the field info['projs'].

Right-Anterior-Superior, denoting the standard way to define coordinate frames in MNE-Python:

+X is right, -X is left

+Y is anterior (front), -Y is posterior (rear)

+Z is superior (top), -Z is inferior (bottom)

Raw objects hold continuous data (preprocessed or not), typically obtained from reading recordings stored in a file. See RawArray for the class definition and The Raw data structure: continuous data for a narrative overview.

A spatial region where an experimental effect is expected to manifest. This can be a collection of sensors or, when performing inverse imaging, a set of vertices on the cortical surface or within the cortical volume. See also label.

A selection is a set of picked channels (for example, all sensors falling within a region of interest).

All the sensors handled by MNE-Python can be divided into two categories: data channels and non-data channels.

A source space specifies where in the brain source amplitudes are estimated. It corresponds to locations of a set of candidate equivalent current dipoles. MNE-Python mostly works with source spaces defined on the cortical surfaces estimated by FreeSurfer from a T1-weighted MRI image. See Head model and forward computation to read about how to compute a forward operator in a source space. See SourceSpaces for the class definition and information about the data it contains.

A superconducting quantum interference device (SQUID) is a type of magnetometer that uses superconducting materials to sense magnetic fluctuations. Standard low-temperature SQUID sensors typically found in MEG systems operate at temperatures within a few degrees of absolute zero (e.g., below 4 K).

Source estimates, commonly referred to as STC (Source Time Courses), are obtained from source localization methods such as dSPM, sLORETA, LCMV, or MxNE. STCs contain the amplitudes of the neural sources over time. In MNE-Python, SourceEstimate objects only store the amplitudes of activation but not the locations of the sources. The locations are stored separately in the SourceSpaces object that was used to compute the forward operator. See SourceEstimate, VolSourceEstimate, VectorSourceEstimate, and MixedSourceEstimate.

A stim channel or trigger channel is a channel that encodes events during the recording. It is typically a channel that is always zero and takes positive values when something happens (such as the onset of a stimulus or a subject response). Stim channels are often prefixed with STI to distinguish them from other channel types. See What is a STIM channel? for more details.

An idealized EEG montage, often provided by the manufacturer of the EEG system or cap. The electrode positions were not actually measured on the participants’ heads, but rather were calculated assuming optimal theoretical placement on a sphere.

A time-frequency representation (TFR) is often a spectrogram (STFT) or scaleogram (wavelet) showing the frequency content as a function of time.

A coordinate frame affine transformation, usually between the Neuromag head coordinate frame and the MRI Surface RAS coordinate frame used by Freesurfer.

A linear operation that transforms data with a known covariance structure into “whitened data”, which has a covariance structure equal to the identity matrix. In other words, whitening creates virtual channels that are uncorrelated and have unit variance. This is also known as a sphering transformation.

The term “whitening” comes from the fact that light with a flat frequency spectrum in the visible range is white, whereas non-uniform frequency spectra lead to perception of different colors (e.g., “pink noise” has a 1/f characteristic, which for visible light would appear pink).

From raw data to dSPM on SPM Faces dataset

Algorithms and other implementation details

---

## How to cite MNE-Python#

**URL:** https://mne.tools/stable/documentation/cite.html

**Contents:**
- How to cite MNE-Python#
- Citing the software#
- Citing the inverse imaging algorithms#
- Citing other algorithms#

To cite specific version numbers of the software, you can use the DOIs provided by Zenodo; look for the “versions” list in the sidebar to find the correct DOI for the version you used in your work (or to cite the project in a general way, use https://doi.org/10.5281/zenodo.592483). Additionally, we ask that when citing MNE-Python you also cite the canonical journal article reference [1]:

Alexandre Gramfort, Martin Luessi, Eric Larson, Denis A. Engemann, Daniel Strohmeier, Christian Brodbeck, Roman Goj, Mainak Jas, Teon Brooks, Lauri Parkkonen, and Matti S. Hämäläinen. MEG and EEG data analysis with MNE-Python. Frontiers in Neuroscience, 7(267):1–13, 2013. doi:10.3389/fnins.2013.00267.

To cite MNE-C or the inverse imaging implementations provided by the MNE software, please use [2]:

Alexandre Gramfort, Martin Luessi, Eric Larson, Denis A. Engemann, Daniel Strohmeier, Christian Brodbeck, Lauri Parkkonen, and Matti S. Hämäläinen. MNE software for processing MEG and EEG data. NeuroImage, 86:446–460, 2014. doi:10.1016/j.neuroimage.2013.10.027.

Depending on your research topic, it may also be appropriate to cite related method papers, some of which are listed in the documentation strings of the relevant functions or methods. All references cited in the MNE-Python codebase and documentation are collected in the General bibliography.

The typical M/EEG workflow

Papers citing MNE-Python

**Examples:**

Example 1 (python):
```python
@article{GramfortEtAl2013a,
  title = {{{MEG}} and {{EEG}} Data Analysis with {{MNE}}-{{Python}}},
  author = {Gramfort, Alexandre and Luessi, Martin and Larson, Eric and Engemann, Denis A. and Strohmeier, Daniel and Brodbeck, Christian and Goj, Roman and Jas, Mainak and Brooks, Teon and Parkkonen, Lauri and H{\"a}m{\"a}l{\"a}inen, Matti S.},
  year = {2013},
  volume = {7},
  pages = {1--13},
  doi = {10.3389/fnins.2013.00267},
  journal = {Frontiers in Neuroscience},
  number = {267}
}
```

Example 2 (python):
```python
@article{GramfortEtAl2014,
  title = {{{MNE}} Software for Processing {{MEG}} and {{EEG}} Data},
  author = {Gramfort, Alexandre and Luessi, Martin and Larson, Eric and Engemann, Denis A. and Strohmeier, Daniel and Brodbeck, Christian and Parkkonen, Lauri and H{\"a}m{\"a}l{\"a}inen, Matti S.},
  year = {2014},
  volume = {86},
  pages = {446--460},
  doi = {10.1016/j.neuroimage.2013.10.027},
  journal = {NeuroImage},
}
```

---

## Logging and Configuration#

**URL:** https://mne.tools/stable/api/logging.html

**Contents:**
- Logging and Configuration#

get_config_path([home_dir])

Get path to standard mne-python config file.

get_config([key, default, raise_error, ...])

Read MNE-Python preferences from environment or config file.

open_docs([kind, version])

Launch a new web browser tab with the MNE documentation.

set_log_level([verbose, return_old_level, ...])

Set the logging level.

set_log_file([fname, output_format, overwrite])

Set the log to print to a file.

set_config(key, value[, home_dir, set_env])

Set a MNE-Python preference key in the config file and environment.

set_cache_dir(cache_dir)

Set the directory to be used for temporary file storage.

set_memmap_min_size(memmap_min_size)

Set the minimum size for memmaping of arrays for parallel processing.

sys_info([fid, show_paths, dependencies, ...])

Print system information.

use_log_level([verbose, add_frames])

Context manager for logging level.

Verbose decorator to allow functions to override log-level.

Mark a function, class, or method as deprecated (decorator).

warn(message[, category, module, ...])

Emit a warning with trace outside the mne namespace.

get_cuda_memory([kind])

Get the amount of free memory for CUDA operations.

init_cuda([ignore_config, verbose])

Initialize CUDA functionality.

set_cuda_device(device_id[, verbose])

Set the CUDA device temporarily for the current session.

---

## mne.AcqParserFIF#

**URL:** https://mne.tools/stable/generated/mne.AcqParserFIF.html

**Contents:**
- mne.AcqParserFIF#

Parser for Elekta data acquisition settings.

This class parses parameters (e.g. events and averaging categories) that are defined in the Elekta TRIUX/VectorView data acquisition software (DACQ) and stored in info['acq_pars']. It can be used to reaverage raw data according to DACQ settings and modify original averaging settings if necessary.

The mne.Info object with information about the sensors and methods of measurement. This is where the DACQ parameters will be taken from.

Return list of averaging categories ordered by DACQ index.

Return events ordered by DACQ index.

Rejection criteria from DACQ that can be used with mne.Epochs. Note that mne does not support all DACQ rejection criteria (e.g. spike, slope).

Flatness rejection criteria from DACQ that can be used with mne.Epochs.

Return an averaging category, or list of categories.

Return number of averaging categories marked active in DACQ.

get_condition(raw[, condition, ...])

Get averaging parameters for a condition (averaging category).

Access the parser through a Raw attribute.

Any averaging category (also non-active ones) can be accessed by indexing as acqparserfif['category_name'].

Return an averaging category, or list of categories.

Name of the category (comment field in DACQ).

Each dict should have the following keys:

The comment field in DACQ.

Whether the category was marked enabled in DACQ.

The index of the category in DACQ. Indices start from 1.

DACQ index of the reference event (trigger event, zero time for the corresponding epochs). Note that the event indices start from 1.

Start time of epoch relative to the reference event.

End time of epoch relative to the reference event.

Index of the required (conditional) event.

Whether the required event is required before (1) or after (2) the reference event.

The time range within which the required event must occur, before or after the reference event.

Whether the category was displayed online in DACQ.

Desired number of averages. DACQ stops collecting averages once this number is reached.

Whether to compute normal and alternating subaverages, and how many epochs to include. See the Elekta data acquisition manual for details. Currently the class does not offer any facility for computing subaverages, but it can be done manually by the user after collecting the epochs.

Return number of averaging categories marked active in DACQ.

The number of categories.

Return list of averaging categories ordered by DACQ index.

Only returns categories marked active in DACQ.

Return events ordered by DACQ index.

Only returns events that are in use (referred to by a category).

Get averaging parameters for a condition (averaging category).

Output is designed to be used with the Epochs class to extract the corresponding epochs.

Condition or a list of conditions. Conditions can be strings (DACQ comment field, e.g. ‘Auditory left’) or category dicts (e.g. acqp[‘Auditory left’], where acqp is an instance of AcqParserFIF). If None, get all conditions marked active in DACQ.

Name of the stim channel or all the stim channels affected by the trigger. If None, the config variables ‘MNE_STIM_CHANNEL’, ‘MNE_STIM_CHANNEL_1’, ‘MNE_STIM_CHANNEL_2’, etc. are read. If these are not found, it will fall back to ‘STI101’ or ‘STI 014’ if present, then fall back to the first channel of type ‘stim’, if present.

The value of the digital mask to apply to the stim channel values. If None (default), no masking is performed.

If True (default False), do a cast to uint16 on the channel data. This can be used to fix a bug with STI101 and STI014 in Neuromag acquisition setups that use channel STI016 (channel 16 turns data into e.g. -32768), similar to mne_fix_stim14 --32 in MNE-C.

The type of operation between the mask and the trigger. Choose ‘and’ for MNE-C masking behavior.

If True, use the ‘delayed lookup’ procedure implemented in Elekta software. When a trigger transition occurs, the lookup of the new trigger value will not happen immediately at the following sample, but with a 1-sample delay. This allows a slight asynchrony between trigger onsets, when they are intended to be synchronous. If you have accurate hardware and want to detect transitions with a resolution of one sample, use delayed_lookup=False.

Each dict has the following keys:

List of zero time points (t0) for the epochs matching the condition. Use as the events parameter to Epochs. Note that these are not (necessarily) actual events.

Name of condition and index compatible with events. Should be passed as the event_id parameter to Epochs.

Epoch starting time relative to t0. Use as the tmin parameter to Epochs.

Epoch ending time relative to t0. Use as the tmax parameter to Epochs.

mne.concatenate_events

---

## mne.add_reference_channels#

**URL:** https://mne.tools/stable/generated/mne.add_reference_channels.html

**Contents:**
- mne.add_reference_channels#
- Examples using mne.add_reference_channels#

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Instance of Raw or Epochs with EEG channels and reference channel(s).

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

Specifies whether the data will be copied (True) or modified in-place (False). Defaults to True.

Data with added EEG reference channels.

When re-referencing, make sure to apply the montage using mne.io.Raw.set_montage() only after calling this function. Applying a montage will only set locations of channels that exist at the time it is applied.

Setting the EEG reference

mne.preprocessing.eyetracking.interpolate_blinks

mne.set_bipolar_reference

---

## mne.add_source_space_distances#

**URL:** https://mne.tools/stable/generated/mne.add_source_space_distances.html

**Contents:**
- mne.add_source_space_distances#

Compute inter-source distances along the cortical surface.

This function will also try to add patch info for the source space. It will only occur if the dist_limit is sufficiently high that all points on the surface are within dist_limit of a point in the source space.

The source spaces to compute distances for.

The upper limit of distances to include (in meters). Note: if limit < np.inf, scipy > 0.13 (bleeding edge as of 10/2013) must be installed. If 0, then only patch (nearest vertex) information is added.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if dist_limit==0..

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The original source spaces, with distance information added. The distances are stored in src[n][‘dist’]. Note: this function operates in-place.

This function can be memory- and CPU-intensive. On a high-end machine (2012) running 6 jobs in parallel, an ico-5 (10242 per hemi) source space takes about 10 minutes to compute all distances (dist_limit = np.inf). With dist_limit = 0.007, computing distances takes about 1 minute.

We recommend computing distances once per source space and then saving the source space to disk, as the computed distances will automatically be stored along with the source space data for future use.

---

## mne.Annotations#

**URL:** https://mne.tools/stable/generated/mne.Annotations.html

**Contents:**
- mne.Annotations#
- Examples using mne.Annotations#

Annotation object for annotating segments of raw data.

To convert events to Annotations, use annotations_from_events. To convert existing Annotations to events, use events_from_annotations.

The starting time of annotations in seconds after orig_time.

Durations of the annotations in seconds. If a float, all the annotations are given the same duration.

Array of strings containing description for each annotation. If a string, all the annotations are given the same description. To reject epochs, use description starting with keyword ‘bad’. See example above.

A POSIX Timestamp, datetime or a tuple containing the timestamp as the first element and microseconds as the second element. Determines the starting time of annotation acquisition. If None (default), starting time is determined from beginning of raw data acquisition. In general, raw.info['meas_date'] (or None) can be used for syncing the annotations with raw data if their acquisition is started at the same time. If it is a string, it should conform to the ISO8601 format. More precisely to this ‘%Y-%m-%d %H:%M:%S.%f’ particular case of the ISO8601 format where the delimiter between date and time is ‘ ‘ and at most microsecond precision (nanoseconds are not supported).

List of lists of channel names associated with the annotations. Empty entries are assumed to be associated with no specific channel, i.e., with all channels or with the time slice itself. None (default) is the same as passing all empty lists. For example, this creates three annotations, associating the first with the time interval itself, the second with two channels, and the third with a single channel:

Optional list of dicts containing extra fields for each annotation. The number of items must match the number of annotations.

The extras of the Annotations.

The time base of the Annotations.

Add (concatencate) two Annotation objects.

__getitem__(key, *[, with_ch_names, with_extras])

Propagate indexing and slicing to the underlying numpy structure.

Iterate over the annotations.

Return the number of annotations.

append(onset, duration, description[, ...])

Add an annotated segment.

Return a copy of the Annotations.

crop([tmin, tmax, emit_warning, ...])

Remove all annotation that are outside of [tmin, tmax].

Remove an annotation.

rename(mapping[, verbose])

Rename annotation description(s).

save(fname, *[, overwrite, verbose])

Save annotations to FIF, CSV or TXT.

set_durations(mapping[, verbose])

Set annotation duration(s).

to_data_frame([time_format])

Export annotations in tabular structure as a pandas DataFrame.

Annotations are added to instance of mne.io.Raw as the attribute raw.annotations.

To reject bad epochs using annotations, use annotation description starting with ‘bad’ keyword. The epochs with overlapping bad segments are then rejected automatically by default.

To remove epochs with blinks you can do:

Specifying channel names allows the creation of channel-specific annotations. Once the annotations are assigned to a raw instance with mne.io.Raw.set_annotations(), if channels are renamed by the raw instance, the annotation channels also get renamed. If channels are dropped from the raw instance, any channel-specific annotation that has no channels left in the raw instance will also be removed.

If orig_time is None, the annotations are synced to the start of the data (0 seconds). Otherwise the annotations are synced to sample 0 and raw.first_samp is taken into account the same way as with events.

When setting annotations, the following alignments between raw.info['meas_date'] and annotation.orig_time take place:

This means that when raw.info['meas_date'] is None, doing raw.set_annotations(raw.annotations) will not alter raw if and only if raw.first_samp == 0. When it’s non-zero, raw.set_annotations will assume that the “new” annotations refer to the original data (with first_samp==0), and will be re-referenced to the new time offset!

BAD_ACQ_SKIP annotation leads to specific reading/writing file behaviours. See mne.io.read_raw_fif() and Raw.save() notes for details.

Add (concatencate) two Annotation objects.

Propagate indexing and slicing to the underlying numpy structure.

Iterate over the annotations.

Return the number of annotations.

The number of annotations.

Add an annotated segment. Operates inplace.

Annotation time onset from the beginning of the recording in seconds.

Duration of the annotation in seconds.

Description for the annotation. To reject epochs, use description starting with keyword ‘bad’.

List of lists of channel names associated with the annotations. Empty entries are assumed to be associated with no specific channel, i.e., with all channels or with the time slice itself. None (default) is the same as passing all empty lists. For example, this creates three annotations, associating the first with the time interval itself, the second with two channels, and the third with a single channel:

Optional list of dicts containing extras fields for each annotation. The number of items must match the number of annotations.

The modified Annotations object.

The array-like support for arguments allows this to be used similarly to not only list.append, but also list.extend.

Examples using append:

Visualise NIRS artifact correction methods

Return a copy of the Annotations.

A copy of the object.

A dictionary containing unique annotation descriptions as keys with their counts as values.

Remove all annotation that are outside of [tmin, tmax].

The method operates inplace.

Start time of selection in seconds.

End time of selection in seconds.

Whether to emit warnings when limiting or omitting annotations. Defaults to False.

Whether to use orig_time as an offset. Defaults to True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped Annotations object.

Sleep stage classification from polysomnography (PSG) data

Remove an annotation. Operates inplace.

Index of the annotation to remove. Can be array-like to remove multiple indices.

The extras of the Annotations.

The extras attribute is a list of dictionaries. It can easily be converted to a pandas DataFrame using: pd.DataFrame(extras).

The time base of the Annotations.

Rename annotation description(s). Operates inplace.

A dictionary mapping the old description to a new description, e.g. {‘1.0’ : ‘Control’, ‘2.0’ : ‘Stimulus’}.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified Annotations object.

Save annotations to FIF, CSV or TXT.

Typically annotations get saved in the FIF file for raw data (e.g., as raw.annotations), but this offers the possibility to also save them to disk separately in different file formats which are easier to share between packages.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The format of the information stored in the saved annotation objects depends on the chosen file format. .csv files store the onset as timestamps (e.g., 2002-12-03 19:01:56.676071), whereas .txt files store onset as seconds since start of the recording (e.g., 45.95597082905339).

Annotating continuous data

Set annotation duration(s). Operates inplace.

A dictionary mapping the annotation description to a duration in seconds e.g. {'ShortStimulus' : 3, 'LongStimulus' : 12}. Alternatively, if a number is provided, then all annotations durations are set to the single provided value.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified Annotations object.

Export annotations in tabular structure as a pandas DataFrame.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. If 'datetime', time values will be converted to pandas.Timestamp values, relative to raw.info['meas_date'] and offset by raw.first_samp. Default is None unless specified otherwise. Default is datetime.

Returns a pandas DataFrame with onset, duration, and description columns. A column named ch_names is added if any annotations are channel-specific.

Automated epochs metadata generation with variable time windows

Visualise NIRS artifact correction methods

Annotate movement artifacts and reestimate dev_head_t

Annotate muscle artifacts

Sleep stage classification from polysomnography (PSG) data

Auto-generating Epochs metadata

Parsing events from raw data

Working with CTF data: the Brainstorm auditory dataset

Importing Data from Eyetracking devices

Rejecting bad data spans and breaks

Working with eye tracker data in MNE-Python

Annotating continuous data

---

## mne.annotations_from_events#

**URL:** https://mne.tools/stable/generated/mne.annotations_from_events.html

**Contents:**
- mne.annotations_from_events#
- Examples using mne.annotations_from_events#

Convert an event array to an Annotations object.

Events description. Can be:

dict: map integer event codes (keys) to descriptions (values). Only the descriptions present will be mapped, others will be ignored.

array-like: list, or 1d array of integers event codes to include. Only the event codes present will be mapped, others will be ignored. Event codes will be passed as string descriptions.

callable: must take a integer event code as input and return a string description or None to ignore it.

None: Use integer event codes as descriptions.

The first data sample (default=0). See mne.io.Raw.first_samp docstring.

Determines the starting time of annotation acquisition. If None (default), starting time is determined from beginning of raw data acquisition. For details, see mne.Annotations() docstring.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Annotations returned by this function will all have zero (null) duration.

Creating events from annotations via the function mne.events_from_annotations takes in event mappings with key→value pairs as description→ID, whereas mne.annotations_from_events takes in event mappings with key→value pairs as ID→description. If you need to use these together, you can invert the mapping by doing:

Parsing events from raw data

mne.events_from_annotations

mne.count_annotations

---

## mne.apply_forward#

**URL:** https://mne.tools/stable/generated/mne.apply_forward.html

**Contents:**
- mne.apply_forward#

Project source space currents to sensor space using a forward operator.

The sensor space data is computed for all channels present in fwd. Use pick_channels_forward or pick_types_forward to restrict the solution to a subset of channels.

The function returns an Evoked object, which is constructed from evoked_template. The evoked_template should be from the same MEG system on which the original data was acquired. An exception will be raised if the forward operator contains channels that are not present in the template.

Forward operator to use.

The source estimate from which the sensor space data is computed.

The mne.Info object with information about the sensors and methods of measurement.

Index of first time sample (index not time is seconds).

Index of first time sample not to include (index not time is seconds).

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when stc has vertices that are not in fwd. Default is “raise”.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Evoked object with computed sensor space data.

Compute sensor space data and return a Raw object.

mne.add_source_space_distances

mne.apply_forward_raw

---

## mne.apply_forward_raw#

**URL:** https://mne.tools/stable/generated/mne.apply_forward_raw.html

**Contents:**
- mne.apply_forward_raw#

Project source space currents to sensor space using a forward operator.

The sensor space data is computed for all channels present in fwd. Use pick_channels_forward or pick_types_forward to restrict the solution to a subset of channels.

The function returns a Raw object, which is constructed using provided info. The info object should be from the same MEG system on which the original data was acquired. An exception will be raised if the forward operator contains channels that are not present in the info.

Forward operator to use.

The source estimate from which the sensor space data is computed.

The mne.Info object with information about the sensors and methods of measurement.

Index of first time sample (index not time is seconds).

Index of first time sample not to include (index not time is seconds).

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when stc has vertices that are not in fwd. Default is “raise”.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Raw object with computed sensor space data.

Compute sensor space data and return an Evoked object.

mne.average_forward_solutions

---

## mne.average_forward_solutions#

**URL:** https://mne.tools/stable/generated/mne.average_forward_solutions.html

**Contents:**
- mne.average_forward_solutions#

Average forward solutions.

Forward solutions to average. Each entry (dict) should be a forward solution.

Weights to apply to each forward solution in averaging. If None, forward solutions will be equally weighted. Weights must be non-negative, and will be adjusted to sum to one.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The averaged forward solution.

mne.apply_forward_raw

mne.convert_forward_solution

---

## mne.baseline.rescale#

**URL:** https://mne.tools/stable/generated/mne.baseline.rescale.html

**Contents:**
- mne.baseline.rescale#
- Examples using mne.baseline.rescale#

Rescale (baseline correct) data.

It can be of any shape. The only constraint is that the last dimension should be time.

Time instants is seconds.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Whether to return a new instance or modify in place.

Data to process along the axis=-2 (None, default, processes all).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Array of same shape as data after rescaling.

Explore event-related dynamics for specific frequency bands

Covariance computation

---

## mne.beamformer.apply_dics#

**URL:** https://mne.tools/stable/generated/mne.beamformer.apply_dics.html

**Contents:**
- mne.beamformer.apply_dics#

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights on evoked data.

The result of this function is meant as an intermediate step for further processing (such as computing connectivity). If you are interested in estimating source time courses, use an LCMV beamformer (make_lcmv(), apply_lcmv()) instead. If you are interested in estimating spectral power at the source level, use apply_dics_csd().

This implementation has not been heavily tested so please report any issues or suggestions.

Evoked data to apply the DICS beamformer weights to.

DICS spatial filter (beamformer weights) Filter weights returned from make_dics().

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Source time courses. If the DICS beamformer has been computed for more than one frequency, a list is returned containing for each frequency the corresponding time courses.

mne.beamformer.make_dics

mne.beamformer.apply_dics_csd

---

## mne.beamformer.apply_dics_csd#

**URL:** https://mne.tools/stable/generated/mne.beamformer.apply_dics_csd.html

**Contents:**
- mne.beamformer.apply_dics_csd#
- Examples using mne.beamformer.apply_dics_csd#

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.

Apply a previously computed DICS beamformer to a cross-spectral density (CSD) object to estimate source power in time and frequency windows specified in the CSD object [1].

Only power can computed from the cross-spectral density, not complex phase-amplitude, so vector DICS filters will be converted to scalar source estimates since power is strictly positive and so 3D directions cannot be combined meaningfully (the direction would be confined to the positive quadrant).

The data cross-spectral density (CSD) matrices. A source estimate is performed for each frequency or frequency-bin defined in the CSD object.

DICS spatial filter (beamformer weights) Filter weights returned from make_dics.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Source power with frequency instead of time.

The frequencies for which the source power has been computed. If the data CSD object defines frequency-bins instead of exact frequencies, the mean of each bin is returned.

Joachim Groß, Jan Kujala, Matti S. Hämäläinen, Lars Timmermann, Alfons Schnitzler, and Riitta Salmelin. Dynamic imaging of coherent sources: studying neural interactions in the human brain. Proceedings of the National Academy of Sciences, 98(2):694–699, 2001. doi:10.1073/pnas.98.2.694.

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

DICS for power mapping

mne.beamformer.apply_dics

mne.beamformer.apply_dics_epochs

---

## mne.beamformer.apply_lcmv#

**URL:** https://mne.tools/stable/generated/mne.beamformer.apply_lcmv.html

**Contents:**
- mne.beamformer.apply_lcmv#
- Examples using mne.beamformer.apply_lcmv#

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights on evoked data.

Evoked data to invert.

LCMV spatial filter (beamformer weights). Filter weights returned from make_lcmv().

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Source reconstruction using an LCMV beamformer

mne.beamformer.make_lcmv

mne.beamformer.apply_lcmv_epochs

---

## mne.beamformer.apply_lcmv_cov#

**URL:** https://mne.tools/stable/generated/mne.beamformer.apply_lcmv_cov.html

**Contents:**
- mne.beamformer.apply_lcmv_cov#
- Examples using mne.beamformer.apply_lcmv_cov#

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights to a data covariance matrix to estimate source power.

Data covariance matrix.

LCMV spatial filter (beamformer weights). Filter weights returned from make_lcmv().

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

mne.beamformer.apply_lcmv_raw

mne.beamformer.make_dics

---

## mne.beamformer.apply_lcmv_raw#

**URL:** https://mne.tools/stable/generated/mne.beamformer.apply_lcmv_raw.html

**Contents:**
- mne.beamformer.apply_lcmv_raw#

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights on raw data.

LCMV spatial filter (beamformer weights). Filter weights returned from make_lcmv().

Index of first time sample (index not time is seconds).

Index of first time sample not to include (index not time is seconds).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.beamformer.apply_lcmv_epochs

mne.beamformer.apply_lcmv_cov

---

## mne.beamformer.Beamformer#

**URL:** https://mne.tools/stable/generated/mne.beamformer.Beamformer.html

**Contents:**
- mne.beamformer.Beamformer#
- Examples using mne.beamformer.Beamformer#

A computed beamformer.

True if the dictionary has the specified key, else False.

Implement iter(self).

fromkeys(iterable[, value])

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

save(fname[, overwrite, verbose])

Save the beamformer filter.

setdefault(key[, default])

Insert key with a value of default if key is not in the dictionary.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

True if the dictionary has the specified key, else False.

Implement iter(self).

A deep copy of the beamformer.

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

Pairs are returned in LIFO (last-in, first-out) order. Raises KeyError if the dict is empty.

Save the beamformer filter.

The filename to use to write the HDF5 data. Should end in '-lcmv.h5' or '-dics.h5'.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Insert key with a value of default if key is not in the dictionary.

Return the value for key if key is in the dictionary, else default.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute cross-talk functions for LCMV beamformers

DICS for power mapping

mne.inverse_sparse.make_stc_from_dipoles

mne.beamformer.read_beamformer

---

## mne.beamformer.make_dics#

**URL:** https://mne.tools/stable/generated/mne.beamformer.make_dics.html

**Contents:**
- mne.beamformer.make_dics#
- Examples using mne.beamformer.make_dics#

Compute a Dynamic Imaging of Coherent Sources (DICS) spatial filter.

This is a beamformer filter that can be used to estimate the source power at a specific frequency range [1]. It does this by constructing a spatial filter for each source point. The computation of these filters is very similar to those of the LCMV beamformer (make_lcmv()), but instead of operating on a covariance matrix, the CSD matrix is used. When applying these filters to a CSD matrix (see apply_dics_csd()), the source power can be estimated for each source point.

The mne.Info object with information about the sensors and methods of measurement.

The data cross-spectral density (CSD) matrices. A source estimate is performed for each frequency or frequency-bin defined in the CSD object.

The regularization to apply to the cross-spectral density before computing the inverse.

Noise cross-spectral density (CSD) matrices. If provided, whitening will be done. The noise CSDs need to have been computed for the same frequencies as the data CSDs. Providing noise CSDs is mandatory if you mix sensor types, e.g. gradiometers with magnetometers or EEG with MEG.

Restricts the solution to a given label.

For forward solutions with fixed orientation, None (default) must be used and a scalar beamformer is computed. For free-orientation forward solutions, a vector beamformer is computed and:

Orientations are pooled after computing a vector beamformer (Default).

Filters are computed for the orientation tangential to the cortical surface.

Filters are computed for the orientation that maximizes power.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

The unit-gain LCMV beamformer [2] will be computed.

The unit-noise gain minimum variance beamformer will be computed (Borgiotti-Kaplan beamformer) [2], which is not rotation invariant when pick_ori='vector'. This should be combined with stc.project('pca') to follow the definition in [2].

The Neural Activity Index [3] will be computed, which simply scales all values from 'unit-noise-gain' by a fixed value.

Compute a rotation-invariant normalization using the matrix square root. This differs from 'unit-noise-gain' only when pick_ori='vector', creating a solution that:

Is rotation invariant ('unit-noise-gain' is not);

Satisfies the first requirement from [2] that w @ w.conj().T == I, whereas 'unit-noise-gain' has non-zero off-diagonals; but

Does not satisfy the second requirement that w @ G.T = θI, which arguably does not make sense for a rotation-invariant solution.

Defaults to None, in which case no normalization is performed.

If True, the rank of the denominator of the beamformer formula (i.e., during pseudo-inversion) will be reduced by one for each spatial location. Setting reduce_rank=True is typically necessary if you use a single sphere model with MEG data.

Changed in version 0.20: Support for reducing rank in all modes (previously only supported pick='max_power' with weight normalization).

How to weight (or normalize) the forward using a depth prior. If float (default 0.8), it acts as the depth weighting exponent (exp) to use None is equivalent to 0, meaning no depth weighting is performed. It can also be a dict containing keyword arguments to pass to mne.forward.compute_depth_prior() (see docstring for details and defaults). This is effectively ignored when method='eLORETA'.

Changed in version 0.20: Depth bias ignored for method='eLORETA'.

If True, take only the real part of the cross-spectral-density matrices to compute real filters.

Changed in version 0.23: Version 0.23 an earlier used real_filter=False as the default, as of version 0.24 True is the default.

This determines how the beamformer deals with source spaces in “free” orientation. Such source spaces define three orthogonal dipoles at each source point. When inversion='single', each dipole is considered as an individual source and the corresponding spatial filter is computed for each dipole separately. When inversion='matrix', all three dipoles at a source vertex are considered as a group and the spatial filters are computed jointly using a matrix inversion. While inversion='single' is more stable, inversion='matrix' is more precise. See section 5 of [4]. Defaults to 'matrix'.

Changed in version 0.21: Default changed to 'matrix'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Dictionary containing filter weights from DICS beamformer. Contains the following keys:

The type of beamformer, in this case ‘DICS’.

For each frequency, the filter weights of the beamformer.

The data cross-spectral density matrices used to compute the beamformer.

Channels used to compute the beamformer.

Projections used to compute the beamformer.

Vertices for which the filter weights were computed.

Number of source location for which the filter weight were computed.

The orientation in which the beamformer filters were computed.

Whether the spatial filters were computed for each dipole separately or jointly for all dipoles at each vertex using a matrix inversion.

The normalization of the weights.

Type of source space.

For each source location, the surface normal.

Whether the filter was computed in a fixed direction (pick_ori=’max-power’, pick_ori=’normal’) or not.

Whitening matrix, provided if whitening was applied to the covariance matrix and leadfield during computation of the beamformer weights.

When pick_ori=’max-power’, this fields contains the estimated direction of maximum power at each source location.

The original reference is [1]. See [4] for a tutorial style paper on the topic.

The DICS beamformer is very similar to the LCMV (make_lcmv()) beamformer and many of the parameters are shared. However, make_dics() and make_lcmv() currently have different defaults for these parameters, which were settled on separately through extensive practical use case testing (but not necessarily exhaustive parameter space searching), and it remains to be seen how functionally interchangeable they could be.

The default setting reproduce the DICS beamformer as described in [4]:

To use the make_lcmv() defaults, use:

For more information about real_filter, see the supplemental information from [5].

Joachim Groß, Jan Kujala, Matti S. Hämäläinen, Lars Timmermann, Alfons Schnitzler, and Riitta Salmelin. Dynamic imaging of coherent sources: studying neural interactions in the human brain. Proceedings of the National Academy of Sciences, 98(2):694–699, 2001. doi:10.1073/pnas.98.2.694.

Kensuke Sekihara and Srikantan S. Nagarajan. Adaptive Spatial Filters for Electromagnetic Brain Imaging. Series in Biomedical Engineering. Springer, Berlin; Heidelberg, 2008. ISBN 978-3-540-79369-4 978-3-540-79370-0. doi:10.1007/978-3-540-79370-0.

Barry D. Van Veen, Wim van Drongelen, Moshe Yuchtman, and Akifumi Suzuki. Localization of brain electrical activity via linearly constrained minimum variance spatial filtering. IEEE Transactions on Biomedical Engineering, 44(9):867–880, 1997. doi:10.1109/10.623056.

Marijn van Vliet, Mia Liljeström, Susanna Aro, Riitta Salmelin, and Jan Kujala. Analysis of functional connectivity and oscillatory power using DICS: from raw MEG data to group-level statistics in Python. bioRxiv, 2018. doi:10.1101/245530.

Joerg F. Hipp, Andreas K. Engel, and Markus Siegel. Oscillatory synchronization in large-scale cortical networks predicts perception. Neuron, 69(2):387–396, 2011. doi:10.1016/j.neuron.2010.12.027.

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

DICS for power mapping

mne.beamformer.apply_lcmv_cov

mne.beamformer.apply_dics

---

## mne.beamformer.make_lcmv#

**URL:** https://mne.tools/stable/generated/mne.beamformer.make_lcmv.html

**Contents:**
- mne.beamformer.make_lcmv#
- Examples using mne.beamformer.make_lcmv#

Compute LCMV spatial filter.

The mne.Info object with information about the sensors and methods of measurement. Specifies the channels to include. Bad channels (in info['bads']) are not used.

The regularization for the whitened data covariance.

The noise covariance. If provided, whitening will be done. Providing a noise covariance is mandatory if you mix sensor types, e.g. gradiometers with magnetometers or EEG with MEG.

If noise_cov is None and weight_norm='unit-noise-gain', the unit noise is assumed to be 1 in SI units, e.g., 1 T for magnetometers, 1 V for EEG, so resulting amplitudes will be tiny. Consider using mne.make_ad_hoc_cov() to provide a noise_cov to set noise values that are more reasonable for neural data or using weight_norm='nai' for weight-normalized beamformer output that is scaled by a noise estimate.

Restricts the LCMV solution to a given label.

For forward solutions with fixed orientation, None (default) must be used and a scalar beamformer is computed. For free-orientation forward solutions, a vector beamformer is computed and:

Orientations are pooled after computing a vector beamformer (Default).

Filters are computed for the orientation tangential to the cortical surface.

Filters are computed for the orientation that maximizes power.

Keeps the currents for each direction separate

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

The default is 'info'.

The unit-gain LCMV beamformer [1] will be computed.

The unit-noise gain minimum variance beamformer will be computed (Borgiotti-Kaplan beamformer) [1], which is not rotation invariant when pick_ori='vector'. This should be combined with stc.project('pca') to follow the definition in [1].

The Neural Activity Index [2] will be computed, which simply scales all values from 'unit-noise-gain' by a fixed value.

Compute a rotation-invariant normalization using the matrix square root. This differs from 'unit-noise-gain' only when pick_ori='vector', creating a solution that:

Is rotation invariant ('unit-noise-gain' is not);

Satisfies the first requirement from [1] that w @ w.conj().T == I, whereas 'unit-noise-gain' has non-zero off-diagonals; but

Does not satisfy the second requirement that w @ G.T = θI, which arguably does not make sense for a rotation-invariant solution.

Defaults to 'unit-noise-gain-invariant'.

If True, the rank of the denominator of the beamformer formula (i.e., during pseudo-inversion) will be reduced by one for each spatial location. Setting reduce_rank=True is typically necessary if you use a single sphere model with MEG data.

Changed in version 0.20: Support for reducing rank in all modes (previously only supported pick='max_power' with weight normalization).

How to weight (or normalize) the forward using a depth prior. If float (default 0.8), it acts as the depth weighting exponent (exp) to use None is equivalent to 0, meaning no depth weighting is performed. It can also be a dict containing keyword arguments to pass to mne.forward.compute_depth_prior() (see docstring for details and defaults). This is effectively ignored when method='eLORETA'.

Changed in version 0.20: Depth bias ignored for method='eLORETA'.

This determines how the beamformer deals with source spaces in “free” orientation. Such source spaces define three orthogonal dipoles at each source point. When inversion='single', each dipole is considered as an individual source and the corresponding spatial filter is computed for each dipole separately. When inversion='matrix', all three dipoles at a source vertex are considered as a group and the spatial filters are computed jointly using a matrix inversion. While inversion='single' is more stable, inversion='matrix' is more precise. See section 5 of [3]. Defaults to 'matrix'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Dictionary containing filter weights from LCMV beamformer. Contains the following keys:

The type of beamformer, in this case ‘LCMV’.

The filter weights of the beamformer.

The data covariance matrix used to compute the beamformer.

The noise covariance matrix used to compute the beamformer.

Whitening matrix, provided if whitening was applied to the covariance matrix and leadfield during computation of the beamformer weights.

Type of weight normalization used to compute the filter weights.

The orientation in which the beamformer filters were computed.

Channels used to compute the beamformer.

Projections used to compute the beamformer.

If True, projections were applied prior to filter computation.

Vertices for which the filter weights were computed.

If True, the filter was computed with free source orientation.

Number of source location for which the filter weight were computed.

Type of source space.

For each source location, the surface normal.

Projections used to compute the beamformer.

The rank of the data covariance matrix used to compute the beamformer weights.

When pick_ori=’max-power’, this fields contains the estimated direction of maximum power at each source location.

Whether the spatial filters were computed for each dipole separately or jointly for all dipoles at each vertex using a matrix inversion.

The original reference is [2].

To obtain the Sekihara unit-noise-gain vector beamformer, you should use weight_norm='unit-noise-gain', pick_ori='vector' followed by vec_stc.project('pca', src).

Changed in version 0.21: The computations were extensively reworked, and the default for weight_norm was set to 'unit-noise-gain-invariant'.

Kensuke Sekihara and Srikantan S. Nagarajan. Adaptive Spatial Filters for Electromagnetic Brain Imaging. Series in Biomedical Engineering. Springer, Berlin; Heidelberg, 2008. ISBN 978-3-540-79369-4 978-3-540-79370-0. doi:10.1007/978-3-540-79370-0.

Barry D. Van Veen, Wim van Drongelen, Moshe Yuchtman, and Akifumi Suzuki. Localization of brain electrical activity via linearly constrained minimum variance spatial filtering. IEEE Transactions on Biomedical Engineering, 44(9):867–880, 1997. doi:10.1109/10.623056.

Marijn van Vliet, Mia Liljeström, Susanna Aro, Riitta Salmelin, and Jan Kujala. Analysis of functional connectivity and oscillatory power using DICS: from raw MEG data to group-level statistics in Python. bioRxiv, 2018. doi:10.1101/245530.

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute cross-talk functions for LCMV beamformers

Source reconstruction using an LCMV beamformer

mne.beamformer.read_beamformer

mne.beamformer.apply_lcmv

---

## mne.beamformer.make_lcmv_resolution_matrix#

**URL:** https://mne.tools/stable/generated/mne.beamformer.make_lcmv_resolution_matrix.html

**Contents:**
- mne.beamformer.make_lcmv_resolution_matrix#
- Examples using mne.beamformer.make_lcmv_resolution_matrix#

Compute resolution matrix for LCMV beamformer.

Dictionary containing filter weights from LCMV beamformer (see mne.beamformer.make_lcmv).

Forward Solution with leadfield matrix.

The mne.Info object with information about the sensors and methods of measurement. Used to compute LCMV filters.

Resolution matrix (filter matrix multiplied to leadfield from forward solution). Numbers of rows (n_dipoles_lcmv) and columns (n_dipoles_fwd) may differ by a factor depending on orientation constraints of filter and forward solution, respectively (e.g. factor 3 for free dipole orientation versus factor 1 for scalar beamformers).

Compute cross-talk functions for LCMV beamformers

mne.beamformer.trap_music

---

## mne.beamformer.rap_music#

**URL:** https://mne.tools/stable/generated/mne.beamformer.rap_music.html

**Contents:**
- mne.beamformer.rap_music#
- Examples using mne.beamformer.rap_music#

RAP-MUSIC source localization method.

Compute Recursively Applied and Projected MUltiple SIgnal Classification (RAP-MUSIC) [1][2] on evoked data.

The goodness of fit (GOF) of all the returned dipoles is the same and corresponds to the GOF of the full set of dipoles.

Evoked data to localize.

The noise covariance.

The number of dipoles to look for. The default value is 5.

If True, the residual is returned as an Evoked instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The residual a.k.a. data not explained by the dipoles. Only returned if return_residual is True.

John C. Mosher and Richard M. Leahy. Source localization using recursively applied and projected (RAP) MUSIC. IEEE Transactions on Signal Processing, 47(2):332–340, 1999. doi:10.1109/78.740118.

J.C. Mosher and R.M. Leahy. EEG and MEG source localization using recursively applied (RAP) MUSIC. In Conference Record of The Thirtieth Asilomar Conference on Signals, Systems and Computers, 1201–1207 vol.2. November 1996. ISSN: 1058-6393. doi:10.1109/ACSSC.1996.599135.

Compute Rap-Music on evoked data

mne.beamformer.apply_dics_tfr_epochs

mne.beamformer.trap_music

---

## mne.beamformer.read_beamformer#

**URL:** https://mne.tools/stable/generated/mne.beamformer.read_beamformer.html

**Contents:**
- mne.beamformer.read_beamformer#

Read a beamformer filter.

The filename of the HDF5 file.

The beamformer filter.

mne.beamformer.Beamformer

mne.beamformer.make_lcmv

---

## mne.beamformer.trap_music#

**URL:** https://mne.tools/stable/generated/mne.beamformer.trap_music.html

**Contents:**
- mne.beamformer.trap_music#
- Examples using mne.beamformer.trap_music#

TRAP-MUSIC source localization method.

Compute Truncated Recursively Applied and Projected MUltiple SIgnal Classification (TRAP-MUSIC) [1] on evoked data.

The goodness of fit (GOF) of all the returned dipoles is the same and corresponds to the GOF of the full set of dipoles.

Evoked data to localize.

The noise covariance.

The number of dipoles to look for. The default value is 5.

If True, the residual is returned as an Evoked instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The residual a.k.a. data not explained by the dipoles. Only returned if return_residual is True.

Niko Mäkelä, Matti Stenroos, Jukka Sarvas, and Risto J. Ilmoniemi. Truncated rap-music (trap-music) for meg and eeg source localization. Neuroimage, 167():73–83, 2018. doi:10.1016/j.neuroimage.2017.11.013.

Compute Trap-Music on evoked data

mne.beamformer.rap_music

mne.beamformer.make_lcmv_resolution_matrix

---

## mne.bem.ConductorModel#

**URL:** https://mne.tools/stable/generated/mne.bem.ConductorModel.html

**Contents:**
- mne.bem.ConductorModel#
- Examples using mne.bem.ConductorModel#

See make_bem_model() and make_bem_solution() to create a mne.bem.ConductorModel.

Sphere radius if an EEG sphere model.

True if the dictionary has the specified key, else False.

Implement iter(self).

Return copy of ConductorModel instance.

fromkeys(iterable[, value])

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

setdefault(key[, default])

Insert key with a value of default if key is not in the dictionary.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

True if the dictionary has the specified key, else False.

Implement iter(self).

Return copy of ConductorModel instance.

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

Pairs are returned in LIFO (last-in, first-out) order. Raises KeyError if the dict is empty.

Sphere radius if an EEG sphere model.

Insert key with a value of default if key is not in the dictionary.

Return the value for key if key is in the dictionary, else default.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

Computing source timecourses with an XFit-like multi-dipole model

Source alignment and coordinate frames

Head model and forward computation

EEG forward operator with a template MRI

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

Setting the EEG reference

mne.bem.fit_sphere_to_headshape

---

## mne.bem.convert_flash_mris#

**URL:** https://mne.tools/stable/generated/mne.bem.convert_flash_mris.html

**Contents:**
- mne.bem.convert_flash_mris#

Synthesize the flash 5 files for use with make_flash_bem.

This function aims to produce a synthesized flash 5 MRI from multiecho flash (MEF) MRI data. This function can use MEF data with 5 or 30 flip angles. If flash5 (and flash30) images are not explicitly provided, it will assume that the different echos are available in the mri/flash folder of the subject with the following naming convention “mef<angle>_<echo>.mgz”, e.g. “mef05_001.mgz” or “mef30_001.mgz”.

The FreeSurfer subject name.

If False do not use 30-degree flip angle data. The list of flash 5 echos to use. If True it will look for files named mef30_*.mgz in the subject’s mri/flash directory and if not False the list of flash 5 echos images will be written to the mri/flash folder with convention mef05_<echo>.mgz. If a SpatialImage object each frame of the image will be interpreted as an echo.

Run grad_unwarp with -unwarp option on each of the converted data sets. It requires FreeSurfer’s MATLAB toolbox to be properly installed.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The list of flash 5 echos to use. If True it will look for files named mef05_*.mgz in the subject’s mri/flash directory and if not None the list of flash 5 echos images will be written to the mri/flash folder with convention mef05_<echo>.mgz. If a SpatialImage object each frame of the image will be interpreted as an echo.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The path the synthesized flash 5 MRI.

This function assumes that the Freesurfer segmentation of the subject has been completed. In particular, the T1.mgz and brain.mgz MRI volumes should be, as usual, in the subject’s mri directory.

mne.bem.make_scalp_surfaces

mne.bem.distance_to_bem

---

## mne.bem.distance_to_bem#

**URL:** https://mne.tools/stable/generated/mne.bem.distance_to_bem.html

**Contents:**
- mne.bem.distance_to_bem#

Calculate the distance of positions to inner skull surface.

Position(s) in m, in head coordinates.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation. If trans is None, an identity matrix is assumed. If None (default), assumes bem is in head coordinates.

Changed in version 0.19: Support for ‘fsaverage’ argument.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The computed distance(s). A float is returned if pos is an array of shape (3,) corresponding to a single position.

mne.bem.convert_flash_mris

---

## mne.bem.fit_sphere_to_headshape#

**URL:** https://mne.tools/stable/generated/mne.bem.fit_sphere_to_headshape.html

**Contents:**
- mne.bem.fit_sphere_to_headshape#

Fit a sphere to the headshape points to determine head center.

The mne.Info object with information about the sensors and methods of measurement.

Kind of digitization points to use in the fitting. These can be any combination of (‘cardinal’, ‘hpi’, ‘eeg’, ‘extra’). Can also be ‘auto’ (default), which will use only the ‘extra’ points if enough (more than 4) are available, and if not, uses ‘extra’ and ‘eeg’ points.

Can be "m" (default) or "mm".

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Head center in head coordinates.

Head center in device coordinates.

This function excludes any points that are low and frontal (z < 0 and y > 0) to improve the fit.

mne.bem.ConductorModel

mne.bem.get_fitting_dig

---

## mne.bem.get_fitting_dig#

**URL:** https://mne.tools/stable/generated/mne.bem.get_fitting_dig.html

**Contents:**
- mne.bem.get_fitting_dig#

Get digitization points suitable for sphere fitting.

The mne.Info object with information about the sensors and methods of measurement.

Kind of digitization points to use in the fitting. These can be any combination of (‘cardinal’, ‘hpi’, ‘eeg’, ‘extra’). Can also be ‘auto’ (default), which will use only the ‘extra’ points if enough (more than 4) are available, and if not, uses ‘extra’ and ‘eeg’ points.

If True, exclude points that have both negative Z values (below the nasion) and positive Y values (in front of the LPA/RPA). Default is True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The digitization points (in head coordinates) to use for fitting.

This will exclude digitization locations that have z < 0 and y > 0, i.e. points on the nose and below the nose on the face.

mne.bem.fit_sphere_to_headshape

mne.bem.make_watershed_bem

---

## mne.bem.make_flash_bem#

**URL:** https://mne.tools/stable/generated/mne.bem.make_flash_bem.html

**Contents:**
- mne.bem.make_flash_bem#

Create 3-Layer BEM model from prepared flash MRI images.

See Using FLASH images for additional information.

The FreeSurfer subject name.

Write over existing .surf files in bem folder.

Show surfaces to visually inspect all three BEM surfaces (recommended).

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

If True (default), use copies instead of symlinks for surfaces (if they do not already exist).

Changed in version 1.1: Use copies instead of symlinks.

The path to the synthesized flash 5 MRI image or the image itself. If None (default), the path defaults to mri/flash/parameter_maps/flash5.mgz within the subject reconstruction. If not present the image is copied or written to the default location.

Register the flash 5 image with T1.mgz file. If False, we assume that the images are already coregistered.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

This program assumes that FreeSurfer is installed and sourced properly.

This function extracts the BEM surfaces (outer skull, inner skull, and outer skin) from a FLASH 5 MRI image synthesized from multiecho FLASH images acquired with spin angles of 5 and 30 degrees.

mne.bem.make_watershed_bem

mne.bem.make_scalp_surfaces

---

## mne.bem.make_scalp_surfaces#

**URL:** https://mne.tools/stable/generated/mne.bem.make_scalp_surfaces.html

**Contents:**
- mne.bem.make_scalp_surfaces#

Create surfaces of the scalp and neck.

The scalp surfaces are required for using the MNE coregistration GUI, and allow for a visualization of the alignment between anatomy and channel locations.

The FreeSurfer subject name.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Force creation of the surface even if it has some topological defects. Defaults to True. See Fixing BEM and head surfaces for ideas on how to fix problematic meshes.

If True (default False), overwrite the destination file if it exists.

Disable the “medium” and “sparse” decimations. In this case, only a “dense” surface will be generated. Defaults to False, i.e., create surfaces for all three types of decimations.

The threshold to use with the MRI in the call to mkheadsurf. The default is 20.

The MRI to use. Should exist in $SUBJECTS_DIR/$SUBJECT/mri.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.bem.make_flash_bem

mne.bem.convert_flash_mris

---

## mne.bem.make_watershed_bem#

**URL:** https://mne.tools/stable/generated/mne.bem.make_watershed_bem.html

**Contents:**
- mne.bem.make_watershed_bem#

Create BEM surfaces using the FreeSurfer watershed algorithm.

See Using the watershed algorithm for additional information.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

If True (default False), overwrite the destination file if it exists.

Specify the --atlas option for mri_watershed.

Specify the --brain_atlas option for mri_watershed.

Change the preflood height.

Show surfaces to visually inspect all three BEM surfaces (recommended).

If True (default), use copies instead of symlinks for surfaces (if they do not already exist).

Changed in version 1.1: Use copies instead of symlinks.

If True, pass the -T1 flag. By default (None), this takes the same value as gcaatlas.

The filename for the brainmask output file relative to the $SUBJECTS_DIR/$SUBJECT/bem/watershed/ directory. Can be for example "../../mri/brainmask.mgz" to overwrite the brainmask obtained via recon-all -autorecon1.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

If your BEM meshes do not look correct when viewed in mne.viz.plot_alignment() or mne.viz.plot_bem(), consider potential solutions from the FAQ.

mne.bem.get_fitting_dig

mne.bem.make_flash_bem

---

## mne.BiHemiLabel#

**URL:** https://mne.tools/stable/generated/mne.BiHemiLabel.html

**Contents:**
- mne.BiHemiLabel#

A freesurfer/MNE label with vertices in both hemispheres.

Label for the left hemisphere.

Label for the right hemisphere.

Label color and alpha (e.g., (1., 0., 0., 1.) for red). Note that due to file specification limitations, the color isn’t saved to or loaded from files written to disk.

Label for the left hemisphere.

Label for the right hemisphere.

A name for the label. It is OK to change that attribute manually.

The name of the subject.

Return the number of vertices.

Return the number of vertices.

The number of vertices.

---

## mne.channels.compute_dev_head_t#

**URL:** https://mne.tools/stable/generated/mne.channels.compute_dev_head_t.html

**Contents:**
- mne.channels.compute_dev_head_t#

Compute device to head transform from a DigMontage.

The DigMontage must contain the fiducials in head coordinate system and hpi points in both head and meg device coordinate system.

A Device-to-Head transformation matrix.

mne.channels.transform_to_head

mne.channels.read_layout

---

## mne.channels.compute_native_head_t#

**URL:** https://mne.tools/stable/generated/mne.channels.compute_native_head_t.html

**Contents:**
- mne.channels.compute_native_head_t#
- Examples using mne.channels.compute_native_head_t#

Compute the native-to-head transformation for a montage.

This uses the fiducials in the native space to transform to compute the transform to the head coordinate frame.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when some necessary fiducial points are missing.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A native-to-head transformation matrix.

Working with sEEG data

EEG forward operator with a template MRI

EEG source localization given electrode locations on an MRI

mne.channels.DigMontage

mne.channels.fix_mag_coil_types

---

## mne.channels.DigMontage#

**URL:** https://mne.tools/stable/generated/mne.channels.DigMontage.html

**Contents:**
- mne.channels.DigMontage#
- Examples using mne.channels.DigMontage#

Montage for digitized electrode and headshape position data.

Montages are typically created using one of the helper functions in the See Also section below instead of instantiating this class directly.

The object containing all the dig points.

The names of the EEG channels.

add_estimated_fiducials(subject[, ...])

Estimate fiducials based on FreeSurfer fsaverage subject.

add_mni_fiducials([subjects_dir, verbose])

Add fiducials to a montage in MNI space.

apply_trans(trans[, verbose])

Apply a transformation matrix to the montage.

Copy the DigMontage object.

Get all channel and fiducial positions.

plot(*[, scale, show_names, kind, show, ...])

remove_fiducials([verbose])

Remove the fiducial points from a montage.

rename_channels(mapping[, allow_duplicates, ...])

save(fname, *[, overwrite, verbose])

Save digitization points to FIF.

Estimate fiducials based on FreeSurfer fsaverage subject.

This takes a montage with the mri coordinate frame, corresponding to the FreeSurfer RAS (xyz in the volume) T1w image of the specific subject. It will call mne.coreg.get_mni_fiducials() to estimate LPA, RPA and Nasion fiducial points.

The FreeSurfer subject name.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

Since MNE uses the FIF data structure, it relies on the head coordinate frame. Any coordinate frame can be transformed to head if the fiducials (i.e. LPA, RPA and Nasion) are defined. One can use this function to estimate those fiducials and then use mne.channels.compute_native_head_t(montage) to get the head <-> MRI transform.

Add fiducials to a montage in MNI space.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

fsaverage is in MNI space and so its fiducials can be added to a montage in “mni_tal”. MNI is an ACPC-aligned coordinate system (the posterior commissure is the origin) so since BIDS requires channel locations for ECoG, sEEG and DBS to be in ACPC space, this function can be used to allow those coordinate to be transformed to “head” space (origin between LPA and RPA).

Examples using add_mni_fiducials:

Working with ECoG data

Apply a transformation matrix to the montage.

The transformation matrix to be applied.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Examples using apply_trans:

How to convert 3D electrode positions to a 2D image

Working with sEEG data

Copy the DigMontage object.

The copied DigMontage instance.

Get all channel and fiducial positions.

A dictionary of the positions for channels (ch_pos), coordinate frame (coord_frame), nasion (nasion), left preauricular point (lpa), right preauricular point (rpa), Head Shape Polhemus (hsp), and Head Position Indicator(hpi). E.g.:

Examples using get_positions:

Working with ECoG data

Determines the scale of the channel points and labels; values < 1 will scale down, whereas values > 1 will scale up.

Whether to display all channel names. If a list, only the channel names in the list are shown. Defaults to True.

Whether to plot the montage as ‘3d’ or ‘topomap’ (default).

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Working with sensor locations

EEG source localization given electrode locations on an MRI

Remove the fiducial points from a montage.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

MNE will transform a montage to the internal “head” coordinate frame if the fiducials are present. Under most circumstances, this is ideal as it standardizes the coordinate frame for things like plotting. However, in some circumstances, such as saving a raw with intracranial data to BIDS format, the coordinate frame should not be changed by removing fiducials.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance. Operates in-place.

Examples using rename_channels:

EEG forward operator with a template MRI

Save digitization points to FIF.

The filename to use. Should end in -dig.fif or -dig.fif.gz.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Changed in version 1.9: Added support for saving the associated channel names.

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Receptive Field Estimation and Prediction

Identify EEG Electrodes Bridged by too much Gel

Interpolate EEG data to any montage

Removing muscle ICA components

How to convert 3D electrode positions to a 2D image

Working with sEEG data

Working with ECoG data

EEG forward operator with a template MRI

Working with sensor locations

EEG source localization given electrode locations on an MRI

Importing data from fNIRS devices

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

mne.channels.compute_native_head_t

---

## mne.channels.find_ch_adjacency#

**URL:** https://mne.tools/stable/generated/mne.channels.find_ch_adjacency.html

**Contents:**
- mne.channels.find_ch_adjacency#
- Examples using mne.channels.find_ch_adjacency#

Find the adjacency matrix for the given channels.

This function tries to infer the appropriate adjacency matrix template for the given channels. If a template is not found, the adjacency matrix is computed using Delaunay triangulation based on 2D sensor locations.

The mne.Info object with information about the sensors and methods of measurement.

The channel type for computing the adjacency matrix. Currently supports 'mag', 'grad', 'eeg' and None. If None, the info must contain only one channel type.

The adjacency matrix.

The list of channel names present in adjacency matrix.

Automatic detection of an appropriate adjacency matrix template only works for MEG data at the moment. This means that the adjacency matrix is always computed for EEG data and never loaded from a template file. If you want to load a template for a given montage use read_ch_adjacency() directly.

If Delaunay triangulation is used to calculate the adjacency matrix it may yield partially unexpected results (e.g., include unwanted edges between non-adjacent sensors). Therefore, it is recommended to check (and, if necessary, manually modify) the result by inspecting it via mne.viz.plot_ch_adjacency().

Note that depending on your use case, you may need to additionally use mne.stats.combine_adjacency() to prepare a final “adjacency” to pass to the eventual function.

Visualising statistical significance thresholds on EEG data

Non-parametric 1 sample cluster statistic on single trial power

Spatiotemporal permutation F-test on full sensor data

mne.channels.make_grid_layout

mne.channels.get_builtin_ch_adjacencies

---

## mne.channels.find_layout#

**URL:** https://mne.tools/stable/generated/mne.channels.find_layout.html

**Contents:**
- mne.channels.find_layout#

Choose a layout based on the channels in the info ‘chs’ field.

The mne.Info object with information about the sensors and methods of measurement.

The channel type for selecting single channel layouts. Defaults to None. Note, this argument will only be considered for VectorView type layout. Use 'meg' to force using the full layout in situations where the info does only contain one sensor type.

List of channels to exclude. If empty do not exclude any. If ‘bads’, exclude channels in info[‘bads’] (default).

None if layout not found.

mne.channels.read_layout

mne.channels.make_eeg_layout

---

## mne.channels.fix_mag_coil_types#

**URL:** https://mne.tools/stable/generated/mne.channels.fix_mag_coil_types.html

**Contents:**
- mne.channels.fix_mag_coil_types#

Fix magnetometer coil types.

The mne.Info object with information about the sensors and methods of measurement. Corrections are done in-place.

If True, further refine the check for old coil types by checking info['chs'][ii]['cal'].

This function changes magnetometer coil types 3022 (T1: SQ20483N) and 3023 (T2: SQ20483-A) to 3024 (T3: SQ20950N) in the channel definition records in the info structure.

Neuromag Vectorview systems can contain magnetometers with two different coil sizes (3022 and 3023 vs. 3024). The systems incorporating coils of type 3024 were introduced last and are used at the majority of MEG sites. At some sites with 3024 magnetometers, the data files have still defined the magnetometers to be of type 3022 to ensure compatibility with older versions of Neuromag software. In the MNE software as well as in the present version of Neuromag software coil type 3024 is fully supported. Therefore, it is now safe to upgrade the data files to use the true coil type.

The effect of the difference between the coil sizes on the current estimates computed by the MNE software is very small. Therefore the use of fix_mag_coil_types is not mandatory.

mne.channels.compute_native_head_t

mne.channels.read_polhemus_fastscan

---

## mne.channels.generate_2d_layout#

**URL:** https://mne.tools/stable/generated/mne.channels.generate_2d_layout.html

**Contents:**
- mne.channels.generate_2d_layout#

Generate a custom 2D layout from xy points.

Generates a 2-D layout for plotting with plot_topo methods and functions. XY points will be normalized between 0 and 1, where normalization extremes will be either the min/max of xy, or the width/height of bg_image.

The xy coordinates of sensor locations.

The width of each sensor’s axis (between 0 and 1).

The height of each sensor’s axis (between 0 and 1).

Portion of the box to reserve for padding. The value can range between 0.0 (boxes will touch, default) to 1.0 (boxes consist of only padding).

The names of each channel. Must be a list of strings, with one string per channel.

Index of each channel - must be a collection of unique integers, one index per channel.

The name of this layout type.

The image over which sensor axes will be plotted. Either a path to an image file, or an array that can be plotted with plt.imshow. If provided, xy points will be normalized by the width/height of this image. If not, xy points will be normalized by their own min/max.

Whether to normalize the coordinates to run from 0 to 1. Defaults to True.

A Layout object that can be plotted with plot_topo functions and methods.

mne.channels.rename_channels

mne.channels.make_1020_channel_selections

---

## mne.channels.get_builtin_ch_adjacencies#

**URL:** https://mne.tools/stable/generated/mne.channels.get_builtin_ch_adjacencies.html

**Contents:**
- mne.channels.get_builtin_ch_adjacencies#
- Examples using mne.channels.get_builtin_ch_adjacencies#

Get a list of all FieldTrip neighbor definitions shipping with MNE.

The names of the these neighbor definitions can be passed to read_ch_adjacency().

Whether to return not only the neighbor definition names, but also their corresponding descriptions. If True, a list of tuples is returned, where the first tuple element is the neighbor definition name and the second is the description. If False (default), only the names are returned.

If descriptions=False, the names of all builtin FieldTrip neighbor definitions that can be loaded directly via read_ch_adjacency().

If descriptions=True, a list of tuples (name, description).

Statistical inference

mne.channels.find_ch_adjacency

mne.channels.read_ch_adjacency

---

## mne.channels.get_builtin_montages#

**URL:** https://mne.tools/stable/generated/mne.channels.get_builtin_montages.html

**Contents:**
- mne.channels.get_builtin_montages#
- Examples using mne.channels.get_builtin_montages#

Get a list of all standard montages shipping with MNE-Python.

The names of the montages can be passed to make_standard_montage().

Whether to return not only the montage names, but also their corresponding descriptions. If True, a list of tuples is returned, where the first tuple element is the montage name and the second is the montage description. If False (default), only the names are returned.

If descriptions=False, the names of all builtin montages that can be used by make_standard_montage().

If descriptions=True, a list of tuples (name, description).

Working with sensor locations

mne.channels.read_polhemus_fastscan

mne.channels.make_dig_montage

---

## mne.channels.Layout#

**URL:** https://mne.tools/stable/generated/mne.channels.Layout.html

**Contents:**
- mne.channels.Layout#
- Examples using mne.channels.Layout#

Layouts are typically loaded from a file using read_layout(). Only use this class directly if you’re constructing a new layout.

The box dimension (x_min, x_max, y_min, y_max).

The unit-normalized positions of the channels in 2d (x, y, width, height).

The type of Layout (e.g. ‘Vectorview-all’).

Return a copy of the layout.

pick([picks, exclude, verbose])

Pick a subset of channels.

plot([picks, show_axes, show])

Plot the sensor positions.

save(fname[, overwrite])

Return a copy of the layout.

A deepcopy of the layout.

Pick a subset of channels.

Channels to include in the layout. Slices and lists of integers will be interpreted as channel indices. Can also be the string value 'all' to pick all channels. None (default) will pick all channels.

Set of channels to exclude, only used when picks is set to 'all' or None. Exclude will not drop channels explicitly provided in picks.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Plot the sensor positions.

Channels to include. Slices and lists of integers will be interpreted as channel indices. None (default) will pick all channels. Note that channels in info['bads'] will be included if their indices are explicitly provided.

Show layout axes if True. Defaults to False.

Show figure if True. Defaults to True.

Figure containing the sensor topography.

Working with sensor locations

The file name (must end with either .lout or .lay).

If True, overwrites the destination file if it exists.

Working with sensor locations

How to convert 3D electrode positions to a 2D image

Visualizing epoched data

Working with sensor locations

mne.channels.DigMontage

---

## mne.channels.make_1020_channel_selections#

**URL:** https://mne.tools/stable/generated/mne.channels.make_1020_channel_selections.html

**Contents:**
- mne.channels.make_1020_channel_selections#
- Examples using mne.channels.make_1020_channel_selections#

Map hemisphere names to corresponding EEG channel names or indices.

This function uses a simple heuristic to separate channel names into three Region of Interest-based selections: Left, Midline and Right.

The heuristic is that any of the channel names ending with odd numbers are filed under Left; those ending with even numbers are filed under Right; and those ending with the character(s) specified in midline are filed under Midline. Other channels are ignored.

This is appropriate for 10/20, 10/10, 10/05, …, sensor arrangements, but not for other naming conventions.

The mne.Info object with information about the sensors and methods of measurement. If channel locations are present, the channel lists will be sorted from posterior to anterior; otherwise, the order specified in info["ch_names"] will be kept.

Names ending in any of these characters are stored under the Midline key. Defaults to 'z'. Capitalization is ignored.

Whether to return channel names instead of channel indices.

A dictionary mapping from region of interest name to a list of channel indices (if return_ch_names=False) or to a list of channel names (if return_ch_names=True).

Using contralateral referencing for EEG

Plot single trial activity, grouped by ROI and sorted by RT

Visualising statistical significance thresholds on EEG data

mne.channels.generate_2d_layout

mne.channels.combine_channels

---

## mne.channels.make_dig_montage#

**URL:** https://mne.tools/stable/generated/mne.channels.make_dig_montage.html

**Contents:**
- mne.channels.make_dig_montage#

Make montage from arrays.

Dictionary of channel positions. Keys are channel names and values are 3D coordinates - array of shape (3,) - in native digitizer space in m.

The position of the nasion fiducial point. This point is assumed to be in the native digitizer space in m.

The position of the left periauricular fiducial point. This point is assumed to be in the native digitizer space in m.

The position of the right periauricular fiducial point. This point is assumed to be in the native digitizer space in m.

This corresponds to an array of positions of the headshape points in 3d. These points are assumed to be in the native digitizer space in m.

This corresponds to an array of HPI points in the native digitizer space. They only necessary if computation of a compute_dev_head_t is True.

The coordinate frame of the points. Usually this is 'unknown' for native digitizer space. Other valid values are: 'head', 'meg', 'mri', 'mri_voxel', 'mni_tal', 'ras', 'fs_tal', 'ctf_head', and 'ctf_meg'.

For custom montages without fiducials, this parameter must be set to 'head'.

mne.channels.get_builtin_montages

mne.channels.read_dig_polhemus_isotrak

---

## mne.channels.make_eeg_layout#

**URL:** https://mne.tools/stable/generated/mne.channels.make_eeg_layout.html

**Contents:**
- mne.channels.make_eeg_layout#
- Examples using mne.channels.make_eeg_layout#

Make a Layout object based on EEG electrode digitization.

The mne.Info object with information about the sensors and methods of measurement.

Viewport radius as a fraction of main figure height. Defaults to 0.5.

Width of sensor axes as a fraction of main figure height. By default, this will be the maximum width possible without axes overlapping.

Height of sensor axes as a fraction of main figure height. By default, this will be the maximum height possible without axes overlapping.

List of channels to exclude. If empty do not exclude any. If ‘bads’, exclude channels in info[‘bads’] (default).

Whether the channels contain current-source-density-transformed data.

The generated Layout.

Working with sensor locations

mne.channels.find_layout

mne.channels.make_grid_layout

---

## mne.channels.make_grid_layout#

**URL:** https://mne.tools/stable/generated/mne.channels.make_grid_layout.html

**Contents:**
- mne.channels.make_grid_layout#

Make a grid Layout object.

This can be helpful to plot custom data such as ICA sources.

The mne.Info object with information about the sensors and methods of measurement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all good misc channels.

Number of columns to generate. If None, a square grid will be produced.

The generated layout.

mne.channels.make_eeg_layout

mne.channels.find_ch_adjacency

---

## mne.channels.make_standard_montage#

**URL:** https://mne.tools/stable/generated/mne.channels.make_standard_montage.html

**Contents:**
- mne.channels.make_standard_montage#
- Examples using mne.channels.make_standard_montage#

Read a generic (built-in) standard montage that ships with MNE-Python.

The name of the montage to use.

You can retrieve the names of all built-in montages via mne.channels.get_builtin_montages().

The head size (radius, in meters) to use for spherical montages. Can be None to not scale the read sizes. 'auto' (default) will use 95mm for all montages except the 'standard*', 'mgh*', and 'artinis*', which are already in fsaverage’s MRI coordinates (same as MNI).

Individualized (digitized) electrode positions should be read in using read_dig_captrak(), read_dig_curry(), read_dig_egi(), read_dig_fif(), read_dig_polhemus_isotrak(), read_dig_hpts(), or manually made with make_dig_montage().

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Receptive Field Estimation and Prediction

Identify EEG Electrodes Bridged by too much Gel

Interpolate EEG data to any montage

Removing muscle ICA components

Plotting sensor layouts of EEG systems

EEG forward operator with a template MRI

Working with sensor locations

Importing data from fNIRS devices

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

mne.channels.read_dig_localite

mne.channels.read_custom_montage

---

## mne.channels.read_ch_adjacency#

**URL:** https://mne.tools/stable/generated/mne.channels.read_ch_adjacency.html

**Contents:**
- mne.channels.read_ch_adjacency#

Read a channel adjacency (“neighbors”) file that ships with MNE.

More information on these neighbor definitions can be found on the related FieldTrip documentation pages.

The path to the file to load, or the name of a channel adjacency matrix that ships with MNE-Python.

You can retrieve the names of all built-in channel adjacencies via mne.channels.get_builtin_ch_adjacencies().

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The adjacency matrix.

The list of channel names present in adjacency matrix.

If the neighbor definition you need is not shipped by MNE-Python, you may use find_ch_adjacency() to compute the adjacency matrix based on your 2D sensor locations.

Note that depending on your use case, you may need to additionally use mne.stats.combine_adjacency() to prepare a final “adjacency” to pass to the eventual function.

mne.channels.get_builtin_ch_adjacencies

mne.channels.equalize_channels

---

## mne.channels.read_custom_montage#

**URL:** https://mne.tools/stable/generated/mne.channels.read_custom_montage.html

**Contents:**
- mne.channels.read_custom_montage#
- Examples using mne.channels.read_custom_montage#

Read a montage from a file.

File extension is expected to be: '.loc' or '.locs' or '.eloc' (for EEGLAB files), '.sfp' (BESA/EGI files), '.csd', '.elc', '.txt', '.csd', '.elp' (BESA spherical), '.bvef' (BrainVision files), '.csv', '.tsv', '.xyz' (XYZ coordinates).

The size of the head (radius, in [m]). If None, returns the values read from the montage file with no modification. Defaults to 0.095m.

The coordinate frame of the points. Usually this is "unknown" for native digitizer space. Defaults to None, which is "unknown" for most readers but "head" for EEGLAB.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The function is a helper to read electrode positions you may have in various formats. Most of these format are weakly specified in terms of units, coordinate systems. It implies that setting a montage using a DigMontage produced by this function may be problematic. If you use a standard/template (eg. 10/20, 10/10 or 10/05) we recommend you use make_standard_montage(). If you can have positions in memory you can also use make_dig_montage() that takes arrays as input.

EEG source localization given electrode locations on an MRI

mne.channels.make_standard_montage

mne.channels.transform_to_head

---

## mne.channels.read_dig_captrak#

**URL:** https://mne.tools/stable/generated/mne.channels.read_dig_captrak.html

**Contents:**
- mne.channels.read_dig_captrak#

Read electrode locations from CapTrak Brain Products system.

BrainVision CapTrak coordinates file from which to read EEG electrode locations. This is typically in XML format with the .bvct extension.

mne.channels.read_dig_polhemus_isotrak

mne.channels.read_dig_dat

---

## mne.channels.read_dig_curry#

**URL:** https://mne.tools/stable/generated/mne.channels.read_dig_curry.html

**Contents:**
- mne.channels.read_dig_curry#

Read electrode locations from Neuroscan Curry files.

mne.channels.read_dig_dat

mne.channels.read_dig_egi

---

## mne.channels.read_dig_dat#

**URL:** https://mne.tools/stable/generated/mne.channels.read_dig_dat.html

**Contents:**
- mne.channels.read_dig_dat#

LEGACY: New code should use read_dig_curry().

Read electrode positions from a *.dat file.

This function was implemented based on *.dat files available from Compumedics and might not work as expected with novel files. If it does not read your files correctly please contact the MNE-Python developers.

File from which to read electrode locations.

*.dat files are plain text files and can be inspected and amended with a plain text editor.

mne.channels.read_dig_captrak

mne.channels.read_dig_curry

---

## mne.channels.read_dig_egi#

**URL:** https://mne.tools/stable/generated/mne.channels.read_dig_egi.html

**Contents:**
- mne.channels.read_dig_egi#

Read electrode locations from EGI system.

EGI MFF XML coordinates file from which to read digitization locations.

mne.channels.read_dig_curry

mne.channels.read_dig_fif

---

## mne.channels.read_dig_fif#

**URL:** https://mne.tools/stable/generated/mne.channels.read_dig_fif.html

**Contents:**
- mne.channels.read_dig_fif#
- Examples using mne.channels.read_dig_fif#

Read digitized points from a .fif file.

FIF file from which to read digitization locations.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Changed in version 1.9: Added support for reading the associated channel names, if present.

In some files, electrode names are not present (e.g., in older files). For those files, the channel names are defined with the convention from VectorView systems (EEG001, EEG002, etc.).

EEG forward operator with a template MRI

mne.channels.read_dig_egi

mne.channels.read_dig_hpts

---

## mne.channels.read_dig_hpts#

**URL:** https://mne.tools/stable/generated/mne.channels.read_dig_hpts.html

**Contents:**
- mne.channels.read_dig_hpts#

Read historical .hpts MNE-C files.

The filepath of .hpts file.

Unit of the positions. Defaults to 'mm'.

The hpts format digitzer data file may contain comment lines starting with the pound sign (#) and data lines of the form:

defines the type of points. Allowed categories are: hpi, cardinal (fiducial), eeg, and extra corresponding to head-position indicator coil locations, cardinal landmarks, EEG electrode locations, and additional head surface points, respectively.

identifies the point. The identifiers are usually sequential numbers. For cardinal landmarks, 1 = left auricular point, 2 = nasion, and 3 = right auricular point. For EEG electrodes, identifier = 0 signifies the reference electrode.

Location of the point, usually in the head coordinate system in millimeters. If your points are in [m] then unit parameter can be changed.

mne.channels.read_dig_fif

mne.channels.read_dig_localite

---

## mne.channels.read_dig_localite#

**URL:** https://mne.tools/stable/generated/mne.channels.read_dig_localite.html

**Contents:**
- mne.channels.read_dig_localite#

Read Localite .csv file.

Name of nasion fiducial point.

Name of left preauricular fiducial point.

Name of right preauricular fiducial point.

mne.channels.read_dig_hpts

mne.channels.make_standard_montage

---

## mne.channels.read_dig_polhemus_isotrak#

**URL:** https://mne.tools/stable/generated/mne.channels.read_dig_polhemus_isotrak.html

**Contents:**
- mne.channels.read_dig_polhemus_isotrak#

Read Polhemus digitizer data from a file.

The filepath of Polhemus ISOTrak formatted file. File extension is expected to be '.hsp', '.elp' or '.eeg'.

The names of the points. This will make the points considered as EEG channels. If None, channels will be assumed to be HPI if the extension is '.elp', and extra headshape points otherwise.

Unit of the digitizer file. Polhemus ISOTrak systems data is usually exported in meters. Defaults to 'm'.

mne.channels.make_dig_montage

mne.channels.read_dig_captrak

---

## mne.channels.read_layout#

**URL:** https://mne.tools/stable/generated/mne.channels.read_layout.html

**Contents:**
- mne.channels.read_layout#
- Examples using mne.channels.read_layout#

Read layout from a file.

Either the path to a .lout or .lay file or the name of a built-in layout. See Notes for a list of the available built-in layouts.

Apply useful scaling for out the box plotting using layout.pos. Defaults to True.

Valid fname arguments are:

How to convert 3D electrode positions to a 2D image

Working with sensor locations

mne.channels.compute_dev_head_t

mne.channels.find_layout

---

## mne.channels.read_polhemus_fastscan#

**URL:** https://mne.tools/stable/generated/mne.channels.read_polhemus_fastscan.html

**Contents:**
- mne.channels.read_polhemus_fastscan#

Read Polhemus FastSCAN digitizer data from a .txt file.

The path of .txt Polhemus FastSCAN file.

Unit of the digitizer file. Polhemus FastSCAN systems data is usually exported in millimeters. Defaults to 'mm'.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when the FastSCAN header is missing.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The digitization points in digitizer coordinates.

mne.channels.fix_mag_coil_types

mne.channels.get_builtin_montages

---

## mne.channels.rename_channels#

**URL:** https://mne.tools/stable/generated/mne.channels.rename_channels.html

**Contents:**
- mne.channels.rename_channels#

The mne.Info object with information about the sensors and methods of measurement. Note: modified in place.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.channels.unify_bad_channels

mne.channels.generate_2d_layout

---

## mne.channels.transform_to_head#

**URL:** https://mne.tools/stable/generated/mne.channels.transform_to_head.html

**Contents:**
- mne.channels.transform_to_head#

Transform a DigMontage object into head coordinate.

A copy of the montage after transforming the points to head coordinate system.

This function requires that the LPA, RPA and Nasion fiducial points are available. If they are not, they will be added based by projecting the fiducials onto a sphere with radius equal to the average distance of each point to the origin (in the given coordinate frame).

This function assumes that all fiducial points are in the same coordinate frame (e.g. ‘unknown’) and it will convert all the point in this coordinate system to Neuromag head coordinate system.

Changed in version 1.2: Fiducial points will be added automatically if the montage does not have them.

mne.channels.read_custom_montage

mne.channels.compute_dev_head_t

---

## mne.channel_indices_by_type#

**URL:** https://mne.tools/stable/generated/mne.channel_indices_by_type.html

**Contents:**
- mne.channel_indices_by_type#
- Examples using mne.channel_indices_by_type#

Get indices of channels by type.

The mne.Info object with information about the sensors and methods of measurement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=”bads” when picks=”meg”).

A dictionary that maps each channel type to a (possibly empty) list of channel indices.

The Info data structure

---

## mne.channel_type#

**URL:** https://mne.tools/stable/generated/mne.channel_type.html

**Contents:**
- mne.channel_type#
- Examples using mne.channel_type#

The mne.Info object with information about the sensors and methods of measurement.

Type of channel. Will be one of:

The Info data structure

mne.channel_indices_by_type

---

## mne.chpi.compute_chpi_amplitudes#

**URL:** https://mne.tools/stable/generated/mne.chpi.compute_chpi_amplitudes.html

**Contents:**
- mne.chpi.compute_chpi_amplitudes#
- Examples using mne.chpi.compute_chpi_amplitudes#

Compute time-varying cHPI amplitudes.

Raw data with cHPI information.

Minimum time step to use.

Time window to use to estimate the amplitudes, default is 0.2 (200 ms).

The external order for SSS-like interfence suppression. The SSS bases are used as projection vectors during fitting.

Changed in version 0.20: Added ext_order=1 by default, which should improve detection of true HPI signals.

Start time of the raw data to use in seconds (must be >= 0).

End time of the raw data to use in seconds (cannot exceed data duration). If None (default), the current end of the data is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The time-varying cHPI coil amplitudes, with entries “times”, “proj”, and “slopes”.

Get HPI frequencies, HPI status channel, HPI status bits, and digitization order using _setup_hpi_amplitude_fitting.

Window data using t_window (half before and half after t) and t_step_min.

Use a linear model (DC + linear slope + sin + cos terms) to fit sinusoidal amplitudes to MEG channels. It uses SVD to determine the phase/amplitude of the sinusoids.

In “auto” mode, t_window will be set to the longer of:

Ensures that the frequency estimate is stable.

Ensures that neighboring frequencies can be disambiguated.

The output is meant to be used with compute_chpi_locs().

Extracting and visualizing subject head movement

mne.chpi.compute_chpi_snr

---

## mne.chpi.compute_chpi_locs#

**URL:** https://mne.tools/stable/generated/mne.chpi.compute_chpi_locs.html

**Contents:**
- mne.chpi.compute_chpi_locs#
- Examples using mne.chpi.compute_chpi_locs#

Compute locations of each cHPI coils over time.

The mne.Info object with information about the sensors and methods of measurement.

The time-varying cHPI coil amplitudes, with entries “times”, “proj”, and “slopes”. Typically obtained by mne.chpi.compute_chpi_amplitudes().

Maximum time step to use.

How to handle HPI positions too close to the sensors, can be 'raise' (default), 'warning', or 'info'.

If True, adjust the digitization locations used for fitting based on the positions localized at the start of the file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The time-varying cHPI coils locations, with entries “times”, “rrs”, “moments”, and “gofs”.

This function is designed to take the output of mne.chpi.compute_chpi_amplitudes() and:

Get HPI coil locations (as digitized in info['dig']) in head coords.

If the amplitudes are 98% correlated with last position (and Δt < t_step_max), skip fitting.

Fit magnetic dipoles using the amplitudes for each coil frequency.

The number of fitted points n_pos will depend on the velocity of head movements as well as t_step_max (and t_step_min from mne.chpi.compute_chpi_amplitudes()).

Extracting and visualizing subject head movement

mne.chpi.compute_chpi_snr

mne.chpi.compute_head_pos

---

## mne.chpi.compute_chpi_snr#

**URL:** https://mne.tools/stable/generated/mne.chpi.compute_chpi_snr.html

**Contents:**
- mne.chpi.compute_chpi_snr#
- Examples using mne.chpi.compute_chpi_snr#

Compute time-varying estimates of cHPI SNR.

Raw data with cHPI information.

Minimum time step to use.

Time window to use to estimate the amplitudes, default is 0.2 (200 ms).

The external order for SSS-like interfence suppression. The SSS bases are used as projection vectors during fitting.

Changed in version 0.20: Added ext_order=1 by default, which should improve detection of true HPI signals.

Start time of the raw data to use in seconds (must be >= 0).

End time of the raw data to use in seconds (cannot exceed data duration). If None (default), the current end of the data is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The time-varying cHPI SNR estimates, with entries “times”, “freqs”, “snr_mag”, “power_mag”, and “resid_mag” (and/or “snr_grad”, “power_grad”, and “resid_grad”, depending on which channel types are present in raw).

Extracting and visualizing subject head movement

mne.chpi.compute_chpi_amplitudes

mne.chpi.compute_chpi_locs

---

## mne.chpi.compute_head_pos#

**URL:** https://mne.tools/stable/generated/mne.chpi.compute_head_pos.html

**Contents:**
- mne.chpi.compute_head_pos#
- Examples using mne.chpi.compute_head_pos#

Compute time-varying head positions.

The mne.Info object with information about the sensors and methods of measurement.

The time-varying cHPI coils locations, with entries “times”, “rrs”, “moments”, and “gofs”. Typically obtained by compute_chpi_locs() or extract_chpi_locs_ctf().

Minimum distance (m) to accept for coil position fitting.

Minimum goodness of fit to accept for each coil.

If True, adjust the digitization locations used for fitting based on the positions localized at the start of the file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

MaxFilter-formatted head position parameters. The columns correspond to [t, q1, q2, q3, x, y, z, gof, err, v] for each time point.

Annotate movement artifacts and reestimate dev_head_t

Extracting and visualizing subject head movement

mne.chpi.compute_chpi_locs

mne.chpi.extract_chpi_locs_ctf

---

## mne.chpi.extract_chpi_locs_ctf#

**URL:** https://mne.tools/stable/generated/mne.chpi.extract_chpi_locs_ctf.html

**Contents:**
- mne.chpi.extract_chpi_locs_ctf#
- Examples using mne.chpi.extract_chpi_locs_ctf#

Extract cHPI locations from CTF data.

Raw data with CTF cHPI information.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The time-varying cHPI coils locations, with entries “times”, “rrs”, “moments”, and “gofs”.

CTF continuous head monitoring stores the x,y,z location (m) of each chpi coil as separate channels in the dataset:

HLC001[123]\\* - nasion

This extracts these positions for use with compute_head_pos().

Annotate movement artifacts and reestimate dev_head_t

mne.chpi.compute_head_pos

mne.chpi.extract_chpi_locs_kit

---

## mne.chpi.extract_chpi_locs_kit#

**URL:** https://mne.tools/stable/generated/mne.chpi.extract_chpi_locs_kit.html

**Contents:**
- mne.chpi.extract_chpi_locs_kit#

Extract cHPI locations from KIT data.

Raw data with KIT cHPI information.

The stimulus channel that encodes HPI measurement intervals.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The time-varying cHPI coils locations, with entries “times”, “rrs”, “moments”, and “gofs”.

mne.chpi.extract_chpi_locs_ctf

---

## mne.chpi.filter_chpi#

**URL:** https://mne.tools/stable/generated/mne.chpi.filter_chpi.html

**Contents:**
- mne.chpi.filter_chpi#
- Examples using mne.chpi.filter_chpi#

Remove cHPI and line noise from data.

This function will only work properly if cHPI was on during the recording.

Raw data with cHPI information. Must be preloaded. Operates in-place.

If True, also filter line noise.

Time step to use for estimation, default is 0.01 (10 ms).

Time window to use to estimate the amplitudes, default is 0.2 (200 ms).

The external order for SSS-like interfence suppression. The SSS bases are used as projection vectors during fitting.

Changed in version 0.20: Added ext_order=1 by default, which should improve detection of true HPI signals.

If True, allow filtering line noise only. The default is False, which only allows the function to run when cHPI information is present.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

cHPI signals are in general not stationary, because head movements act like amplitude modulators on cHPI signals. Thus it is recommended to use this procedure, which uses an iterative fitting method, to remove cHPI signals, as opposed to notch filtering.

Signal-space separation (SSS) and Maxwell filtering

mne.chpi.extract_chpi_locs_kit

mne.chpi.get_active_chpi

---

## mne.chpi.get_active_chpi#

**URL:** https://mne.tools/stable/generated/mne.chpi.get_active_chpi.html

**Contents:**
- mne.chpi.get_active_chpi#
- Examples using mne.chpi.get_active_chpi#

Determine how many HPI coils were active for a time point.

Raw data with cHPI information.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when no cHPI information can be found. If 'ignore' or 'warn', all return values will be empty arrays or None. If 'raise', an exception will be raised.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The number of active cHPIs for every timepoint in raw.

Signal-space separation (SSS) and Maxwell filtering

mne.chpi.get_chpi_info

---

## mne.chpi.get_chpi_info#

**URL:** https://mne.tools/stable/generated/mne.chpi.get_chpi_info.html

**Contents:**
- mne.chpi.get_chpi_info#
- Examples using mne.chpi.get_chpi_info#

Retrieve cHPI information from the data.

The mne.Info object with information about the sensors and methods of measurement.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when no cHPI information can be found. If 'ignore' or 'warn', all return values will be empty arrays or None. If 'raise', an exception will be raised.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The frequency used for each individual cHPI coil.

The index of the STIM channel containing information about when which cHPI coils were switched on.

The values coding for the “on” state of each individual cHPI coil.

Extracting and visualizing subject head movement

mne.chpi.get_active_chpi

mne.chpi.head_pos_to_trans_rot_t

---

## mne.chpi.head_pos_to_trans_rot_t#

**URL:** https://mne.tools/stable/generated/mne.chpi.head_pos_to_trans_rot_t.html

**Contents:**
- mne.chpi.head_pos_to_trans_rot_t#

Convert Maxfilter-formatted head position quaternions.

MaxFilter-formatted position and quaternion parameters. See mne.chpi.read_head_pos() for details on the columns.

Translations at each time point.

Rotations at each time point.

mne.chpi.get_chpi_info

mne.chpi.read_head_pos

---

## mne.chpi.read_head_pos#

**URL:** https://mne.tools/stable/generated/mne.chpi.read_head_pos.html

**Contents:**
- mne.chpi.read_head_pos#
- Examples using mne.chpi.read_head_pos#

Read MaxFilter-formatted head position parameters.

The filename to read. This can be produced by e.g., maxfilter -headpos <name>.pos.

The position and quaternion parameters from cHPI fitting. See mne.chpi.compute_head_pos() for details on the columns.

Maxwell filter data with movement compensation

Extracting and visualizing subject head movement

Signal-space separation (SSS) and Maxwell filtering

mne.chpi.head_pos_to_trans_rot_t

---

## mne.chpi.refit_hpi#

**URL:** https://mne.tools/stable/generated/mne.chpi.refit_hpi.html

**Contents:**
- mne.chpi.refit_hpi#

Refit HPI coil order.

This operates inplace on info, and will typically be called via refit_hpi(raw.info) before further processing.

The measurement info.

Whether to recompute the HPI amplitudes (slopes) from the raw data obtained during the original fit using compute_chpi_amplitudes(), or used the already-computed ones stored in info['hpi_meas']. If this is True, locs and order must also be True.

Whether to recompute the HPI coil locations using compute_chpi_locs(), or use the already-computed ones stored in info['hpi_results']. If this is True, order must also be True.

Whether to refit the coil order by testing all permutations for the best goodness of fit between digitized coil locations and (rigid-transformed) fitted coil locations.

The external order for SSS-like interfence suppression. The SSS bases are used as projection vectors during fitting.

Changed in version 0.20: Added ext_order=1 by default, which should improve detection of true HPI signals.

The goodness-of-fit limit to use when choosing which coils to use for refitting.

The distance limit (in meters) to use when choosing which coils to use for refitting.

The maximum number of coils to use when testing different coil orderings. The default for hpifit in MEGIN software is 3. Default (None) means to use all coils above gof_limit. Can also be an ndarray of coil indices (0-indexed!) to use, e.g., [1, 2, 4].

The RMS limit (in meters) to use when checking for colinearity of coil locations. If the RMS difference between the used points and a best-fit linear approximation is less than this limit, a warning is emitted. The default (0) avoids colinearity warnings altogether. The appropriate value here is dataset dependent, but for one problematic dataset the value of 0.03 worked well.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified measurement info (same as input).

This adds additional entries to info["hpi_meas"] and info["hpi_results"], leaving the existing ones intact. It will always modify info["dev_head_t"] inplace.

The algorithm is as follows:

Optionally recompute HPI amplitudes (sinusoidal fit for each channel) using compute_chpi_amplitudes().

Optionally use HPI amplitudes to fit HPI coil locations using compute_chpi_locs().

Optionally determine coil digitization order by testing all permutations for the best goodness of fit between digitized coil locations and (rigid-transformed) fitted coil locations, choosing the order first based on those that satisfy gof_limit then the others.

Subselect coils to use for fitting dev_head_t based on gof_limit, dist_limit, and use.

Update info inplace by modifying info["dev_head_t"] and appending new entries to info["hpi_meas"] and info["hpi_results"].

mne.chpi.read_head_pos

mne.chpi.write_head_pos

---

## mne.chpi.write_head_pos#

**URL:** https://mne.tools/stable/generated/mne.chpi.write_head_pos.html

**Contents:**
- mne.chpi.write_head_pos#
- Examples using mne.chpi.write_head_pos#

Write MaxFilter-formatted head position parameters.

The filename to write.

The position and quaternion parameters from cHPI fitting. See mne.chpi.compute_head_pos() for details on the columns.

Extracting and visualizing subject head movement

mne.transforms.Transform

---

## mne.compute_covariance#

**URL:** https://mne.tools/stable/generated/mne.compute_covariance.html

**Contents:**
- mne.compute_covariance#
- Examples using mne.compute_covariance#

Estimate noise covariance matrix from epochs.

The noise covariance is typically estimated on pre-stimulus periods when the stimulus onset is defined from events.

If the covariance is computed for multiple event types (events with different IDs), the following two options can be used and combined:

either an Epochs object for each event type is created and a list of Epochs is passed to this function.

an Epochs object is created for multiple events and passed to this function.

To estimate the noise covariance from non-epoched raw data, such as an empty-room recording, use mne.compute_raw_covariance() instead.

If False, the average response over epochs is computed for each event type and subtracted during the covariance computation. This is useful if the evoked response from a previous stimulus extends into the baseline period of the next. Note. This option is only implemented for method=’empirical’.

Start time for baseline. If None start at first sample.

End time for baseline. If None end at last sample.

List of projectors to use in covariance calculation, or None to indicate that the projectors from the epochs should be inherited. If None, then projectors from all epochs must match.

Can be ‘warn’ (default), ‘ignore’, or ‘raise’ to control behavior when there are fewer samples than channels, which can lead to inaccurate covariance or rank estimates.

The method used for covariance estimation. If ‘empirical’ (default), the sample covariance will be computed. A list can be passed to perform estimates using multiple methods. If ‘auto’ or a list of methods, the best estimator will be determined based on log-likelihood and cross-validation on unseen data as described in [1]. Valid methods are ‘empirical’, ‘diagonal_fixed’, ‘shrunk’, ‘oas’, ‘ledoit_wolf’, ‘factor_analysis’, ‘shrinkage’, and ‘pca’ (see Notes). If 'auto', it expands to:

'factor_analysis' is removed when rank is not ‘full’. The 'auto' mode is not recommended if there are many segments of data, since computation can take a long time.

Additional parameters to the estimation procedure. Only considered if method is not None. Keys must correspond to the value(s) of method. If None (default), expands to the following (with the addition of {'store_precision': False, 'assume_centered': True} for all methods except ``'factor_analysis' and 'pca'):

The cross validation method. Defaults to 3, which will internally trigger by default sklearn.model_selection.KFold with 3 splits.

Defaults to dict(mag=1e15, grad=1e13, eeg=1e6). These defaults will scale data to roughly the same order of magnitude.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Whether to return all estimators or the best. Only considered if method equals ‘auto’ or is a list of str. Defaults to False.

What to do when the MEG<->Head transformations do not match between epochs. If “raise” (default) an error is raised, if “warn” then a warning is emitted, if “ignore” then nothing is printed. Having mismatched transforms can in some cases lead to unexpected or unstable results in covariance calculation, e.g. when data have been processed with Maxwell filtering but not transformed to the same head position.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

New in v0.18: Support for ‘info’ mode.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The computed covariance. If method equals 'auto' or is a list of str and return_estimators=True, a list of covariance estimators is returned (sorted by log-likelihood, from high to low, i.e. from best to worst).

Estimate noise covariance from raw data, such as empty-room recordings.

Baseline correction or sufficient high-passing should be used when creating the Epochs to ensure that the data are zero mean, otherwise the computed covariance matrix will be inaccurate.

Valid method strings are:

The empirical or sample covariance (default)

A diagonal regularization based on channel types as in mne.cov.regularize().

The Ledoit-Wolf estimator, which uses an empirical formula for the optimal shrinkage value [2].

The OAS estimator [3], which uses a different empricial formula for the optimal shrinkage value.

Like ‘ledoit_wolf’, but with cross-validation for optimal alpha.

Probabilistic PCA with low rank [4].

Factor analysis with low rank [5].

'ledoit_wolf' and 'pca' are similar to 'shrunk' and 'factor_analysis', respectively, except that they use cross validation (which is useful when samples are correlated, which is often the case for M/EEG data). The former two are not included in the 'auto' mode to avoid redundancy.

For multiple event types, it is also possible to create a single Epochs object with events obtained using mne.merge_events(). However, the resulting covariance matrix will only be correct if keep_sample_mean is True.

The covariance can be unstable if the number of samples is small. In that case it is common to regularize the covariance estimate. The method parameter allows to regularize the covariance in an automated way. It also allows to select between different alternative estimation algorithms which themselves achieve regularization. Details are described in Engemann and Gramfort[1].

For more information on the advanced estimation methods, see the sklearn manual.

Denis A. Engemann and Alexandre Gramfort. Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals. NeuroImage, 108:328–342, 2015. doi:10.1016/j.neuroimage.2014.12.040.

Olivier Ledoit and Michael Wolf. A well-conditioned estimator for large-dimensional covariance matrices. Journal of Multivariate Analysis, 88(2):365–411, 2004. doi:10.1016/S0047-259X(03)00096-4.

Yilun Chen, Ami Wiesel, Yonina C. Eldar, and Alfred O. Hero. Shrinkage algorithms for MMSE covariance estimation. IEEE Transactions on Signal Processing, 58(10):5016–5029, 2010. doi:10.1109/TSP.2010.2053029.

Michael E. Tipping and Christopher M. Bishop. Probabilistic principal component analysis. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3):611–622, 1999. doi:10.1111/1467-9868.00196.

David Barber. Bayesian Reasoning and Machine Learning. Cambridge University Press, Cambridge, 2012. ISBN 978-0-521-51814-7. URL: http://www.cs.ucl.ac.uk/staff/d.barber/brml/.

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute source power estimate by projecting the covariance with MNE

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Compute cross-talk functions for LCMV beamformers

Plot sensor denoising using oversampled temporal projection

Generate simulated raw data

Whitening evoked data with a noise covariance

Plotting whitened data

Computing a covariance matrix

Source localization with MNE, dSPM, sLORETA, and eLORETA

Source reconstruction using an LCMV beamformer

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

Preprocessing optically pumped magnetometer (OPM) MEG data

Corrupt known signal with point spread

mne.compute_raw_covariance

---

## mne.compute_proj_raw#

**URL:** https://mne.tools/stable/generated/mne.compute_proj_raw.html

**Contents:**
- mne.compute_proj_raw#
- Examples using mne.compute_proj_raw#

Compute SSP (signal-space projection) vectors on continuous data.

This function aims to find those SSP vectors that will project out the n most prominent signals from the data for each specified sensor type. Consequently, if the provided input data contains high levels of noise, the produced SSP vectors can then be used to eliminate that noise from the data.

A raw object to use the data from.

Time (in seconds) to start computing SSP.

Time (in seconds) to stop computing SSP. None will go to the end of the file.

Duration (in seconds) to chunk data into for SSP If duration is None, data will not be chunked.

Number of vectors for gradiometers. Either an integer or a float between 0 and 1 to select the number of vectors to explain the cumulative variance greater than n_grad.

Number of vectors for magnetometers. Either an integer or a float between 0 and 1 to select the number of vectors to explain the cumulative variance greater than n_mag.

Number of vectors for EEG channels. Either an integer or a float between 0 and 1 to select the number of vectors to explain the cumulative variance greater than n_eeg.

Epoch PTP rejection threshold used if duration != None. See Epochs.

Epoch flatness rejection threshold used if duration != None. See Epochs.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Number of jobs to use to compute covariance.

Can be 'separate' (default) or 'combined' to compute projectors for magnetometers and gradiometers separately or jointly. If 'combined', n_mag == n_grad is required and the number of projectors computed for MEG will be n_mag.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of projection vectors.

Repairing artifacts with SSP

mne.compute_proj_evoked

---

## mne.compute_rank#

**URL:** https://mne.tools/stable/generated/mne.compute_rank.html

**Contents:**
- mne.compute_rank#
- Examples using mne.compute_rank#

Compute the rank of data or noise covariance.

This function will normalize the rows of the data (typically channels or vertices) such that non-zero singular values should be close to one. It operates on data channels only.

Raw measurements to compute the rank from or the covariance.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

Defaults to dict(mag=1e15, grad=1e13, eeg=1e6). These defaults will scale different channel types to comparable values.

The mne.Info object with information about the sensors and methods of measurement. Only necessary if inst is a mne.Covariance object (since this does not provide inst.info).

Tolerance for singular values to consider non-zero in calculating the rank. The singular values are calculated in this method such that independent data are expected to have singular value around one. Can be ‘auto’ to use the same thresholding as scipy.linalg.orth().

If True, all projs in inst and info will be applied or considered when rank=None or rank='info'.

Can be: “absolute” (default) or “relative”. Only used if tol is a float, because when tol is a string the mode is implicitly relative. After applying the chosen scale factors / normalization to the data, the singular values are computed, and the rank is then taken as:

The number of singular values s greater than tol. This mode can fail if your data do not adhere to typical data scalings.

The number of singular values s greater than tol * s.max(). This mode can fail if you have one or more large components in the data (e.g., artifacts).

If an explicit MEG value is passed, what to do when it does not match an empirically computed rank (only used for covariances). Can be ‘raise’ to raise an error, ‘warn’ (default) to emit a warning, or ‘ignore’ to ignore.

Can be ‘warn’, ‘ignore’, or ‘raise’ to control behavior when there are fewer samples than channels, which can lead to inaccurate rank estimates. None (default) means “ignore” if inst is a mne.Covariance or rank in ("info", "full"), and “warn” otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Estimated rank of the data for each channel type. To get the total rank, you can use sum(rank.values()).

Kernel OPM phantom data

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

---

## mne.compute_raw_covariance#

**URL:** https://mne.tools/stable/generated/mne.compute_raw_covariance.html

**Contents:**
- mne.compute_raw_covariance#
- Examples using mne.compute_raw_covariance#

Estimate noise covariance matrix from a continuous segment of raw data.

It is typically useful to estimate a noise covariance from empty room data or time intervals before starting the stimulation.

To estimate the noise covariance from epoched data, use mne.compute_covariance() instead.

Beginning of time interval in seconds. Defaults to 0.

End of time interval in seconds. If None (default), use the end of the recording.

Length of data chunks for artifact rejection in seconds. Can also be None to use a single epoch of (tmax - tmin) duration. This can use a lot of memory for large Raw instances.

Rejection parameters based on peak-to-peak amplitude. Valid keys are ‘grad’ | ‘mag’ | ‘eeg’ | ‘eog’ | ‘ecg’. If reject is None then no rejection is done. Example:

Rejection parameters based on flatness of signal. Valid keys are ‘grad’ | ‘mag’ | ‘eeg’ | ‘eog’ | ‘ecg’, and values are floats that set the minimum acceptable peak-to-peak amplitude. If flat is None then no rejection is done.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Can be ‘warn’ (default), ‘ignore’, or ‘raise’ to control behavior when there are fewer samples than channels, which can lead to inaccurate covariance or rank estimates.

The method used for covariance estimation. See mne.compute_covariance().

Additional parameters to the estimation procedure. See mne.compute_covariance().

The cross validation method. Defaults to 3, which will internally trigger by default sklearn.model_selection.KFold with 3 splits.

Defaults to dict(mag=1e15, grad=1e13, eeg=1e6). These defaults will scale magnetometers and gradiometers at the same unit.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Whether to return all estimators or the best. Only considered if method equals ‘auto’ or is a list of str. Defaults to False.

Whether to reject based on annotations. If True (default), epochs overlapping with segments whose description begins with 'bad' are rejected. If False, no rejection based on annotations is performed.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

New in v0.18: Support for ‘info’ mode.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The computed covariance. If method equals ‘auto’ or is a list of str and return_estimators equals True, a list of covariance estimators is returned (sorted by log-likelihood, from high to low, i.e. from best to worst).

Estimate noise covariance matrix from epoched data.

Partition the data into evenly spaced, equal-length epochs.

Load them into memory.

Subtract the mean across all time points and epochs for each channel.

Process the Epochs by compute_covariance().

This will produce a slightly different result compared to using make_fixed_length_events(), Epochs, and compute_covariance() directly, since that would (with the recommended baseline correction) subtract the mean across time for each epoch (instead of across epochs) for each channel.

Compute source power estimate by projecting the covariance with MNE

Compute source power spectral density (PSD) of VectorView and OPM data

Computing a covariance matrix

Brainstorm CTF phantom dataset tutorial

Working with CTF data: the Brainstorm auditory dataset

mne.compute_covariance

mne.cov.compute_whitener

---

## mne.compute_source_morph#

**URL:** https://mne.tools/stable/generated/mne.compute_source_morph.html

**Contents:**
- mne.compute_source_morph#
- Examples using mne.compute_source_morph#

Create a SourceMorph from one subject to another.

Method is based on spherical morphing by FreeSurfer for surface cortical estimates [1] and Symmetric Diffeomorphic Registration for volumic data [2].

The SourceSpaces of subject_from (can be a SourceEstimate if only using a surface source space).

Name of the original subject as named in the SUBJECTS_DIR. If None (default), then src[0]['subject_his_id]' will be used.

Name of the subject to which to morph as named in the SUBJECTS_DIR. Default is 'fsaverage'. If None, src_to[0]['subject_his_id'] will be used.

Changed in version 0.20: Support for subject_to=None.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The voxel size of volume for each spatial dimension in mm. If spacing is None, MRIs won’t be resliced, and both volumes must have the same number of spatial dimensions. Can also be 'auto' to use 5. if src_to is None and the zooms from src_to otherwise.

Changed in version 0.20: Support for ‘auto’ mode.

Number of levels (len(niter_affine)) and number of iterations per level - for each successive stage of iterative refinement - to perform the affine transform. Default is niter_affine=(100, 100, 10).

Number of levels (len(niter_sdr)) and number of iterations per level - for each successive stage of iterative refinement - to perform the Symmetric Diffeomorphic Registration (sdr) transform. Default is niter_sdr=(5, 5, 3).

The resolution of the icosahedral mesh (typically 5). If None, all vertices will be used (potentially filling the surface). If a list, then values will be morphed to the set of vertices specified in in spacing[0] and spacing[1]. This will be ignored if src_to is supplied.

Changed in version 0.21: src_to, if provided, takes precedence.

Number of iterations for the smoothing of the surface data. If None, smooth is automatically defined to fill the surface with non-zero values. Can also be 'nearest' to use the nearest vertices on the surface.

Changed in version 0.20: Added support for ‘nearest’.

If True, warn if not all vertices were used. The default is warn=True.

Morph across hemisphere. Currently only implemented for subject_to == subject_from. See notes below. The default is xhemi=False.

Morph as a sparse source estimate. Works only with (Vector) SourceEstimate. If True the only parameters used are subject_to and subject_from, and spacing has to be None. Default is sparse=False.

The destination source space.

For surface-based morphing, this is the preferred over spacing for providing the vertices.

For volumetric morphing, this should be passed so that 1) the resultingmorph volume is properly constrained to the brain volume, and 2) STCs from multiple subjects morphed to the same destination subject/source space have the vertices.

For mixed (surface + volume) morphing, this is required.

If True (default False), compute the sparse matrix representation of the volumetric morph (if present). This takes a long time to compute, but can make morphs faster when thousands of points are used. See mne.SourceMorph.compute_vol_morph_mat() (which can be called later if desired) for more information.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The mne.SourceMorph object.

This function can be used to morph surface data between hemispheres by setting xhemi=True. The full cross-hemisphere morph matrix maps left to right and right to left. A matrix for cross-mapping only one hemisphere can be constructed by specifying the appropriate vertices, for example, to map the right hemisphere to the left:

Cross-hemisphere mapping requires appropriate sphere.left_right morph-maps in the subject’s directory. These morph maps are included with the fsaverage_sym FreeSurfer subject, and can be created for other subjects with the mris_left_right_register FreeSurfer command. The fsaverage_sym subject is included with FreeSurfer > 5.1 and can be obtained as described here. For statistical comparisons between hemispheres, use of the symmetric fsaverage_sym model is recommended to minimize bias [1].

New in v0.21.0: Support for morphing mixed source estimates.

Douglas N. Greve, Lise Van der Haegen, Qing Cai, Steven Stufflebeam, Mert R. Sabuncu, Bruce Fischl, and Marc Brysbaert. A surface-based analysis of language lateralization and cortical asymmetry. Journal of Cognitive Neuroscience, 25(9):1477–1492, 2013. doi:10.1162/jocn_a_00405.

Brian B. Avants, Charles L. Epstein, Murray C. Grossman, and James C. Gee. Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain. Medical Image Analysis, 12(1):26–41, 2008. doi:10.1016/j.media.2007.06.004.

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Morph surface source estimate

Morph volumetric source estimate

Cross-hemisphere comparison

Source reconstruction using an LCMV beamformer

Visualize source time courses (stcs)

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.extract_label_time_course

---

## mne.concatenate_events#

**URL:** https://mne.tools/stable/generated/mne.concatenate_events.html

**Contents:**
- mne.concatenate_events#

Concatenate event lists to be compatible with concatenate_raws.

This is useful, for example, if you processed and/or changed events in raw files separately before combining them using mne.concatenate_raws().

List of events arrays, typically each extracted from a corresponding raw file that is being concatenated.

First sample numbers of the raw files concatenated.

Last sample numbers of the raw files concatenated.

The concatenated events.

---

## mne.concatenate_raws#

**URL:** https://mne.tools/stable/generated/mne.concatenate_raws.html

**Contents:**
- mne.concatenate_raws#
- Examples using mne.concatenate_raws#

Concatenate Raw instances as if they were continuous.

raws[0] is modified in-place to achieve the concatenation. Boundaries of the raw files are annotated bad. If you wish to use the data as continuous recording, you can remove the boundary annotations after concatenation (see mne.Annotations.delete()).

List of Raw instances to concatenate (in order).

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory). If preload is None, preload=True or False is inferred using the preload status of the instances passed in.

The events to concatenate. Defaults to None.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when the device-to-head transformation differs between instances.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The result of the concatenation (first Raw instance passed in).

The events. Only returned if event_list is not None.

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Representational Similarity Analysis

Annotate movement artifacts and reestimate dev_head_t

Compute and visualize ERDS maps

Working with CTF data: the Brainstorm auditory dataset

mne.equalize_channels

---

## mne.convert_forward_solution#

**URL:** https://mne.tools/stable/generated/mne.convert_forward_solution.html

**Contents:**
- mne.convert_forward_solution#
- Examples using mne.convert_forward_solution#

Convert forward solution between different source orientations.

The forward solution to modify.

Use surface-based source coordinate system? Note that force_fixed=True implies surf_ori=True.

If True, force fixed source orientation mode.

Whether to return a new instance or modify in place.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified forward solution.

Optically pumped magnetometer (OPM) data

Display sensitivity maps for EEG and MEG sensors

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Cortical Signal Suppression (CSS) for removal of cortical signals

Head model and forward computation

The role of dipole orientations in distributed source localization

Corrupt known signal with point spread

mne.average_forward_solutions

---

## mne.coreg.Coregistration#

**URL:** https://mne.tools/stable/generated/mne.coreg.Coregistration.html

**Contents:**
- mne.coreg.Coregistration#
- Examples using mne.coreg.Coregistration#

Class for MRI<->head coregistration.

The measurement info.

The FreeSurfer subject name.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The fiducials given in the MRI (surface RAS) coordinate system. If a dictionary is provided, it must contain the keys 'lpa', 'rpa', and 'nasion', with values being the respective coordinates in meters. If a list, it must be a list of DigPoint instances as returned by the mne.io.read_fiducials() function. If 'estimated', the fiducials are derived from the fsaverage template. If 'auto' (default), tries to find the fiducials in a file with the canonical name ({subjects_dir}/{subject}/bem/{subject}-fiducials.fif) and if absent, falls back to 'estimated'.

What to do if the surface is found to have topological defects. Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when one or more defects are found. Note that a lot of computations in MNE-Python assume the surfaces to be topologically correct, topological defects may still make other computations (e.g., mne.make_bem_model and mne.make_bem_solution) fail irrespective of this parameter.

A montage containing the MRI fiducials.

The head->mri Transform.

compute_dig_mri_distances()

Compute distance between head shape points and MRI skin surface.

fit_fiducials([lpa_weight, nasion_weight, ...])

Find rotation and translation to fit all 3 fiducials.

fit_icp([n_iterations, lpa_weight, ...])

Find MRI scaling, translation, and rotation to match HSP.

omit_head_shape_points(distance)

Exclude head shape points that are far away from the MRI head.

Reset all the parameters affecting the coregistration.

Set the strategy for fitting anatomical landmark (fiducial) points.

Compensate for hair on the digitizer head shape.

Set the rotation parameter.

Set the scale parameter.

set_scale_mode(scale_mode)

Select how to fit the scale parameters.

Set the translation parameter.

Internal computation quantities parameters are in the following units:

rotation are in radians

scale are in scale proportion

If using a scale mode, the scale_mri() should be used to create a surrogate MRI subject with the proper scale factors.

Compute distance between head shape points and MRI skin surface.

The distance of the head shape points to the MRI skin surface.

Examples using compute_dig_mri_distances:

Using an automated approach to coregistration

Find rotation and translation to fit all 3 fiducials.

Relative weight for LPA. The default value is 1.

Relative weight for nasion. The default value is 10.

Relative weight for RPA. The default value is 1.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified Coregistration object.

Examples using fit_fiducials:

Using an automated approach to coregistration

Find MRI scaling, translation, and rotation to match HSP.

Maximum number of iterations.

Relative weight for LPA. The default value is 1.

Relative weight for nasion. The default value is 10.

Relative weight for RPA. The default value is 1.

Relative weight for HSP. The default value is 1.

Relative weight for EEG. The default value is 1.

Relative weight for HPI. The default value is 1.

A function to call on each iteration. Useful for status message updates. It will be passed the keyword arguments iteration and n_iterations.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified Coregistration object.

Examples using fit_icp:

Using an automated approach to coregistration

Exclude head shape points that are far away from the MRI head.

Exclude all points that are further away from the MRI head than this distance (in m.). A value of distance <= 0 excludes nothing.

The modified Coregistration object.

Examples using omit_head_shape_points:

Using an automated approach to coregistration

Reset all the parameters affecting the coregistration.

The modified Coregistration object.

Get the current scale factor.

Set the strategy for fitting anatomical landmark (fiducial) points.

Alignment strategy; 'nearest' aligns anatomical landmarks to any point on the head surface; 'matched' aligns to the fiducial points in the MRI.

The modified Coregistration object.

Compensate for hair on the digitizer head shape.

Move the back of the MRI head outwards by value (mm).

The modified Coregistration object.

Set the rotation parameter.

The rotation parameter (in radians).

The modified Coregistration object.

Set the scale parameter.

The modified Coregistration object.

Select how to fit the scale parameters.

The scale mode can be ‘uniform’, ‘3-axis’ or disabled. Defaults to None.

‘uniform’: 1 scale factor is recovered.

‘3-axis’: 3 scale factors are recovered.

None: do not scale the MRI.

The modified Coregistration object.

Examples using set_scale_mode:

Using an automated approach to coregistration

Set the translation parameter.

The translation parameter (in m.).

The modified Coregistration object.

The head->mri Transform.

Using an automated approach to coregistration

---

## mne.coreg.estimate_head_mri_t#

**URL:** https://mne.tools/stable/generated/mne.coreg.estimate_head_mri_t.html

**Contents:**
- mne.coreg.estimate_head_mri_t#
- Examples using mne.coreg.estimate_head_mri_t#

Estimate the head->mri transform from fsaverage fiducials.

A subject’s fiducials can be estimated given a Freesurfer recon-all by transforming fsaverage fiducials using the inverse Talairach transform, see mne.coreg.get_mni_fiducials().

The FreeSurfer subject name.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation.

How to convert 3D electrode positions to a 2D image

Working with sEEG data

mne.coreg.get_mni_fiducials

mne.io.read_fiducials

---

## mne.coreg.get_mni_fiducials#

**URL:** https://mne.tools/stable/generated/mne.coreg.get_mni_fiducials.html

**Contents:**
- mne.coreg.get_mni_fiducials#
- Examples using mne.coreg.get_mni_fiducials#

Estimate fiducials for a subject.

The FreeSurfer subject name.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of estimated fiducials (each point in a dict), in the order LPA, nasion, RPA.

This takes the fsaverage-fiducials.fif file included with MNE—which contain the LPA, nasion, and RPA for the fsaverage subject—and transforms them to the given FreeSurfer subject’s MRI space. The MRI of fsaverage is already in MNI Talairach space, so applying the inverse of the given subject’s MNI Talairach affine transformation ($SUBJECTS_DIR/$SUBJECT/mri/transforms/talairach.xfm) is used to estimate the subject’s fiducial locations.

For more details about the coordinate systems and transformations involved, see https://surfer.nmr.mgh.harvard.edu/fswiki/CoordinateSystems and Source alignment and coordinate frames.

How MNE uses FreeSurfer’s outputs

mne.coreg.estimate_head_mri_t

---

## mne.count_annotations#

**URL:** https://mne.tools/stable/generated/mne.count_annotations.html

**Contents:**
- mne.count_annotations#

The annotations instance.

A dictionary containing unique annotation descriptions as keys with their counts as values.

mne.annotations_from_events

mne.event.define_target_events

---

## mne.count_events#

**URL:** https://mne.tools/stable/generated/mne.count_events.html

**Contents:**
- mne.count_events#

The events array (consisting of N events).

If None, count all event types present in the input. If array-like of int, count only those event types given by ids.

A dictionary containing the event types as keys with their counts as values.

mne.concatenate_events

---

## mne.Covariance#

**URL:** https://mne.tools/stable/generated/mne.Covariance.html

**Contents:**
- mne.Covariance#
- Examples using mne.Covariance#

Noise covariance matrix.

This class should not be instantiated directly via mne.Covariance(...). Instead, use one of the functions listed in the See Also section below.

The method used to compute the covariance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Numpy array of Noise covariance matrix.

Number of degrees of freedom.

The number of channels n_channels.

Add Covariance taking into account number of degrees of freedom.

True if the dictionary has the specified key, else False.

Implement iter(self).

Set covariance to be processed as being diagonal.

Copy the Covariance object.

fromkeys(iterable[, value])

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

pick_channels(ch_names[, ordered, verbose])

Pick channels from this covariance matrix.

plot(info[, exclude, colorbar, proj, ...])

Plot Covariance data.

plot_topomap(info[, ch_type, scalings, ...])

Plot a topomap of the covariance diagonal.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

save(fname, *[, overwrite, verbose])

Save covariance matrix in a FIF file.

setdefault(key[, default])

Insert key with a value of default if key is not in the dictionary.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

Add Covariance taking into account number of degrees of freedom.

True if the dictionary has the specified key, else False.

Implement iter(self).

Set covariance to be processed as being diagonal.

This function allows creation of inverse operators equivalent to using the old “–diagnoise” mne option.

This function operates in place.

Copy the Covariance object.

Computing source timecourses with an XFit-like multi-dipole model

Numpy array of Noise covariance matrix.

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

Number of degrees of freedom.

Pick channels from this covariance matrix.

List of channels to keep. All other channels are dropped.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified covariance matrix.

Plot Covariance data.

The mne.Info object with information about the sensors and methods of measurement.

List of channels to exclude. If empty do not exclude any channel. If ‘bads’, exclude info[‘bads’].

Show colorbar or not.

Apply projections or not.

Plot also singular values of the noise covariance for each sensor type. We show square roots ie. standard deviations.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The SVD plot of the covariance (i.e., the eigenvalues or “matrix spectrum”).

For each channel type, the rank is estimated using mne.compute_rank().

Changed in version 0.19: Approximate ranks for each channel type are shown with red dashed lines.

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Reading/Writing a noise covariance matrix

Computing a covariance matrix

Source reconstruction using an LCMV beamformer

Working with CTF data: the Brainstorm auditory dataset

Plot a topomap of the covariance diagonal.

The mne.Info object with information about the sensors and methods of measurement.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown. If 'reconstruct', projection vectors will be applied and then M/EEG data will be reconstructed via field mapping to reduce the signal bias caused by projection.

Changed in version 0.21: Support for ‘reconstruct’ was added.

If not None, whiten the instance with noise_cov before plotting.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel(s) to highlight with a distinct plotting style. Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None and scalings=None the unit is automatically determined, otherwise the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1. Default is None.

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The matplotlib figure.

Examples using plot_topomap:

Compute source power estimate by projecting the covariance with MNE

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

Pairs are returned in LIFO (last-in, first-out) order. Raises KeyError if the dict is empty.

Save covariance matrix in a FIF file.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Insert key with a value of default if key is not in the dictionary.

Return the value for key if key is in the dictionary, else default.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

Kernel OPM phantom data

From raw data to dSPM on SPM Faces dataset

Decoding source space data

Source localization with a custom inverse solver

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Compute source power estimate by projecting the covariance with MNE

Computing source timecourses with an XFit-like multi-dipole model

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Plot point-spread functions (PSFs) for a volume

Compute Rap-Music on evoked data

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Reading/Writing a noise covariance matrix

Cortical Signal Suppression (CSS) for removal of cortical signals

Compare simulated and estimated source activity

Generate simulated evoked data

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

Compute source power spectral density (PSD) of VectorView and OPM data

Whitening evoked data with a noise covariance

Plotting whitened data

Computing a covariance matrix

Getting started with mne.Report

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Source reconstruction using an LCMV beamformer

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

Working with CTF data: the Brainstorm auditory dataset

Repairing artifacts with ICA

Preprocessing optically pumped magnetometer (OPM) MEG data

Corrupt known signal with point spread

DICS for power mapping

Covariance computation

mne.compute_covariance

---

## mne.cov.compute_whitener#

**URL:** https://mne.tools/stable/generated/mne.cov.compute_whitener.html

**Contents:**
- mne.cov.compute_whitener#

Compute whitening matrix.

The noise covariance.

The mne.Info object with information about the sensors and methods of measurement. Can be None if noise_cov has already been prepared with prepare_noise_cov().

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

New in v0.18: Support for ‘info’ mode.

The rescaling method to be applied. See documentation of prepare_noise_cov for details.

If True, return the rank used to compute the whitener.

Space to project the data into. Options:

Whitener will be shape (n_nonzero, n_channels).

Whitener will be shape (n_channels, n_channels), potentially rank deficient, and have the first n_channels - n_nonzero rows and columns set to zero.

Whitener will be shape (n_channels, n_channels), potentially rank deficient, and rotated back to the space of the original data.

If True, return the colorer as well.

If an explicit MEG value is passed, what to do when it does not match an empirically computed rank (only used for covariances). Can be ‘raise’ to raise an error, ‘warn’ (default) to emit a warning, or ‘ignore’ to ignore.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The whitening matrix.

Rank reduction of the whitener. Returned only if return_rank is True.

mne.compute_raw_covariance

mne.cov.prepare_noise_cov

---

## mne.cov.prepare_noise_cov#

**URL:** https://mne.tools/stable/generated/mne.cov.prepare_noise_cov.html

**Contents:**
- mne.cov.prepare_noise_cov#

Prepare noise covariance matrix.

The noise covariance to process.

The mne.Info object with information about the sensors and methods of measurement. (Used to get channel types and bad channels).

The channel names to be considered. Can be None to use info['ch_names'].

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

New in v0.18: Support for ‘info’ mode.

Data will be rescaled before rank estimation to improve accuracy. If dict, it will override the following dict (default if None):

If an explicit MEG value is passed, what to do when it does not match an empirically computed rank (only used for covariances). Can be ‘raise’ to raise an error, ‘warn’ (default) to emit a warning, or ‘ignore’ to ignore.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A copy of the covariance with the good channels subselected and parameters updated.

mne.cov.compute_whitener

---

## mne.cov.regularize#

**URL:** https://mne.tools/stable/generated/mne.cov.regularize.html

**Contents:**
- mne.cov.regularize#
- Examples using mne.cov.regularize#

Regularize noise covariance matrix.

This method works by adding a constant to the diagonal for each channel type separately. Special care is taken to keep the rank of the data constant.

This function is kept for reasons of backward-compatibility. Please consider explicitly using the method parameter in mne.compute_covariance() to directly combine estimation with regularization in a data-driven fashion. See the FAQ for more information.

The noise covariance matrix.

The mne.Info object with information about the sensors and methods of measurement. (Used to get channel types and bad channels).

Regularization factor for MEG magnetometers.

Regularization factor for MEG gradiometers. Must be the same as mag if data have been processed with SSS.

Regularization factor for EEG.

List of channels to mark as bad. If ‘bads’, bads channels are extracted from both info[‘bads’] and cov[‘bads’].

Apply projections to keep rank of data.

Regularization factor for sEEG signals.

Regularization factor for ECoG signals.

Regularization factor for HBO signals.

Regularization factor for HBR signals.

Regularization factor for fNIRS CW raw signals.

Regularization factor for fNIRS FD AC raw signals.

Regularization factor for fNIRS raw phase signals.

Regularization factor for fNIRS optical density signals.

Regularization factor for EEG-CSD signals.

Regularization factor for DBS signals.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

New in v0.18: Support for ‘info’ mode.

Data will be rescaled before rank estimation to improve accuracy. See mne.compute_covariance().

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The regularized covariance matrix.

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute cross-talk functions for LCMV beamformers

mne.cov.prepare_noise_cov

---

## mne.create_default_subject#

**URL:** https://mne.tools/stable/generated/mne.create_default_subject.html

**Contents:**
- mne.create_default_subject#

Create an average brain subject for subjects without structural MRI.

Create a copy of fsaverage from the FreeSurfer directory in subjects_dir and add auxiliary files from the mne package.

The FreeSurfer home directory (only needed if FREESURFER_HOME is not specified as environment variable).

In cases where a copy of the fsaverage brain already exists in the subjects_dir, this option allows to only copy files that don’t already exist in the fsaverage directory.

Override the SUBJECTS_DIR environment variable (os.environ['SUBJECTS_DIR']) as destination for the new subject.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

When no structural MRI is available for a subject, an average brain can be substituted. FreeSurfer comes with such an average brain model, and MNE comes with some auxiliary files which make coregistration easier. create_default_subject() copies the relevant files from FreeSurfer into the current subjects_dir, and also adds the auxiliary files provided by MNE.

mne.gui.coregistration

---

## mne.create_info#

**URL:** https://mne.tools/stable/generated/mne.create_info.html

**Contents:**
- mne.create_info#
- Examples using mne.create_info#

Create a basic Info instance suitable for use with create_raw.

Channel names. If an int, a list of channel names will be created from range(ch_names).

Sample rate of the data.

Channel types, default is 'misc' which is a non-data channel. Currently supported fields are ‘bio’, ‘chpi’, ‘csd’, ‘dbs’, ‘dipole’, ‘ecg’, ‘ecog’, ‘eeg’, ‘emg’, ‘eog’, ‘exci’, ‘eyegaze’, ‘fnirs_cw_amplitude’, ‘fnirs_fd_ac_amplitude’, ‘fnirs_fd_phase’, ‘fnirs_od’, ‘gof’, ‘gsr’, ‘hbo’, ‘hbr’, ‘ias’, ‘misc’, ‘pupil’, ‘ref_meg’, ‘resp’, ‘seeg’, ‘stim’, ‘syst’, ‘temperature’ (see also sensor types). If str, then all channels are assumed to be of the same type.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The mne.Info object with information about the sensors and methods of measurement.

The info dictionary will be sparsely populated to enable functionality within the rest of the package. Advanced functionality such as source localization can only be obtained through substantial, proper modifications of the info structure (not recommended).

Note that the MEG device-to-head transform info['dev_head_t'] will be initialized to the identity transform.

Proper units of measure:

V: eeg, eog, seeg, dbs, emg, ecg, bio, ecog, resp, fnirs_fd_ac_amplitude, fnirs_cw_amplitude, fnirs_od

T: mag, chpi, ref_meg

AU: misc, stim, eyegaze, pupil

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Analysis of evoked response using ICA and PCA reduction techniques

Receptive Field Estimation and Prediction

How to use data in neural ensemble (NEO) format

Identify EEG Electrodes Bridged by too much Gel

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Plotting sensor layouts of EEG systems

EEG forward operator with a template MRI

Importing data from fNIRS devices

Creating MNE-Python data structures from scratch

---

## mne.cuda.get_cuda_memory#

**URL:** https://mne.tools/stable/generated/mne.cuda.get_cuda_memory.html

**Contents:**
- mne.cuda.get_cuda_memory#

Get the amount of free memory for CUDA operations.

Can be "available" or "total".

The amount of available or total memory as a human-readable string.

---

## mne.cuda.init_cuda#

**URL:** https://mne.tools/stable/generated/mne.cuda.init_cuda.html

**Contents:**
- mne.cuda.init_cuda#

Initialize CUDA functionality.

This function attempts to load the necessary interfaces (hardware connectivity) to run CUDA-based filtering. This function should only need to be run once per session.

If the config var (set via mne.set_config or in ENV) MNE_USE_CUDA == ‘true’, this function will be executed when the first CUDA setup is performed. If this variable is not set, this function can be manually executed.

If True, ignore the config value MNE_USE_CUDA and force init.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.cuda.get_cuda_memory

mne.cuda.set_cuda_device

---

## mne.cuda.set_cuda_device#

**URL:** https://mne.tools/stable/generated/mne.cuda.set_cuda_device.html

**Contents:**
- mne.cuda.set_cuda_device#

Set the CUDA device temporarily for the current session.

Numeric ID of the CUDA-capable device you want MNE-Python to use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

---

## mne.datasets.brainstorm.bst_auditory.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.brainstorm.bst_auditory.data_path.html

**Contents:**
- mne.datasets.brainstorm.bst_auditory.data_path#

Get path to local copy of brainstorm (bst_auditory) dataset.

Location of where to look for the brainstorm (bst_auditory) dataset. If None, the environment variable or config parameter MNE_DATASETS_BRAINSTORM_DATA_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the brainstorm (bst_auditory) dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the brainstorm (bst_auditory) dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_BRAINSTORM_DATA_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the brainstorm (bst_auditory) dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

If True (default False), accept the license terms of this dataset.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to brainstorm (bst_auditory) dataset directory.

mne.datasets.has_dataset

mne.datasets.brainstorm.bst_resting.data_path

---

## mne.datasets.brainstorm.bst_raw.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.brainstorm.bst_raw.data_path.html

**Contents:**
- mne.datasets.brainstorm.bst_raw.data_path#

Get path to local copy of brainstorm (bst_raw) dataset.

Location of where to look for the brainstorm (bst_raw) dataset. If None, the environment variable or config parameter MNE_DATASETS_BRAINSTORM_DATA_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the brainstorm (bst_raw) dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the brainstorm (bst_raw) dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_BRAINSTORM_DATA_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the brainstorm (bst_raw) dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

If True (default False), accept the license terms of this dataset.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to brainstorm (bst_raw) dataset directory.

mne.datasets.brainstorm.bst_resting.data_path

mne.datasets.default_path

---

## mne.datasets.brainstorm.bst_resting.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.brainstorm.bst_resting.data_path.html

**Contents:**
- mne.datasets.brainstorm.bst_resting.data_path#

Get path to local copy of brainstorm (bst_resting) dataset.

Location of where to look for the brainstorm (bst_resting) dataset. If None, the environment variable or config parameter MNE_DATASETS_BRAINSTORM_DATA_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the brainstorm (bst_resting) dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the brainstorm (bst_resting) dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_BRAINSTORM_DATA_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the brainstorm (bst_resting) dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

If True (default False), accept the license terms of this dataset.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to brainstorm (bst_resting) dataset directory.

mne.datasets.brainstorm.bst_auditory.data_path

mne.datasets.brainstorm.bst_raw.data_path

---

## mne.datasets.default_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.default_path.html

**Contents:**
- mne.datasets.default_path#

Get the default MNE_DATA path.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to the default MNE_DATA directory.

mne.datasets.brainstorm.bst_raw.data_path

mne.datasets.eegbci.load_data

---

## mne.datasets.eegbci.load_data#

**URL:** https://mne.tools/stable/generated/mne.datasets.eegbci.load_data.html

**Contents:**
- mne.datasets.eegbci.load_data#

Get paths to local copies of EEGBCI dataset files.

This will fetch data for the EEGBCI dataset [1], which is also available at PhysioNet [2]. Metadata, such as the meaning of event markers may be obtained from the PhysioNet documentation page.

The subjects to use. Can be in the range of 1-109 (inclusive).

The runs to use (see Notes for details).

Location of where to look for the EEGBCI data. If None, the environment variable or config parameter MNE_DATASETS_EEGBCI_PATH is used. If neither exists, the ~/mne_data directory is used. If the EEGBCI dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the dataset even if a local copy exists.

If True, set MNE_DATASETS_EEGBCI_PATH in the configuration to the given path. If None, the user is prompted.

The URL root for the data.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of local data paths of the given type.

The run numbers correspond to:

Baseline, eyes closed

Motor execution: left vs right hand

Motor imagery: left vs right hand

Motor execution: hands vs feet

Motor imagery: hands vs feet

For example, one could do:

This would download runs 6, 10, and 14 (hand/foot motor imagery) runs from subjects 1 and 2 in the EEGBCI dataset to “~/datasets” and prompt the user to store this path in the config (if it does not already exist).

Gerwin Schalk, Dennis J. McFarland, Thilo Hinterberger, Niels Birbaumer, and Jonathan R. Wolpaw. BCI2000: a general-purpose brain-computer interface (BCI) system. IEEE Transactions on Biomedical Engineering, 51(6):1034–1043, 2004. doi:10.1109/TBME.2004.827072.

Ary L. Goldberger, Luis A. N. Amaral, Leon Glass, Jeffrey M. Hausdorff, Plamen Ch. Ivanov, Roger G. Mark, Joseph E. Mietus, George B. Moody, Chung-Kang Peng, and H. Eugene Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation, 2000. doi:10.1161/01.CIR.101.23.e215.

mne.datasets.default_path

mne.datasets.eegbci.standardize

---

## mne.datasets.eegbci.standardize#

**URL:** https://mne.tools/stable/generated/mne.datasets.eegbci.standardize.html

**Contents:**
- mne.datasets.eegbci.standardize#

Standardize channel positions and names.

The raw data to standardize. Operates in-place.

mne.datasets.eegbci.load_data

mne.datasets.fetch_aparc_sub_parcellation

---

## mne.datasets.epilepsy_ecog.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.epilepsy_ecog.data_path.html

**Contents:**
- mne.datasets.epilepsy_ecog.data_path#
- Examples using mne.datasets.epilepsy_ecog.data_path#

Get path to local copy of epilepsy_ecog dataset.

Location of where to look for the epilepsy_ecog dataset. If None, the environment variable or config parameter MNE_DATASETS_EPILEPSY_ECOG_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the epilepsy_ecog dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the epilepsy_ecog dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_EPILEPSY_ECOG_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the epilepsy_ecog dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to epilepsy_ecog dataset directory.

Working with ECoG data

mne.datasets.erp_core.data_path

mne.datasets.eyelink.data_path

---

## mne.datasets.erp_core.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.erp_core.data_path.html

**Contents:**
- mne.datasets.erp_core.data_path#

Get path to local copy of erp_core dataset.

Location of where to look for the erp_core dataset. If None, the environment variable or config parameter MNE_DATASETS_ERP_CORE_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the erp_core dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the erp_core dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_ERP_CORE_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the erp_core dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to erp_core dataset directory.

mne.datasets.ssvep.data_path

mne.datasets.epilepsy_ecog.data_path

---

## mne.datasets.eyelink.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.eyelink.data_path.html

**Contents:**
- mne.datasets.eyelink.data_path#

Get path to local copy of eyelink dataset.

Location of where to look for the eyelink dataset. If None, the environment variable or config parameter MNE_DATASETS_EYELINK_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the eyelink dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the eyelink dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_EYELINK_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the eyelink dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to eyelink dataset directory.

mne.datasets.epilepsy_ecog.data_path

---

## mne.datasets.fetch_aparc_sub_parcellation#

**URL:** https://mne.tools/stable/generated/mne.datasets.fetch_aparc_sub_parcellation.html

**Contents:**
- mne.datasets.fetch_aparc_sub_parcellation#

Fetch the modified subdivided aparc parcellation.

This will download and install the subdivided aparc parcellation :footcite:’KhanEtAl2018’ files for FreeSurfer’s fsaverage to the specified directory.

The subjects directory to use. The file will be placed in subjects_dir + '/fsaverage/label'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.datasets.eegbci.standardize

mne.datasets.fetch_fsaverage

---

## mne.datasets.fetch_dataset#

**URL:** https://mne.tools/stable/generated/mne.datasets.fetch_dataset.html

**Contents:**
- mne.datasets.fetch_dataset#

Fetch an MNE-compatible dataset using pooch.

The dataset name(s) and corresponding parameters to download the dataset(s). The dataset parameters that contains the following keys: archive_name, url, folder_name, hash, config_key (optional). See Notes.

What to do after downloading the file. "unzip" and "untar" will decompress the downloaded file in place; for custom extraction (e.g., only extracting certain files from the archive) pass an instance of pooch.Unzip or pooch.Untar. If None (the default), the files are left as-is.

Directory in which to put the dataset. If None, the dataset location is determined by first checking whether dataset_params['config_key'] is defined, and if so, whether that config key exists in the MNE-Python config file. If so, the configured path is used; if not, the location is set to the value of the MNE_DATA config key (if it exists), or ~/mne_data otherwise.

Force update of the dataset even if a local copy exists. Default is False.

If True (default), set the mne-python config to the given path. If None, the user is prompted.

If False and the dataset has not been downloaded yet, it will not be downloaded and the path will be returned as '' (empty string). This is mostly used for testing purposes and can be safely ignored by most users.

Whether to check the version of the dataset or not. Each version of the dataset is stored in the root with a version.txt file.

Whether or not to return the version of the dataset or not. Defaults to False.

Some MNE-supplied datasets require acceptance of an additional license. Default is False.

Optional authentication tuple containing the username and password/token, passed to pooch.HTTPDownloader (e.g., auth=('foo', 012345)).

Optional authentication token passed to pooch.HTTPDownloader.

The path to the fetched dataset.

Only returned if return_version is True.

The dataset_params argument must contain the following keys:

archive_name: The name of the (possibly compressed) file to download

url: URL from which the file can be downloaded

save and uncompress (if needed) the file(s)

then the hash value (examples: “sha256:19uheid…”, “md5:upodh2io…”)

the on-disk location of the downloaded dataset (e.g., "MNE_DATASETS_EEGBCI_PATH"). This will only work for the provided datasets listed here; do not use for user-defined datasets.

An example would look like:

For datasets where a single (possibly compressed) file must be downloaded, pass a single dict as dataset_params. For datasets where multiple files must be downloaded and (optionally) uncompressed separately, pass a list of dicts.

mne.datasets.has_dataset

---

## mne.datasets.fetch_fsaverage#

**URL:** https://mne.tools/stable/generated/mne.datasets.fetch_fsaverage.html

**Contents:**
- mne.datasets.fetch_fsaverage#

Fetch and update fsaverage.

The path to use as the subjects directory in the MNE-Python config file. None will use the existing config variable (i.e., will not change anything), and if it does not exist, will use ~/mne_data/MNE-fsaverage-data.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The fsaverage directory. (essentially subjects_dir / 'fsaverage').

Changed in version 1.8: A pathlib.Path object is returned instead of a string.

This function is designed to provide

All modern (Freesurfer 6) fsaverage subject files

All MNE fsaverage parcellations

fsaverage head surface, fiducials, head<->MRI trans, 1- and 3-layer BEMs (and surfaces)

This function will compare the contents of subjects_dir/fsaverage to the ones provided in the remote zip file. If any are missing, the zip file is downloaded and files are updated. No files will be overwritten.

mne.datasets.fetch_aparc_sub_parcellation

mne.datasets.fetch_hcp_mmp_parcellation

---

## mne.datasets.fetch_hcp_mmp_parcellation#

**URL:** https://mne.tools/stable/generated/mne.datasets.fetch_hcp_mmp_parcellation.html

**Contents:**
- mne.datasets.fetch_hcp_mmp_parcellation#

Fetch the HCP-MMP parcellation.

This will download and install the HCP-MMP parcellation [1] files for FreeSurfer’s fsaverage [2] to the specified directory.

The subjects directory to use. The file will be placed in subjects_dir + '/fsaverage/label'.

If True, also produce the combined/reduced set of 23 labels per hemisphere as HCPMMP1_combined.annot [3].

If True (default False), accept the license terms of this dataset.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Use of this parcellation is subject to terms of use on the HCP-MMP webpage.

Matthew F. Glasser, Timothy S. Coalson, Emma C. Robinson, Carl D. Hacker, John Harwell, Essa Yacoub, Kamil Ugurbil, Jesper Andersson, Christian F. Beckmann, Mark Jenkinson, Stephen M. Smith, and David C. Van Essen. A multi-modal parcellation of human cerebral cortex. Nature, 536(7615):171–178, 2016. doi:10.1038/nature18933.

Kathryn Mills. HCP-MMP1.0 projected on fsaverage. 2016. doi:10.6084/m9.figshare.3498446.v2.

Matthew F. Glasser, Timothy S. Coalson, Emma C. Robinson, Carl D. Hacker, John Harwell, Essa Yacoub, Kamil Ugurbil, Jesper Andersson, Christian F. Beckmann, Mark Jenkinson, Stephen M. Smith, and David C. Van Essen. Supplementary neuroanatomical results for “A multi-modal parcellation of human cerebral cortex”. Nature, 2016. URL: https://static-content.springer.com/esm/art%3A10.1038%2Fnature18933/MediaObjects/41586_2016_BFnature18933_MOESM330_ESM.pdf#page=2.

mne.datasets.fetch_fsaverage

mne.datasets.fetch_infant_template

---

## mne.datasets.fetch_infant_template#

**URL:** https://mne.tools/stable/generated/mne.datasets.fetch_infant_template.html

**Contents:**
- mne.datasets.fetch_infant_template#
- Examples using mne.datasets.fetch_infant_template#

Fetch and update an infant MRI template.

Age to download. Can be one of {'2wk', '1mo', '2mo', '3mo', '4.5mo', '6mo', '7.5mo', '9mo', '10.5mo', '12mo', '15mo', '18mo', '2yr'}.

The path to download the template data to.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The standard subject name, e.g. ANTS4-5Month3T.

If you use these templates in your work, please cite [1] and [2].

Christian O’Reilly, Eric Larson, John E. Richards, and Mayada Elsabbagh. Structural templates for imaging EEG cortical sources in infants. NeuroImage, 227:117682, 2021. doi:10.1016/j.neuroimage.2020.117682.

John E. Richards, Carmen Sanchez, Michelle Phillips-Meek, and Wanze Xie. A database of age-appropriate average MRI templates. NeuroImage, 124:1254–1259, 2016. doi:10.1016/j.neuroimage.2015.04.055.

Using an automated approach to coregistration

EEG forward operator with a template MRI

mne.datasets.fetch_hcp_mmp_parcellation

mne.datasets.fetch_phantom

---

## mne.datasets.fetch_phantom#

**URL:** https://mne.tools/stable/generated/mne.datasets.fetch_phantom.html

**Contents:**
- mne.datasets.fetch_phantom#

Fetch and update a phantom subject.

The kind of phantom to fetch. Can only be 'otaniemi' (default).

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resulting phantom subject directory.

This function is designed to provide a head surface and T1.mgz for the 32-dipole Otaniemi phantom. The VectorView/TRIUX phantom has the same basic outside geometry, but different internal dipole positions.

Unlike most FreeSurfer subjects, the Otaniemi phantom scan was aligned to the “head” coordinate frame, so an identity head<->MRI trans is appropriate.

mne.datasets.fetch_infant_template

mne.datasets.fnirs_motor.data_path

---

## mne.datasets.fnirs_motor.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.fnirs_motor.data_path.html

**Contents:**
- mne.datasets.fnirs_motor.data_path#

Get path to local copy of fnirs_motor dataset.

Location of where to look for the fnirs_motor dataset. If None, the environment variable or config parameter MNE_DATASETS_FNIRS_MOTOR_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the fnirs_motor dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the fnirs_motor dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_FNIRS_MOTOR_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the fnirs_motor dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to fnirs_motor dataset directory.

mne.datasets.fetch_phantom

mne.datasets.hf_sef.data_path

---

## mne.datasets.has_dataset#

**URL:** https://mne.tools/stable/generated/mne.datasets.has_dataset.html

**Contents:**
- mne.datasets.has_dataset#

Check for presence of a dataset.

The dataset to check. Strings refer to one of the supported datasets listed here. A dict can be used to check for user-defined datasets (see the Notes section of fetch_dataset()), and must contain keys dataset_name, archive_name, url, folder_name, hash.

True if the dataset is present.

mne.datasets.fetch_dataset

mne.datasets.brainstorm.bst_auditory.data_path

---

## mne.datasets.hf_sef.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.hf_sef.data_path.html

**Contents:**
- mne.datasets.hf_sef.data_path#

Get path to local copy of the high frequency SEF dataset.

Gets a local copy of the high frequency SEF MEG dataset [1].

Whether to get the main dataset (evoked, structural and the rest) or the separate dataset containing raw MEG data only.

Where to look for the HF-SEF data storing location. If None, the environment variable or config parameter MNE_DATASETS_HF_SEF_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the HF-SEF dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the dataset even if a local copy exists.

If True, set the MNE_DATASETS_HF_SEF_PATH in mne-python config to the given path. If None, the user is prompted.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Local path to the directory where the HF-SEF data is stored.

Jussi Nurminen, Hilla Paananen, and Jyrki Mäkelä. High frequency somatosensory MEG: evoked responses, freesurfer reconstruction. 2017. doi:10.5281/zenodo.889234.

mne.datasets.fnirs_motor.data_path

mne.datasets.kiloword.data_path

---

## mne.datasets.kiloword.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.kiloword.data_path.html

**Contents:**
- mne.datasets.kiloword.data_path#

Get path to local copy of the kiloword dataset.

This is the dataset from [1].

Location of where to look for the kiloword data storing location. If None, the environment variable or config parameter MNE_DATASETS_KILOWORD_PATH is used. If it doesn’t exist, the “mne-python/examples” directory is used. If the kiloword dataset is not found under the given path (e.g., as “mne-python/examples/MNE-kiloword-data”), the data will be automatically downloaded to the specified folder.

Force update of the dataset even if a local copy exists.

If True, set the MNE_DATASETS_KILOWORD_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the kiloword dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Local path to the given data file. This path is contained inside a list of length one, for compatibility.

Stéphane Dufau, Jonathan Grainger, Katherine J. Midgley, and Phillip J. Holcomb. A thousand words are worth a picture: snapshots of printed-word processing in an event-related potential megastudy. Psychological Science, 26(12):1887–1897, 2015. doi:10.1177/0956797615603934.

mne.datasets.hf_sef.data_path

mne.datasets.limo.load_data

---

## mne.datasets.limo.load_data#

**URL:** https://mne.tools/stable/generated/mne.datasets.limo.load_data.html

**Contents:**
- mne.datasets.limo.load_data#

Fetch subjects epochs data for the LIMO data set.

Subject to use. Must be of class ìnt in the range from 1 to 18.

Location of where to look for the LIMO data. If None, the environment variable or config parameter MNE_DATASETS_LIMO_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used.

Force update of the dataset even if a local copy exists.

If True, set the MNE_DATASETS_LIMO_PATH in mne-python config to the given path. If None, the user is prompted.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.datasets.kiloword.data_path

mne.datasets.misc.data_path

---

## mne.datasets.misc.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.misc.data_path.html

**Contents:**
- mne.datasets.misc.data_path#

Get path to local copy of misc dataset.

Location of where to look for the misc dataset. If None, the environment variable or config parameter MNE_DATASETS_MISC_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the misc dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the misc dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_MISC_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the misc dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to misc dataset directory.

mne.datasets.limo.load_data

mne.datasets.mtrf.data_path

---

## mne.datasets.mtrf.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.mtrf.data_path.html

**Contents:**
- mne.datasets.mtrf.data_path#

Get path to local copy of mtrf dataset.

Location of where to look for the mtrf dataset. If None, the environment variable or config parameter MNE_DATASETS_MTRF_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the mtrf dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the mtrf dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_MTRF_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the mtrf dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to mtrf dataset directory.

mne.datasets.misc.data_path

mne.datasets.multimodal.data_path

---

## mne.datasets.multimodal.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.multimodal.data_path.html

**Contents:**
- mne.datasets.multimodal.data_path#

Get path to local copy of multimodal dataset.

Location of where to look for the multimodal dataset. If None, the environment variable or config parameter MNE_DATASETS_MULTIMODAL_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the multimodal dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the multimodal dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_MULTIMODAL_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the multimodal dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to multimodal dataset directory.

mne.datasets.mtrf.data_path

mne.datasets.opm.data_path

---

## mne.datasets.opm.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.opm.data_path.html

**Contents:**
- mne.datasets.opm.data_path#

Get path to local copy of opm dataset.

Location of where to look for the opm dataset. If None, the environment variable or config parameter MNE_DATASETS_OPML_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the opm dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the opm dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_OPML_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the opm dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to opm dataset directory.

mne.datasets.multimodal.data_path

mne.datasets.sleep_physionet.age.fetch_data

---

## mne.datasets.phantom_4dbti.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.phantom_4dbti.data_path.html

**Contents:**
- mne.datasets.phantom_4dbti.data_path#

Get path to local copy of phantom_4dbti dataset.

Location of where to look for the phantom_4dbti dataset. If None, the environment variable or config parameter MNE_DATASETS_PHANTOM_4DBTI_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the phantom_4dbti dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the phantom_4dbti dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_PHANTOM_4DBTI_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the phantom_4dbti dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to phantom_4dbti dataset directory.

mne.datasets.phantom_kit.data_path

mne.datasets.phantom_kernel.data_path

---

## mne.datasets.phantom_kernel.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.phantom_kernel.data_path.html

**Contents:**
- mne.datasets.phantom_kernel.data_path#

Get path to local copy of phantom_kernel dataset.

Location of where to look for the phantom_kernel dataset. If None, the environment variable or config parameter MNE_DATASETS_PHANTOM_KERNEL_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the phantom_kernel dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the phantom_kernel dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_PHANTOM_KERNEL_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the phantom_kernel dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to phantom_kernel dataset directory.

mne.datasets.phantom_4dbti.data_path

mne.datasets.refmeg_noise.data_path

---

## mne.datasets.phantom_kit.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.phantom_kit.data_path.html

**Contents:**
- mne.datasets.phantom_kit.data_path#

Get path to local copy of phantom_kit dataset.

Location of where to look for the phantom_kit dataset. If None, the environment variable or config parameter MNE_DATASETS_PHANTOM_KIT_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the phantom_kit dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the phantom_kit dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_PHANTOM_KIT_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the phantom_kit dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to phantom_kit dataset directory.

mne.datasets.visual_92_categories.data_path

mne.datasets.phantom_4dbti.data_path

---

## mne.datasets.refmeg_noise.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.refmeg_noise.data_path.html

**Contents:**
- mne.datasets.refmeg_noise.data_path#

Get path to local copy of refmeg_noise dataset.

Location of where to look for the refmeg_noise dataset. If None, the environment variable or config parameter MNE_DATASETS_REFMEG_NOISE_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the refmeg_noise dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the refmeg_noise dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_REFMEG_NOISE_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the refmeg_noise dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to refmeg_noise dataset directory.

mne.datasets.phantom_kernel.data_path

mne.datasets.ssvep.data_path

---

## mne.datasets.sample.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.sample.data_path.html

**Contents:**
- mne.datasets.sample.data_path#
- Examples using mne.datasets.sample.data_path#

Get path to local copy of sample dataset.

Location of where to look for the sample dataset. If None, the environment variable or config parameter MNE_DATASETS_SAMPLE_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the sample dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the sample dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_SAMPLE_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the sample dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to sample dataset directory.

Overview of MEG/EEG analysis with MNE-Python

mne.datasets.sleep_physionet.temazepam.fetch_data

mne.datasets.somato.data_path

---

## mne.datasets.sleep_physionet.age.fetch_data#

**URL:** https://mne.tools/stable/generated/mne.datasets.sleep_physionet.age.fetch_data.html

**Contents:**
- mne.datasets.sleep_physionet.age.fetch_data#
- Examples using mne.datasets.sleep_physionet.age.fetch_data#

Get paths to local copies of PhysioNet Polysomnography dataset files.

This will fetch data from the publicly available subjects from PhysioNet’s study of age effects on sleep in healthy subjects [1][2]. This corresponds to a subset of 153 recordings from 37 males and 41 females that were 25-101 years old at the time of the recordings. There are two night recordings per subject except for subjects 13, 36 and 52 which have one record missing each due to missing recording hardware.

See more details in physionet website.

The subjects to use. Can be in the range of 0-82 (inclusive), however the following subjects are not available: 39, 68, 69, 78 and 79.

The night recording indices. Valid values are : [1], [2], or [1, 2]. The following recordings are not available: recording 1 for subject 36 and 52, and recording 2 for subject 13.

Location of where to look for the PhysioNet data storing location. If None, the environment variable or config parameter PHYSIONET_SLEEP_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the Polysomnography dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the dataset even if a local copy exists.

What to do if one or several recordings are not available. Valid keys are ‘raise’ | ‘warn’ | ‘ignore’. Default is ‘error’. If on_missing is ‘warn’ it will proceed but warn, if ‘ignore’ it will proceed silently.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of local data paths of the given type.

For example, one could do:

This would download data for subject 0 if it isn’t there already.

M. S. Mourtazaev, B. Kemp, A. H. Zwinderman, and H. A. C. Kamphuisen. Age and gender affect different characteristics of slow waves in the sleep EEG. Sleep, 18(7):557–564, 1995. doi:10.1093/sleep/18.7.557.

Ary L. Goldberger, Luis A. N. Amaral, Leon Glass, Jeffrey M. Hausdorff, Plamen Ch. Ivanov, Roger G. Mark, Joseph E. Mietus, George B. Moody, Chung-Kang Peng, and H. Eugene Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation, 2000. doi:10.1161/01.CIR.101.23.e215.

Sleep stage classification from polysomnography (PSG) data

mne.datasets.opm.data_path

mne.datasets.sleep_physionet.temazepam.fetch_data

---

## mne.datasets.sleep_physionet.temazepam.fetch_data#

**URL:** https://mne.tools/stable/generated/mne.datasets.sleep_physionet.temazepam.fetch_data.html

**Contents:**
- mne.datasets.sleep_physionet.temazepam.fetch_data#

Get paths to local copies of PhysioNet Polysomnography dataset files.

This will fetch data from the publicly available subjects from PhysioNet’s study of Temazepam effects on sleep [1]. This corresponds to a set of 22 subjects. Subjects had mild difficulty falling asleep but were otherwise healthy.

See more details in the physionet website [2].

The subjects to use. Can be in the range of 0-21 (inclusive).

Location of where to look for the PhysioNet data storing location. If None, the environment variable or config parameter PHYSIONET_SLEEP_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the Polysomnography dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the dataset even if a local copy exists.

The base URL to download from.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of local data paths of the given type.

For example, one could do:

This would download data for subject 0 if it isn’t there already.

B. Kemp, A. H. Zwinderman, B. Tuk, H. A. C. Kamphuisen, and J. J. L. Oberyé. Analysis of a sleep-dependent neuronal feedback loop: the slow-wave microcontinuity of the EEG. IEEE Transactions on Biomedical Engineering, 47(9):1185–1194, 2000. doi:10.1109/10.867928.

Ary L. Goldberger, Luis A. N. Amaral, Leon Glass, Jeffrey M. Hausdorff, Plamen Ch. Ivanov, Roger G. Mark, Joseph E. Mietus, George B. Moody, Chung-Kang Peng, and H. Eugene Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation, 2000. doi:10.1161/01.CIR.101.23.e215.

mne.datasets.sleep_physionet.age.fetch_data

mne.datasets.sample.data_path

---

## mne.datasets.somato.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.somato.data_path.html

**Contents:**
- mne.datasets.somato.data_path#

Get path to local copy of somato dataset.

Location of where to look for the somato dataset. If None, the environment variable or config parameter MNE_DATASETS_SOMATO_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the somato dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the somato dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_SOMATO_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the somato dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to somato dataset directory.

mne.datasets.sample.data_path

mne.datasets.spm_face.data_path

---

## mne.datasets.spm_face.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.spm_face.data_path.html

**Contents:**
- mne.datasets.spm_face.data_path#

Get path to local copy of spm dataset.

Location of where to look for the spm dataset. If None, the environment variable or config parameter MNE_DATASETS_SPM_DATA_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the spm dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the spm dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_SPM_DATA_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the spm dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to spm dataset directory.

mne.datasets.somato.data_path

mne.datasets.ucl_opm_auditory.data_path

---

## mne.datasets.ssvep.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.ssvep.data_path.html

**Contents:**
- mne.datasets.ssvep.data_path#

Get path to local copy of ssvep dataset.

Location of where to look for the ssvep dataset. If None, the environment variable or config parameter MNE_DATASETS_SSVEP_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the ssvep dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the ssvep dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_SSVEP_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the ssvep dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to ssvep dataset directory.

mne.datasets.refmeg_noise.data_path

mne.datasets.erp_core.data_path

---

## mne.datasets.ucl_opm_auditory.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.ucl_opm_auditory.data_path.html

**Contents:**
- mne.datasets.ucl_opm_auditory.data_path#

Get path to local copy of ucl_opm_auditory dataset.

Location of where to look for the ucl_opm_auditory dataset. If None, the environment variable or config parameter MNE_DATASETS_UCL_OPM_AUDITORY_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the ucl_opm_auditory dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the ucl_opm_auditory dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_UCL_OPM_AUDITORY_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the ucl_opm_auditory dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to ucl_opm_auditory dataset directory.

mne.datasets.spm_face.data_path

mne.datasets.visual_92_categories.data_path

---

## mne.datasets.visual_92_categories.data_path#

**URL:** https://mne.tools/stable/generated/mne.datasets.visual_92_categories.data_path.html

**Contents:**
- mne.datasets.visual_92_categories.data_path#

Get path to local copy of visual_92_categories dataset.

Location of where to look for the visual_92_categories dataset. If None, the environment variable or config parameter MNE_DATASETS_VISUAL_92_CATEGORIES_PATH is used. If it doesn’t exist, the “~/mne_data” directory is used. If the visual_92_categories dataset is not found under the given path, the data will be automatically downloaded to the specified folder.

Force update of the visual_92_categories dataset even if a local copy exists. Default is False.

If True (default), set the MNE_DATASETS_VISUAL_92_CATEGORIES_PATH in mne-python config to the given path. If None, the user is prompted.

If False and the visual_92_categories dataset has not been downloaded yet, it will not be downloaded and the path will be returned as ‘’ (empty string). This is mostly used for debugging purposes and can be safely ignored by most users.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Path to visual_92_categories dataset directory.

mne.datasets.ucl_opm_auditory.data_path

mne.datasets.phantom_kit.data_path

---

## mne.decimate_surface#

**URL:** https://mne.tools/stable/generated/mne.decimate_surface.html

**Contents:**
- mne.decimate_surface#

Decimate surface data.

The surface to be decimated, a 3 x number of points array.

The surface to be decimated, a 3 x number of triangles array.

The desired number of triangles.

Can be “quadric” or “sphere”. “sphere” will inflate the surface to a sphere using Freesurfer and downsample to an icosahedral or octahedral mesh.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated points.

The decimated triangles.

This requires VTK. If an odd target number was requested, the 'decimation' algorithm used results in the next even number of triangles. For example a reduction request to 30001 triangles may result in 30000 triangles.

This requires Freesurfer to be installed and available in the environment. The destination number of triangles must be one of [20, 80, 320, 1280, 5120, 20480] for ico (0-5) downsampling or one of [8, 32, 128, 512, 2048, 8192, 32768] for oct (1-7) downsampling.

This mode is slower, but could be more suitable for decimating meshes for BEM creation (recommended n_triangles=5120) due to better topological property preservation.

mne.convert_forward_solution

mne.dig_mri_distances

---

## mne.dig_mri_distances#

**URL:** https://mne.tools/stable/generated/mne.dig_mri_distances.html

**Contents:**
- mne.dig_mri_distances#
- Examples using mne.dig_mri_distances#

Compute distances between head shape points and the scalp surface.

This function is useful to check that coregistration is correct. Unless outliers are present in the head shape points, one can assume an average distance around 2-3 mm.

The mne.Info object with information about the sensors and methods of measurement. Must contain the head shape points in info['dig'].

The head<->MRI transform. If str is passed it is the path to file on disk.

The name of the subject.

Directory containing subjects data. If None use the Freesurfer SUBJECTS_DIR environment variable.

Kind of digitization points to use in the fitting. These can be any combination of (‘cardinal’, ‘hpi’, ‘eeg’, ‘extra’). Can also be ‘auto’ (default), which will use only the ‘extra’ points if enough (more than 4) are available, and if not, uses ‘extra’ and ‘eeg’ points.

If True, exclude points that have both negative Z values (below the nasion) and positive Y values (in front of the LPA/RPA). Default is False.

What to do if the surface is found to have topological defects. Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when one or more defects are found. Note that a lot of computations in MNE-Python assume the surfaces to be topologically correct, topological defects may still make other computations (e.g., mne.make_bem_model and mne.make_bem_solution) fail irrespective of this parameter.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Source alignment and coordinate frames

mne.forward.compute_depth_prior

---

## mne.DipoleFixed#

**URL:** https://mne.tools/stable/generated/mne.DipoleFixed.html

**Contents:**
- mne.DipoleFixed#
- Examples using mne.DipoleFixed#

Dipole class for fixed-position dipole fits.

This class should usually not be instantiated directly via mne.DipoleFixed(...). Instead, use one of the functions listed in the See Also section below.

The mne.Info object with information about the sensors and methods of measurement.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Time vector in seconds.

Copy the DipoleFixed object.

crop([tmin, tmax, include_tmax, verbose])

Crop data to a given time interval.

decimate(decim[, offset, verbose])

Decimate the time-series data.

plot([show, time_unit])

save(fname, *[, overwrite, verbose])

Save fixed dipole in FIF format.

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

This class is for fixed-position dipole fits, where the position (and maybe orientation) is static over time. For sequential dipole fits, where the position can change a function of time, use mne.Dipole.

Copy the DipoleFixed object.

Crop data to a given time interval.

Start time of selection in seconds.

End time of selection in seconds.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped time-series object, modified in-place.

Unlike Python slices, MNE time intervals by default include both their end points; crop(tmin, tmax) returns the interval tmin <= t <= tmax. Pass include_tmax=False to specify the half-open interval tmin <= t < tmax instead.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / “decimation” refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [1], p. 172; which cites [2]):

“… a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).”

Hence “decimation” in MNE is what is considered “compression” in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Call pyplot.show() at the end or not.

The units for the time axis, can be “ms” or “s” (default).

The figure containing the time courses.

Source localization with equivalent current dipole (ECD) fit

Save fixed dipole in FIF format.

The .fif[.gz] format is for mne.DipoleFixed objects, that is, fixed-position and optionally fixed-orientation dipole fits. For these fits, the amplitude (and optionally orientation) vary as a function of time, but not the position.

The name of the FIF file. Must end with '-dip.fif' or '-dip.fif.gz' to make it explicit that the file contains dipole information in FIF format.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

Time vector in seconds.

Source localization with equivalent current dipole (ECD) fit

---

## mne.dipole.get_phantom_dipoles#

**URL:** https://mne.tools/stable/generated/mne.dipole.get_phantom_dipoles.html

**Contents:**
- mne.dipole.get_phantom_dipoles#
- Examples using mne.dipole.get_phantom_dipoles#

Get standard phantom dipole locations and orientations.

Get the information for the given system:

The Neuromag VectorView phantom.

The older Neuromag phantom used at Otaniemi.

The phantom from [1].

Changed in version 1.6: Support added for 'oyama'.

The dipole positions.

The dipole orientations.

The Elekta phantoms have a radius of 79.5mm, and HPI coil locations in the XY-plane at the axis extrema (e.g., (79.5, 0), (0, -79.5), …).

Daisuke Oyama, Yoshiaki Adachi, Masato Yumoto, Isao Hashimoto, and Gen Uehara. Dry phantom for magnetoencephalography —Configuration, calibration, and contribution. Journal of Neuroscience Methods, 251:24–36, August 2015. doi:10.1016/j.jneumeth.2015.05.004.

Kernel OPM phantom data

Plot sensor denoising using oversampled temporal projection

Brainstorm Elekta phantom dataset tutorial

KIT phantom dataset tutorial

---

## mne.Dipole#

**URL:** https://mne.tools/stable/generated/mne.Dipole.html

**Contents:**
- mne.Dipole#
- Examples using mne.Dipole#

Dipole class for sequential dipole fits.

This class should usually not be instantiated directly via mne.Dipole(...). Instead, use one of the functions listed in the See Also section below.

Used to store positions, orientations, amplitudes, times, goodness of fit of dipoles, typically obtained with Neuromag/xfit, mne_dipole_fit or certain inverse solvers. Note that dipole position vectors are given in the head coordinate frame.

The time instants at which each dipole was fitted (s).

The dipoles positions (m) in head coordinates.

The amplitude of the dipoles (Am).

The dipole orientations (normalized to unit length).

Confidence limits in dipole orientation for “vol” in m^3 (volume), “depth” in m (along the depth axis), “long” in m (longitudinal axis), “trans” in m (transverse axis), “qlong” in Am, and “qtrans” in Am (currents). The current confidence limit in the depth direction is assumed to be zero (although it can be non-zero when a BEM is used).

The χ^2 values for the fits.

The number of free parameters for each fit.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The amplitude of the dipoles (Am).

Confidence limits in dipole orientation.

The χ^2 values for the fits.

The number of free parameters for each fit.

The dipole orientations (normalized to unit length).

The dipoles positions (m) in head coordinates.

Time vector in seconds.

Return the number of dipoles.

Copy the Dipoles object.

crop([tmin, tmax, include_tmax, verbose])

Crop data to a given time interval.

plot_amplitudes([color, show])

Plot the dipole amplitudes as a function of time.

plot_locations(trans, subject[, ...])

Plot dipole locations.

save(fname[, overwrite, verbose])

Save dipole in a .dip or .bdip file.

time_as_index(times[, use_rounding])

Convert time to indices.

to_mni(subject, trans[, subjects_dir, verbose])

Convert dipole location from head to MNI coordinates.

to_mri(subject, trans[, subjects_dir, verbose])

Convert dipole location from head to MRI surface RAS coordinates.

to_volume_labels(trans[, subject, aseg, ...])

Find an ROI in atlas for the dipole positions.

This class is for sequential dipole fits, where the position changes as a function of time. For fixed dipole fits, where the position is fixed as a function of time, use mne.DipoleFixed.

The slice of time points to use.

Return the number of dipoles.

The number of dipoles.

The amplitude of the dipoles (Am).

Confidence limits in dipole orientation.

Copy the Dipoles object.

The copied dipole instance.

Crop data to a given time interval.

Start time of selection in seconds.

End time of selection in seconds.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped instance.

Compute MxNE with time-frequency sparse prior

The χ^2 values for the fits.

The number of free parameters for each fit.

The dipole orientations (normalized to unit length).

Plot the dipole amplitudes as a function of time.

Color to use for the trace.

The figure object containing the plot.

Plot dipole locations.

If mode is set to ‘arrow’ or ‘sphere’, only the location of the first time point of each dipole is shown else use the show_all parameter.

The mri to head trans. Can be None with mode set to ‘3d’.

The FreeSurfer subject name (will be used to set the FreeSurfer environment variable SUBJECT). Can be None with mode set to '3d'.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Plot in 3D mode using PyVista with the given glyph type.

Plot in matplotlib Axes3D using matplotlib with MRI slices shown on the sides of a cube, with the dipole(s) shown as arrows extending outward from a dot (i.e., the arrows pivot on the tail).

Plot in matplotlib Axes using a quiver of arrows for the dipoles in three axes (axial, coronal, and sagittal views), with the arrow pivoting in the middle of the arrow.

Changed in version 1.1: Added support for 'outlines'.

Coordinate frame to use: ‘head’ or ‘mri’. Can also be ‘mri_rotated’ when mode equals 'outlines'. Defaults to ‘mri’.

Changed in version 1.1: Added support for 'mri_rotated'.

Index of the initially plotted dipole. Can also be ‘gof’ to plot the dipole with highest goodness of fit value or ‘amplitude’ to plot the dipole with the highest amplitude. The dipoles can also be browsed through using up/down arrow keys or mouse scroll. Defaults to ‘gof’. Only used if mode equals ‘orthoview’.

Whether to always plot all the dipoles. If True (default), the active dipole is plotted as a red dot and its location determines the shown MRI slices. The non-active dipoles are plotted as small blue dots. If False, only the active dipole is plotted. Only used if mode='orthoview'.

Axes to plot into. If None (default), axes will be created. If mode equals 'orthoview', must be a single Axes3D. If mode equals 'outlines', must be a list of three Axes.

Whether to halt program execution until the figure is closed. Defaults to False. Only used if mode equals ‘orthoview’.

Show figure if True. Defaults to True. Only used if mode equals ‘orthoview’.

The scale (size in meters) of the dipoles if mode is not 'orthoview'. The default is 0.03 when mode is 'outlines' and 0.005 otherwise.

The color of the dipoles. The default (None) will use 'y' if mode is 'orthoview' and show_all is True, else ‘r’. Can also be a list of colors to use when mode is 'outlines'.

Changed in version 0.19.0: Color is now passed in orthoview mode.

The highlight color. Only used in orthoview mode with show_all=True.

3D figure in which to plot the alignment. If None, creates a new 600x600 pixel figure with black background. Only used when mode is 'arrow' or 'sphere'.

The title of the figure if mode='orthoview' (ignored for all other modes). If None, dipole number and its properties (amplitude, orientation etc.) will be shown. Defaults to None.

Head source(s) to use. See the source option of mne.get_head_surf() for more information. Only used when mode equals 'outlines'.

Brain surface to show outlines for, can be 'white', 'pial', or None. Only used when mode is 'outlines'.

Width of the matplotlib quiver arrow, see matplotlib.axes.Axes.quiver(). If None (default), when mode is 'outlines' 0.015 will be used, and when mode is 'orthoview' the matplotlib default is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The PyVista figure or matplotlib Figure.

Examples using plot_locations:

Optically pumped magnetometer (OPM) data

Source localization with equivalent current dipole (ECD) fit

Visualize source time courses (stcs)

The dipoles positions (m) in head coordinates.

Save dipole in a .dip or .bdip file.

The .[b]dip format is for mne.Dipole objects, that is, fixed-position dipole fits. For these fits, the amplitude, orientation, and position vary as a function of time.

The name of the .dip or .bdip file.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Changed in version 0.20: Support for writing bdip (Xfit binary) files.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

Time vector in seconds.

Convert dipole location from head to MNI coordinates.

The FreeSurfer subject name.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The MNI coordinates (in mm) of pos.

Examples using to_mni:

Source localization with equivalent current dipole (ECD) fit

Convert dipole location from head to MRI surface RAS coordinates.

The FreeSurfer subject name.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The Freesurfer surface RAS coordinates (in mm) of pos.

Examples using to_mri:

Source localization with equivalent current dipole (ECD) fit

Find an ROI in atlas for the dipole positions.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation. If trans is None, an identity matrix is assumed.

Changed in version 0.19: Support for ‘fsaverage’ argument.

The FreeSurfer subject name.

The anatomical segmentation file. Default auto uses aparc+aseg if available and wmparc if not. This may be any anatomical segmentation file in the mri subdirectory of the Freesurfer subject directory.

Changed in version 1.8: Added support for the new default 'auto'.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of anatomical region names from anatomical segmentation atlas.

Examples using to_volume_labels:

Source localization with equivalent current dipole (ECD) fit

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Computing source timecourses with an XFit-like multi-dipole model

Compute MxNE with time-frequency sparse prior

Plotting with mne.viz.Brain

Source localization with equivalent current dipole (ECD) fit

The role of dipole orientations in distributed source localization

Visualize source time courses (stcs)

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

mne.beamformer.make_lcmv_resolution_matrix

---

## mne.event.define_target_events#

**URL:** https://mne.tools/stable/generated/mne.event.define_target_events.html

**Contents:**
- mne.event.define_target_events#
- Examples using mne.event.define_target_events#

Define new events by co-occurrence of existing events.

This function can be used to evaluate events depending on the temporal lag to another event. For example, this can be used to analyze evoked responses which were followed by a button press within a defined time window.

Array as returned by mne.find_events.

The reference event. The event defining the epoch of interest.

The target event. The event co-occurring in within a certain time window around the reference event.

The sampling frequency of the data.

The lower limit in seconds from the target event.

The upper limit border in seconds from the target event.

New ID for the new event.

Fill event to be inserted if target is not available within the time window specified. If None, the ‘null’ events will be dropped.

The new defined events.

Time lag between reference and target in milliseconds.

Define target events based on time lag, plot evoked response

Plot single trial activity, grouped by ROI and sorted by RT

mne.count_annotations

mne.event.match_event_names

---

## mne.event.match_event_names#

**URL:** https://mne.tools/stable/generated/mne.event.match_event_names.html

**Contents:**
- mne.event.match_event_names#

Search a collection of event names for matching (sub-)groups of events.

This function is particularly helpful when using grouped event names (i.e., event names containing forward slashes /). Please see the Examples section below for a working example.

Either a collection of event names, or the event_id dictionary mapping event names to event codes.

One or multiple event names or groups to search for in event_names.

How to handle situations when none of the keys can be found in event_names. If 'warn' or 'ignore', an empty list will be returned.

All event names that match any of the keys provided.

Assuming the following grouped event names in the data, you could easily query for all auditory and left event names:

mne.event.define_target_events

mne.event.shift_time_events

---

## mne.event.shift_time_events#

**URL:** https://mne.tools/stable/generated/mne.event.shift_time_events.html

**Contents:**
- mne.event.shift_time_events#

Shift a set of events.

The identity and timing of experimental events, around which the epochs were created. See events for more information.

The ids of events to shift.

Time-shift event. Use positive value tshift for forward shifting the event and negative value for backward shift.

The sampling frequency of the data.

mne.event.match_event_names

mne.epochs.average_movements

---

## mne.events_from_annotations#

**URL:** https://mne.tools/stable/generated/mne.events_from_annotations.html

**Contents:**
- mne.events_from_annotations#
- Examples using mne.events_from_annotations#

Get events and event_id from an Annotations object.

The raw data for which Annotations are defined.

dict: map descriptions (keys) to integer event codes (values). Only the descriptions present will be mapped, others will be ignored.

callable: must take a string input and return an integer event code, or return None to ignore the event.

None: Map descriptions to unique integer values based on their sorted order.

‘auto’ (default): prefer a raw-format-specific parser:

Brainvision: map stimulus events to their integer part; response events to integer part + 1000; optic events to integer part + 2000; ‘SyncStatus/Sync On’ to 99998; ‘New Segment/’ to 99999; all others like None with an offset of 10000.

Other raw formats: Behaves like None.

Regular expression used to filter the annotations whose descriptions is a match. The default ignores descriptions beginning 'bad' or 'edge' (case-insensitive).

Changed in version 0.18: Default ignores bad and edge descriptions.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Chunk duration in seconds. If chunk_duration is set to None (default), generated events correspond to the annotation onsets. If not, mne.events_from_annotations() returns as many events as they fit within the annotation duration spaced according to chunk_duration. As a consequence annotations with duration shorter than chunk_duration will not contribute events.

The tolerance used to check if a chunk fits within an annotation when chunk_duration is not None. If the duration from a computed chunk onset to the end of the annotation is smaller than chunk_duration minus tol, the onset will be discarded.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The identity and timing of experimental events, around which the epochs were created. See events for more information.

The event_id variable that can be passed to Epochs.

For data formats that store integer events as strings (e.g., NeuroScan .cnt files), passing the Python built-in function int as the event_id parameter will do what most users probably want in those circumstances: return an event_id dictionary that maps event '1' to integer event code 1, '2' to 2, etc.

Automated epochs metadata generation with variable time windows

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Plot single trial activity, grouped by ROI and sorted by RT

Sleep stage classification from polysomnography (PSG) data

Auto-generating Epochs metadata

Parsing events from raw data

KIT phantom dataset tutorial

Preprocessing functional near-infrared spectroscopy (fNIRS) data

mne.concatenate_epochs

mne.annotations_from_events

---

## mne.export.export_raw#

**URL:** https://mne.tools/stable/generated/mne.export.export_raw.html

**Contents:**
- mne.export.export_raw#

Export Raw to external formats.

BrainVision (.vhdr, .vmrk, .eeg, uses pybv)

EEGLAB (.set, uses eeglabio)

EDF (.edf, uses edfio)

Since we are exporting to external formats, there’s no guarantee that all the info will be preserved in the external format. See Notes for details.

When exporting Raw with annotations, raw.info["meas_date"] must be the same as raw.annotations.orig_time. This guarantees that the annotations are in the same reference frame as the samples. When Raw.first_time is not zero (e.g., after cropping), the onsets are automatically corrected so that onsets are always relative to the first sample.

Name of the output file.

The raw instance to export.

Format of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.

The physical range of the data. If ‘auto’ (default), the physical range is inferred from the data, taking the minimum and maximum values per channel type. If ‘channelwise’, the range will be defined per channel. If a tuple of minimum and maximum, this manual physical range will be used. Only used for exporting EDF files.

Whether to incorporate the channel type into the signal label (e.g. whether to store channel “Fz” as “EEG Fz”). Only used for EDF format. Default is False.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.io.Raw.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.io.Raw.apply_proj().

For EEGLAB exports, channel locations are expanded to full EEGLAB format. For more details see eeglabio.utils.cart_to_eeglab().

Although this function supports storing channel types in the signal label (e.g. EEG Fz or MISC E), other software may not support this (optional) feature of the EDF standard.

If add_ch_type is True, then channel types are written based on what they are currently set in MNE-Python. One should double check that all their channels are set correctly. You can call mne.io.Raw.set_channel_types() to set channel types.

In addition, EDF does not support storing a montage. You will need to store the montage separately and call mne.io.Raw.set_montage().

The physical range of the signals is determined by signal type by default (physical_range="auto"). However, if individual channel ranges vary significantly due to the presence of e.g. drifts/offsets/biases, setting physical_range="channelwise" might be more appropriate. This will ensure a maximum resolution for each individual channel, but some tools might not be able to handle this appropriately (even though channel-wise ranges are covered by the EDF standard).

mne.export.export_evokeds_mff

---

## mne.extract_label_time_course#

**URL:** https://mne.tools/stable/generated/mne.extract_label_time_course.html

**Contents:**
- mne.extract_label_time_course#
- Examples using mne.extract_label_time_course#

Extract label time course for lists of labels and source estimates.

This function will extract one time course for each label and source estimate. The way the time courses are extracted depends on the mode parameter (see Notes).

The source estimates from which to extract the time course.

If using a surface or mixed source space, this should be the Label’s for which to extract the time course. If working with whole-brain volume source estimates, this must be one of:

a string path to a FreeSurfer atlas for the subject (e.g., their ‘aparc.a2009s+aseg.mgz’) to extract time courses for all volumes in the atlas

a two-element list or tuple, the first element being a path to an atlas, and the second being a list or dict of volume_labels to extract (see mne.setup_volume_source_space() for details).

Changed in version 0.21.0: Support for volume source estimates.

The source spaces for the source time courses.

Extraction mode, see Notes.

False (default) will emit an error if there are labels that have no vertices in the source estimate. True and 'ignore' will return all-zero time courses for labels that do not have any vertices in the source estimate, and True will emit a warning while and “ignore” will just log a message.

Changed in version 0.21.0: Support for “ignore”.

If True, a generator instead of a list is returned.

If True (default), the volume source space will be upsampled to the original MRI resolution via trilinear interpolation before the atlas values are extracted. This ensnures that each atlas label will contain source activations. When False, only the original source space points are used, and some atlas labels thus may not contain any source space vertices.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Extracted time course for each label and source estimate.

Valid values for mode are:

Maximum absolute value across vertices at each time point within each label.

Average across vertices at each time point within each label. Ignores orientation of sources for standard source estimates, which varies across the cortical surface, which can lead to cancellation. Vector source estimates are always in XYZ / RAS orientation, and are thus already geometrically aligned.

Finds the dominant direction of source space normal vector orientations within each label, applies a sign-flip to time series at vertices whose orientation is more than 90° different from the dominant direction, and then averages across vertices at each time point within each label.

Applies singular value decomposition to the time courses within each label, and uses the first right-singular vector as the representative label time course. This signal is scaled so that its power matches the average (per-vertex) power within the label, and sign-flipped by multiplying by np.sign(u @ flip), where u is the first left-singular vector and flip is the same sign-flip vector used when mode='mean_flip'. This sign-flip ensures that extracting time courses from the same label in similar STCs does not result in 180° direction/phase changes.

Uses 'mean_flip' when a standard source estimate is applied, and 'mean' when a vector source estimate is supplied.

No aggregation is performed, and an array of shape (n_vertices, n_times) is returned.

New in v0.21: Support for 'auto', vector, and volume source estimates.

The only modes that work for vector and volume source estimates are 'mean', 'max', and 'auto'.

If encountering a ValueError due to mismatch between number of source points in the subject source space and computed stc object set src argument to fwd['src'] or inv['src'] to ensure the source space is the one actually used by the inverse to compute the source time courses.

Compute MNE inverse solution on evoked data with a mixed source space

mne.compute_source_morph

---

## mne.filter.construct_iir_filter#

**URL:** https://mne.tools/stable/generated/mne.filter.construct_iir_filter.html

**Contents:**
- mne.filter.construct_iir_filter#
- Examples using mne.filter.construct_iir_filter#

Use IIR parameters to get filtering coefficients.

This function works like a wrapper for iirdesign and iirfilter in scipy.signal to make filter coefficients for IIR filtering. It also estimates the number of padding samples based on the filter ringing. It creates a new iir_params dict (or updates the one passed to the function) with the filter coefficients (‘b’ and ‘a’) and an estimate of the padding necessary (‘padlen’) so IIR filtering can be performed.

Dictionary of parameters to use for IIR filtering.

If iir_params['sos'] exists, it will be used as second-order sections to perform IIR filtering.

Otherwise, if iir_params['b'] and iir_params['a'] exist, these will be used as coefficients to perform IIR filtering.

Otherwise, if iir_params['order'] and iir_params['ftype'] exist, these will be used with scipy.signal.iirfilter to make a filter. You should also supply iir_params['rs'] and iir_params['rp'] if using elliptic or Chebychev filters.

Otherwise, if iir_params['gpass'] and iir_params['gstop'] exist, these will be used with scipy.signal.iirdesign to design a filter.

iir_params['padlen'] defines the number of samples to pad (and an estimate will be calculated if it is not given). See Notes for more details.

iir_params['output'] defines the system output kind when designing filters, either “sos” or “ba”. For 0.13 the default is ‘ba’ but will change to ‘sos’ in 0.14.

Frequency for the pass-band. Low-pass and high-pass filters should be a float, band-pass should be a 2-element list of float.

Stop-band frequency (same size as f_pass). Not used if ‘order’ is specified in iir_params.

Type of filter. Should be ‘lowpass’, ‘highpass’, or ‘bandpass’ (or analogous string representations known to scipy.signal.iirfilter()).

If False, the ‘sos’, ‘b’, ‘a’, and ‘padlen’ entries in iir_params will be set inplace (if they weren’t already). Otherwise, a new iir_params instance will be created and returned with these entries.

Phase of the filter. phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Updated iir_params dict, with the entries (set only if they didn’t exist before) for ‘sos’ (or ‘b’, ‘a’), and ‘padlen’ for IIR filtering.

This function triages calls to scipy.signal.iirfilter() and scipy.signal.iirdesign() based on the input arguments (see linked functions for more details).

Changed in version 0.14: Second-order sections are used in filter design by default (replacing output='ba' by output='sos') to help ensure filter stability and reduce numerical error.

iir_params can have several forms. Consider constructing a low-pass filter at 40 Hz with 1000 Hz sampling rate.

In the most basic (2-parameter) form of iir_params, the order of the filter ‘N’ and the type of filtering ‘ftype’ are specified. To get coefficients for a 4th-order Butterworth filter, this would be:

Filters can also be constructed using filter design methods. To get a 40 Hz Chebyshev type 1 lowpass with specific gain characteristics in the pass and stop bands (assuming the desired stop band is at 45 Hz), this would be a filter with much longer ringing:

Padding and/or filter coefficients can also be manually specified. For a 10-sample moving window with no padding during filtering, for example, one can just do:

For more information, see the tutorials Background information on filtering and Filtering and resampling data.

Background information on filtering

mne.set_eeg_reference

mne.filter.create_filter

---

## mne.filter.create_filter#

**URL:** https://mne.tools/stable/generated/mne.filter.create_filter.html

**Contents:**
- mne.filter.create_filter#
- Examples using mne.filter.create_filter#

Create a FIR or IIR filter.

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

The data that will be filtered. This is used for sanity checking only. If None, no sanity checking related to the length of the signal relative to the filter order will be performed.

The sample frequency in Hz.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Will be an array of FIR coefficients for method=’fir’, and dict with IIR parameters for method=’iir’.

For FIR filters, the cutoff frequency, i.e. the -6 dB point, is in the middle of the transition band (when using phase=’zero’ and fir_design=’firwin’). For IIR filters, the cutoff frequency is given by l_freq or h_freq directly, and l_trans_bandwidth and h_trans_bandwidth are ignored.

The frequency response is (approximately) given by:

Fs1 = Fp1 - l_trans_bandwidth in Hz

Fs2 = Fp2 + h_trans_bandwidth in Hz

The frequency response is (approximately) given by:

Where Fs1 = Fp1 + l_trans_bandwidth and Fs2 = Fp2 - h_trans_bandwidth.

Multiple stop bands can be specified using arrays.

The frequency response is (approximately) given by:

Where Fstop = Fp + trans_bandwidth.

The frequency response is (approximately) given by:

Where Fstop = Fp - trans_bandwidth.

Background information on filtering

Filtering and resampling data

mne.filter.construct_iir_filter

mne.filter.estimate_ringing_samples

---

## mne.filter.estimate_ringing_samples#

**URL:** https://mne.tools/stable/generated/mne.filter.estimate_ringing_samples.html

**Contents:**
- mne.filter.estimate_ringing_samples#

Estimate filter ringing.

A tuple of (b, a) or ndarray of second-order sections coefficients.

Approximate maximum number of samples to try. This will be changed to a multiple of 1000.

The approximate ringing.

mne.filter.create_filter

mne.filter.filter_data

---

## mne.filter.filter_data#

**URL:** https://mne.tools/stable/generated/mne.filter.filter_data.html

**Contents:**
- mne.filter.filter_data#

Filter a subset of channels.

The sample frequency in Hz.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. None (default) will pick all channels. Note that channels in info['bads'] will be included if their indices are explicitly provided. Currently this is only supported for 2D (n_channels, n_times) and 3D (n_epochs, n_channels, n_times) arrays.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

If True, a copy of x, filtered, is returned. Otherwise, it operates on x in place.

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'. The default is 'reflect_limited'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks.

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

mne.filter.estimate_ringing_samples

mne.filter.notch_filter

---

## mne.filter.notch_filter#

**URL:** https://mne.tools/stable/generated/mne.filter.notch_filter.html

**Contents:**
- mne.filter.notch_filter#

Notch filter for the signal x.

Applies a zero-phase notch filter to the signal x, operating on the last dimension.

Frequencies to notch filter in Hz, e.g. np.arange(60, 241, 60). Multiple stop-bands can only be used with method=’fir’ and method=’spectrum_fit’. None can only be used with the mode ‘spectrum_fit’, where an F test is used to find sinusoidal components.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

When method=='spectrum_fit', this sets the effective window duration over which fits are computed. See mne.filter.create_filter() for options. Longer window lengths will give more stable frequency estimates, but require (potentially much) more processing and are not able to adapt as well to non-stationarities.

The default in 0.21 is None, but this will change to '10s' in 0.22.

Width of the stop band (centred at each freq in freqs) in Hz. If None, freqs / 200 is used.

Width of the transition band in Hz. Only used for method='fir' and method='iir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()). ‘spectrum_fit’ will use multi-taper estimation of sinusoidal components. If freqs=None and method=’spectrum_fit’, significant sinusoidal components are detected using an F test, and noted by logging.

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

The bandwidth of the multitaper windowing function in Hz. Only used in ‘spectrum_fit’ mode.

P-value to use in F-test thresholding to determine significant sinusoidal components to remove when method=’spectrum_fit’ and freqs=None. Note that this will be Bonferroni corrected for the number of frequencies, so large p-values may be justified.

Channels to include. Slices and lists of integers will be interpreted as channel indices. None (default) will pick all channels. Note that channels in info['bads'] will be included if their indices are explicitly provided. Only supported for 2D (n_channels, n_times) and 3D (n_epochs, n_channels, n_times) data.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

If True, a copy of x, filtered, is returned. Otherwise, it operates on x in place.

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'. The default is 'reflect_limited'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The x array filtered.

The frequency response is (approximately) given by:

For each freq in freqs, where Fp1 = freq - trans_bandwidth / 2 and Fs2 = freq + trans_bandwidth / 2.

Multi-taper removal is inspired by code from the Chronux toolbox, see www.chronux.org and the book “Observed Brain Dynamics” by Partha Mitra & Hemant Bokil, Oxford University Press, New York, 2008. Please cite this in publications if method ‘spectrum_fit’ is used.

mne.filter.filter_data

---

## mne.filter.resample#

**URL:** https://mne.tools/stable/generated/mne.filter.resample.html

**Contents:**
- mne.filter.resample#
- Examples using mne.filter.resample#

Operates along the last dimension of the array.

Factor to upsample by.

Factor to downsample by.

Axis along which to resample (default is the last axis).

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly. n_jobs='cuda' is only supported when method="fft".

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn(). The default (“auto”) means 'reflect_limited' for method='fft' and 'reflect' for method='polyphase'.

Amount to pad the start and end of the data. Can also be "auto" to use a padding that will result in a power-of-two size (can be much faster).

Only used when method="fft".

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The x array resampled.

When using method="fft" (default), this uses (hopefully) intelligent edge padding and frequency-domain windowing improve scipy.signal.resample()’s resampling method, which we have adapted for our use here. Choices of npad and window have important consequences, and the default choices should work well for most natural signals.

Receptive Field Estimation and Prediction

Spectro-temporal receptive field (STRF) estimation on continuous data

mne.filter.notch_filter

mne.chpi.compute_chpi_amplitudes

---

## mne.find_events#

**URL:** https://mne.tools/stable/generated/mne.find_events.html

**Contents:**
- mne.find_events#
- Examples using mne.find_events#

Find events from raw file.

See Parsing events from raw data and Working with events for more information about events.

Name of the stim channel or all the stim channels affected by triggers. If None, the config variables ‘MNE_STIM_CHANNEL’, ‘MNE_STIM_CHANNEL_1’, ‘MNE_STIM_CHANNEL_2’, etc. are read. If these are not found, it will fall back to ‘STI 014’ if present, then fall back to the first channel of type ‘stim’, if present. If multiple channels are provided then the returned events are the union of all the events extracted from individual stim channels.

Whether to report when events start, when events end, or both.

If True, consider instances where the value of the events channel changes without first returning to zero as multiple events. If False, report only instances where the value of the events channel changes from/to zero. If ‘increasing’, report adjacent events only when the second event code is greater than the first.

The minimum duration of a change in the events channel required to consider it as an event (in seconds).

Minimum number of samples an event must last (default is 2). If the duration is less than this an exception will be raised.

The value of the digital mask to apply to the stim channel values. If None (default), no masking is performed.

If True (default False), do a cast to uint16 on the channel data. This can be used to fix a bug with STI101 and STI014 in Neuromag acquisition setups that use channel STI016 (channel 16 turns data into e.g. -32768), similar to mne_fix_stim14 --32 in MNE-C.

The type of operation between the mask and the trigger. Choose ‘and’ (default) for MNE-C masking behavior.

If True (default False), an event is created if the stim channel has a value different from 0 as its first sample. This is useful if an event at t=0s is present.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The identity and timing of experimental events, around which the epochs were created. See events for more information.

Find all the steps in the stim channel.

Read events from disk.

Write events to disk.

If you are working with downsampled data, events computed before decimation are no longer valid. Please recompute your events after decimation, but note this reduces the precision of event timing.

Consider data with a stim channel that looks like:

By default, find_events returns all samples at which the value of the stim channel increases:

If consecutive is False, find_events only returns the samples at which the stim channel changes from zero to a non-zero value:

If consecutive is True, find_events returns samples at which the event changes, regardless of whether it first returns to zero:

If output is ‘offset’, find_events returns the last sample of each event instead of the first one:

If output is ‘step’, find_events returns the samples at which an event starts or ends:

To ignore spurious events, it is also possible to specify a minimum event duration. Assuming our events channel has a sample rate of 1000 Hz:

For the digital mask, if mask_type is set to ‘and’ it will take the binary representation of the digital mask, e.g. 5 -> ‘00000101’, and will allow the values to pass where mask is one, e.g.:

For the digital mask, if mask_type is set to ‘not_and’ it will take the binary representation of the digital mask, e.g. 5 -> ‘00000101’, and will block the values where mask is one, e.g.:

Brainstorm raw (median nerve) dataset

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Representational Similarity Analysis

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute source power estimate by projecting the covariance with MNE

Computing source timecourses with an XFit-like multi-dipole model

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Compute cross-talk functions for LCMV beamformers

Transform EEG data using current source density (CSD)

Show EOG artifact timing

Reduce EOG artifacts through regression

Maxwell filter data with movement compensation

Plot sensor denoising using oversampled temporal projection

Compare simulated and estimated source activity

Generate simulated raw data

Generate simulated source data

Regression on continuous data (rER[P/F])

Compute power and phase lock in label of the source space

Compute source power spectral density (PSD) in a label

Compute induced power in the source space with dSPM

Explore event-related dynamics for specific frequency bands

The Epochs data structure: discontinuous data

Regression-based baseline correction

Visualizing epoched data

The Evoked data structure: evoked/averaged data

Plotting whitened data

Computing a covariance matrix

Overview of MEG/EEG analysis with MNE-Python

Parsing events from raw data

Getting started with mne.Report

Source localization with MNE, dSPM, sLORETA, and eLORETA

Source reconstruction using an LCMV beamformer

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

Working with CTF data: the Brainstorm auditory dataset

Handling bad channels

Filtering and resampling data

Repairing artifacts with regression

Repairing artifacts with ICA

Repairing artifacts with SSP

Preprocessing optically pumped magnetometer (OPM) MEG data

Working with eye tracker data in MNE-Python

Corrupt known signal with point spread

DICS for power mapping

Non-parametric 1 sample cluster statistic on single trial power

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency and time-frequency sensor analysis

---

## mne.find_stim_steps#

**URL:** https://mne.tools/stable/generated/mne.find_stim_steps.html

**Contents:**
- mne.find_stim_steps#

Find all steps in data from a stim channel.

Values to assume outside of the stim channel (e.g., if pad_start=0 and the stim channel starts with value 5, an event of [0, 0, 5] will be inserted at the beginning). With None, no steps will be inserted.

Values to assume outside of the stim channel, see pad_start.

Merge steps occurring in neighboring samples. The integer value indicates over how many samples events should be merged, and the sign indicates in which direction they should be merged (negative means towards the earlier event, positive towards the later event).

Name of the stim channel or all the stim channels affected by the trigger. If None, the config variables ‘MNE_STIM_CHANNEL’, ‘MNE_STIM_CHANNEL_1’, ‘MNE_STIM_CHANNEL_2’, etc. are read. If these are not found, it will default to ‘STI101’ or ‘STI 014’, whichever is present.

For each step in the stim channel the values [sample, v_from, v_to]. The first column contains the event time in samples (the first sample with the new value). The second column contains the stim channel value before the step, and the third column contains value after the step.

More sophisticated options for finding events in a Raw file.

mne.make_fixed_length_events

---

## mne.fit_dipole#

**URL:** https://mne.tools/stable/generated/mne.fit_dipole.html

**Contents:**
- mne.fit_dipole#
- Examples using mne.fit_dipole#

The noise covariance.

The BEM filename (str) or conductor model.

The head<->MRI transform filename. Must be provided unless BEM is a sphere model.

Minimum distance (in millimeters) from the dipole to the inner skull. Must be positive. Note that because this is a constraint passed to a solver it is not strict but close, i.e. for a min_dist=5. the fits could be 4.9 mm from the inner skull.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. It is used in field computation and fitting.

Position of the dipole to use. If None (default), sequential fitting (different position and orientation for each time instance) is performed. If a position (in head coords) is given as an array, the position is fixed during fitting.

Orientation of the dipole to use. If None (default), the orientation is free to change as a function of time. If an orientation (in head coordinates) is given as an array, pos must also be provided, and the routine computes the amplitude and goodness of fit of the dipole at the given position and orientation for each time instant.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

Can be "normal" (default) or "accurate", which gives the most accurate coil definition but is typically not necessary for real-world data.

Final accuracy of the optimization (see rhoend argument of scipy.optimize.fmin_cobyla()).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The dipole fits. A mne.DipoleFixed is returned if pos and ori are both not None, otherwise a mne.Dipole is returned.

The M-EEG data channels with the fitted dipolar activity removed.

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

Computing source timecourses with an XFit-like multi-dipole model

Plot sensor denoising using oversampled temporal projection

Source localization with equivalent current dipole (ECD) fit

Visualize source time courses (stcs)

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

mne.dipole.get_phantom_dipoles

---

## mne.forward.compute_depth_prior#

**URL:** https://mne.tools/stable/generated/mne.forward.compute_depth_prior.html

**Contents:**
- mne.forward.compute_depth_prior#

Compute depth prior for depth weighting.

The forward solution.

The mne.Info object with information about the sensors and methods of measurement.

Exponent for the depth weighting, must be between 0 and 1.

The upper bound on depth weighting. Can be None to be bounded by the largest finite prior.

How to deal with multiple channel types in depth weighting. The default is True, which whitens based on the source sensitivity of the highest-SNR channel type. See Notes for details.

Changed in version 0.18: Added the “whiten” option.

When a loose (or free) orientation is used, how the depth weighting for each triplet should be calculated. If ‘spectral’, use the squared spectral norm of Gk. If ‘fro’, use the squared Frobenius norm of Gk.

The noise covariance to use to whiten the gain matrix when limit_depth_chs='whiten'.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The defaults used by the minimum norm code and sparse solvers differ. In particular, the values for MNE are:

In sparse solvers and LCMV, the values are:

The limit_depth_chs argument can take the following values:

Use only grad channels in depth weighting (equivalent to MNE C minimum-norm code). If grad channels aren’t present, only mag channels will be used (if no mag, then eeg). This makes the depth prior dependent only on the sensor geometry (and relationship to the sources).

Compute a whitener and apply it to the gain matrix before computing the depth prior. In this case noise_cov must not be None. Whitening the gain matrix makes the depth prior depend on both sensor geometry and the data of interest captured by the noise covariance (e.g., projections, SNR).

Use all channels. Not recommended since the depth weighting will be biased toward whichever channel type has the largest values in SI units (such as EEG being orders of magnitude larger than MEG).

mne.dig_mri_distances

mne.forward.compute_orient_prior

---

## mne.forward.compute_orient_prior#

**URL:** https://mne.tools/stable/generated/mne.forward.compute_orient_prior.html

**Contents:**
- mne.forward.compute_orient_prior#

Compute orientation prior.

Value that weights the source variances of the dipole components that are parallel (tangential) to the cortical surface. Can be:

If 0, then the solution is computed with fixed orientation. If 1, it corresponds to free orientations.

Uses 0.2 for surface source spaces (unless fixed is True) and 1.0 for other source spaces (volume or mixed).

Mapping from the key for a given source space type (surface, volume, discrete) to the loose value. Useful mostly for mixed source spaces.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.forward.compute_depth_prior

mne.forward.restrict_forward_to_label

---

## mne.forward.restrict_forward_to_label#

**URL:** https://mne.tools/stable/generated/mne.forward.restrict_forward_to_label.html

**Contents:**
- mne.forward.restrict_forward_to_label#

Restrict forward operator to labels.

Label object or list of label objects.

Restricted forward operator.

mne.forward.compute_orient_prior

mne.forward.restrict_forward_to_stc

---

## mne.forward.restrict_forward_to_stc#

**URL:** https://mne.tools/stable/generated/mne.forward.restrict_forward_to_stc.html

**Contents:**
- mne.forward.restrict_forward_to_stc#

Restrict forward operator to active sources in a source estimate.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when stc has vertices that are not in fwd. Default is “ignore”.

Restricted forward operator.

mne.forward.restrict_forward_to_label

---

## mne.Forward#

**URL:** https://mne.tools/stable/generated/mne.Forward.html

**Contents:**
- mne.Forward#
- Examples using mne.Forward#

Forward class to represent info from forward solution.

Like mne.Info, this data structure behaves like a dictionary. It contains all metadata necessary for a forward solution.

This class should not be modified or created by users. Forward objects should be obtained using mne.make_forward_solution() or mne.read_forward_solution().

A convenience wrapper accessible as fwd.ch_names which wraps fwd['info']['ch_names'].

Copy the Forward instance.

pick_channels(ch_names[, ordered])

Pick channels from this forward operator.

save(fname, *[, overwrite, verbose])

Save the forward solution.

Forward data is accessible via string keys using standard dict access (e.g., fwd['nsource'] == 4096):

The source orientation, either FIFF.FIFFV_MNE_FIXED_ORI or FIFF.FIFFV_MNE_FREE_ORI.

The coordinate frame of the forward solution, usually FIFF.FIFFV_COORD_HEAD.

The number of source locations.

The number of channels.

The forward solution, with entries:

The forward solution data. The shape will be (n_channels, nsource) for a fixed-orientation forward and (n_channels, nsource * 3) for a free-orientation forward.

The mri ↔ head transformation that was used.

The measurement information (with contents reduced compared to that of the original data).

The source space used during forward computation. This can differ from the original source space as:

Source points are removed due to proximity to (or existing outside) the inner skull surface.

The source space will be converted to the coord_frame of the forward solution, which typically means it gets converted from MRI to head coordinates.

The source locations.

The source normals. Will be all +Z ((0, 0, 1.)) for volume source spaces. For surface source spaces, these are normal to the cortical surface.

Whether sol is surface-oriented with the surface normal in the Z component (FIFF.FIFFV_MNE_FIXED_ORI) or +Z in the given coord_frame in the Z component (FIFF.FIFFV_MNE_FREE_ORI).

Forward objects also have some attributes that are accessible via . access, like fwd.ch_names.

Copy the Forward instance.

Pick channels from this forward operator.

List of channels to include.

If true (default False), treat include as an ordered list rather than a set.

The modified forward model.

Save the forward solution.

File name to save the forward solution to. It should end with -fwd.fif or -fwd.fif.gz to save to FIF, or -fwd.h5 to save to HDF5.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

From raw data to dSPM on SPM Faces dataset

Display sensitivity maps for EEG and MEG sensors

Use source space morphing

Source localization with a custom inverse solver

Compute source level time-frequency timecourses using a DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute source power estimate by projecting the covariance with MNE

Morph surface source estimate

Computing source timecourses with an XFit-like multi-dipole model

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Plot point-spread functions (PSFs) for a volume

Compute Rap-Music on evoked data

Compute spatial resolution metrics to compare MEG with EEG+MEG

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Cortical Signal Suppression (CSS) for removal of cortical signals

Compare simulated and estimated source activity

Generate simulated evoked data

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

Sensitivity map of SSP projections

Head model and forward computation

EEG forward operator with a template MRI

Getting started with mne.Report

Source localization with equivalent current dipole (ECD) fit

The role of dipole orientations in distributed source localization

EEG source localization given electrode locations on an MRI

Setting the EEG reference

Preprocessing optically pumped magnetometer (OPM) MEG data

Corrupt known signal with point spread

DICS for power mapping

---

## mne.get_config#

**URL:** https://mne.tools/stable/generated/mne.get_config.html

**Contents:**
- mne.get_config#
- Examples using mne.get_config#

Read MNE-Python preferences from environment or config file.

The preference key to look for. The os environment is searched first, then the mne-python config file is parsed. If None, all the config parameters present in environment variables or the path are returned. If key is an empty string, a list of all valid keys (but not values) is returned.

Value to return if the key is not found.

If True, raise an error if the key is not found (instead of returning default).

The folder that contains the .mne config folder. If None, it is found automatically.

If True, consider env vars, if available. If False, only use MNE-Python configuration file values.

The preference key value.

Configuring MNE-Python

---

## mne.get_config_path#

**URL:** https://mne.tools/stable/generated/mne.get_config_path.html

**Contents:**
- mne.get_config_path#
- Examples using mne.get_config_path#

Get path to standard mne-python config file.

The folder that contains the .mne config folder. If None, it is found automatically.

The path to the mne-python configuration file. On windows, this will be ‘%USERPROFILE%.mnemne-python.json’. On every other system, this will be ~/.mne/mne-python.json.

Configuring MNE-Python

Logging and Configuration

---

## mne.get_head_surf#

**URL:** https://mne.tools/stable/generated/mne.get_head_surf.html

**Contents:**
- mne.get_head_surf#

Load the subject head surface.

Type to load. Common choices would be 'bem' or 'head'. We first try loading '$SUBJECTS_DIR/$SUBJECT/bem/$SUBJECT-$SOURCE.fif', and then look for '$SUBJECT*$SOURCE.fif' in the same directory by going through all files matching the pattern. The head surface will be read from the first file containing a head surface. Can also be a list to try multiple strings.

Path to the SUBJECTS_DIR. If None, the path is obtained by using the environment variable SUBJECTS_DIR.

What to do if the surface is found to have topological defects. Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when one or more defects are found. Note that a lot of computations in MNE-Python assume the surfaces to be topologically correct, topological defects may still make other computations (e.g., mne.make_bem_model and mne.make_bem_solution) fail irrespective of this parameter.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.channel_indices_by_type

mne.get_meg_helmet_surf

---

## mne.get_meg_helmet_surf#

**URL:** https://mne.tools/stable/generated/mne.get_meg_helmet_surf.html

**Contents:**
- mne.get_meg_helmet_surf#

Load the MEG helmet associated with the MEG sensors.

The mne.Info object with information about the sensors and methods of measurement.

The head<->MRI transformation, usually obtained using read_trans(). Can be None, in which case the surface will be in head coordinates instead of MRI coordinates.

The upsampling factor to use for the helmet mesh. The default (1) does no upsampling. Larger integers lead to more densely sampled helmet surfaces, and the number of vertices increases as a factor of 4**(upsampling-1).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The MEG helmet as a surface.

A built-in helmet is loaded if possible. If not, a helmet surface will be approximated based on the sensor locations.

mne.get_volume_labels_from_aseg

---

## mne.get_montage_volume_labels#

**URL:** https://mne.tools/stable/generated/mne.get_montage_volume_labels.html

**Contents:**
- mne.get_montage_volume_labels#
- Examples using mne.get_montage_volume_labels#

Get regions of interest near channels from a Freesurfer parcellation.

This is applicable for channels inside the brain (intracranial electrodes).

A montage containing channel positions. If a string or DigMontage is specified, the existing channel information will be updated with the channel positions from the montage. Valid strings are the names of the built-in montages that ship with MNE-Python; you can list those via mne.channels.get_builtin_montages(). If None (default), the channel positions will be removed from the Info.

The FreeSurfer subject name.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The anatomical segmentation file. Default auto uses aparc+aseg if available and wmparc if not. This may be any anatomical segmentation file in the mri subdirectory of the Freesurfer subject directory.

Changed in version 1.8: Added support for the new default 'auto'.

The distance in mm to use for identifying regions of interest.

The regions of interest labels within dist of each channel.

The Freesurfer lookup table colors for the labels.

Working with sEEG data

mne.io.write_fiducials

mne.gui.coregistration

---

## mne.get_volume_labels_from_aseg#

**URL:** https://mne.tools/stable/generated/mne.get_volume_labels_from_aseg.html

**Contents:**
- mne.get_volume_labels_from_aseg#
- Examples using mne.get_volume_labels_from_aseg#

Return a list of names and colors of segmented volumes.

Filename to read. Typically aseg.mgz or some variant in the freesurfer pipeline.

If True returns also the labels colors.

A lookup table providing a mapping from region names (str) to ID values (int). Can be None to use the standard Freesurfer LUT.

The names of segmented volumes included in this mgz file.

The RGB colors of the labels included in this mgz file.

Changed in version 0.21.0: The label names are now sorted in the same order as their corresponding values in the MRI file.

Visualize source time courses (stcs)

mne.get_meg_helmet_surf

mne.get_volume_labels_from_src

---

## mne.get_volume_labels_from_src#

**URL:** https://mne.tools/stable/generated/mne.get_volume_labels_from_src.html

**Contents:**
- mne.get_volume_labels_from_src#

Return a list of Label of segmented volumes included in the src space.

The source space containing the volume regions.

The FreeSurfer subject name.

Freesurfer folder of the subjects.

List of Label of segmented volumes included in src space.

mne.get_volume_labels_from_aseg

---

## mne.grade_to_tris#

**URL:** https://mne.tools/stable/generated/mne.grade_to_tris.html

**Contents:**
- mne.grade_to_tris#

Get tris defined for a certain grade.

Grade of an icosahedral mesh.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

2-element list containing Nx3 arrays of tris, suitable for use in spatio_temporal_tris_adjacency.

mne.extract_label_time_course

mne.grade_to_vertices

---

## mne.grade_to_vertices#

**URL:** https://mne.tools/stable/generated/mne.grade_to_vertices.html

**Contents:**
- mne.grade_to_vertices#

Convert a grade to source space vertices for a given subject.

Resolution of the icosahedral mesh (typically 5). If None, all vertices will be used (potentially filling the surface). If a list, then values will be morphed to the set of vertices specified in in grade[0] and grade[1]. Note that specifying the vertices (e.g., grade=[np.arange(10242), np.arange(10242)] for fsaverage on a standard grade 5 source space) can be substantially faster than computing vertex locations. Note that if subject=’fsaverage’ and ‘grade=5’, this set of vertices will automatically be used (instead of computed) for speed, since this is a common morph.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Vertex numbers for LH and RH.

mne.label.select_sources

---

## mne.grand_average#

**URL:** https://mne.tools/stable/generated/mne.grand_average.html

**Contents:**
- mne.grand_average#
- Examples using mne.grand_average#

Make grand average of a list of Evoked, AverageTFR, or Spectrum data.

For mne.Evoked data, the function interpolates bad channels based on the interpolate_bads parameter. If interpolate_bads is True, the grand average file will contain good channels and the bad channels interpolated from the good MEG/EEG channels. For mne.time_frequency.AverageTFR and mne.time_frequency.Spectrum data, the function takes the subset of channels not marked as bad in any of the instances.

The grand_average.nave attribute will be equal to the number of datasets used to calculate the grand average.

A grand average evoked should not be used for source localization.

Changed in version 1.10.0: Added support for Spectrum objects.

If True, bad MEG and EEG channels are interpolated. Ignored for AverageTFR and Spectrum data.

If True, drop all bad channels marked as bad in any data set. If neither interpolate_bads nor drop_bads is True, in the output file, every channel marked as bad in at least one of the input files will be marked as bad, but no interpolation or dropping will be performed.

The grand average data. Same type as input.

Aggregating multitaper TFR datasets with a taper dimension such as for complex or phase data is not supported.

EEG analysis - Event-Related Potentials (ERPs)

mne.equalize_channels

mne.match_channel_orders

---

## mne.grow_labels#

**URL:** https://mne.tools/stable/generated/mne.grow_labels.html

**Contents:**
- mne.grow_labels#

Generate circular labels in source space with region growing.

This function generates a number of labels in source space by growing regions starting from the vertices defined in “seeds”. For each seed, a label is generated containing all vertices within a maximum geodesic distance on the white matter surface from the seed.

The FreeSurfer subject name.

Seed, or list of seeds. Each seed can be either a vertex number or a list of vertex numbers.

Extents (radius in mm) of the labels.

Hemispheres to use for the labels (0: left, 1: right).

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Likely only useful if tens or hundreds of labels are being expanded simultaneously. Does not apply with overlap=False.

Produce overlapping labels. If True (default), the resulting labels can be overlapping. If False, each label will be grown one step at a time, and occupied territory will not be invaded.

Assign names to the new labels (list needs to have the same length as seeds).

The surface along which to do the computations, defaults to 'white' (the gray-white matter boundary).

How to assign colors to each label. If None then unique colors will be chosen automatically (default), otherwise colors will be broadcast from the array. The first three values will be interpreted as RGB colors and the fourth column as the alpha value (commonly 1).

The labels’ comment attribute contains information on the seed vertex and extent; the values attribute contains distance from the seed in millimeters.

“extents” and “hemis” can either be arrays with the same length as seeds, which allows using a different extent and hemisphere for label, or integers, in which case the same extent and hemisphere is used for each label.

mne.label.select_sources

---

## mne.gui.coregistration#

**URL:** https://mne.tools/stable/generated/mne.gui.coregistration.html

**Contents:**
- mne.gui.coregistration#
- Examples using mne.gui.coregistration#

Coregister an MRI with a subject’s head shape.

The GUI can be launched through the command line interface:

or using a python interpreter as shown in Source alignment and coordinate frames.

Specify the width for window (in logical pixels). Default is None, which uses MNE_COREG_WINDOW_WIDTH config value (which defaults to 800).

Specify a height for window (in logical pixels). Default is None, which uses MNE_COREG_WINDOW_WIDTH config value (which defaults to 400).

Path to an instance file containing the digitizer data. Compatible for Raw, Epochs, and Evoked files.

Name of the mri subject.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The opacity of the head surface in the range [0., 1.]. Default is None, which uses MNE_COREG_HEAD_OPACITY config value (which defaults to 1.).

Use a high resolution head surface. Default is None, which uses MNE_COREG_HEAD_HIGH_RES config value (which defaults to True).

The Head<->MRI transform or the path to its FIF file ("-trans.fif").

If True (default), orient EEG electrode and head shape points to the head surface.

If True (default), scale the digitization points by their distance from the scalp surface.

If True (default), mark points inside the head surface in a different color.

How interactions with the scene via an input device (e.g., mouse or trackpad) modify the camera position. If 'terrain', one axis is fixed, enabling “turntable-style” rotations. If 'trackball', movement along all axes is possible, which provides more freedom of movement, but you may incidentally perform unintentional rotations along some axes. If None, the setting stored in the MNE-Python configuration file is used. Defaults to 'terrain'.

Changed in version 1.0: Default interaction mode if None and no config setting found changed from 'trackball' to 'terrain'.

Whether to start in fullscreen (True) or windowed mode (False). Default is None, which uses MNE_COREG_FULLSCREEN config value (which defaults to False).

Show the GUI if True.

Whether to halt program execution until the figure is closed.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The coregistration frame.

Many parameters (e.g., head_opacity) take None as a parameter, which means that the default will be read from the MNE-Python configuration file (which gets saved when exiting).

Step by step instructions for the coregistrations are shown below:

Source alignment and coordinate frames

mne.get_montage_volume_labels

mne.create_default_subject

---

## mne.head_to_mni#

**URL:** https://mne.tools/stable/generated/mne.head_to_mni.html

**Contents:**
- mne.head_to_mni#

Convert pos from head coordinate system to MNI ones.

The coordinates (in m) in head coordinate system.

The FreeSurfer subject name.

MRI<->Head coordinate transformation.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The MNI coordinates (in mm) of pos.

This function requires either nibabel.

mne.create_default_subject

---

## mne.head_to_mri#

**URL:** https://mne.tools/stable/generated/mne.head_to_mri.html

**Contents:**
- mne.head_to_mri#

Convert pos from head coordinate system to MRI ones.

The coordinates (in m) in head coordinate system.

The FreeSurfer subject name.

MRI<->Head coordinate transformation.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The MRI coordinate frame kind, can be 'mri' (default) for FreeSurfer surface RAS or 'ras' (default in 1.2) to use MRI RAS (scanner RAS).

For surrogate MRIs (e.g., scaled using mne coreg), if True (default False), use the MRI scaling parameters to obtain points in the original/surrogate subject’s MRI space.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The MRI RAS coordinates (in mm) of pos.

This function requires nibabel.

---

## mne.Info#

**URL:** https://mne.tools/stable/generated/mne.Info.html

**Contents:**
- mne.Info#
- Examples using mne.Info#

Measurement information.

This data structure behaves like a dictionary. It contains all metadata that is available for a recording. However, its keys are restricted to those provided by the FIF format specification, so new entries should not be manually added.

This class should not be instantiated directly via mne.Info(...). Instead, use mne.create_info() to create measurement information from scratch.

The only entries that should be manually changed by the user are: info['bads'], info['description'], info['device_info'], info['proj_id'], info['proj_name'], info['dev_head_t'], info['experimenter'], info['helium_info'], info['line_freq'], info['temp'], and info['subject_info'].

All other entries should be considered read-only, though they can be modified by various MNE-Python functions or methods (which have safeguards to ensure all fields remain in sync).

MEG system acquisition parameters. See mne.AcqParserFIF for details.

MEG system stimulus parameters.

List of bad (noisy/broken) channels, by name. These channels will by default be ignored by many processing steps.

The names of the channels.

A list of channel information dictionaries, one per channel. See Notes for more information.

Contains the command and arguments used to create the source space (used for source estimation).

CTF software gradient compensation data. See Notes for more information.

The transformation from 4D/CTF head coordinates to Neuromag head coordinates. This is only present in 4D/CTF data.

Whether a custom (=other than an average projector) reference has been applied to the EEG data. This flag is checked by some algorithms that require an average reference to be set.

String description of the recording.

The transformation from device coordinates to 4D/CTF head coordinates. This is only present in 4D/CTF data.

The device to head transformation.

Information about the acquisition device. See Notes for details.

The Polhemus digitization data in head coordinates. See Notes for more information.

Event list, sometimes extracted from the stim channels by Neuromag systems. In general this should not be used and mne.find_events() should be used for event processing. See Notes for more information.

Name of the person that ran the experiment.

The FIF globally unique ID. See Notes for more information.

Tilt angle of the gantry in degrees.

Information about the device helium. See Notes for details.

Highpass corner frequency in Hertz. Zero indicates a DC recording.

HPI measurements that were taken at the start of the recording (e.g. coil frequencies). See Notes for details.

Head position indicator (HPI) digitization points and fit information (e.g., the resulting transform). See Notes for details.

Information about the HPI subsystem that was used (e.g., event channel used for cHPI measurements). See Notes for details.

Identifies the KIT system.

Frequency of the power line in Hertz.

Lowpass corner frequency in Hertz. It is automatically set to half the sampling rate if there is otherwise no low-pass applied to the data.

True if active shielding (IAS) was active during recording.

The time (UTC) of the recording.

Changed in version 0.20: This is stored as a datetime object instead of a tuple of seconds/microseconds.

Raw measurement file (used for source estimation).

The ID assigned to this measurement by the acquisition system or during file conversion. Follows the same format as file_id.

File containing the MRI to head transformation (used for source estimation).

Transformation from MRI to head coordinates (used for source estimation).

MRI unique ID (used for source estimation).

The MaxFilter processing history. See Notes for details.

ID number of the project the experiment belongs to.

Name of the project the experiment belongs to.

List of SSP operators that operate on the data. See mne.Projection for details.

Sampling frequency in Hertz.

Information about the subject. See Notes for details.

Can be used to store temporary objects in an Info instance. It will not survive an I/O roundtrip.

“UTC offset of related meas_date (sHH:MM).

Working directory used when the source space was created (used for source estimation).

Layout of the Xplotter (Neuromag system only).

True if the dictionary has the specified key, else False.

Implement iter(self).

anonymize([daysback, keep_his, verbose])

Anonymize measurement information in place.

from_json_dict(data_dict)

Reconstruct Info object from a dictionary.

fromkeys(iterable[, value])

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

Get a DigMontage from instance.

(Re-)Normalize projection vectors after subselection.

plot_sensors([kind, ch_type, title, ...])

Plot sensor positions.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

rename_channels(mapping[, allow_duplicates, ...])

save(fname, *[, overwrite, verbose])

Write measurement info in fif file.

set_channel_types(mapping, *[, ...])

Specify the sensor types of channels.

set_meas_date(meas_date)

Set the measurement start date.

set_montage(montage[, match_case, ...])

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

setdefault(key[, default])

Insert key with a value of default if key is not in the dictionary.

Convert Info to a JSON-serializable dictionary.

Update method using __setitem__().

The following parameters have a nested structure.

The calibration factor to bring the channels to physical units. Used in product with range to scale the data read from disk.

Coil type, e.g. FIFFV_COIL_MEG.

The coordinate frame used, e.g. FIFFV_COORD_HEAD.

The kind of channel, e.g. FIFFV_EEG_CH.

Channel location information. The first three elements [:3] always store the nominal channel position. The remaining 9 elements store different information based on the channel type:

Remaining 9 elements [3:], contain the EX, EY, and EZ normal triplets (columns) of the coil rotation/orientation matrix.

Elements [3:6] contain the reference channel position.

Element [3] contains information about which eye was tracked (-1 for left, 1 for right), and element [4] contains information about the the axis of coordinate data (-1 for x-coordinate data, 1 for y-coordinate data).

Elements [3:6] contain dipole orientation information.

Logical channel number, conventions in the usage of this number vary.

The hardware-oriented part of the calibration factor. This should be only applied to the continuous raw data. Used in product with cal to scale data read from disk.

Scanning order number, starting from 1.

The unit to use, e.g. FIFF_UNIT_T_M.

Unit multipliers, most commonly FIFF_UNITM_NONE.

CTF compensation grade.

A named matrix dictionary (with entries “data”, “col_names”, etc.) containing the compensation matrix.

Were the compensation data saved in calibrated form.

The kind of channel, e.g. FIFFV_POINT_EEG, FIFFV_POINT_CARDINAL.

3D position in m. and coord_frame.

Number specifying the identity of the point. e.g. FIFFV_POINT_NASION if kind is FIFFV_POINT_CARDINAL, or 42 if kind is FIFFV_POINT_EEG.

The coordinate frame used, e.g. FIFFV_COORD_HEAD.

Channel indices for the events.

Events in triplets as number of samples, before, after.

FIF format version, i.e. FIFFC_VERSION.

Unique machine ID, usually derived from the MAC address.

Time in microseconds.

Helium level (%) before position correction.

Helium level (%) after position correction.

The helium level meas date.

Changed in version 1.8: This is stored as a datetime object instead of a tuple of seconds/microseconds.

hpi_meas list of dict:

Program that did the measurement.

Number of channels used.

Number of averages used.

Number of coils used.

Buffer containing one epoch and channel.

HPI curve fit correlations.

HPI coil excitation frequency

hpi_results list of dict:

Digitization points (see dig definition) for the HPI coils.

The determined digitization order.

The indices of the used coils.

The goodness of fits.

The goodness of fit limit.

Whether or not the fit was accepted.

The resulting MEG<->head transformation.

The event channel used to encode cHPI status (e.g., STI201).

List of length ncoil, each 4-element ndarray contains the event bits used on the event channel to indicate cHPI status (using the first element of these arrays is typically sufficient).

FIF format version, i.e. FIFFC_VERSION.

Unique machine ID, usually derived from the MAC address.

Time in microseconds.

proc_history list of dict:

2-element tuple of seconds and microseconds.

Name of the person who ran the program.

Program that did the processing.

Maxwel filtering info, can contain:

SSS processing information.

tSSS processing information.

Cross-talk processing information.

Fine-calibration information.

MaxShield information. This dictionary is (always?) empty, but its presence implies that MaxShield was used during acquisition.

Integer subject identifier.

String subject identifier.

The subject birthday.

Changed in version 1.8: This is stored as a date object instead of a tuple of seconds/microseconds.

Subject sex (0=unknown, 1=male, 2=female).

Handedness (1=right, 2=left, 3=ambidextrous).

True if the dictionary has the specified key, else False.

Implement iter(self).

Anonymize measurement information in place.

Number of days to subtract from all dates. If None (default), the acquisition date, info['meas_date'], will be set to January 1ˢᵗ, 2000. This parameter is ignored if info['meas_date'] is None (i.e., no acquisition date has been set).

If True, his_id of subject_info will not be overwritten. Defaults to False.

This could mean that info is not fully anonymized. Use with caution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Removes potentially identifying information if it exists in info. Specifically for each of the following we use:

A default value, or as specified by daysback.

Default values, except for ‘birthday’ which is adjusted to maintain the subject age.

Dates use the meas_date logic, and experimenter a default string.

Dates use the meas_date logic, meta info uses defaults.

If info['meas_date'] is None, it will remain None during processing the above fields.

The current gradient compensation grade.

Reconstruct Info object from a dictionary.

A dictionary representation of an Info object, typically created by the to_json_dict() method.

The reconstructed Info object.

Convert Info to dictionary.

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get a DigMontage from instance.

A copy of the channel positions, if available, otherwise None.

(Re-)Normalize projection vectors after subselection.

Applying projection after sub-selecting a set of channels that were originally used to compute the original projection vectors can be dangerous (e.g., if few channels remain, most power was in channels that are no longer picked, etc.). By default, mne will emit a warning when this is done.

This function will re-normalize projectors to use only the remaining channels, thus avoiding that warning. Only use this function if you’re confident that the projection vectors still adequately capture the original signal of interest.

Examples using normalize_proj:

Computing source timecourses with an XFit-like multi-dipole model

Plot sensor positions.

Whether to plot the sensors as 3d, topomap or as an interactive sensor selection dialog. Available options ‘topomap’, ‘3d’, ‘select’. If ‘select’, a set of channels can be selected interactively by using lasso selector or clicking while holding control key. The selected channels are returned along with the figure instance. Defaults to ‘topomap’.

The channel type to plot. Available options 'mag', 'grad', 'eeg', 'seeg', 'dbs', 'ecog', 'all'. If 'all', all the available mag, grad, eeg, seeg, dbs, and ecog channels are plotted. If None (default), then channels are chosen in the order given above.

Title for the figure. If None (default), equals to 'Sensor positions (%s)' % ch_type.

Whether to display all channel names. If an array, only the channel names in the array are shown. Defaults to False.

Channel groups for coloring the sensors. If None (default), default coloring scheme is used. If ‘position’, the sensors are divided into 8 regions. See order kwarg of mne.viz.plot_raw(). If array, the channels are divided by picks given in the array.

Whether to project the 3d locations to a sphere. When False, the sensor array appears similar as to looking downwards straight above the subject’s head. Has no effect when kind=’3d’. Defaults to True.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Whether to halt program execution until the figure is closed. Defaults to False.

Show figure if True. Defaults to True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the sensor topography.

A list of selected channels. Only returned if kind=='select'.

This function plots the sensor locations from the info structure using matplotlib. For drawing the sensors using PyVista see mne.viz.plot_alignment().

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

Pairs are returned in LIFO (last-in, first-out) order. Raises KeyError if the dict is empty.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

Write measurement info in fif file.

The name of the file. Should end by '-info.fif'.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Specify the sensor types of channels.

A dictionary mapping channel names to sensor types, e.g., {'EEG061': 'eog'}.

What to do if the measurement unit of a channel is changed automatically to match the new sensor type.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The following sensor types are accepted:

bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci, eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase, fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp, seeg, stim, syst, temperature.

When working with eye-tracking data, see mne.preprocessing.eyetracking.set_channel_types_eyetrack().

Set the measurement start date.

The new measurement date. If datetime object, it must be timezone-aware and in UTC. A tuple of (seconds, microseconds) or float (alias for (meas_date, 0)) can also be passed and a datetime object will be automatically created. If None, will remove the time reference.

The modified raw instance. Operates in place.

If you want to remove all time references in the file, call mne.io.anonymize_info(inst.info) after calling inst.set_meas_date(None).

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

A montage containing channel positions. If a string or DigMontage is specified, the existing channel information will be updated with the channel positions from the montage. Valid strings are the names of the built-in montages that ship with MNE-Python; you can list those via mne.channels.get_builtin_montages(). If None (default), the channel positions will be removed from the Info.

If True (default), channel name matching will be case sensitive.

Whether to use a lookup table to match unrecognized channel location names to their known aliases. If True, uses the mapping in mne.io.constants.CHANNEL_LOC_ALIASES. If a dict is passed, it will be used instead, and should map from non-standard channel names to names in the specified montage. Default is False.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when channels have missing coordinates.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

Only EEG/sEEG/ECoG/DBS/fNIRS channels can have their positions set using a montage. Other channel types (e.g., MEG channels) should have their positions defined properly using their data reading functions.

Applying a montage will only set locations of channels that exist at the time it is applied. This means when re-referencing make sure to apply the montage only after calling mne.add_reference_channels()

Examples using set_montage:

Creating MNE-Python data structures from scratch

Insert key with a value of default if key is not in the dictionary.

Return the value for key if key is in the dictionary, else default.

Convert Info to a JSON-serializable dictionary.

This method converts the Info object to a standard Python dictionary containing only JSON-serializable types (dict, list, str, int, float, bool, None). Numpy arrays are converted to nested lists, and datetime objects to ISO format strings.

A JSON-serializable dictionary representation of the Info object.

Reconstruct Info object from dictionary.

This method is useful for serializing Info objects to JSON or other formats that don’t support numpy arrays or custom objects.

Update method using __setitem__().

Brainstorm raw (median nerve) dataset

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Decoding source space data

Continuous Target Decoding with SPoC

Decoding sensor space data with generalization across time and conditions

Analysis of evoked response using ICA and PCA reduction techniques

XDAWN Decoding From EEG data

Compute effect-matched-spatial filtering (EMS)

Linear classifier on sensor data with plot patterns and filters

Receptive Field Estimation and Prediction

Compute spatial filters with Spatio-Spectral Decomposition (SSD)

Use source space morphing

Compute MNE-dSPM inverse solution on single epochs

Source localization with a custom inverse solver

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Compute source power estimate by projecting the covariance with MNE

Computing source timecourses with an XFit-like multi-dipole model

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Plot point-spread functions (PSFs) for a volume

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Getting impedances from raw files

How to use data in neural ensemble (NEO) format

Reading/Writing a noise covariance matrix

Using contralateral referencing for EEG

Cortical Signal Suppression (CSS) for removal of cortical signals

Define target events based on time lag, plot evoked response

Identify EEG Electrodes Bridged by too much Gel

Show EOG artifact timing

Automated epochs metadata generation with variable time windows

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Find MEG reference channel artifacts

Visualise NIRS artifact correction methods

Maxwell filter data with movement compensation

Annotate movement artifacts and reestimate dev_head_t

Compare simulated and estimated source activity

Generate simulated evoked data

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

Permutation F-test on sensor data with 1D cluster level

FDR correction on T-test on sensor data

Regression on continuous data (rER[P/F])

Permutation T-test on sensor data

Compute a cross-spectral density (CSD) matrix

Compute Power Spectral Density of inverse solution from single epochs

Compute power and phase lock in label of the source space

Compute source power spectral density (PSD) in a label

Compute source power spectral density (PSD) of VectorView and OPM data

Compute induced power in the source space with dSPM

Temporal whitening with AR model

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

How to convert 3D electrode positions to a 2D image

Plotting with mne.viz.Brain

Visualize channel over epochs as an image

Plotting EEG sensors on the scalp

Plotting topographic arrowmaps of evoked data

Whitening evoked data with a noise covariance

Plotting sensor layouts of MEG systems

Plot the MNE brain and helmet

Plot single trial activity, grouped by ROI and sorted by RT

Plot custom topographies for MEG sensors

Working with sEEG data

Working with ECoG data

Visualizing epoched data

Auto-generating Epochs metadata

Visualizing Evoked data

EEG analysis - Event-Related Potentials (ERPs)

Source alignment and coordinate frames

Using an automated approach to coregistration

Head model and forward computation

EEG forward operator with a template MRI

How MNE uses FreeSurfer’s outputs

Computing a covariance matrix

Overview of MEG/EEG analysis with MNE-Python

Modifying data in-place

Parsing events from raw data

The Info data structure

Working with sensor locations

Getting started with mne.Report

Source localization with equivalent current dipole (ECD) fit

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Source reconstruction using an LCMV beamformer

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

Importing data from fNIRS devices

Working with CTF data: the Brainstorm auditory dataset

Overview of artifact detection

Handling bad channels

Rejecting bad data spans and breaks

Filtering and resampling data

Repairing artifacts with regression

Background on projectors and projections

Repairing artifacts with SSP

Setting the EEG reference

Extracting and visualizing subject head movement

Signal-space separation (SSS) and Maxwell filtering

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Preprocessing optically pumped magnetometer (OPM) MEG data

The Raw data structure: continuous data

Annotating continuous data

Built-in plotting methods for Raw objects

Creating MNE-Python data structures from scratch

Corrupt known signal with point spread

DICS for power mapping

Visualising statistical significance thresholds on EEG data

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

Frequency and time-frequency sensor analysis

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

Make figures more publication ready

---

## mne.inverse_sparse.gamma_map#

**URL:** https://mne.tools/stable/generated/mne.inverse_sparse.gamma_map.html

**Contents:**
- mne.inverse_sparse.gamma_map#
- Examples using mne.inverse_sparse.gamma_map#

Hierarchical Bayes (Gamma-MAP) sparse source localization method.

Models each source time course using a zero-mean Gaussian prior with an unknown variance (gamma) parameter. During estimation, most gammas are driven to zero, resulting in a sparse source estimate, as in [1] and [2].

For fixed-orientation forward operators, a separate gamma is used for each source time course, while for free-orientation forward operators, the same gamma is used for the three source time courses at each source space point (separate gammas can be used in this case by using xyz_same_gamma=False).

Evoked data to invert.

Noise covariance to compute whitener.

Regularization parameter (noise variance).

Value that weights the source variances of the dipole components that are parallel (tangential) to the cortical surface. Can be:

If 0, then the solution is computed with fixed orientation. If 1, it corresponds to free orientations.

Uses 0.2 for surface source spaces (unless fixed is True) and 1.0 for other source spaces (volume or mixed).

Mapping from the key for a given source space type (surface, volume, discrete) to the loose value. Useful mostly for mixed source spaces.

How to weight (or normalize) the forward using a depth prior. If float (default 0.8), it acts as the depth weighting exponent (exp) to use None is equivalent to 0, meaning no depth weighting is performed. It can also be a dict containing keyword arguments to pass to mne.forward.compute_depth_prior() (see docstring for details and defaults). This is effectively ignored when method='eLORETA'.

Changed in version 0.20: Depth bias ignored for method='eLORETA'.

Use same gamma for xyz current components at each source space point. Recommended for free-orientation forward solutions.

Maximum number of iterations.

Tolerance parameter for convergence.

Update mode, 1: MacKay update (default), 2: Modified MacKay update.

Initial values for posterior variances (gammas). If None, a variance of 1.0 is used.

If True the rank of the data is reduced to the true dimension.

If True, the residual is returned as an Evoked instance.

If True, the sources are returned as a list of Dipole instances.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

Pooling is performed by taking the norm of loose/free orientations. In case of a fixed source space no norm is computed leading to signed source activity.

Only the normal to the cortical surface is kept. This is only implemented when working with loose orientations.

No pooling of the orientations is done, and the vector result will be returned in the form of a mne.VectorSourceEstimate object.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The residual a.k.a. data not explained by the sources. Only returned if return_residual is True.

David P. Wipf, Rey Ramírez, Jason Palmer, Scott Makeig, and Bhaskar D. Rao. Analysis of empirical bayesian methods for neuroelectromagnetic source localization. In Bernhard Schölkopf, John C. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, 1505–1512. MIT Press, 2007. URL: http://papers.nips.cc/paper/3089-analysis-of-empirical-bayesian-methods-for-neuroelectromagnetic-source-localization.pdf.

David Wipf and Srikantan Nagarajan. A unified Bayesian framework for MEG/EEG source imaging. NeuroImage, 44(3):947–966, 2009. doi:10.1016/j.neuroimage.2008.02.059.

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

mne.inverse_sparse.tf_mixed_norm

mne.inverse_sparse.make_stc_from_dipoles

---

## mne.inverse_sparse.make_stc_from_dipoles#

**URL:** https://mne.tools/stable/generated/mne.inverse_sparse.make_stc_from_dipoles.html

**Contents:**
- mne.inverse_sparse.make_stc_from_dipoles#
- Examples using mne.inverse_sparse.make_stc_from_dipoles#

Convert a list of spatio-temporal dipoles into a SourceEstimate.

The dipoles to convert.

The source space used to generate the forward operator.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Compute MxNE with time-frequency sparse prior

mne.inverse_sparse.gamma_map

mne.beamformer.Beamformer

---

## mne.inverse_sparse.mixed_norm#

**URL:** https://mne.tools/stable/generated/mne.inverse_sparse.mixed_norm.html

**Contents:**
- mne.inverse_sparse.mixed_norm#
- Examples using mne.inverse_sparse.mixed_norm#

Mixed-norm estimate (MxNE) and iterative reweighted MxNE (irMxNE).

Compute L1/L2 mixed-norm solution [1] or L0.5/L2 [2] mixed-norm solution on evoked data.

Evoked data to invert.

Noise covariance to compute whitener.

Regularization parameter. If float it should be in the range [0, 100): 0 means no regularization, 100 would give 0 active dipole. If 'sure' (default), the SURE method from [3] will be used.

Changed in version 0.24: The default was changed to 'sure'.

Value that weights the source variances of the dipole components that are parallel (tangential) to the cortical surface. Can be:

If 0, then the solution is computed with fixed orientation. If 1, it corresponds to free orientations.

Uses 0.2 for surface source spaces (unless fixed is True) and 1.0 for other source spaces (volume or mixed).

Mapping from the key for a given source space type (surface, volume, discrete) to the loose value. Useful mostly for mixed source spaces.

How to weight (or normalize) the forward using a depth prior. If float (default 0.8), it acts as the depth weighting exponent (exp) to use None is equivalent to 0, meaning no depth weighting is performed. It can also be a dict containing keyword arguments to pass to mne.forward.compute_depth_prior() (see docstring for details and defaults). This is effectively ignored when method='eLORETA'.

Changed in version 0.20: Depth bias ignored for method='eLORETA'.

Maximum number of iterations.

Size of active set increment. If None, no active set strategy is used.

Remove coefficient amplitude bias due to L1 penalty.

If True the rank of the concatenated epochs is reduced to its true dimension. If is ‘int’ the rank is limited to this value.

Weight for penalty in mixed_norm. Can be None, a 1d array with shape (n_sources,), or a SourceEstimate (e.g. obtained with wMNE, dSPM, or fMRI).

Do not consider in the estimation sources for which weights is less than weights_min.

The algorithm to use for the optimization. ‘cd’ uses coordinate descent, and ‘bcd’ applies block coordinate descent. ‘cd’ is only available for fixed orientation.

The number of MxNE iterations. If > 1, iterative reweighting is applied.

If True, the residual is returned as an Evoked instance.

If True, the sources are returned as a list of Dipole instances.

The duality gap is evaluated every dgap_freq iterations. Ignored if solver is ‘cd’.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

Pooling is performed by taking the norm of loose/free orientations. In case of a fixed source space no norm is computed leading to signed source activity.

Only the normal to the cortical surface is kept. This is only implemented when working with loose orientations.

No pooling of the orientations is done, and the vector result will be returned in the form of a mne.VectorSourceEstimate object.

If 'auto' (default), the SURE is evaluated along 15 uniformly distributed alphas between alpha_max and 0.1 * alpha_max. If array, the grid is directly specified. Ignored if alpha is not “sure”.

The random state used in a random number generator for delta and epsilon used for the SURE computation. Defaults to None.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Source time courses for each evoked data passed as input.

The residual a.k.a. data not explained by the sources. Only returned if return_residual is True.

Alexandre Gramfort, Matthieu Kowalski, and Matti S. Hämäläinen. Mixed-norm estimates for the M/EEG inverse problem using accelerated gradient methods. Physics in Medicine and Biology, 57(7):1937–1961, 2012. doi:10.1088/0031-9155/57/7/1937.

Daniel Strohmeier, Yousra Bekhti, Jens Haueisen, and Alexandre Gramfort. The iterative reweighted mixed-norm estimate for spatio-temporal MEG/EEG source reconstruction. IEEE Transactions on Medical Imaging, 35(10):2218–2228, 2016. doi:10.1109/TMI.2016.2553445.

Charles-Alban Deledalle, Samuel Vaiter, Jalal Fadili, and Gabriel Peyré. Stein unbiased gradient estimator of the risk (sugar) for multiple parameter selection. SIAM Journal on Imaging Sciences, 7(4):2448–2487, 2014. doi:10.1137/140968045.

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

mne.minimum_norm.get_point_spread

mne.inverse_sparse.tf_mixed_norm

---

## mne.inverse_sparse.tf_mixed_norm#

**URL:** https://mne.tools/stable/generated/mne.inverse_sparse.tf_mixed_norm.html

**Contents:**
- mne.inverse_sparse.tf_mixed_norm#
- Examples using mne.inverse_sparse.tf_mixed_norm#

Time-Frequency Mixed-norm estimate (TF-MxNE).

Compute L1/L2 + L1 mixed-norm solution on time-frequency dictionary. Works with evoked data [1][2].

Evoked data to invert.

Noise covariance to compute whitener.

Value that weights the source variances of the dipole components that are parallel (tangential) to the cortical surface. Can be:

If 0, then the solution is computed with fixed orientation. If 1, it corresponds to free orientations.

Uses 0.2 for surface source spaces (unless fixed is True) and 1.0 for other source spaces (volume or mixed).

Mapping from the key for a given source space type (surface, volume, discrete) to the loose value. Useful mostly for mixed source spaces.

How to weight (or normalize) the forward using a depth prior. If float (default 0.8), it acts as the depth weighting exponent (exp) to use None is equivalent to 0, meaning no depth weighting is performed. It can also be a dict containing keyword arguments to pass to mne.forward.compute_depth_prior() (see docstring for details and defaults). This is effectively ignored when method='eLORETA'.

Changed in version 0.20: Depth bias ignored for method='eLORETA'.

Maximum number of iterations.

Weight for penalty in mixed_norm. Can be None or 1d array of length n_sources or a SourceEstimate e.g. obtained with wMNE or dSPM or fMRI.

Do not consider in the estimation sources for which weights is less than weights_min.

If True the rank of the data is reduced to true dimension.

Remove coefficient amplitude bias due to L1 penalty.

Length of the STFT window in samples (must be a multiple of 4). If an array is passed, multiple TF dictionaries are used (each having its own wsize and tstep) and each entry of wsize must be a multiple of 4. See [3].

Step between successive windows in samples (must be a multiple of 2, a divider of wsize and smaller than wsize/2) (default: wsize/2). If an array is passed, multiple TF dictionaries are used (each having its own wsize and tstep), and each entry of tstep must be a multiple of 2 and divide the corresponding entry of wsize. See [3].

Length of time window used to take care of edge artifacts in seconds. It can be one float or float if the values are different for left and right window length.

If True, the residual is returned as an Evoked instance.

If True, the sources are returned as a list of Dipole instances.

Overall regularization parameter. If alpha and l1_ratio are not None, alpha_space and alpha_time are overridden by alpha * alpha_max * (1. - l1_ratio) and alpha * alpha_max * l1_ratio. 0 means no regularization, 100 would give 0 active dipole.

Proportion of temporal regularization. If l1_ratio and alpha are not None, alpha_space and alpha_time are overridden by alpha * alpha_max * (1. - l1_ratio) and alpha * alpha_max * l1_ratio. 0 means no time regularization a.k.a. MxNE.

The duality gap is evaluated every dgap_freq iterations.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

Pooling is performed by taking the norm of loose/free orientations. In case of a fixed source space no norm is computed leading to signed source activity.

Only the normal to the cortical surface is kept. This is only implemented when working with loose orientations.

No pooling of the orientations is done, and the vector result will be returned in the form of a mne.VectorSourceEstimate object.

Number of TF-MxNE iterations. If > 1, iterative reweighting is applied.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The residual a.k.a. data not explained by the sources. Only returned if return_residual is True.

Alexandre Gramfort, Daniel T. Strohmeier, Jens Haueisen, Matti S. Hämäläinen, and Matthieu Kowalski. Time-frequency mixed-norm estimates: sparse M/EEG imaging with non-stationary source activations. NeuroImage, 70:410–422, 2013. doi:10.1016/j.neuroimage.2012.12.051.

Alexandre Gramfort, Daniel Strohmeier, Jens Haueisen, Matti S. Hämäläinen, and Matthieu Kowalski. Functional brain imaging with M/EEG using structured sparsity in time-frequency dictionaries. In Gábor Székely and Horst K. Hahn, editors, Information Processing in Medical Imaging, volume 6801, pages 600–611. Springer, Berlin; Heidelberg, 2011. doi:10.1007/978-3-642-22092-0_49.

Yousra Bekhti, Daniel Strohmeier, Mainak Jas, Roland Badeau, and Alexandre Gramfort. M/EEG source localization with multi-scale time-frequency dictionaries. In Proceedings of PRNI-2016, 1–4. Trento, 2016. IEEE. doi:10.1109/PRNI.2016.7552337.

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Compute MxNE with time-frequency sparse prior

mne.inverse_sparse.mixed_norm

mne.inverse_sparse.gamma_map

---

## mne.io.anonymize_info#

**URL:** https://mne.tools/stable/generated/mne.io.anonymize_info.html

**Contents:**
- mne.io.anonymize_info#

Anonymize measurement information in place.

If info is part of an object like raw.info, you should directly use the method raw.anonymize() to ensure that all parts of the data are anonymized and stay synchronized (e.g., raw.annotations).

The mne.Info object with information about the sensors and methods of measurement.

Number of days to subtract from all dates. If None (default), the acquisition date, info['meas_date'], will be set to January 1ˢᵗ, 2000. This parameter is ignored if info['meas_date'] is None (i.e., no acquisition date has been set).

If True, his_id of subject_info will not be overwritten. Defaults to False.

This could mean that info is not fully anonymized. Use with caution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The anonymized measurement information.

Removes potentially identifying information if it exists in info. Specifically for each of the following we use:

A default value, or as specified by daysback.

Default values, except for ‘birthday’ which is adjusted to maintain the subject age.

Dates use the meas_date logic, and experimenter a default string.

Dates use the meas_date logic, meta info uses defaults.

If info['meas_date'] is None, it will remain None during processing the above fields.

---

## mne.io.BaseRaw#

**URL:** https://mne.tools/stable/generated/mne.io.BaseRaw.html

**Contents:**
- mne.io.BaseRaw#

Base class for Raw data.

The mne.Info object with information about the sensors and methods of measurement.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory). If preload is an ndarray, the data are taken from that array. If False, data are not read until save.

Iterable of the first sample number from each raw file. For unsplit raw files this should be a length-one list or tuple.

Iterable of the last sample number from each raw file. For unsplit raw files this should be a length-one list or tuple. If None, then preload must be an ndarray.

Tuple of length one (for unsplit raw files) or length > 1 (for split raw files).

The data necessary for on-demand reads for the given reader format. Should be the same length as filenames. Will have the entry raw_extras['orig_nchan'] added to it for convenience.

The data format of the original raw file (e.g., 'double').

The dtype of the raw data. If preload is an ndarray, its dtype must match what is passed here.

The buffer size in seconds that should be written by default using mne.io.Raw.save().

Dictionary mapping channel names to their units as specified in the header file. Example: {‘FC1’: ‘nV’}.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Annotations for marking segments of data.

The current gradient compensation grade.

Duration of the data in seconds.

The first data sample.

The first time point (including first_samp but not meas_date).

The last data sample.

Number of time points.

Whether or not projections are active.

__contains__(ch_type)

Check channel type membership.

Get raw data and times.

Return the number of time points.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_events(events[, stim_channel, replace])

Add events to stim channel.

add_proj(projs[, remove_existing, verbose])

Add SSP projection vectors.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

anonymize([daysback, keep_his, verbose])

Anonymize measurement information in place.

append(raws[, preload])

Concatenate raw instances as if they were continuous.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of channels.

apply_gradient_compensation(grade[, verbose])

Apply CTF gradient compensation.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

apply_proj([verbose])

Apply the signal space projection (SSP) operators to the data.

compute_psd([method, fmin, fmax, tmin, ...])

Perform spectral analysis on sensor data.

compute_tfr(method, freqs, *[, tmin, tmax, ...])

Compute a time-frequency representation of sensor data.

Return copy of Raw instance.

crop([tmin, tmax, include_tmax, verbose])

crop_by_annotations([annotations, verbose])

Get crops of raw data file for selected annotations.

Remove SSP projection vector.

describe([data_frame])

Describe channels (name, type, descriptive statistics).

drop_channels(ch_names[, on_missing])

export(fname[, fmt, physical_range, ...])

Export Raw to external formats.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, start, stop, ...])

Get data in the given range.

Get a DigMontage from instance.

interpolate_bads([reset_bads, mode, origin, ...])

Interpolate bad MEG and EEG channels.

interpolate_to(sensors[, origin, method, reg])

Interpolate EEG data onto a new montage.

load_bad_channels([bad_file, force, verbose])

Mark channels as bad from a text file.

notch_filter(freqs[, picks, filter_length, ...])

Notch filter a subset of channels.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([events, duration, start, n_channels, ...])

plot_projs_topomap([ch_type, sensors, ...])

plot_psd([fmin, fmax, tmin, tmax, picks, ...])

plot_psd_topo([tmin, tmax, fmin, fmax, ...])

plot_psd_topomap([bands, tmin, tmax, ...])

plot_sensors([kind, ch_type, title, ...])

Plot sensor positions.

rename_channels(mapping[, allow_duplicates, ...])

reorder_channels(ch_names)

resample(sfreq, *[, npad, window, ...])

Resample all channels.

rescale(scalings, *[, verbose])

save(fname[, picks, tmin, tmax, ...])

Save raw data to file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

set_annotations(annotations[, emit_warning, ...])

Setter for annotations.

set_channel_types(mapping, *[, ...])

Specify the sensor types of channels.

set_eeg_reference([ref_channels, ...])

Specify which reference to use for EEG data.

set_meas_date(meas_date)

Set the measurement start date.

set_montage(montage[, match_case, ...])

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

time_as_index(times[, use_rounding, origin])

Convert time to indices.

to_data_frame([picks, index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

Documentation of attributes and methods.

This class is public to allow for stable type-checking in user code (i.e., isinstance(my_raw_object, BaseRaw)) but should not be used as a constructor for Raw objects (use instead one of the subclass constructors, or one of the mne.io.read_raw_* functions).

Subclasses must provide the following methods:

_read_segment_file(self, data, idx, fi, start, stop, cals, mult) (only needed for types that support on-demand disk reads)

mne.io.read_raw_snirf

---

## mne.io.get_channel_type_constants#

**URL:** https://mne.tools/stable/generated/mne.io.get_channel_type_constants.html

**Contents:**
- mne.io.get_channel_type_constants#

Return all known channel types, and associated FIFF constants.

Whether to include default values for “unit” and “coil_type” for all entries (see Notes). Defaults are generally based on values normally present for a VectorView MEG system. Defaults to False.

The keys are channel type strings, and the values are dictionaries of FIFF constants for “kind”, and possibly “unit” and “coil_type”.

Values which might vary within a channel type across real data recordings are excluded unless include_defaults=True. For example, “ref_meg” channels may have coil type FIFFV_COIL_MAGNES_OFFDIAG_REF_GRAD, FIFFV_COIL_VV_MAG_T3, etc (depending on the recording system), so no “coil_type” entry is given for “ref_meg” unless include_defaults is requested.

---

## mne.io.kit.read_mrk#

**URL:** https://mne.tools/stable/generated/mne.io.kit.read_mrk.html

**Contents:**
- mne.io.kit.read_mrk#

Marker Point Extraction in MEG space directly from sqd.

Absolute path to Marker file. File formats allowed: *.sqd, *.mrk, *.txt.

Marker points in MEG space [m].

---

## mne.io.RawArray#

**URL:** https://mne.tools/stable/generated/mne.io.RawArray.html

**Contents:**
- mne.io.RawArray#
- Examples using mne.io.RawArray#

Raw object from numpy array.

The channels’ time series. See notes for proper units of measure.

The mne.Info object with information about the sensors and methods of measurement. Consider using mne.create_info() to populate this structure. This may be modified in place by the class.

First sample offset used during recording (default 0).

Determines what gets copied on instantiation. “auto” (default) will copy info, and copy “data” only if necessary to get to double floating point precision.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Annotations for marking segments of data.

The current gradient compensation grade.

Duration of the data in seconds.

The first data sample.

The first time point (including first_samp but not meas_date).

The last data sample.

Number of time points.

Whether or not projections are active.

__contains__(ch_type)

Check channel type membership.

Get raw data and times.

Return the number of time points.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_events(events[, stim_channel, replace])

Add events to stim channel.

add_proj(projs[, remove_existing, verbose])

Add SSP projection vectors.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

anonymize([daysback, keep_his, verbose])

Anonymize measurement information in place.

append(raws[, preload])

Concatenate raw instances as if they were continuous.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of channels.

apply_gradient_compensation(grade[, verbose])

Apply CTF gradient compensation.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

apply_proj([verbose])

Apply the signal space projection (SSP) operators to the data.

compute_psd([method, fmin, fmax, tmin, ...])

Perform spectral analysis on sensor data.

compute_tfr(method, freqs, *[, tmin, tmax, ...])

Compute a time-frequency representation of sensor data.

Return copy of Raw instance.

crop([tmin, tmax, include_tmax, verbose])

crop_by_annotations([annotations, verbose])

Get crops of raw data file for selected annotations.

Remove SSP projection vector.

describe([data_frame])

Describe channels (name, type, descriptive statistics).

drop_channels(ch_names[, on_missing])

export(fname[, fmt, physical_range, ...])

Export Raw to external formats.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, start, stop, ...])

Get data in the given range.

Get a DigMontage from instance.

interpolate_bads([reset_bads, mode, origin, ...])

Interpolate bad MEG and EEG channels.

interpolate_to(sensors[, origin, method, reg])

Interpolate EEG data onto a new montage.

load_bad_channels([bad_file, force, verbose])

Mark channels as bad from a text file.

notch_filter(freqs[, picks, filter_length, ...])

Notch filter a subset of channels.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([events, duration, start, n_channels, ...])

plot_projs_topomap([ch_type, sensors, ...])

plot_psd([fmin, fmax, tmin, tmax, picks, ...])

plot_psd_topo([tmin, tmax, fmin, fmax, ...])

plot_psd_topomap([bands, tmin, tmax, ...])

plot_sensors([kind, ch_type, title, ...])

Plot sensor positions.

rename_channels(mapping[, allow_duplicates, ...])

reorder_channels(ch_names)

resample(sfreq, *[, npad, window, ...])

Resample all channels.

rescale(scalings, *[, verbose])

save(fname[, picks, tmin, tmax, ...])

Save raw data to file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

set_annotations(annotations[, emit_warning, ...])

Setter for annotations.

set_channel_types(mapping, *[, ...])

Specify the sensor types of channels.

set_eeg_reference([ref_channels, ...])

Specify which reference to use for EEG data.

set_meas_date(meas_date)

Set the measurement start date.

set_montage(montage[, match_case, ...])

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

time_as_index(times[, use_rounding, origin])

Convert time to indices.

to_data_frame([picks, index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

Proper units of measure:

V: eeg, eog, seeg, dbs, emg, ecg, bio, ecog

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Get raw data and times.

See below for use cases.

The times associated with the data.

Generally raw data is accessed as:

To get all data, you can thus do either of:

Which will be equivalent to:

To get only the good MEG data from 10-20 seconds, you could do:

Return the number of time points.

The number of time points.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won’t be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add events to stim channel.

Events to add. The first column specifies the sample number of each event, the second column is ignored, and the third column provides the event value. If events already exist in the Raw instance at the given sample numbers, the event values will be added together.

Name of the stim channel to add to. If None, the config variable ‘MNE_STIM_CHANNEL’ is used. If this is not found, it will default to 'STI 014'.

If True the old events on the stim channel are removed before adding the new ones.

Data must be preloaded in order to add events.

Add SSP projection vectors.

List with projection vectors.

Remove the projection vectors currently in the file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Annotations for marking segments of data.

Anonymize measurement information in place.

Number of days to subtract from all dates. If None (default), the acquisition date, info['meas_date'], will be set to January 1ˢᵗ, 2000. This parameter is ignored if info['meas_date'] is None (i.e., no acquisition date has been set).

If True, his_id of subject_info will not be overwritten. Defaults to False.

This could mean that info is not fully anonymized. Use with caution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Removes potentially identifying information if it exists in info. Specifically for each of the following we use:

A default value, or as specified by daysback.

Default values, except for ‘birthday’ which is adjusted to maintain the subject age.

Dates use the meas_date logic, and experimenter a default string.

Dates use the meas_date logic, meta info uses defaults.

If info['meas_date'] is None, it will remain None during processing the above fields.

Concatenate raw instances as if they were continuous.

Boundaries of the raw files are annotated bad. If you wish to use the data as continuous recording, you can remove the boundary annotations after concatenation (see mne.Annotations.delete()).

List of Raw instances to concatenate to the current instance (in order), or a single raw instance to concatenate.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory). If preload is None, preload=True or False is inferred using the preload status of the instances passed in.

Apply a function to a subset of channels.

The function fun is applied to the channels defined in picks. The raw object’s data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to channels in picks). The object has to have the data loaded e.g. with preload=True or self.load_data().

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) if channel_wise=True and (len(picks), n_times) otherwise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if channel_wise=False as the workload is split across channels.

Whether to apply the function to each channel individually. If False, the function will be applied to all channels at once. Default True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The raw object with transformed data.

Apply CTF gradient compensation.

The compensation matrices are stored with single precision, so repeatedly switching between different of compensation (e.g., 0->1->3->2) can increase numerical noise, especially if data are saved to disk in between changing grades. It is thus best to only use a single gradient compensation level in final analyses.

CTF gradient compensation level.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified Raw instance. Works in-place.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‘auto’, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal “x_a(t)” of “x(t)” is:

where “F” is the Fourier transform, “U” the unit step function, and “y” the Hilbert transform of “x”. One usage of the analytic signal is the computation of the envelope signal, which is given by “e(t) = abs(x_a(t))”. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Examples using apply_hilbert:

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Apply the signal space projection (SSP) operators to the data.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Once the projectors have been applied, they can no longer be removed. It is usually not recommended to apply the projectors at too early stages, as they are applied automatically later on (e.g. when computing inverse solutions). Hint: using the copy method individual projection vectors can be tested without affecting the original data. With evoked data, consider the following example:

Does nothing for objects that close their file descriptors. Things like Raw will override this method.

The current gradient compensation grade.

Perform spectral analysis on sensor data.

Spectral estimation method. 'welch' uses Welch’s method [1], 'multitaper' uses DPSS tapers [2]. Note that "multitaper" cannot be used if reject_by_annotation=True and there are "bad_*" annotations in the Raw data; in such cases use "welch". Default is 'welch'.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

Whether to apply SSP projection vectors before spectral estimation. Default is False.

If True, the mean is subtracted from each segment before computing its spectrum.

Whether to omit bad spans of data before spectral estimation. If True, spans with annotations whose description begins with bad will be omitted.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

The spectral representation of the data.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70–73, 1967. doi:10.1109/TAU.1967.1161901.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371–1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Compute a time-frequency representation of sensor data.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [2]. None (the default) only works when using __setstate__ and will raise an error otherwise.

The frequencies at which to compute the power estimates. Must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

What kind of estimate to return. Allowed values are "complex", "phase", and "power". Default is "power".

Whether to omit bad spans of data before spectrotemporal power estimation. If True, spans with annotations whose description begins with bad will be represented with np.nan in the time-frequency representation.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet() and tfr_array_multitaper() for additional details.

The time-frequency-resolved power estimates of the data.

Return copy of Raw instance.

A copy of the instance.

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Limit the data from the raw file to go between specific times. Note that the new tmin is assumed to be t=0 for all subsequently called functions (e.g., time_as_index(), or Epochs). New first_samp and last_samp are set accordingly.

Thus function operates in-place on the instance. Use mne.io.Raw.copy() if operation on a copy is desired.

Start time of the raw data to use in seconds (must be >= 0).

End time of the raw data to use in seconds (cannot exceed data duration). If None (default), the current end of the data is used.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped raw object, modified in-place.

Get crops of raw data file for selected annotations.

The annotations to use for cropping the raw file. If None, the annotations from the instance are used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped raw objects.

Remove SSP projection vector.

The projection vector can only be removed if it is inactive (has not been applied to the data).

Index of the projector to remove. Can also be “all” (default) to remove all projectors.

Describe channels (name, type, descriptive statistics).

If True, return results in a pandas.DataFrame. If False, only print results. Columns ‘ch’, ‘type’, and ‘unit’ indicate channel index, channel type, and unit of the remaining five columns. These columns are ‘min’ (minimum), ‘Q1’ (first quartile or 25% percentile), ‘median’, ‘Q3’ (third quartile or 75% percentile), and ‘max’ (maximum).

If data_frame=False, returns None. If data_frame=True, returns results in a pandas.DataFrame (requires pandas).

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Duration of the data in seconds.

Export Raw to external formats.

BrainVision (.vhdr, .vmrk, .eeg, uses pybv)

EEGLAB (.set, uses eeglabio)

EDF (.edf, uses edfio)

Since we are exporting to external formats, there’s no guarantee that all the info will be preserved in the external format. See Notes for details.

Name of the output file.

Format of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.

The physical range of the data. If ‘auto’ (default), the physical range is inferred from the data, taking the minimum and maximum values per channel type. If ‘channelwise’, the range will be defined per channel. If a tuple of minimum and maximum, this manual physical range will be used. Only used for exporting EDF files.

Whether to incorporate the channel type into the signal label (e.g. whether to store channel “Fz” as “EEG Fz”). Only used for EDF format. Default is False.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.io.Raw.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.io.Raw.apply_proj().

For EEGLAB exports, channel locations are expanded to full EEGLAB format. For more details see eeglabio.utils.cart_to_eeglab().

Although this function supports storing channel types in the signal label (e.g. EEG Fz or MISC E), other software may not support this (optional) feature of the EDF standard.

If add_ch_type is True, then channel types are written based on what they are currently set in MNE-Python. One should double check that all their channels are set correctly. You can call mne.io.Raw.set_channel_types() to set channel types.

In addition, EDF does not support storing a montage. You will need to store the montage separately and call mne.io.Raw.set_montage().

The physical range of the signals is determined by signal type by default (physical_range="auto"). However, if individual channel ranges vary significantly due to the presence of e.g. drifts/offsets/biases, setting physical_range="channelwise" might be more appropriate. This will ensure a maximum resolution for each individual channel, but some tools might not be able to handle this appropriately (even though channel-wise ranges are covered by the EDF standard).

tuple of pathlib.Path | None

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Examples using filter:

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

The first data sample.

The first time point (including first_samp but not meas_date).

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get data in the given range.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The first sample to include. Defaults to 0.

End sample (first not to include). If None (default), the end of the data is used.

Whether to reject by annotation. If None (default), no rejection is done. If ‘omit’, segments annotated with description starting with ‘bad’ are omitted. If ‘NaN’, the bad samples are filled with NaNs.

Whether to return times as well. Defaults to False.

Specify the unit(s) that the data should be returned in. If None (default), the data is returned in the channel-type-specific default units, which are SI units (see Internal representation (units) and data channels). If a string, must be a sub-multiple of SI units that will be used to scale the data from all channels of the type associated with that unit. This only works if the data contains one channel type that has a unit (unitless channel types are left unchanged). For example if there are only EEG and STIM channels, units='uV' will scale EEG channels to micro-Volts while STIM channels will be unchanged. Finally, if a dictionary is provided, keys must be channel types, and values must be units to scale the data of that channel type to. For example dict(grad='fT/cm', mag='fT') will scale the corresponding types accordingly, but all other channel types will remain in their channel-type-specific default unit.

Start time of data to get in seconds. The tmin parameter is ignored if the start parameter is bigger than 0.

End time of data to get in seconds. The tmax parameter is ignored if the stop parameter is defined.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Copy of the data in the given range.

Times associated with the data samples. Only returned if return_times=True.

Get a DigMontage from instance.

A copy of the channel positions, if available, otherwise None.

Interpolate bad MEG and EEG channels.

If True, remove the bads from info.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used for interpolation of channels using the minimum-norm method.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for each channel type.

"meg" channels support "MNE" (default) and "nan"

"eeg" channels support "spline" (default), "MNE" and "nan"

"fnirs" channels support "nearest" (default) and "nan"

"ecog" channels support "spline" (default) and "nan"

"seeg" channels support "spline" (default) and "nan"

None is an alias for:

If a str is provided, the method will be applied to all channel types supported and available in the instance. The method "nan" will replace the channel data with np.nan.

Be careful when using method="nan"; the default value reset_bads=True may not be what you want.

The channels to exclude from interpolation. If excluded a bad channel will stay in bads.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

The "MNE" method uses minimum-norm projection to a sphere and back.

Interpolate EEG data onto a new montage.

Be careful, only EEG channels are interpolated. Other channel types are not interpolated.

The target montage containing channel positions to interpolate onto.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for EEG channels. Supported methods are ‘spline’ (default) and ‘MNE’.

The regularization parameter for the interpolation method (only used when the method is ‘spline’).

The instance with updated channel locations and data.

This method is useful for standardizing EEG layouts across datasets. However, some attributes may be lost after interpolation.

The last data sample.

Mark channels as bad from a text file.

This function operates mostly in the style of the C function mne_mark_bad_channels. Each line in the text file will be interpreted as a name of a bad channel.

File name of the text file containing bad channels. If None (default), bad channels are cleared, but this is more easily done directly with raw.info['bads'] = [].

Whether or not to force bad channel marking (of those that exist) if channels are not found, instead of raising an error. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with data.

This function will load raw data if it was not already preloaded. If data were already preloaded, it will do nothing.

Number of time points.

Notch filter a subset of channels.

Specific frequencies to filter out from data, e.g., np.arange(60, 241, 60) in the US or np.arange(50, 251, 50) in Europe. None can only be used with the mode 'spectrum_fit', where an F test is used to find sinusoidal components.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

When method=='spectrum_fit', this sets the effective window duration over which fits are computed. See mne.filter.create_filter() for options. Longer window lengths will give more stable frequency estimates, but require (potentially much) more processing and are not able to adapt as well to non-stationarities.

The default in 0.21 is None, but this will change to '10s' in 0.22.

Width of each stop band (centred at each freq in freqs) in Hz. If None, freqs / 200 is used.

Width of the transition band in Hz. Only used for method='fir' and method='iir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

The bandwidth of the multitaper windowing function in Hz. Only used in ‘spectrum_fit’ mode.

P-value to use in F-test thresholding to determine significant sinusoidal components to remove when method='spectrum_fit' and freqs=None. Note that this will be Bonferroni corrected for the number of frequencies, so large p-values may be justified.

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'. The default is 'reflect_limited'.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw instance with filtered data.

Applies a zero-phase notch filter to the channels selected by “picks”. By default the data of the Raw object is modified inplace.

The Raw object has to have the data loaded e.g. with preload=True or self.load_data().

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

For details, see mne.filter.notch_filter().

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=”bads” when picks=”meg”).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Compare simulated and estimated source activity

LEGACY: New code should use inst.pick(…).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(…).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‘auto’, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‘hbo’ (to include channels measuring oxyhemoglobin) or ‘hbr’ (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‘eyegaze’ (to include eye position channels) or ‘pupil’ (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‘bads’ (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Events to show with vertical bars.

Time window (s) to plot. The lesser of this value and the duration of the raw file will be used.

Initial time to show (can be changed dynamically once plotted). If show_first_samp is True, then it is taken relative to raw.first_samp.

Number of channels to plot at once. Defaults to 20. The lesser of n_channels and len(raw.ch_names) will be shown. Has no effect if order is ‘position’, ‘selection’ or ‘butterfly’.

Color of the background.

Color for the data traces. If None, defaults to:

Color to make bad channels.

Color(s) to use for events. To show all events in the same color, pass any matplotlib-compatible color. To color events differently, pass a dict that maps event names or integer event numbers to colors (must include entries for all events, or include a “fallback” entry with key -1). If None, colors are chosen from the current Matplotlib color cycle. Defaults to 'cyan'.

A regex pattern applied to each annotation’s label. Matching labels remain visible, non-matching labels are hidden.

Scaling factors for the traces. If a dictionary where any value is 'auto', the scaling factor is set to match the 99.5th percentile of the respective data. If 'auto', all scalings (for all channel types) are set to 'auto'. If any values are 'auto' and the data is not preloaded, a subset up to 100 MB will be loaded. If None, defaults to:

A particular scaling value s corresponds to half of the visualized signal range around zero (i.e. from 0 to +s or from 0 to -s). For example, the default scaling of 20e-6 (20µV) for EEG signals means that the visualized range will be 40 µV (20 µV in the positive direction and 20 µV in the negative direction).

If True remove DC component when plotting data.

Order in which to plot data. If the array is shorter than the number of channels, only the given channels are plotted. If None (default), all channels are plotted. If group_by is 'position' or 'selection', the order parameter is used only for selecting the channels to be plotted.

If True, a dialog for options related to projection is shown.

The title of the window. If None, and either the filename of the raw object or ‘<unknown>’ will be displayed as title.

Whether to halt program execution until the figure is closed. Useful for setting bad channels on the fly by clicking on a line. May not work on all systems / platforms. (Only Qt) If you run from a script, this needs to be True or a Qt-eventloop needs to be started somewhere else in the script (e.g. if you want to implement the browser inside another Qt-Application).

Highpass to apply when displaying data.

Lowpass to apply when displaying data. If highpass > lowpass, a bandstop rather than bandpass filter will be applied.

Filtering order. 0 will use FIR filtering with MNE defaults. Other values will construct an IIR filter of the given order and apply it with filtfilt() (making the effective order twice filtorder). Filtering may produce some edge artifacts (at the left and right edges) of the signals during display.

Changed in version 0.18: Support for filtorder=0 to use FIR filtering.

If None, channels are allowed to exceed their designated bounds in the plot. If “clamp”, then values are clamped to the appropriate range for display, creating step-like artifacts. If “transparent”, then excessive values are not shown, creating gaps in the traces. If float, clipping occurs for values beyond the clipping multiple of their dedicated range, so clipping=1. is an alias for clipping='transparent'.

Changed in version 0.21: Support for float, and default changed from None to 1.5.

If True, show time axis relative to the raw.first_samp.

Whether to apply projectors prior to plotting (default is True). Individual projectors can be enabled/disabled interactively (see Notes). This argument only affects the plot; use raw.apply_proj() to modify the data stored in the Raw object.

How to group channels. 'type' groups by channel type, 'original' plots in the order of ch_names, 'selection' uses Elekta’s channel groupings (only works for Neuromag data), 'position' groups the channels by the positions of the sensors. 'selection' and 'position' modes allow custom selections by using a lasso selector on the topomap. In butterfly mode, 'type' and 'original' group the channels by type, whereas 'selection' and 'position' use regional grouping. 'type' and 'original' modes are ignored when order is not None. Defaults to 'type'.

Whether to start in butterfly mode. Defaults to False.

Amount to decimate the data during display for speed purposes. You should only decimate if the data are sufficiently low-passed, otherwise aliasing can occur. The ‘auto’ mode (default) uses the decimation that results in a sampling rate least three times larger than min(info['lowpass'], lowpass) (e.g., a 40 Hz lowpass will result in at least a 120 Hz displayed sample rate).

Noise covariance used to whiten the data while plotting. Whitened data channels are scaled by scalings['whitened'], and their channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().

Event IDs used to show at event markers (default None shows the event numbers).

Whether to show scrollbars when the plot is initialized. Can be toggled after initialization by pressing z (“zen mode”) while the plot window is focused. Default is True.

Whether to show scale bars when the plot is initialized. Can be toggled after initialization by pressing s while the plot window is focused. Default is True.

Style of time labels on the horizontal axis. If 'float', labels will be number of seconds from the start of the recording. If 'clock', labels will show “clock time” (hours/minutes/seconds) inferred from raw.info['meas_date']. Default is 'float'.

Whether to load all data (not just the visible portion) into RAM and apply preprocessing (e.g., projectors) to the full data array in a separate processor thread, instead of window-by-window during scrolling. The default None uses the MNE_BROWSER_PRECOMPUTE variable, which defaults to 'auto'. 'auto' compares available RAM space to the expected size of the precomputed data, and precomputes only if enough RAM is available. This is only used with the Qt backend.

Changed in version 1.0: Support for the MNE_BROWSER_PRECOMPUTE config variable.

Whether to use OpenGL when rendering the plot (requires pyopengl). May increase performance, but effect is dependent on system CPU and graphics hardware. Only works if using the Qt backend. Default is None, which will use False unless the user configuration variable MNE_BROWSER_USE_OPENGL is set to 'true', see mne.set_config().

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Can be “auto”, “light”, or “dark” or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_BROWSER_THEME will be used, defaulting to “auto” if it’s not found. Only supported by the 'qt' backend.

Can be “channels”, “empty”, or “hidden” to set the overview bar mode for the 'qt' backend. If None (default), the config option MNE_BROWSER_OVERVIEW_MODE will be used, defaulting to “channels” if it’s not found.

If True (default), a splash screen is shown during the application startup. Only applicable to the qt backend.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The arrow keys (up/down/left/right) can typically be used to navigate between channels and time ranges, but this depends on the backend matplotlib is configured to use (e.g., mpl.use(‘TkAgg’) should work). The left/right arrows will scroll by 25% of duration, whereas shift+left/shift+right will scroll by 100% of duration. The scaling can be adjusted with - and + (or =) keys. The viewport dimensions can be adjusted with page up/page down and home/end keys. Full screen mode can be toggled with the F11 key, and scrollbars can be hidden/shown by pressing ‘z’. Right-click a channel label to view its location. To mark or un-mark a channel as bad, click on a channel label or a channel trace. The changes will be reflected immediately in the raw object’s raw.info['bads'] entry.

If projectors are present, a button labelled “Prj” in the lower right corner of the plot window opens a secondary control window, which allows enabling/disabling specific projectors individually. This provides a means of interactively observing how each projector would affect the raw data if it were applied.

Annotation mode is toggled by pressing ‘a’, butterfly mode by pressing ‘b’, and whitening mode (when noise_cov is not None) by pressing ‘w’. By default, the channel means are removed when remove_dc is set to True. This flag can be toggled by pressing ‘d’.

MNE-Python provides two different backends for browsing plots (i.e., raw.plot(), epochs.plot(), and ica.plot_sources()). One is based on matplotlib, and the other is based on PyQtGraph. You can set the backend temporarily with the context manager mne.viz.use_browser_backend(), you can set it for the duration of a Python session using mne.viz.set_browser_backend(), and you can set the default for your computer via mne.set_config('MNE_BROWSER_BACKEND', 'matplotlib') (or 'qt').

For the PyQtGraph backend to run in IPython with block=False you must run the magic command %gui qt5 first.

To report issues with the PyQtGraph backend, please use the issues of mne-qt-browser.

How to use data in neural ensemble (NEO) format

Visualise NIRS artifact correction methods

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

Creating MNE-Python data structures from scratch

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None it will return all channel types present.. If a list of ch_types is provided, it will return multiple figures. Defaults to None.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches. Only applies when plotting multiple topomaps at a time.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all projectors of the same channel type (instead of separately for each projector), using the min/max of the data for that channel type. If vlim is "joint", info must not be None. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of projectors. Default is None.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

LEGACY: New code should use .compute_psd().plot().

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (╎) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (⋮). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Whether to omit bad spans of data before spectral estimation. If True, spans with annotations whose description begins with bad will be omitted.

Spectral estimation method. 'welch' uses Welch’s method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch’s method for continuous data and multitaper for Epochs or Evoked data.

If False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap.

Plot power spectral density (PSD) in units (dB/Hz) if dB=True and estimate='power'. Plot PSD in units (amplitude**2/Hz) if dB=False and estimate='power'. Plot amplitude spectral density (ASD) in units (amplitude/sqrt(Hz)) if dB=False and estimate='amplitude'. Plot ASD in units (dB/sqrt(Hz)) if dB=True and estimate='amplitude'.

Can be “power” for power spectral density (PSD; default), “amplitude” for amplitude spectrum density (ASD).

Scale of the frequency axis. Default is 'linear'.

Mode for plotting area. If ‘std’, the mean +/- 1 STD (across channels) will be plotted. If ‘range’, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Alpha for the PSD line. Can be None (default) to use 1.0 when average=True and 0.1 when average=False.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channels names to exclude from being shown. If ‘bads’, the bad channels are excluded. Pass an empty list to plot all channels (including channels marked “bad”, if any).

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of channel types present in the object.. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure with frequency spectra of the data channels.

This method exists to support legacy code; for new code the preferred idiom is inst.compute_psd().plot() (where inst is an instance of Raw, Epochs, or Evoked).

LEGACY: New code should use .compute_psd().plot_topo().

Plot power spectral density, separately for each channel.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=100.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch’s method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch’s method for continuous data and multitaper for Epochs or Evoked data.

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch(). Defaults to dict(n_fft=2048).

Figure distributing one image per channel across sensor topography.

LEGACY: New code should use .compute_psd().plot_topomap().

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch’s method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch’s method for continuous data and multitaper for Epochs or Evoked data.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‘%0.3f’ if dB=False and ‘%0.1f’ if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure showing one scalp topography per frequency band.

Plot sensor positions.

Whether to plot the sensors as 3d, topomap or as an interactive sensor selection dialog. Available options ‘topomap’, ‘3d’, ‘select’. If ‘select’, a set of channels can be selected interactively by using lasso selector or clicking while holding control key. The selected channels are returned along with the figure instance. Defaults to ‘topomap’.

The channel type to plot. Available options 'mag', 'grad', 'eeg', 'seeg', 'dbs', 'ecog', 'all'. If 'all', all the available mag, grad, eeg, seeg, dbs, and ecog channels are plotted. If None (default), then channels are chosen in the order given above.

Title for the figure. If None (default), equals to 'Sensor positions (%s)' % ch_type.

Whether to display all channel names. If an array, only the channel names in the array are shown. Defaults to False.

Channel groups for coloring the sensors. If None (default), default coloring scheme is used. If ‘position’, the sensors are divided into 8 regions. See order kwarg of mne.viz.plot_raw(). If array, the channels are divided by picks given in the array.

Whether to project the 3d locations to a sphere. When False, the sensor array appears similar as to looking downwards straight above the subject’s head. Has no effect when kind=’3d’. Defaults to True.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Whether to halt program execution until the figure is closed. Defaults to False.

Show figure if True. Defaults to True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the sensor topography.

A list of selected channels. Only returned if kind=='select'.

This function plots the sensor locations from the info structure using matplotlib. For drawing the sensors using PyVista see mne.viz.plot_alignment().

Examples using plot_sensors:

Importing data from fNIRS devices

Whether or not projections are active.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Resample all channels.

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

The intended purpose of this function is primarily to speed up computations (e.g., projection calculation) when precise timing of events is not required, as downsampling raw data effectively jitters trigger timings. It is generally recommended not to epoch downsampled data, but instead epoch and then downsample, as epoching downsampled data jitters triggers. For more, see this illustrative gist.

If resampling the continuous data is desired, it is recommended to construct events using the original data. The event onsets can be jointly resampled with the raw data using the ‘events’ parameter (a resampled copy is returned).

New sample rate to use.

Amount to pad the start and end of the data. Can also be "auto" to use a padding that will result in a power-of-two size (can be much faster).

Only used when method="fft".

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

Stim channels. These channels are simply subsampled or supersampled (without applying any filtering). This reduces resampling artifacts in stim channels, but may lead to missing triggers. If None, stim channels are automatically chosen using mne.pick_types().

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly.

An optional event matrix. When specified, the onsets of the events are resampled jointly with the data. NB: The input events are not modified, but a new array is returned with the raw instead.

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn(). The default (“auto”) means 'reflect_limited' for method='fft' and 'reflect' for method='polyphase'.

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled version of the raw object.

If events are jointly resampled, these are returned with the raw.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent – check your data!

For optimum performance and to make use of n_jobs > 1, the raw object has to have the data loaded e.g. with preload=True or self.load_data(), but this increases memory requirements. The resulting raw object will have the data loaded into memory.

MNE-Python assumes data are stored in SI base units. This function should typically only be used to fix an incorrect scaling factor in the data to get it to be in SI base units, otherwise unintended problems (e.g., incorrect source imaging results) and analysis errors can occur.

The scaling factor(s) by which to multiply the data. If a float, the same scaling factor is applied to all channels (this works only if all channels are of the same type). If a dict, the keys must be valid channel types and the values the scaling factors to apply to the corresponding channels.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with rescaled data (modified in-place).

A common use case for EEG data is to convert from µV to V, since many EEG systems store data in µV, but MNE-Python expects the data to be in V. Therefore, the data needs to be rescaled by a factor of 1e-6. To rescale all channels from µV to V, you can do:

Note that the previous example only works if all channels are of the same type. If there are multiple channel types, you can pass a dict with the individual scaling factors. For example, to rescale only EEG channels, you can do:

Save raw data to file.

File name of the new dataset. This has to be a new filename unless data have been preloaded. Filenames should end with raw.fif (common raw data), raw_sss.fif (Maxwell-filtered continuous data), raw_tsss.fif (temporally signal-space-separated data), _meg.fif (common MEG data), _eeg.fif (common EEG data), or _ieeg.fif (common intracranial EEG data). You may also append an additional .gz suffix to enable gzip compression.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Start time of the raw data to use in seconds (must be >= 0).

End time of the raw data to use in seconds (cannot exceed data duration). If None (default), the current end of the data is used.

Size of data chunks in seconds. If None (default), the buffer size of the original file is used.

Drop or not the last buffer. It is required by maxfilter (SSS) that only accepts raw files with buffers of the same size.

If True the data is saved with the projections applied (active).

If apply_proj() was used to apply the projections, the projectons will be active even if proj is False.

Format to use to save raw data. Valid options are ‘double’, ‘single’, ‘int’, and ‘short’ for 64- or 32-bit float, or 32- or 16-bit integers, respectively. It is strongly recommended to use ‘single’, as this is backward-compatible, and is standard for maintaining precision. Note that using ‘short’ or ‘int’ may result in loss of precision, complex data cannot be saved as ‘short’, and neither complex data types nor real data stored as ‘double’ can be loaded with the MNE command-line tools. See raw.orig_format to determine the format the original data were stored in.

If True (default False), overwrite the destination file if it exists. To overwrite original file (the same one that was loaded), data must be preloaded upon reading.

Large raw files are automatically split into multiple pieces. This parameter specifies the maximum size of each piece. If the parameter is an integer, it specifies the size in Bytes. It is also possible to pass a human-readable string, e.g., 100MB.

Due to FIFF file limitations, the maximum split size is 2GB.

When splitting files, append a filename partition with the appropriate naming schema. For 'neuromag', a split file fname.fif will be named fname.fif, fname-1.fif, fname-2.fif, and so on. For 'bids', a filename is expected to consist of parts separated by underscores, like <part-1>_<part-N>_<suffix>.fif, and the according split naming will return filenames like <part-1>_<part-N>_split-01_<suffix>.fif, <part-1>_<part-N>_split-02_<suffix>.fif, and so on.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of path-like objects containing the path to each file split.

If Raw is a concatenation of several raw files, be warned that only the measurement information from the first raw file is stored. This likely means that certain operations with external tools may not work properly on a saved concatenated file (e.g., probably some or all forms of SSS). It is recommended not to concatenate and then save raw files for this reason.

Samples annotated BAD_ACQ_SKIP are not stored in order to optimize memory. Whatever values, they will be loaded as 0s when reading file.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [3] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627–1639, 1964. doi:10.1021/ac60214a047.

Setter for annotations.

This setter checks if they are inside the data range.

Annotations to set. If None, the annotations is defined but empty.

Whether to emit warnings when cropping or omitting annotations. The default is True.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with annotations.

Examples using set_annotations:

Visualise NIRS artifact correction methods

Specify the sensor types of channels.

A dictionary mapping channel names to sensor types, e.g., {'EEG061': 'eog'}.

What to do if the measurement unit of a channel is changed automatically to match the new sensor type.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The following sensor types are accepted:

bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci, eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase, fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp, seeg, stim, syst, temperature.

When working with eye-tracking data, see mne.preprocessing.eyetracking.set_channel_types_eyetrack().

Specify which reference to use for EEG data.

Use this function to explicitly specify the desired reference for EEG. This can be either an existing electrode or a new virtual channel. This function will re-reference the data according to the desired reference.

The name(s) of the channel(s) used to construct the reference for every channel of ch_type.

'average' to apply an average reference (default)

'REST' to use the Reference Electrode Standardization Technique infinity reference [4].

A dictionary mapping names of data channels to (lists of) names of reference channels. For example, {‘A1’: ‘A3’} would replace the data in channel ‘A1’ with the difference between ‘A1’ and ‘A3’. To take the average of multiple channels as reference, supply a list of channel names as the dictionary value, e.g. {‘A1’: [‘A2’, ‘A3’]} would replace channel A1 with A1 - mean(A2, A3).

An empty list, in which case MNE will not attempt any re-referencing of the data

If ref_channels='average' this argument specifies if the average reference should be computed as a projection (True) or not (False; default). If projection=True, the average reference is added as a projection and is not applied to the data (it can be applied afterwards with the apply_proj method). If projection=False, the average reference is directly applied to the data. If ref_channels is not 'average', projection must be set to False (the default in this case).

The name of the channel type to apply the reference to. Valid channel types are 'auto', 'eeg', 'ecog', 'seeg', 'dbs'. If 'auto', the first channel type of eeg, ecog, seeg or dbs that is found (in that order) will be selected.

Changed in version 1.2: list-of-str is now supported with projection=True.

Forward solution to use. Only used with ref_channels='REST'.

How to handle list-of-str ch_type. If False (default), one projector is created per channel type. If True, one projector is created across all channel types. This is only used when projection=True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data with EEG channels re-referenced. If ref_channels='average' and projection=True a projection will be added instead of directly re-referencing the data.

Convenience function for creating bipolar references.

Some common referencing schemes and the corresponding value for the ref_channels parameter:

A new virtual reference electrode is created by averaging the current EEG signal by setting ref_channels='average'. Bad EEG channels are automatically excluded if they are properly set in info['bads'].

Set ref_channels to a list containing the name of the channel that will act as the new reference, for example ref_channels=['Cz'].

A new virtual reference electrode is created by computing the average of the current EEG signal recorded from two or more selected channels. Set ref_channels to a list of channel names, indicating which channels to use. For example, to apply an average mastoid reference, when using the 10-20 naming scheme, set ref_channels=['M1', 'M2'].

The given EEG electrodes are referenced to a point at infinity using the lead fields in forward, which helps standardize the signals.

Set ref_channels to a dictionary mapping source channel names (str) to the reference channel names (str or list of str). Unlike the other approaches where the same reference is applied globally, you can set different references for different channels with this method. For example, to re-reference channel ‘A1’ to ‘A2’ and ‘B1’ to the average of ‘B2’ and ‘B3’, set ref_channels={'A1': 'A2', 'B1': ['B2', 'B3']}. Warnings are issued when a mapping involves bad channels or channels of different types.

If a reference is requested that is not the average reference, this function removes any pre-existing average reference projections.

During source localization, the EEG signal should have an average reference.

In order to apply a reference, the data must be preloaded. This is not necessary if ref_channels='average' and projection=True.

For an average or REST reference, bad EEG channels are automatically excluded if they are properly set in info['bads'].

D. Yao. A method to standardize a reference of scalp EEG recordings to a point at infinity. Physiological Measurement, 22(4):693–711, 2001. doi:10.1088/0967-3334/22/4/305.

Examples using set_eeg_reference:

Simulate raw data using subject anatomy

EEG forward operator with a template MRI

Set the measurement start date.

The new measurement date. If datetime object, it must be timezone-aware and in UTC. A tuple of (seconds, microseconds) or float (alias for (meas_date, 0)) can also be passed and a datetime object will be automatically created. If None, will remove the time reference.

The modified raw instance. Operates in place.

If you want to remove all time references in the file, call mne.io.anonymize_info(inst.info) after calling inst.set_meas_date(None).

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

A montage containing channel positions. If a string or DigMontage is specified, the existing channel information will be updated with the channel positions from the montage. Valid strings are the names of the built-in montages that ship with MNE-Python; you can list those via mne.channels.get_builtin_montages(). If None (default), the channel positions will be removed from the Info.

If True (default), channel name matching will be case sensitive.

Whether to use a lookup table to match unrecognized channel location names to their known aliases. If True, uses the mapping in mne.io.constants.CHANNEL_LOC_ALIASES. If a dict is passed, it will be used instead, and should map from non-standard channel names to names in the specified montage. Default is False.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when channels have missing coordinates.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

Only EEG/sEEG/ECoG/DBS/fNIRS channels can have their positions set using a montage. Other channel types (e.g., MEG channels) should have their positions defined properly using their data reading functions.

Applying a montage will only set locations of channels that exist at the time it is applied. This means when re-referencing make sure to apply the montage only after calling mne.add_reference_channels()

Examples using set_montage:

EEG forward operator with a template MRI

Importing data from fNIRS devices

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Time reference for times. If None, times are assumed to be relative to first_samp.

Indices relative to first_samp corresponding to the times supplied.

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, an additional column “time” is added, unless index is not None (in which case time values form the DataFrame’s index).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index, pandas.DatetimeIndex, or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) — i.e., converts EEG to µV, magnetometers to fT, and gradiometers to fT/cm.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

Starting sample index for creating the DataFrame from a temporal span of the Raw object. None (the default) uses the first sample.

Ending sample index for creating the DataFrame from a temporal span of the Raw object. None (the default) uses the last sample.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and channel. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. If 'datetime', time values will be converted to pandas.Timestamp values, relative to raw.info['meas_date'] and offset by raw.first_samp. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Receptive Field Estimation and Prediction

How to use data in neural ensemble (NEO) format

Identify EEG Electrodes Bridged by too much Gel

Visualise NIRS artifact correction methods

Compare simulated and estimated source activity

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

EEG forward operator with a template MRI

Importing data from fNIRS devices

Rejecting bad data spans and breaks

Creating MNE-Python data structures from scratch

DICS for power mapping

---

## mne.io.Raw#

**URL:** https://mne.tools/stable/generated/mne.io.Raw.html

**Contents:**
- mne.io.Raw#
- Examples using mne.io.Raw#

Raw data in FIF format.

The raw filename to load. For files that have automatically been split, the split part will be automatically loaded. Filenames not ending with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, or _ieeg.fif (with or without an optional additional .gz extension) will generate a warning. If a file-like object is provided, preloading must be used.

Changed in version 0.18: Support for file-like objects.

If True, allow loading of data that has been recorded with internal active compensation (MaxShield). Data recorded with MaxShield should generally not be loaded directly, but should first be processed using SSS/tSSS to remove the compensation signals that may also affect brain activity. Can also be “yes” to load without eliciting a warning.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when split file is missing.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The mne.Info object with information about the sensors and methods of measurement.

Number of time points.

Duration of the data in seconds.

Indicates whether raw data are in memory.

__contains__(ch_type)

Check channel type membership.

Get raw data and times.

Return the number of time points.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_events(events[, stim_channel, replace])

Add events to stim channel.

add_proj(projs[, remove_existing, verbose])

Add SSP projection vectors.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

anonymize([daysback, keep_his, verbose])

Anonymize measurement information in place.

append(raws[, preload])

Concatenate raw instances as if they were continuous.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of channels.

apply_gradient_compensation(grade[, verbose])

Apply CTF gradient compensation.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

apply_proj([verbose])

Apply the signal space projection (SSP) operators to the data.

compute_psd([method, fmin, fmax, tmin, ...])

Perform spectral analysis on sensor data.

compute_tfr(method, freqs, *[, tmin, tmax, ...])

Compute a time-frequency representation of sensor data.

Return copy of Raw instance.

crop([tmin, tmax, include_tmax, verbose])

crop_by_annotations([annotations, verbose])

Get crops of raw data file for selected annotations.

Remove SSP projection vector.

describe([data_frame])

Describe channels (name, type, descriptive statistics).

drop_channels(ch_names[, on_missing])

export(fname[, fmt, physical_range, ...])

Export Raw to external formats.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

Fix Elekta magnetometer coil types.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, start, stop, ...])

Get data in the given range.

Get a DigMontage from instance.

interpolate_bads([reset_bads, mode, origin, ...])

Interpolate bad MEG and EEG channels.

interpolate_to(sensors[, origin, method, reg])

Interpolate EEG data onto a new montage.

load_bad_channels([bad_file, force, verbose])

Mark channels as bad from a text file.

notch_filter(freqs[, picks, filter_length, ...])

Notch filter a subset of channels.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([events, duration, start, n_channels, ...])

plot_projs_topomap([ch_type, sensors, ...])

plot_psd([fmin, fmax, tmin, tmax, picks, ...])

plot_psd_topo([tmin, tmax, fmin, fmax, ...])

plot_psd_topomap([bands, tmin, tmax, ...])

plot_sensors([kind, ch_type, title, ...])

Plot sensor positions.

rename_channels(mapping[, allow_duplicates, ...])

reorder_channels(ch_names)

resample(sfreq, *[, npad, window, ...])

Resample all channels.

rescale(scalings, *[, verbose])

save(fname[, picks, tmin, tmax, ...])

Save raw data to file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

set_annotations(annotations[, emit_warning, ...])

Setter for annotations.

set_channel_types(mapping, *[, ...])

Specify the sensor types of channels.

set_eeg_reference([ref_channels, ...])

Specify which reference to use for EEG data.

set_meas_date(meas_date)

Set the measurement start date.

set_montage(montage[, match_case, ...])

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

time_as_index(times[, use_rounding, origin])

Convert time to indices.

to_data_frame([picks, index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Get raw data and times.

See below for use cases.

The times associated with the data.

Generally raw data is accessed as:

To get all data, you can thus do either of:

Which will be equivalent to:

To get only the good MEG data from 10-20 seconds, you could do:

Return the number of time points.

The number of time points.

The AcqParserFIF for the measurement info.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won’t be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Examples using add_channels:

Find MEG reference channel artifacts

Add events to stim channel.

Events to add. The first column specifies the sample number of each event, the second column is ignored, and the third column provides the event value. If events already exist in the Raw instance at the given sample numbers, the event values will be added together.

Name of the stim channel to add to. If None, the config variable ‘MNE_STIM_CHANNEL’ is used. If this is not found, it will default to 'STI 014'.

If True the old events on the stim channel are removed before adding the new ones.

Data must be preloaded in order to add events.

Examples using add_events:

Show EOG artifact timing

Add SSP projection vectors.

List with projection vectors.

Remove the projection vectors currently in the file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Examples using add_proj:

Kernel OPM phantom data

Generate simulated evoked data

Temporal whitening with AR model

Divide continuous data into equally-spaced epochs

Computing a covariance matrix

Background on projectors and projections

Repairing artifacts with SSP

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Annotations for marking segments of data.

Anonymize measurement information in place.

Number of days to subtract from all dates. If None (default), the acquisition date, info['meas_date'], will be set to January 1ˢᵗ, 2000. This parameter is ignored if info['meas_date'] is None (i.e., no acquisition date has been set).

If True, his_id of subject_info will not be overwritten. Defaults to False.

This could mean that info is not fully anonymized. Use with caution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Removes potentially identifying information if it exists in info. Specifically for each of the following we use:

A default value, or as specified by daysback.

Default values, except for ‘birthday’ which is adjusted to maintain the subject age.

Dates use the meas_date logic, and experimenter a default string.

Dates use the meas_date logic, meta info uses defaults.

If info['meas_date'] is None, it will remain None during processing the above fields.

Concatenate raw instances as if they were continuous.

Boundaries of the raw files are annotated bad. If you wish to use the data as continuous recording, you can remove the boundary annotations after concatenation (see mne.Annotations.delete()).

List of Raw instances to concatenate to the current instance (in order), or a single raw instance to concatenate.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory). If preload is None, preload=True or False is inferred using the preload status of the instances passed in.

Examples using append:

The Raw data structure: continuous data

Apply a function to a subset of channels.

The function fun is applied to the channels defined in picks. The raw object’s data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to channels in picks). The object has to have the data loaded e.g. with preload=True or self.load_data().

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) if channel_wise=True and (len(picks), n_times) otherwise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if channel_wise=False as the workload is split across channels.

Whether to apply the function to each channel individually. If False, the function will be applied to all channels at once. Default True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The raw object with transformed data.

Examples using apply_function:

Modifying data in-place

Apply CTF gradient compensation.

The compensation matrices are stored with single precision, so repeatedly switching between different of compensation (e.g., 0->1->3->2) can increase numerical noise, especially if data are saved to disk in between changing grades. It is thus best to only use a single gradient compensation level in final analyses.

CTF gradient compensation level.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified Raw instance. Works in-place.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‘auto’, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal “x_a(t)” of “x(t)” is:

where “F” is the Fourier transform, “U” the unit step function, and “y” the Hilbert transform of “x”. One usage of the analytic signal is the computation of the envelope signal, which is given by “e(t) = abs(x_a(t))”. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Examples using apply_hilbert:

Modifying data in-place

Apply the signal space projection (SSP) operators to the data.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Once the projectors have been applied, they can no longer be removed. It is usually not recommended to apply the projectors at too early stages, as they are applied automatically later on (e.g. when computing inverse solutions). Hint: using the copy method individual projection vectors can be tested without affecting the original data. With evoked data, consider the following example:

Examples using apply_proj:

Divide continuous data into equally-spaced epochs

Repairing artifacts with SSP

Does nothing for objects that close their file descriptors. Things like Raw will override this method.

The current gradient compensation grade.

Perform spectral analysis on sensor data.

Spectral estimation method. 'welch' uses Welch’s method [1], 'multitaper' uses DPSS tapers [2]. Note that "multitaper" cannot be used if reject_by_annotation=True and there are "bad_*" annotations in the Raw data; in such cases use "welch". Default is 'welch'.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

Whether to apply SSP projection vectors before spectral estimation. Default is False.

If True, the mean is subtracted from each segment before computing its spectrum.

Whether to omit bad spans of data before spectral estimation. If True, spans with annotations whose description begins with bad will be omitted.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

The spectral representation of the data.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70–73, 1967. doi:10.1109/TAU.1967.1161901.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371–1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Examples using compute_psd:

Transform EEG data using current source density (CSD)

Find MEG reference channel artifacts

Plot custom topographies for MEG sensors

Overview of MEG/EEG analysis with MNE-Python

Brainstorm Elekta phantom dataset tutorial

Overview of artifact detection

Filtering and resampling data

Repairing artifacts with SSP

Extracting and visualizing subject head movement

Built-in plotting methods for Raw objects

The Spectrum and EpochsSpectrum classes: frequency-domain data

Compute a time-frequency representation of sensor data.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [2]. None (the default) only works when using __setstate__ and will raise an error otherwise.

The frequencies at which to compute the power estimates. Must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

What kind of estimate to return. Allowed values are "complex", "phase", and "power". Default is "power".

Whether to omit bad spans of data before spectrotemporal power estimation. If True, spans with annotations whose description begins with bad will be represented with np.nan in the time-frequency representation.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet() and tfr_array_multitaper() for additional details.

The time-frequency-resolved power estimates of the data.

Return copy of Raw instance.

A copy of the instance.

Find MEG reference channel artifacts

Plot sensor denoising using oversampled temporal projection

Regression-based baseline correction

Modifying data in-place

Parsing events from raw data

Handling bad channels

Filtering and resampling data

Background on projectors and projections

Setting the EEG reference

Signal-space separation (SSS) and Maxwell filtering

The Raw data structure: continuous data

Annotating continuous data

Make figures more publication ready

Limit the data from the raw file to go between specific times. Note that the new tmin is assumed to be t=0 for all subsequently called functions (e.g., time_as_index(), or Epochs). New first_samp and last_samp are set accordingly.

Thus function operates in-place on the instance. Use mne.io.Raw.copy() if operation on a copy is desired.

Start time of the raw data to use in seconds (must be >= 0).

End time of the raw data to use in seconds (cannot exceed data duration). If None (default), the current end of the data is used.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped raw object, modified in-place.

Automated epochs metadata generation with variable time windows

Plot sensor denoising using oversampled temporal projection

Divide continuous data into equally-spaced epochs

EEG analysis - Event-Related Potentials (ERPs)

Modifying data in-place

Parsing events from raw data

Overview of artifact detection

Handling bad channels

Rejecting bad data spans and breaks

Filtering and resampling data

Background on projectors and projections

Setting the EEG reference

Extracting and visualizing subject head movement

Signal-space separation (SSS) and Maxwell filtering

The Raw data structure: continuous data

Annotating continuous data

Built-in plotting methods for Raw objects

Frequency and time-frequency sensor analysis

Get crops of raw data file for selected annotations.

The annotations to use for cropping the raw file. If None, the annotations from the instance are used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped raw objects.

Remove SSP projection vector.

The projection vector can only be removed if it is inactive (has not been applied to the data).

Index of the projector to remove. Can also be “all” (default) to remove all projectors.

Examples using del_proj:

Overview of artifact detection

Rejecting bad data spans and breaks

Repairing artifacts with SSP

Setting the EEG reference

Describe channels (name, type, descriptive statistics).

If True, return results in a pandas.DataFrame. If False, only print results. Columns ‘ch’, ‘type’, and ‘unit’ indicate channel index, channel type, and unit of the remaining five columns. These columns are ‘min’ (minimum), ‘Q1’ (first quartile or 25% percentile), ‘median’, ‘Q3’ (third quartile or 75% percentile), and ‘max’ (maximum).

If data_frame=False, returns None. If data_frame=True, returns results in a pandas.DataFrame (requires pandas).

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Examples using drop_channels:

Kernel OPM phantom data

The Raw data structure: continuous data

Duration of the data in seconds.

Export Raw to external formats.

BrainVision (.vhdr, .vmrk, .eeg, uses pybv)

EEGLAB (.set, uses eeglabio)

EDF (.edf, uses edfio)

Since we are exporting to external formats, there’s no guarantee that all the info will be preserved in the external format. See Notes for details.

Name of the output file.

Format of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.

The physical range of the data. If ‘auto’ (default), the physical range is inferred from the data, taking the minimum and maximum values per channel type. If ‘channelwise’, the range will be defined per channel. If a tuple of minimum and maximum, this manual physical range will be used. Only used for exporting EDF files.

Whether to incorporate the channel type into the signal label (e.g. whether to store channel “Fz” as “EEG Fz”). Only used for EDF format. Default is False.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.io.Raw.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.io.Raw.apply_proj().

For EEGLAB exports, channel locations are expanded to full EEGLAB format. For more details see eeglabio.utils.cart_to_eeglab().

Although this function supports storing channel types in the signal label (e.g. EEG Fz or MISC E), other software may not support this (optional) feature of the EDF standard.

If add_ch_type is True, then channel types are written based on what they are currently set in MNE-Python. One should double check that all their channels are set correctly. You can call mne.io.Raw.set_channel_types() to set channel types.

In addition, EDF does not support storing a montage. You will need to store the montage separately and call mne.io.Raw.set_montage().

The physical range of the signals is determined by signal type by default (physical_range="auto"). However, if individual channel ranges vary significantly due to the presence of e.g. drifts/offsets/biases, setting physical_range="channelwise" might be more appropriate. This will ensure a maximum resolution for each individual channel, but some tools might not be able to handle this appropriately (even though channel-wise ranges are covered by the EDF standard).

tuple of pathlib.Path | None

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Examples using filter:

Kernel OPM phantom data

Decoding source space data

Decoding sensor space data with generalization across time and conditions

Analysis of evoked response using ICA and PCA reduction techniques

XDAWN Decoding From EEG data

Compute effect-matched-spatial filtering (EMS)

Reduce EOG artifacts through regression

Compare the different ICA algorithms in MNE

Plot sensor denoising using oversampled temporal projection

Regression on continuous data (rER[P/F])

How to convert 3D electrode positions to a 2D image

Whitening evoked data with a noise covariance

Plot custom topographies for MEG sensors

Auto-generating Epochs metadata

EEG analysis - Event-Related Potentials (ERPs)

Modifying data in-place

Background information on filtering

Filtering and resampling data

Repairing artifacts with regression

Repairing artifacts with ICA

Spatiotemporal permutation F-test on full sensor data

The first data sample.

The first time point (including first_samp but not meas_date).

Fix Elekta magnetometer coil types.

The raw object. Operates in place.

This function changes magnetometer coil types 3022 (T1: SQ20483N) and 3023 (T2: SQ20483-A) to 3024 (T3: SQ20950N) in the channel definition records in the info structure.

Neuromag Vectorview systems can contain magnetometers with two different coil sizes (3022 and 3023 vs. 3024). The systems incorporating coils of type 3024 were introduced last and are used at the majority of MEG sites. At some sites with 3024 magnetometers, the data files have still defined the magnetometers to be of type 3022 to ensure compatibility with older versions of Neuromag software. In the MNE software as well as in the present version of Neuromag software coil type 3024 is fully supported. Therefore, it is now safe to upgrade the data files to use the true coil type.

The effect of the difference between the coil sizes on the current estimates computed by the MNE software is very small. Therefore the use of mne_fix_mag_coil_types is not mandatory.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Examples using get_channel_types:

The Info data structure

Get data in the given range.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The first sample to include. Defaults to 0.

End sample (first not to include). If None (default), the end of the data is used.

Whether to reject by annotation. If None (default), no rejection is done. If ‘omit’, segments annotated with description starting with ‘bad’ are omitted. If ‘NaN’, the bad samples are filled with NaNs.

Whether to return times as well. Defaults to False.

Specify the unit(s) that the data should be returned in. If None (default), the data is returned in the channel-type-specific default units, which are SI units (see Internal representation (units) and data channels). If a string, must be a sub-multiple of SI units that will be used to scale the data from all channels of the type associated with that unit. This only works if the data contains one channel type that has a unit (unitless channel types are left unchanged). For example if there are only EEG and STIM channels, units='uV' will scale EEG channels to micro-Volts while STIM channels will be unchanged. Finally, if a dictionary is provided, keys must be channel types, and values must be units to scale the data of that channel type to. For example dict(grad='fT/cm', mag='fT') will scale the corresponding types accordingly, but all other channel types will remain in their channel-type-specific default unit.

Start time of data to get in seconds. The tmin parameter is ignored if the start parameter is bigger than 0.

End time of data to get in seconds. The tmax parameter is ignored if the stop parameter is defined.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Copy of the data in the given range.

Times associated with the data samples. Only returned if return_times=True.

Examples using get_data:

Modifying data in-place

Rejecting bad data spans and breaks

Filtering and resampling data

The Raw data structure: continuous data

Make figures more publication ready

Get a DigMontage from instance.

A copy of the channel positions, if available, otherwise None.

Examples using get_montage:

How to convert 3D electrode positions to a 2D image

Interpolate bad MEG and EEG channels.

If True, remove the bads from info.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used for interpolation of channels using the minimum-norm method.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for each channel type.

"meg" channels support "MNE" (default) and "nan"

"eeg" channels support "spline" (default), "MNE" and "nan"

"fnirs" channels support "nearest" (default) and "nan"

"ecog" channels support "spline" (default) and "nan"

"seeg" channels support "spline" (default) and "nan"

None is an alias for:

If a str is provided, the method will be applied to all channel types supported and available in the instance. The method "nan" will replace the channel data with np.nan.

Be careful when using method="nan"; the default value reset_bads=True may not be what you want.

The channels to exclude from interpolation. If excluded a bad channel will stay in bads.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

The "MNE" method uses minimum-norm projection to a sphere and back.

Interpolate EEG data onto a new montage.

Be careful, only EEG channels are interpolated. Other channel types are not interpolated.

The target montage containing channel positions to interpolate onto.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for EEG channels. Supported methods are ‘spline’ (default) and ‘MNE’.

The regularization parameter for the interpolation method (only used when the method is ‘spline’).

The instance with updated channel locations and data.

This method is useful for standardizing EEG layouts across datasets. However, some attributes may be lost after interpolation.

The last data sample.

Mark channels as bad from a text file.

This function operates mostly in the style of the C function mne_mark_bad_channels. Each line in the text file will be interpreted as a name of a bad channel.

File name of the text file containing bad channels. If None (default), bad channels are cleared, but this is more easily done directly with raw.info['bads'] = [].

Whether or not to force bad channel marking (of those that exist) if channels are not found, instead of raising an error. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with data.

This function will load raw data if it was not already preloaded. If data were already preloaded, it will do nothing.

Examples using load_data:

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

How to convert 3D electrode positions to a 2D image

Overview of MEG/EEG analysis with MNE-Python

Repairing artifacts with regression

Repairing artifacts with SSP

Number of time points.

Notch filter a subset of channels.

Specific frequencies to filter out from data, e.g., np.arange(60, 241, 60) in the US or np.arange(50, 251, 50) in Europe. None can only be used with the mode 'spectrum_fit', where an F test is used to find sinusoidal components.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

When method=='spectrum_fit', this sets the effective window duration over which fits are computed. See mne.filter.create_filter() for options. Longer window lengths will give more stable frequency estimates, but require (potentially much) more processing and are not able to adapt as well to non-stationarities.

The default in 0.21 is None, but this will change to '10s' in 0.22.

Width of each stop band (centred at each freq in freqs) in Hz. If None, freqs / 200 is used.

Width of the transition band in Hz. Only used for method='fir' and method='iir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

The bandwidth of the multitaper windowing function in Hz. Only used in ‘spectrum_fit’ mode.

P-value to use in F-test thresholding to determine significant sinusoidal components to remove when method='spectrum_fit' and freqs=None. Note that this will be Bonferroni corrected for the number of frequencies, so large p-values may be justified.

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'. The default is 'reflect_limited'.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw instance with filtered data.

Applies a zero-phase notch filter to the channels selected by “picks”. By default the data of the Raw object is modified inplace.

The Raw object has to have the data loaded e.g. with preload=True or self.load_data().

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

For details, see mne.filter.notch_filter().

Examples using notch_filter:

Modifying data in-place

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=”bads” when picks=”meg”).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Kernel OPM phantom data

Compute effect-matched-spatial filtering (EMS)

Computing source timecourses with an XFit-like multi-dipole model

Transform EEG data using current source density (CSD)

Regression on continuous data (rER[P/F])

How to convert 3D electrode positions to a 2D image

Regression-based baseline correction

EEG analysis - Event-Related Potentials (ERPs)

Modifying data in-place

Getting started with mne.Report

EEG source localization given electrode locations on an MRI

Rejecting bad data spans and breaks

Repairing artifacts with regression

Repairing artifacts with ICA

Setting the EEG reference

Signal-space separation (SSS) and Maxwell filtering

The Raw data structure: continuous data

Make figures more publication ready

LEGACY: New code should use inst.pick(…).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(…).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‘auto’, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‘hbo’ (to include channels measuring oxyhemoglobin) or ‘hbr’ (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‘eyegaze’ (to include eye position channels) or ‘pupil’ (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‘bads’ (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Events to show with vertical bars.

Time window (s) to plot. The lesser of this value and the duration of the raw file will be used.

Initial time to show (can be changed dynamically once plotted). If show_first_samp is True, then it is taken relative to raw.first_samp.

Number of channels to plot at once. Defaults to 20. The lesser of n_channels and len(raw.ch_names) will be shown. Has no effect if order is ‘position’, ‘selection’ or ‘butterfly’.

Color of the background.

Color for the data traces. If None, defaults to:

Color to make bad channels.

Color(s) to use for events. To show all events in the same color, pass any matplotlib-compatible color. To color events differently, pass a dict that maps event names or integer event numbers to colors (must include entries for all events, or include a “fallback” entry with key -1). If None, colors are chosen from the current Matplotlib color cycle. Defaults to 'cyan'.

A regex pattern applied to each annotation’s label. Matching labels remain visible, non-matching labels are hidden.

Scaling factors for the traces. If a dictionary where any value is 'auto', the scaling factor is set to match the 99.5th percentile of the respective data. If 'auto', all scalings (for all channel types) are set to 'auto'. If any values are 'auto' and the data is not preloaded, a subset up to 100 MB will be loaded. If None, defaults to:

A particular scaling value s corresponds to half of the visualized signal range around zero (i.e. from 0 to +s or from 0 to -s). For example, the default scaling of 20e-6 (20µV) for EEG signals means that the visualized range will be 40 µV (20 µV in the positive direction and 20 µV in the negative direction).

If True remove DC component when plotting data.

Order in which to plot data. If the array is shorter than the number of channels, only the given channels are plotted. If None (default), all channels are plotted. If group_by is 'position' or 'selection', the order parameter is used only for selecting the channels to be plotted.

If True, a dialog for options related to projection is shown.

The title of the window. If None, and either the filename of the raw object or ‘<unknown>’ will be displayed as title.

Whether to halt program execution until the figure is closed. Useful for setting bad channels on the fly by clicking on a line. May not work on all systems / platforms. (Only Qt) If you run from a script, this needs to be True or a Qt-eventloop needs to be started somewhere else in the script (e.g. if you want to implement the browser inside another Qt-Application).

Highpass to apply when displaying data.

Lowpass to apply when displaying data. If highpass > lowpass, a bandstop rather than bandpass filter will be applied.

Filtering order. 0 will use FIR filtering with MNE defaults. Other values will construct an IIR filter of the given order and apply it with filtfilt() (making the effective order twice filtorder). Filtering may produce some edge artifacts (at the left and right edges) of the signals during display.

Changed in version 0.18: Support for filtorder=0 to use FIR filtering.

If None, channels are allowed to exceed their designated bounds in the plot. If “clamp”, then values are clamped to the appropriate range for display, creating step-like artifacts. If “transparent”, then excessive values are not shown, creating gaps in the traces. If float, clipping occurs for values beyond the clipping multiple of their dedicated range, so clipping=1. is an alias for clipping='transparent'.

Changed in version 0.21: Support for float, and default changed from None to 1.5.

If True, show time axis relative to the raw.first_samp.

Whether to apply projectors prior to plotting (default is True). Individual projectors can be enabled/disabled interactively (see Notes). This argument only affects the plot; use raw.apply_proj() to modify the data stored in the Raw object.

How to group channels. 'type' groups by channel type, 'original' plots in the order of ch_names, 'selection' uses Elekta’s channel groupings (only works for Neuromag data), 'position' groups the channels by the positions of the sensors. 'selection' and 'position' modes allow custom selections by using a lasso selector on the topomap. In butterfly mode, 'type' and 'original' group the channels by type, whereas 'selection' and 'position' use regional grouping. 'type' and 'original' modes are ignored when order is not None. Defaults to 'type'.

Whether to start in butterfly mode. Defaults to False.

Amount to decimate the data during display for speed purposes. You should only decimate if the data are sufficiently low-passed, otherwise aliasing can occur. The ‘auto’ mode (default) uses the decimation that results in a sampling rate least three times larger than min(info['lowpass'], lowpass) (e.g., a 40 Hz lowpass will result in at least a 120 Hz displayed sample rate).

Noise covariance used to whiten the data while plotting. Whitened data channels are scaled by scalings['whitened'], and their channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().

Event IDs used to show at event markers (default None shows the event numbers).

Whether to show scrollbars when the plot is initialized. Can be toggled after initialization by pressing z (“zen mode”) while the plot window is focused. Default is True.

Whether to show scale bars when the plot is initialized. Can be toggled after initialization by pressing s while the plot window is focused. Default is True.

Style of time labels on the horizontal axis. If 'float', labels will be number of seconds from the start of the recording. If 'clock', labels will show “clock time” (hours/minutes/seconds) inferred from raw.info['meas_date']. Default is 'float'.

Whether to load all data (not just the visible portion) into RAM and apply preprocessing (e.g., projectors) to the full data array in a separate processor thread, instead of window-by-window during scrolling. The default None uses the MNE_BROWSER_PRECOMPUTE variable, which defaults to 'auto'. 'auto' compares available RAM space to the expected size of the precomputed data, and precomputes only if enough RAM is available. This is only used with the Qt backend.

Changed in version 1.0: Support for the MNE_BROWSER_PRECOMPUTE config variable.

Whether to use OpenGL when rendering the plot (requires pyopengl). May increase performance, but effect is dependent on system CPU and graphics hardware. Only works if using the Qt backend. Default is None, which will use False unless the user configuration variable MNE_BROWSER_USE_OPENGL is set to 'true', see mne.set_config().

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Can be “auto”, “light”, or “dark” or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_BROWSER_THEME will be used, defaulting to “auto” if it’s not found. Only supported by the 'qt' backend.

Can be “channels”, “empty”, or “hidden” to set the overview bar mode for the 'qt' backend. If None (default), the config option MNE_BROWSER_OVERVIEW_MODE will be used, defaulting to “channels” if it’s not found.

If True (default), a splash screen is shown during the application startup. Only applicable to the qt backend.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The arrow keys (up/down/left/right) can typically be used to navigate between channels and time ranges, but this depends on the backend matplotlib is configured to use (e.g., mpl.use(‘TkAgg’) should work). The left/right arrows will scroll by 25% of duration, whereas shift+left/shift+right will scroll by 100% of duration. The scaling can be adjusted with - and + (or =) keys. The viewport dimensions can be adjusted with page up/page down and home/end keys. Full screen mode can be toggled with the F11 key, and scrollbars can be hidden/shown by pressing ‘z’. Right-click a channel label to view its location. To mark or un-mark a channel as bad, click on a channel label or a channel trace. The changes will be reflected immediately in the raw object’s raw.info['bads'] entry.

If projectors are present, a button labelled “Prj” in the lower right corner of the plot window opens a secondary control window, which allows enabling/disabling specific projectors individually. This provides a means of interactively observing how each projector would affect the raw data if it were applied.

Annotation mode is toggled by pressing ‘a’, butterfly mode by pressing ‘b’, and whitening mode (when noise_cov is not None) by pressing ‘w’. By default, the channel means are removed when remove_dc is set to True. This flag can be toggled by pressing ‘d’.

MNE-Python provides two different backends for browsing plots (i.e., raw.plot(), epochs.plot(), and ica.plot_sources()). One is based on matplotlib, and the other is based on PyQtGraph. You can set the backend temporarily with the context manager mne.viz.use_browser_backend(), you can set it for the duration of a Python session using mne.viz.set_browser_backend(), and you can set the default for your computer via mne.set_config('MNE_BROWSER_BACKEND', 'matplotlib') (or 'qt').

For the PyQtGraph backend to run in IPython with block=False you must run the magic command %gui qt5 first.

To report issues with the PyQtGraph backend, please use the issues of mne-qt-browser.

Transform EEG data using current source density (CSD)

Find MEG reference channel artifacts

Maxwell filter data with movement compensation

Plot sensor denoising using oversampled temporal projection

Auto-generating Epochs metadata

EEG analysis - Event-Related Potentials (ERPs)

Plotting whitened data

Overview of MEG/EEG analysis with MNE-Python

Modifying data in-place

Parsing events from raw data

Brainstorm Elekta phantom dataset tutorial

Importing Data from Eyetracking devices

Overview of artifact detection

Handling bad channels

Rejecting bad data spans and breaks

Filtering and resampling data

Repairing artifacts with regression

Background on projectors and projections

Repairing artifacts with SSP

Setting the EEG reference

Annotating continuous data

Built-in plotting methods for Raw objects

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None it will return all channel types present.. If a list of ch_types is provided, it will return multiple figures. Defaults to None.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches. Only applies when plotting multiple topomaps at a time.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all projectors of the same channel type (instead of separately for each projector), using the min/max of the data for that channel type. If vlim is "joint", info must not be None. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of projectors. Default is None.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Examples using plot_projs_topomap:

Built-in plotting methods for Raw objects

LEGACY: New code should use .compute_psd().plot().

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (╎) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (⋮). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Whether to omit bad spans of data before spectral estimation. If True, spans with annotations whose description begins with bad will be omitted.

Spectral estimation method. 'welch' uses Welch’s method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch’s method for continuous data and multitaper for Epochs or Evoked data.

If False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap.

Plot power spectral density (PSD) in units (dB/Hz) if dB=True and estimate='power'. Plot PSD in units (amplitude**2/Hz) if dB=False and estimate='power'. Plot amplitude spectral density (ASD) in units (amplitude/sqrt(Hz)) if dB=False and estimate='amplitude'. Plot ASD in units (dB/sqrt(Hz)) if dB=True and estimate='amplitude'.

Can be “power” for power spectral density (PSD; default), “amplitude” for amplitude spectrum density (ASD).

Scale of the frequency axis. Default is 'linear'.

Mode for plotting area. If ‘std’, the mean +/- 1 STD (across channels) will be plotted. If ‘range’, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Alpha for the PSD line. Can be None (default) to use 1.0 when average=True and 0.1 when average=False.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channels names to exclude from being shown. If ‘bads’, the bad channels are excluded. Pass an empty list to plot all channels (including channels marked “bad”, if any).

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of channel types present in the object.. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure with frequency spectra of the data channels.

This method exists to support legacy code; for new code the preferred idiom is inst.compute_psd().plot() (where inst is an instance of Raw, Epochs, or Evoked).

LEGACY: New code should use .compute_psd().plot_topo().

Plot power spectral density, separately for each channel.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=100.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch’s method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch’s method for continuous data and multitaper for Epochs or Evoked data.

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch(). Defaults to dict(n_fft=2048).

Figure distributing one image per channel across sensor topography.

LEGACY: New code should use .compute_psd().plot_topomap().

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch’s method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch’s method for continuous data and multitaper for Epochs or Evoked data.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‘%0.3f’ if dB=False and ‘%0.1f’ if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure showing one scalp topography per frequency band.

Plot sensor positions.

Whether to plot the sensors as 3d, topomap or as an interactive sensor selection dialog. Available options ‘topomap’, ‘3d’, ‘select’. If ‘select’, a set of channels can be selected interactively by using lasso selector or clicking while holding control key. The selected channels are returned along with the figure instance. Defaults to ‘topomap’.

The channel type to plot. Available options 'mag', 'grad', 'eeg', 'seeg', 'dbs', 'ecog', 'all'. If 'all', all the available mag, grad, eeg, seeg, dbs, and ecog channels are plotted. If None (default), then channels are chosen in the order given above.

Title for the figure. If None (default), equals to 'Sensor positions (%s)' % ch_type.

Whether to display all channel names. If an array, only the channel names in the array are shown. Defaults to False.

Channel groups for coloring the sensors. If None (default), default coloring scheme is used. If ‘position’, the sensors are divided into 8 regions. See order kwarg of mne.viz.plot_raw(). If array, the channels are divided by picks given in the array.

Whether to project the 3d locations to a sphere. When False, the sensor array appears similar as to looking downwards straight above the subject’s head. Has no effect when kind=’3d’. Defaults to True.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Whether to halt program execution until the figure is closed. Defaults to False.

Show figure if True. Defaults to True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the sensor topography.

A list of selected channels. Only returned if kind=='select'.

This function plots the sensor locations from the info structure using matplotlib. For drawing the sensors using PyVista see mne.viz.plot_alignment().

Examples using plot_sensors:

EEG analysis - Event-Related Potentials (ERPs)

Working with sensor locations

EEG source localization given electrode locations on an MRI

Built-in plotting methods for Raw objects

Whether or not projections are active.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

Examples using rename_channels:

Find MEG reference channel artifacts

EEG analysis - Event-Related Potentials (ERPs)

The Raw data structure: continuous data

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Resample all channels.

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

The intended purpose of this function is primarily to speed up computations (e.g., projection calculation) when precise timing of events is not required, as downsampling raw data effectively jitters trigger timings. It is generally recommended not to epoch downsampled data, but instead epoch and then downsample, as epoching downsampled data jitters triggers. For more, see this illustrative gist.

If resampling the continuous data is desired, it is recommended to construct events using the original data. The event onsets can be jointly resampled with the raw data using the ‘events’ parameter (a resampled copy is returned).

New sample rate to use.

Amount to pad the start and end of the data. Can also be "auto" to use a padding that will result in a power-of-two size (can be much faster).

Only used when method="fft".

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

Stim channels. These channels are simply subsampled or supersampled (without applying any filtering). This reduces resampling artifacts in stim channels, but may lead to missing triggers. If None, stim channels are automatically chosen using mne.pick_types().

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly.

An optional event matrix. When specified, the onsets of the events are resampled jointly with the data. NB: The input events are not modified, but a new array is returned with the raw instead.

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn(). The default (“auto”) means 'reflect_limited' for method='fft' and 'reflect' for method='polyphase'.

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled version of the raw object.

If events are jointly resampled, these are returned with the raw.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent – check your data!

For optimum performance and to make use of n_jobs > 1, the raw object has to have the data loaded e.g. with preload=True or self.load_data(), but this increases memory requirements. The resulting raw object will have the data loaded into memory.

Examples using resample:

Filtering and resampling data

MNE-Python assumes data are stored in SI base units. This function should typically only be used to fix an incorrect scaling factor in the data to get it to be in SI base units, otherwise unintended problems (e.g., incorrect source imaging results) and analysis errors can occur.

The scaling factor(s) by which to multiply the data. If a float, the same scaling factor is applied to all channels (this works only if all channels are of the same type). If a dict, the keys must be valid channel types and the values the scaling factors to apply to the corresponding channels.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with rescaled data (modified in-place).

A common use case for EEG data is to convert from µV to V, since many EEG systems store data in µV, but MNE-Python expects the data to be in V. Therefore, the data needs to be rescaled by a factor of 1e-6. To rescale all channels from µV to V, you can do:

Note that the previous example only works if all channels are of the same type. If there are multiple channel types, you can pass a dict with the individual scaling factors. For example, to rescale only EEG channels, you can do:

Save raw data to file.

File name of the new dataset. This has to be a new filename unless data have been preloaded. Filenames should end with raw.fif (common raw data), raw_sss.fif (Maxwell-filtered continuous data), raw_tsss.fif (temporally signal-space-separated data), _meg.fif (common MEG data), _eeg.fif (common EEG data), or _ieeg.fif (common intracranial EEG data). You may also append an additional .gz suffix to enable gzip compression.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Start time of the raw data to use in seconds (must be >= 0).

End time of the raw data to use in seconds (cannot exceed data duration). If None (default), the current end of the data is used.

Size of data chunks in seconds. If None (default), the buffer size of the original file is used.

Drop or not the last buffer. It is required by maxfilter (SSS) that only accepts raw files with buffers of the same size.

If True the data is saved with the projections applied (active).

If apply_proj() was used to apply the projections, the projectons will be active even if proj is False.

Format to use to save raw data. Valid options are ‘double’, ‘single’, ‘int’, and ‘short’ for 64- or 32-bit float, or 32- or 16-bit integers, respectively. It is strongly recommended to use ‘single’, as this is backward-compatible, and is standard for maintaining precision. Note that using ‘short’ or ‘int’ may result in loss of precision, complex data cannot be saved as ‘short’, and neither complex data types nor real data stored as ‘double’ can be loaded with the MNE command-line tools. See raw.orig_format to determine the format the original data were stored in.

If True (default False), overwrite the destination file if it exists. To overwrite original file (the same one that was loaded), data must be preloaded upon reading.

Large raw files are automatically split into multiple pieces. This parameter specifies the maximum size of each piece. If the parameter is an integer, it specifies the size in Bytes. It is also possible to pass a human-readable string, e.g., 100MB.

Due to FIFF file limitations, the maximum split size is 2GB.

When splitting files, append a filename partition with the appropriate naming schema. For 'neuromag', a split file fname.fif will be named fname.fif, fname-1.fif, fname-2.fif, and so on. For 'bids', a filename is expected to consist of parts separated by underscores, like <part-1>_<part-N>_<suffix>.fif, and the according split naming will return filenames like <part-1>_<part-N>_split-01_<suffix>.fif, <part-1>_<part-N>_split-02_<suffix>.fif, and so on.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of path-like objects containing the path to each file split.

If Raw is a concatenation of several raw files, be warned that only the measurement information from the first raw file is stored. This likely means that certain operations with external tools may not work properly on a saved concatenated file (e.g., probably some or all forms of SSS). It is recommended not to concatenate and then save raw files for this reason.

Samples annotated BAD_ACQ_SKIP are not stored in order to optimize memory. Whatever values, they will be loaded as 0s when reading file.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [3] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627–1639, 1964. doi:10.1021/ac60214a047.

Setter for annotations.

This setter checks if they are inside the data range.

Annotations to set. If None, the annotations is defined but empty.

Whether to emit warnings when cropping or omitting annotations. The default is True.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with annotations.

Examples using set_annotations:

Parsing events from raw data

Rejecting bad data spans and breaks

Annotating continuous data

Specify the sensor types of channels.

A dictionary mapping channel names to sensor types, e.g., {'EEG061': 'eog'}.

What to do if the measurement unit of a channel is changed automatically to match the new sensor type.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The following sensor types are accepted:

bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci, eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase, fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp, seeg, stim, syst, temperature.

When working with eye-tracking data, see mne.preprocessing.eyetracking.set_channel_types_eyetrack().

Examples using set_channel_types:

The Raw data structure: continuous data

Specify which reference to use for EEG data.

Use this function to explicitly specify the desired reference for EEG. This can be either an existing electrode or a new virtual channel. This function will re-reference the data according to the desired reference.

The name(s) of the channel(s) used to construct the reference for every channel of ch_type.

'average' to apply an average reference (default)

'REST' to use the Reference Electrode Standardization Technique infinity reference [4].

A dictionary mapping names of data channels to (lists of) names of reference channels. For example, {‘A1’: ‘A3’} would replace the data in channel ‘A1’ with the difference between ‘A1’ and ‘A3’. To take the average of multiple channels as reference, supply a list of channel names as the dictionary value, e.g. {‘A1’: [‘A2’, ‘A3’]} would replace channel A1 with A1 - mean(A2, A3).

An empty list, in which case MNE will not attempt any re-referencing of the data

If ref_channels='average' this argument specifies if the average reference should be computed as a projection (True) or not (False; default). If projection=True, the average reference is added as a projection and is not applied to the data (it can be applied afterwards with the apply_proj method). If projection=False, the average reference is directly applied to the data. If ref_channels is not 'average', projection must be set to False (the default in this case).

The name of the channel type to apply the reference to. Valid channel types are 'auto', 'eeg', 'ecog', 'seeg', 'dbs'. If 'auto', the first channel type of eeg, ecog, seeg or dbs that is found (in that order) will be selected.

Changed in version 1.2: list-of-str is now supported with projection=True.

Forward solution to use. Only used with ref_channels='REST'.

How to handle list-of-str ch_type. If False (default), one projector is created per channel type. If True, one projector is created across all channel types. This is only used when projection=True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data with EEG channels re-referenced. If ref_channels='average' and projection=True a projection will be added instead of directly re-referencing the data.

Convenience function for creating bipolar references.

Some common referencing schemes and the corresponding value for the ref_channels parameter:

A new virtual reference electrode is created by averaging the current EEG signal by setting ref_channels='average'. Bad EEG channels are automatically excluded if they are properly set in info['bads'].

Set ref_channels to a list containing the name of the channel that will act as the new reference, for example ref_channels=['Cz'].

A new virtual reference electrode is created by computing the average of the current EEG signal recorded from two or more selected channels. Set ref_channels to a list of channel names, indicating which channels to use. For example, to apply an average mastoid reference, when using the 10-20 naming scheme, set ref_channels=['M1', 'M2'].

The given EEG electrodes are referenced to a point at infinity using the lead fields in forward, which helps standardize the signals.

Set ref_channels to a dictionary mapping source channel names (str) to the reference channel names (str or list of str). Unlike the other approaches where the same reference is applied globally, you can set different references for different channels with this method. For example, to re-reference channel ‘A1’ to ‘A2’ and ‘B1’ to the average of ‘B2’ and ‘B3’, set ref_channels={'A1': 'A2', 'B1': ['B2', 'B3']}. Warnings are issued when a mapping involves bad channels or channels of different types.

If a reference is requested that is not the average reference, this function removes any pre-existing average reference projections.

During source localization, the EEG signal should have an average reference.

In order to apply a reference, the data must be preloaded. This is not necessary if ref_channels='average' and projection=True.

For an average or REST reference, bad EEG channels are automatically excluded if they are properly set in info['bads'].

D. Yao. A method to standardize a reference of scalp EEG recordings to a point at infinity. Physiological Measurement, 22(4):693–711, 2001. doi:10.1088/0967-3334/22/4/305.

Examples using set_eeg_reference:

Compute sLORETA inverse solution on raw data

Transform EEG data using current source density (CSD)

Generate simulated raw data

Computing a covariance matrix

EEG source localization given electrode locations on an MRI

Importing data from EEG devices

Repairing artifacts with regression

Setting the EEG reference

Corrupt known signal with point spread

Set the measurement start date.

The new measurement date. If datetime object, it must be timezone-aware and in UTC. A tuple of (seconds, microseconds) or float (alias for (meas_date, 0)) can also be passed and a datetime object will be automatically created. If None, will remove the time reference.

The modified raw instance. Operates in place.

If you want to remove all time references in the file, call mne.io.anonymize_info(inst.info) after calling inst.set_meas_date(None).

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

A montage containing channel positions. If a string or DigMontage is specified, the existing channel information will be updated with the channel positions from the montage. Valid strings are the names of the built-in montages that ship with MNE-Python; you can list those via mne.channels.get_builtin_montages(). If None (default), the channel positions will be removed from the Info.

If True (default), channel name matching will be case sensitive.

Whether to use a lookup table to match unrecognized channel location names to their known aliases. If True, uses the mapping in mne.io.constants.CHANNEL_LOC_ALIASES. If a dict is passed, it will be used instead, and should map from non-standard channel names to names in the specified montage. Default is False.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when channels have missing coordinates.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

Only EEG/sEEG/ECoG/DBS/fNIRS channels can have their positions set using a montage. Other channel types (e.g., MEG channels) should have their positions defined properly using their data reading functions.

Applying a montage will only set locations of channels that exist at the time it is applied. This means when re-referencing make sure to apply the montage only after calling mne.add_reference_channels()

Examples using set_montage:

Working with sensor locations

EEG source localization given electrode locations on an MRI

Importing data from EEG devices

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Time reference for times. If None, times are assumed to be relative to first_samp.

Indices relative to first_samp corresponding to the times supplied.

Examples using time_as_index:

Compute sLORETA inverse solution on raw data

The Raw data structure: continuous data

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, an additional column “time” is added, unless index is not None (in which case time values form the DataFrame’s index).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index, pandas.DatetimeIndex, or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) — i.e., converts EEG to µV, magnetometers to fT, and gradiometers to fT/cm.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

Starting sample index for creating the DataFrame from a temporal span of the Raw object. None (the default) uses the first sample.

Ending sample index for creating the DataFrame from a temporal span of the Raw object. None (the default) uses the last sample.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and channel. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. If 'datetime', time values will be converted to pandas.Timestamp values, relative to raw.info['meas_date'] and offset by raw.first_samp. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Examples using to_data_frame:

The Raw data structure: continuous data

Kernel OPM phantom data

Decoding source space data

Decoding sensor space data with generalization across time and conditions

Analysis of evoked response using ICA and PCA reduction techniques

XDAWN Decoding From EEG data

Compute effect-matched-spatial filtering (EMS)

Compute MNE-dSPM inverse solution on single epochs

Compute sLORETA inverse solution on raw data

Compute source level time-frequency timecourses using a DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Computing source timecourses with an XFit-like multi-dipole model

Getting averaging info from .fif files

Getting impedances from raw files

How to use data in neural ensemble (NEO) format

Cortical Signal Suppression (CSS) for removal of cortical signals

Define target events based on time lag, plot evoked response

Transform EEG data using current source density (CSD)

Show EOG artifact timing

Reduce EOG artifacts through regression

Automated epochs metadata generation with variable time windows

Find MEG reference channel artifacts

Compare the different ICA algorithms in MNE

Maxwell filter data with movement compensation

Plot sensor denoising using oversampled temporal projection

Generate simulated evoked data

Generate simulated raw data

Permutation F-test on sensor data with 1D cluster level

FDR correction on T-test on sensor data

Regression on continuous data (rER[P/F])

Permutation T-test on sensor data

Compute a cross-spectral density (CSD) matrix

Compute Power Spectral Density of inverse solution from single epochs

Compute power and phase lock in label of the source space

Compute source power spectral density (PSD) in a label

Compute induced power in the source space with dSPM

Temporal whitening with AR model

How to convert 3D electrode positions to a 2D image

Visualize channel over epochs as an image

Plotting EEG sensors on the scalp

Whitening evoked data with a noise covariance

Compare evoked responses for different conditions

Plot custom topographies for MEG sensors

Working with sEEG data

Regression-based baseline correction

Visualizing epoched data

Auto-generating Epochs metadata

Divide continuous data into equally-spaced epochs

The Evoked data structure: evoked/averaged data

EEG analysis - Event-Related Potentials (ERPs)

Plotting whitened data

Source alignment and coordinate frames

Computing a covariance matrix

Overview of MEG/EEG analysis with MNE-Python

Modifying data in-place

Parsing events from raw data

The Info data structure

Working with sensor locations

Getting started with mne.Report

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

Importing data from EEG devices

Working with CTF data: the Brainstorm auditory dataset

Overview of artifact detection

Handling bad channels

Rejecting bad data spans and breaks

Filtering and resampling data

Repairing artifacts with regression

Repairing artifacts with ICA

Background on projectors and projections

Repairing artifacts with SSP

Setting the EEG reference

Extracting and visualizing subject head movement

Signal-space separation (SSS) and Maxwell filtering

The Raw data structure: continuous data

Annotating continuous data

Built-in plotting methods for Raw objects

Creating MNE-Python data structures from scratch

Corrupt known signal with point spread

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency and time-frequency sensor analysis

Make figures more publication ready

---

## mne.io.read_fiducials#

**URL:** https://mne.tools/stable/generated/mne.io.read_fiducials.html

**Contents:**
- mne.io.read_fiducials#

Read fiducials from a fiff file.

The filename to read.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of digitizer points (each point in a dict).

The coordinate frame of the points (one of mne.io.constants.FIFF.FIFFV_COORD_...).

mne.coreg.estimate_head_mri_t

mne.io.write_fiducials

---

## mne.io.read_info#

**URL:** https://mne.tools/stable/generated/mne.io.read_info.html

**Contents:**
- mne.io.read_info#
- Examples using mne.io.read_info#

Read measurement info from a file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The mne.Info object with information about the sensors and methods of measurement.

Use source space morphing

Reading/Writing a noise covariance matrix

Compare simulated and estimated source activity

Generate simulated evoked data

Simulate raw data using subject anatomy

Generate simulated source data

Using an automated approach to coregistration

Head model and forward computation

How MNE uses FreeSurfer’s outputs

The Info data structure

---

## mne.io.read_raw#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw.html

**Contents:**
- mne.io.read_raw#
- Examples using mne.io.read_raw#

This function is a convenient wrapper for readers defined in mne.io. The correct reader is automatically selected based on the detected file format. All function arguments are passed to the respective reader.

The following readers are currently supported:

Name of the file to read.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to the underlying reader. For details, see the arguments of the reader for the respective file format.

Using contralateral referencing for EEG

Identify EEG Electrodes Bridged by too much Gel

Automated epochs metadata generation with variable time windows

Working with sEEG data

Auto-generating Epochs metadata

Getting started with mne.Report

DICS for power mapping

mne.io.anonymize_info

---

## mne.io.read_raw_ant#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_ant.html

**Contents:**
- mne.io.read_raw_ant#
- Examples using mne.io.read_raw_ant#

Reader for Raw ANT files in .cnt format.

Path to the ANT raw file to load. The file should have the extension .cnt.

Regex pattern to find EOG channel labels. If None, no EOG channels are automatically detected.

Regex pattern to find miscellaneous channels. If None, no miscellaneous channels are automatically detected. The default pattern "BIP\d+" will mark all bipolar channels as misc.

A bipolar channel might actually contain ECG, EOG or other signal types which might have a dedicated channel type in MNE-Python. In this case, use mne.io.Raw.set_channel_types() to change the channel type of the channel.

The list of channels to treat as bipolar EEG channels. Each element should be a string of the form 'anode-cathode' or in ANT terminology as 'label- reference'. If None, all channels are interpreted as 'eeg' channels referenced to the same reference electrode. Bipolar channels are treated as EEG channels with a special coil type in MNE-Python, see also mne.set_bipolar_reference()

Do not provide auxiliary channels in this argument, provide them in the eog and misc arguments.

The string to use for impedance annotations. Defaults to "impedance", however, the impedance measurement might mark the end of a segment and the beginning of a new segment, in which case a discontinuity similar to what mne.concatenate_raws() produces is present. In this case, it’s better to include a BAD_xxx annotation to mark the discontinuity.

Note that the impedance annotation will likely have a duration of 0. If the measurement marks a discontinuity, the duration should be modified to cover the discontinuity in its entirety.

Encoding to use for str in the CNT file. Defaults to 'latin-1'.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing ANT data. See mne.io.Raw for documentation of attributes and methods.

Getting impedances from raw files

mne.io.read_raw_artemis123

---

## mne.io.read_raw_artemis123#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_artemis123.html

**Contents:**
- mne.io.read_raw_artemis123#
- Examples using mne.io.read_raw_artemis123#

Read Artemis123 data as raw object.

Path to the data file (extension .bin). The header file with the same file name stem and an extension .txt is expected to be found in the same directory.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

If not None, load digitized head points from this file.

If True attempt to perform initial head localization. Compute initial device to head coordinate transform using HPI coils. If no HPI coils are in info[‘dig’] hpi coils are assumed to be in canonical order of fiducial points (nas, rpa, lpa).

A Raw object containing the data.

Documentation of attributes and methods.

Plotting sensor layouts of MEG systems

---

## mne.io.read_raw_bdf#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_bdf.html

**Contents:**
- mne.io.read_raw_bdf#
- Examples using mne.io.read_raw_bdf#

Reader function for BDF files.

Path to the BDF file of BDF file itself. If a file-like object is provided, preload must be used.

Changed in version 1.10: Added support for file-like objects

Names of channels or list of indices that should be designated EOG channels. Values should correspond to the electrodes in the file. Default is None.

Names of channels or list of indices that should be designated MISC channels. Values should correspond to the electrodes in the file. Default is None.

Defaults to 'auto', which means that channels named 'status' or 'trigger' (case insensitive) are set to STIM. If str (or list of str), all channels matching the name(s) are set to STIM. If int (or list of ints), channels corresponding to the indices are set to STIM.

Channel names to exclude. This can help when reading data with different sampling rates to avoid unnecessary resampling. A str is interpreted as a regular expression.

If True, try to infer channel types from channel labels. If a channel label starts with a known type (such as ‘EEG’) followed by a space and a name (such as ‘Fp1’), the channel type will be set accordingly, and the channel will be renamed to the original label without the prefix. For unknown prefixes, the type will be ‘EEG’ and the name will not be modified. If False, do not infer types and assume all channels are of type ‘EEG’.

Channel names to be included. A str is interpreted as a regular expression. ‘exclude’ must be empty if include is assigned.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

The units of the channels as stored in the file. This argument is useful only if the units are missing from the original file. If a dict, it must map a channel name to its unit, and if str it is assumed that all channels have the same units.

Encoding of annotations channel(s). Default is “utf8” (the only correct encoding according to the EDF+ standard).

If True, exclude channels are searched for after they have been made unique. This is useful to choose channels that have been made unique by adding a suffix. If False, the original names are checked.

Changed in version 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw instance. See mne.io.Raw for documentation of attributes and methods.

Reader function for EDF and EDF+ files.

Reader function for GDF files.

Documentation of attributes and methods of RawEDF.

mne.io.Raw only stores signals with matching sampling frequencies. Therefore, if mixed sampling frequency signals are requested, all signals are upsampled to the highest loaded sampling frequency. In this case, using preload=True is recommended, as otherwise, edge artifacts appear when slices of the signal are requested.

Biosemi devices trigger codes are encoded in 16-bit format, whereas system codes (CMS in/out-of range, battery low, etc.) are coded in bits 16-23 of the status channel (see http://www.biosemi.com/faq/trigger_signals.htm). To retrieve correct event values (bits 1-16), one could do:

The above operation can be carried out directly in mne.find_events() using the mask and mask_type parameters (see mne.find_events() for more details).

It is also possible to retrieve system codes, but no particular effort has been made to decode these in MNE. In case it is necessary, for instance to check the CMS bit, the following operation can be carried out:

It is worth noting that in some special cases, it may be necessary to shift event values in order to retrieve correct event triggers. This depends on the triggering device used to perform the synchronization. For instance, in some files events need to be shifted by 8 bits:

TAL channels called ‘BDF Annotations’ are parsed and extracted annotations are stored in raw.annotations. Use mne.events_from_annotations() to obtain events from these annotations.

If channels named ‘status’ or ‘trigger’ are present, they are considered as STIM channels by default. Use func:mne.find_events to parse events encoded in such analog stim channels.

Importing data from EEG devices

mne.io.read_raw_artemis123

---

## mne.io.read_raw_boxy#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_boxy.html

**Contents:**
- mne.io.read_raw_boxy#

Reader for an optical imaging recording.

This function has been tested using the ISS Imagent I and II systems and versions 0.40/0.84 of the BOXY recording software.

Path to the BOXY data file.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing BOXY data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawBOXY.

mne.io.read_raw_brainvision

---

## mne.io.read_raw_brainvision#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_brainvision.html

**Contents:**
- mne.io.read_raw_brainvision#
- Examples using mne.io.read_raw_brainvision#

Reader for Brain Vision EEG file.

Path to the EEG header file.

Names of channels or list of indices that should be designated EOG channels. Values should correspond to the header file Default is ('HEOGL', 'HEOGR', 'VEOGb').

Names of channels or list of indices that should be designated MISC channels. Values should correspond to the electrodes in the header file. If 'auto', units in header file are used for inferring misc channels. Default is 'auto'.

The scaling factor for EEG data. Unless specified otherwise by header file, units are in microvolts. Default scale factor is 1.

If True, ignore marker types and only use marker descriptions. Default is False.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing BrainVision data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawBrainVision.

If the BrainVision header file contains impedance measurements, these may be accessed using raw.impedances after reading using this function. However, this attribute will NOT be available after a save and re-load of the data. That is, it is only available when reading data directly from the BrainVision header file.

BrainVision markers consist of a type and a description (in addition to other fields like onset and duration). In contrast, annotations in MNE only have a description. Therefore, a BrainVision marker of type “Stimulus” and description “S 1” will be converted to an annotation “Stimulus/S 1” by default. If you want to ignore the type and instead only use the description, set ignore_marker_types=True, which will convert the same marker to an annotation “S 1”.

The first marker in a BrainVision file is usually a “New Segment” marker, which contains the recording time. This time is stored in the info['meas_date'] attribute of the returned object and is not converted to an annotation.

Working with sensor locations

Importing data from EEG devices

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

---

## mne.io.read_raw_bti#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_bti.html

**Contents:**
- mne.io.read_raw_bti#
- Examples using mne.io.read_raw_bti#

Raw object from 4D Neuroimaging MagnesWH3600 data.

Currently direct inclusion of reference channel weights is not supported. Please use mne_create_comp_data to include the weights or use the low level functions from this module to include them by yourself.

The informed guess for the 4D name is E31 for the ECG channel and E63, E63 for the EOG channels. Please check and adjust if those channels are present in your dataset but ‘ECG 01’ and ‘EOG 01’, ‘EOG 02’ don’t appear in the channel names of the raw object.

Path to the processed data file (PDF).

Path to system config file.

Path to the head shape file.

Degrees to tilt x-axis for sensor frame misalignment. Ignored if convert is True.

The translation to place the origin of coordinate system to the center of the head. Ignored if convert is True.

Convert to Neuromag coordinates or not.

Whether to keep original 4D channel labels or not. Defaults to True.

Reorder channels according to channel label. 4D channels don’t have monotonically increasing numbers in their labels. Defaults to True.

The 4D name of the ECG channel. If None, the channel will be treated as regular EEG channel.

The 4D names of the EOG channels. If None, the channels will be treated as regular EEG channels.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing BTI data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawBTi.

Plotting sensor layouts of MEG systems

4D Neuroimaging/BTi phantom dataset tutorial

mne.io.read_raw_brainvision

---

## mne.io.read_raw_cnt#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_cnt.html

**Contents:**
- mne.io.read_raw_cnt#
- Examples using mne.io.read_raw_cnt#

Read CNT data as raw object.

2d spatial coordinates (x, y) for EEG channels are read from the file header and fit to a sphere to compute corresponding z-coordinates. If channels assigned as EEG channels have locations far away from the head (i.e. x and y coordinates don’t fit to a sphere), all the channel locations will be distorted (all channels that are not assigned with keywords eog, ecg, emg and misc are assigned as EEG channels). If you are not sure that the channel locations in the header are correct, it is probably safer to replace them with mne.io.Raw.set_montage(). Montages can be created/imported with:

Standard montages with mne.channels.make_standard_montage()

Montages for Compumedics systems with mne.channels.read_dig_curry()

Other reader functions are listed under See Also at mne.channels.DigMontage

Path to the data file.

Names of channels or list of indices that should be designated EOG channels. If ‘header’, VEOG and HEOG channels assigned in the file header are used. If 'auto', channel names containing 'EOG' are used. Defaults to empty tuple.

Names of channels or list of indices that should be designated MISC channels. Defaults to empty tuple.

Names of channels or list of indices that should be designated ECG channels. If 'auto', the channel names containing 'ECG' are used. Defaults to empty tuple.

Names of channels or list of indices that should be designated EMG channels. If ‘auto’, the channel names containing ‘EMG’ are used. Defaults to empty tuple.

Defines the data format the data is read in. If 'auto', it is determined from the file header using numsamples field. Defaults to 'auto'.

Format of date in the header. Defaults to 'mm/dd/yy'.

Defines the header format. Used to describe how bad channels are formatted. If auto, reads using old and new header and if either contain a bad channel make channel bad. Defaults to 'auto'.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawCNT.

Importing data from EEG devices

---

## mne.io.read_raw_ctf#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_ctf.html

**Contents:**
- mne.io.read_raw_ctf#
- Examples using mne.io.read_raw_ctf#

Raw object from CTF directory.

Path to the CTF data (ending in '.ds').

How to treat the system clock. Use “truncate” (default) to truncate the data file when the system clock drops to zero, and use “ignore” to ignore the system clock (e.g., if head positions are measured multiple times during a recording).

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

If True main channel names and compensation channel names will be cleaned from CTF suffixes. The default is False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

To read in the Polhemus digitization data (for example, from a .pos file), include the file in the CTF directory. The points will then automatically be read into the mne.io.Raw instance via mne.io.read_raw_ctf.

Brainstorm raw (median nerve) dataset

From raw data to dSPM on SPM Faces dataset

Continuous Target Decoding with SPoC

Compute spatial filters with Spatio-Spectral Decomposition (SSD)

Annotate movement artifacts and reestimate dev_head_t

Annotate muscle artifacts

Plotting topographic arrowmaps of evoked data

Plotting sensor layouts of MEG systems

Brainstorm CTF phantom dataset tutorial

Working with CTF data: the Brainstorm auditory dataset

mne.io.read_raw_curry

---

## mne.io.read_raw_curry#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_curry.html

**Contents:**
- mne.io.read_raw_curry#

Read raw data from Curry files.

Changed in version 1.11: This function now requires curryreader to be installed.

Path to a valid curry file.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Can be 'raise' to raise an error, 'warn' (default) to emit a warning, or 'ignore' to ignore when there is poor matching of HPI coordinates (>10mm difference) for device - head transform.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing Curry data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawCurry.

---

## mne.io.read_raw_edf#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_edf.html

**Contents:**
- mne.io.read_raw_edf#
- Examples using mne.io.read_raw_edf#

Reader function for EDF and EDF+ files.

Path to the EDF or EDF+ file or EDF/EDF+ file itself. If a file-like object is provided, preload must be used.

Changed in version 1.10: Added support for file-like objects

Names of channels or list of indices that should be designated EOG channels. Values should correspond to the electrodes in the file. Default is None.

Names of channels or list of indices that should be designated MISC channels. Values should correspond to the electrodes in the file. Default is None.

Defaults to 'auto', which means that channels named 'status' or 'trigger' (case insensitive) are set to STIM. If str (or list of str), all channels matching the name(s) are set to STIM. If int (or list of ints), channels corresponding to the indices are set to STIM.

Channel names to exclude. This can help when reading data with different sampling rates to avoid unnecessary resampling. A str is interpreted as a regular expression.

If True, try to infer channel types from channel labels. If a channel label starts with a known type (such as ‘EEG’) followed by a space and a name (such as ‘Fp1’), the channel type will be set accordingly, and the channel will be renamed to the original label without the prefix. For unknown prefixes, the type will be ‘EEG’ and the name will not be modified. If False, do not infer types and assume all channels are of type ‘EEG’.

Channel names to be included. A str is interpreted as a regular expression. ‘exclude’ must be empty if include is assigned.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

The units of the channels as stored in the file. This argument is useful only if the units are missing from the original file. If a dict, it must map a channel name to its unit, and if str it is assumed that all channels have the same units.

Encoding of annotations channel(s). Default is “utf8” (the only correct encoding according to the EDF+ standard).

If True, exclude channels are searched for after they have been made unique. This is useful to choose channels that have been made unique by adding a suffix. If False, the original names are checked.

Changed in version 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw instance. See mne.io.Raw for documentation of attributes and methods.

Reader function for BDF files.

Reader function for GDF files.

Export function for EDF files.

Documentation of attributes and methods of RawEDF.

mne.io.Raw only stores signals with matching sampling frequencies. Therefore, if mixed sampling frequency signals are requested, all signals are upsampled to the highest loaded sampling frequency. In this case, using preload=True is recommended, as otherwise, edge artifacts appear when slices of the signal are requested.

It is worth noting that in some special cases, it may be necessary to shift event values in order to retrieve correct event triggers. This depends on the triggering device used to perform the synchronization. For instance, in some files events need to be shifted by 8 bits:

TAL channels called ‘EDF Annotations’ are parsed and extracted annotations are stored in raw.annotations. Use mne.events_from_annotations() to obtain events from these annotations.

If channels named ‘status’ or ‘trigger’ are present, they are considered as STIM channels by default. Use func:mne.find_events to parse events encoded in such analog stim channels.

The EDF specification allows optional storage of channel types in the prefix of the signal label for each channel. For example, EEG Fz implies that Fz is an EEG channel and MISC E would imply E is a MISC channel. However, there is no standard way of specifying all channel types. MNE-Python will try to infer the channel type, when such a string exists, defaulting to EEG, when there is no prefix or the prefix is not recognized.

The following prefix strings are mapped to MNE internal types:

The EDF specification allows storage of subseconds in measurement date. However, this reader currently sets subseconds to 0 by default.

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Removing muscle ICA components

Compute and visualize ERDS maps

Sleep stage classification from polysomnography (PSG) data

EEG forward operator with a template MRI

Importing data from EEG devices

Repairing artifacts with ICA

mne.io.read_raw_curry

mne.io.read_raw_eeglab

---

## mne.io.read_raw_eeglab#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_eeglab.html

**Contents:**
- mne.io.read_raw_eeglab#
- Examples using mne.io.read_raw_eeglab#

Read an EEGLAB .set file.

Path to the .set file. If the data is stored in a separate .fdt file, it is expected to be in the same folder as the .set file.

Names or indices of channels that should be designated EOG channels. If ‘auto’, the channel names containing EOG or EYE are used. Defaults to empty tuple.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

If your set file contains non-ascii characters, sometimes reading it may fail and give rise to error message stating that “buffer is too small”. uint16_codec allows to specify what codec (for example: ‘latin1’ or ‘utf-8’) should be used when reading character arrays and can therefore help you solve this problem.

Units that channel positions are represented in. Defaults to “mm” (millimeters), but can be any prefix + “m” combination (including just “m” for meters).

Changed in version 1.6: Support for 'auto' was added and is the new default.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing EEGLAB .set data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawEEGLAB.

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Plot single trial activity, grouped by ROI and sorted by RT

Parsing events from raw data

---

## mne.io.read_raw_egi#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_egi.html

**Contents:**
- mne.io.read_raw_egi#
- Examples using mne.io.read_raw_egi#

Read EGI simple binary as raw object.

Path to the raw file. Files with an extension .mff are automatically considered to be EGI’s native MFF format files.

Names of channels or list of indices that should be designated EOG channels. Default is None.

Names of channels or list of indices that should be designated MISC channels. Default is None.

The event channels to be included when creating the synthetic trigger or annotations. Defaults to None. Note. Overrides exclude parameter.

The event channels to be ignored when creating the synthetic trigger or annotations. Defaults to None. If None, the sync and TREV channels will be ignored. This is ignored when include is not None.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Channel naming convention for the data channels. Defaults to 'E%d' (resulting in channel names 'E1', 'E2', 'E3'…). The effective default prior to 0.14.0 was 'EEG %03d'.

If True, annotations are created from experiment events. If False (default), a synthetic trigger channel STI 014 is created from experiment events. See the Notes section for details. The default will change from False to True in version 1.9.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing EGI data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawEGI.

When events_from_annotations=True, event codes on stimulus channels like DIN1 are stored as annotations with the description set to the stimulus channel name.

When events_from_annotations=False and events are present on the included stimulus channels, a new stim channel STI014 will be synthesized from the events. It will contain 1-sample pulses where the Netstation file had event timestamps. A raw.event_id dictionary is added to the raw object that will have arbitrary sequential integer IDs for the events. This will fail if any timestamps are duplicated. The event_id will also not survive a save/load roundtrip.

For these reasons, it is recommended to use events_as_annotations=True.

Working with eye tracker data in MNE-Python

mne.io.read_raw_eeglab

mne.io.read_raw_eximia

---

## mne.io.read_raw_eximia#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_eximia.html

**Contents:**
- mne.io.read_raw_eximia#

Reader for an eXimia EEG file.

Path to the eXimia .nxe data file.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing eXimia data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawEximia.

mne.io.read_raw_eyelink

---

## mne.io.read_raw_eyelink#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_eyelink.html

**Contents:**
- mne.io.read_raw_eyelink#
- Examples using mne.io.read_raw_eyelink#

Reader for an Eyelink .asc file.

Path to the eyelink file (.asc).

Whether to create Annotations from occular events (blinks, fixations, saccades) and experiment messages. If a list, must contain one or more of ['fixations', 'saccades',' blinks', messages']. If True, creates Annotations for both occular events and experiment messages.

Adjusts the onset time of the Annotations created from Eyelink experiment messages, if offset values exist in the ASCII file. If False, any offset-like values will be prepended to the annotation description.

Combine left and right eye mne.Annotations (blinks, fixations, saccades) if their start times and their stop times are both not separated by more than overlap_threshold.

Time in seconds. Threshold of allowable time-gap between both the start and stop times of the left and right eyes. If the gap is larger than the threshold, the mne.Annotations will be kept separate (i.e. "blink_L", "blink_R"). If the gap is smaller than the threshold, the mne.Annotations will be merged and labeled as "blink_both". Defaults to 0.05 seconds (50 ms), meaning that if the blink start times of the left and right eyes are separated by less than 50 ms, and the blink stop times of the left and right eyes are separated by less than 50 ms, then the blink will be merged into a single mne.Annotations.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing eyetracker data.

Documentation of attribute and methods.

It is common for SR Research Eyelink eye trackers to only record data during trials. To avoid frequent data discontinuities and to ensure that the data is continuous so that it can be aligned with EEG and MEG data (if applicable), this reader will preserve the times between recording trials and annotate them with 'BAD_ACQ_SKIP'.

Plotting eye-tracking heatmaps in MNE-Python

Importing Data from Eyetracking devices

Working with eye tracker data in MNE-Python

mne.io.read_raw_eximia

mne.io.read_raw_fieldtrip

---

## mne.io.read_raw_fieldtrip#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_fieldtrip.html

**Contents:**
- mne.io.read_raw_fieldtrip#

Load continuous (raw) data from a FieldTrip preprocessing structure.

This function expects to find single trial raw data (FT_DATATYPE_RAW) in the structure data_name is pointing at.

FieldTrip does not normally store the original information concerning channel location, orientation, type etc. It is therefore highly recommended to provide the info field. This can be obtained by reading the original raw data file with MNE functions (without preload). The returned object contains the necessary info field.

Path and filename of the .mat file containing the data.

The info dict of the raw data file corresponding to the data to import. If this is set to None, limited information is extracted from the FieldTrip structure.

Name of heading dict/variable name under which the data was originally saved in MATLAB.

A Raw Object containing the loaded data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawArray.

mne.io.read_raw_eyelink

---

## mne.io.read_raw_fif#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_fif.html

**Contents:**
- mne.io.read_raw_fif#
- Examples using mne.io.read_raw_fif#

Reader function for Raw FIF data.

The raw filename to load. For files that have automatically been split, the split part will be automatically loaded. Filenames should end with raw.fif, raw.fif.gz, raw_sss.fif, raw_sss.fif.gz, raw_tsss.fif, raw_tsss.fif.gz, or _meg.fif. If a file-like object is provided, preloading must be used.

Changed in version 0.18: Support for file-like objects.

If True, allow loading of data that has been recorded with internal active compensation (MaxShield). Data recorded with MaxShield should generally not be loaded directly, but should first be processed using SSS/tSSS to remove the compensation signals that may also affect brain activity. Can also be “yes” to load without eliciting a warning.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when split file is missing.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing FIF data.

When reading a FIF file, note that the first N seconds annotated BAD_ACQ_SKIP are skipped. They are removed from raw.times and raw.n_times parameters but raw.first_samp and raw.first_time are updated accordingly.

How to convert 3D electrode positions to a 2D image

Overview of MEG/EEG analysis with MNE-Python

Importing data from MEG devices

Background on projectors and projections

Built-in plotting methods for Raw objects

mne.io.read_raw_fieldtrip

---

## mne.io.read_raw_fil#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_fil.html

**Contents:**
- mne.io.read_raw_fil#
- Examples using mne.io.read_raw_fil#

Raw object from FIL-OPMEG formatted data.

Path to the MEG data binary (ending in '_meg.bin').

How is the data represented? 'single' if 32-bit or 'double' if 64-bit (default is single).

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawFIL.

Preprocessing optically pumped magnetometer (OPM) MEG data

---

## mne.io.read_raw_gdf#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_gdf.html

**Contents:**
- mne.io.read_raw_gdf#
- Examples using mne.io.read_raw_gdf#

Reader function for GDF files.

Path to the GDF file or GDF file itself. If a file-like object is provided, preload must be used.

Changed in version 1.10: Added support for file-like objects

Names of channels or list of indices that should be designated EOG channels. Values should correspond to the electrodes in the file. Default is None.

Names of channels or list of indices that should be designated MISC channels. Values should correspond to the electrodes in the file. Default is None.

Defaults to 'auto', which means that channels named 'status' or 'trigger' (case insensitive) are set to STIM. If str (or list of str), all channels matching the name(s) are set to STIM. If int (or list of ints), channels corresponding to the indices are set to STIM.

Channel names to exclude. This can help when reading data with different sampling rates to avoid unnecessary resampling. A str is interpreted as a regular expression.

Channel names to be included. A str is interpreted as a regular expression. ‘exclude’ must be empty if include is assigned.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw instance. See mne.io.Raw for documentation of attributes and methods.

Reader function for EDF and EDF+ files.

Reader function for BDF files.

Documentation of attributes and methods of RawGDF.

If channels named ‘status’ or ‘trigger’ are present, they are considered as STIM channels by default. Use func:mne.find_events to parse events encoded in such analog stim channels.

Importing data from EEG devices

mne.io.read_raw_hitachi

---

## mne.io.read_raw_hitachi#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_hitachi.html

**Contents:**
- mne.io.read_raw_hitachi#

Reader for a Hitachi fNIRS recording.

Path(s) to the Hitachi CSV file(s). This should only be a list for multiple probes that were acquired simultaneously.

Changed in version 1.2: Added support for list-of-str.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing Hitachi data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawHitachi.

Hitachi does not encode their channel positions, so you will need to create a suitable mapping using mne.channels.make_standard_montage() or mne.channels.make_dig_montage() like (for a 3x5/ETG-7000 example):

The 3x3 (ETG-100) is laid out as two separate layouts:

The 3x5 (ETG-7000) is laid out as:

The 4x4 (ETG-7000) is laid out as:

The 3x11 (ETG-4000) is laid out as:

For each layout, the channels come from the (left-to-right) neighboring source-detector pairs in the first row, then between the first and second row, then the second row, etc.

---

## mne.io.read_raw_kit#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_kit.html

**Contents:**
- mne.io.read_raw_kit#
- Examples using mne.io.read_raw_kit#

Reader function for Ricoh/KIT conversion to FIF.

Path to the SQD file.

Marker points representing the location of the marker coils with respect to the MEG sensors, or path to a marker file. If list, all of the markers will be averaged together.

Digitizer points representing the location of the fiducials and the marker coils with respect to the digitized head shape, or path to a file containing these points.

Digitizer head shape points, or path to head shape file. If more than 10,000 points are in the head shape, they are automatically decimated.

Channel-value correspondence when converting KIT trigger channels to a Neuromag-style stim channel. For '<', the largest values are assigned to the first channel (default). For '>', the largest values are assigned to the last channel. Can also be specified as a list of trigger channel indexes. If None, no synthesized channel is generated.

How to interpret values on KIT trigger channels when synthesizing a Neuromag-style stim channel. With '+', a positive slope (low-to-high) is interpreted as an event. With '-', a negative slope (high-to-low) is interpreted as an event.

The threshold level for accepting voltage changes in KIT trigger channels as a trigger event. If None, stim must also be set to None.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

How to decode trigger values from stim channels. 'binary' read stim channel events as binary code, ‘channel’ encodes channel number.

Force reading old data that is not officially supported. Alternatively, read and re-save the data with the KIT MEG Laboratory application.

If True, standardize MEG and EEG channel names to be 'MEG ###' and 'EEG ###'. If False (default), native channel names in the file will be used when possible.

Indices of (up to two) bad marker coils to be removed. These marker coils must be present in the elp and mrk files.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing KIT data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawKIT.

elp and hsp are usually the exported text files (*.txt) from the Polhemus FastScan system. hsp refers to the headshape surface points. elp refers to the points in head-space that corresponds to the HPI points.

If mrk, hsp or elp are array_like inputs, then the numbers in xyz coordinates should be in units of meters.

Plotting sensor layouts of MEG systems

Configuring MNE-Python

mne.io.read_raw_hitachi

---

## mne.io.read_raw_nedf#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_nedf.html

**Contents:**
- mne.io.read_raw_nedf#

Read NeuroElectrics .nedf files.

NEDF file versions starting from 1.3 are supported.

Path to the .nedf file.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing NEDF data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawNedf.

mne.io.read_raw_nicolet

---

## mne.io.read_raw_neuralynx#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_neuralynx.html

**Contents:**
- mne.io.read_raw_neuralynx#

Reader for Neuralynx files.

Path to a folder with Neuralynx .ncs files.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

List of glob-like string patterns to exclude from channel list. Useful when not all channels have the same number of samples so you can read separate instances.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing Neuralynx data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawNeuralynx.

Neuralynx files are read from disk using the Neo package. Currently, only reading of the .ncs files is supported.

raw.info["meas_date"] is read from the recording_opened property of the first .ncs file (i.e. channel) in the dataset (a warning is issued if files have different dates of acquisition).

Channel-specific high and lowpass frequencies of online filters are determined based on the DspLowCutFrequency and DspHighCutFrequency header fields, respectively. If no filters were used for a channel, the default lowpass is set to the Nyquist frequency and the default highpass is set to 0. If channels have different high/low cutoffs, raw.info["highpass"] and raw.info["lowpass"] are then set to the maximum highpass and minimumlowpass values across channels, respectively.

Other header variables can be inspected using Neo directly. For example:

mne.io.read_raw_persyst

---

## mne.io.read_raw_nicolet#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_nicolet.html

**Contents:**
- mne.io.read_raw_nicolet#

Read Nicolet data as raw object.

This reader takes data files with the extension .data as an input. The header file with the same file name stem and an extension .head is expected to be found in the same directory.

Path to the data file (ending with .data not .head).

Channel type to designate to the data channels. Supported data types include 'eeg', 'dbs'.

Names of channels or list of indices that should be designated EOG channels. If 'auto', the channel names beginning with EOG are used. Defaults to empty tuple.

Names of channels or list of indices that should be designated ECG channels. If 'auto', the channel names beginning with ECG are used. Defaults to empty tuple.

Names of channels or list of indices that should be designated EMG channels. If 'auto', the channel names beginning with EMG are used. Defaults to empty tuple.

Names of channels or list of indices that should be designated MISC channels. Defaults to empty tuple.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing the data.

Documentation of attributes and methods.

mne.io.read_raw_nihon

---

## mne.io.read_raw_nihon#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_nihon.html

**Contents:**
- mne.io.read_raw_nihon#

Reader for an Nihon Kohden EEG file.

Path to the Nihon Kohden data file (.EEG).

If True, all data are loaded at initialization.

Text encoding of Nihon Kohden annotations. See Standard Encodings.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing Nihon Kohden data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawNihon.

mne.io.read_raw_nicolet

---

## mne.io.read_raw_nirx#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_nirx.html

**Contents:**
- mne.io.read_raw_nirx#
- Examples using mne.io.read_raw_nirx#

Reader for a NIRX fNIRS recording.

Path to the NIRX data folder or header file.

Replace saturated segments of data with NaNs, can be:

The measured data is returned, even if it contains measurements while the amplifier was saturated.

The returned data will contain NaNs during time segments when the amplifier was saturated.

The returned data will contain annotations specifying sections the saturate segments.

This argument will only be used if there is no .nosatflags file (only if a NIRSport device is used and saturation occurred).

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Text encoding of the NIRX header file. See Standard Encodings.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing NIRX data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawNIRX.

This function has only been tested with NIRScout and NIRSport devices, and with the NIRStar software version 15 and above and Aurora software 2021 and above.

The NIRSport device can detect if the amplifier is saturated. Starting from NIRStar 14.2, those saturated values are replaced by NaNs in the standard .wlX files. The raw unmodified measured values are stored in another file called .nosatflags_wlX. As NaN values can cause unexpected behaviour with mathematical functions the default behaviour is to return the saturated data.

Visualise NIRS artifact correction methods

Preprocessing functional near-infrared spectroscopy (fNIRS) data

mne.io.read_raw_nihon

---

## mne.io.read_raw_nsx#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_nsx.html

**Contents:**
- mne.io.read_raw_nsx#

Reader function for NSx (Blackrock Microsystems) files.

Path to the NSx file.

Defaults to 'auto', which means that channels named 'status' or 'trigger' (case insensitive) are set to STIM. If str (or list of str), all channels matching the name(s) are set to STIM. If int (or list of ints), channels corresponding to the indices are set to STIM.

Names of channels or list of indices that should be designated EOG channels. Values should correspond to the electrodes in the file. Default is None.

Names of channels or list of indices that should be designated MISC channels. Values should correspond to the electrodes in the file. Default is None.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw instance. See mne.io.Raw for documentation of attributes and methods.

NSx files with id (= NEURALSG), i.e., version 2.1 is currently not supported.

If channels named ‘status’ or ‘trigger’ are present, they are considered as STIM channels by default. Use func:mne.find_events to parse events encoded in such analog stim channels.

mne.io.read_raw_neuralynx

---

## mne.io.read_raw_persyst#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_persyst.html

**Contents:**
- mne.io.read_raw_persyst#

Reader for a Persyst (.lay/.dat) recording.

Path to the Persyst header .lay file.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing Persyst data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawPersyst.

It is assumed that the .lay and .dat file are in the same directory. To get the correct file path to the .dat file, read_raw_persyst will get the corresponding dat filename from the lay file, and look for that file inside the same directory as the lay file.

mne.io.read_raw_neuralynx

mne.io.read_raw_snirf

---

## mne.io.read_raw_snirf#

**URL:** https://mne.tools/stable/generated/mne.io.read_raw_snirf.html

**Contents:**
- mne.io.read_raw_snirf#
- Examples using mne.io.read_raw_snirf#

Reader for a continuous wave SNIRF data.

This reader supports the .snirf file type only, not the .jnirs version. Files with either 3D or 2D locations can be read. However, we strongly recommend using 3D positions. If 2D positions are used the behaviour of MNE functions can not be guaranteed.

Path to the SNIRF data file.

Coordinate frame used for the optode positions. The default is unknown, in which case the positions are not modified. If a known coordinate frame is provided (head, meg, mri), then the positions are transformed in to the Neuromag head coordinate frame (head).

The nominal sampling frequency at which the data were acquired. If None, will be estimated from the time data in the file.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A Raw object containing fNIRS data. See mne.io.Raw for documentation of attributes and methods.

Documentation of attributes and methods of RawSNIRF.

Importing data from fNIRS devices

mne.io.read_raw_persyst

---

## mne.io.show_fiff#

**URL:** https://mne.tools/stable/generated/mne.io.show_fiff.html

**Contents:**
- mne.io.show_fiff#

Show FIFF information.

This function is similar to mne_show_fiff.

Filename to evaluate.

How to indent the lines.

Max number of bytes of data to read from a tag. Can be np.inf to always read all data (helps test read completion).

Max number of characters of string representation to print for each tag’s data.

Either str or list. str is a convenience output for printing.

Provide information about this tag. If None (default), all information is shown.

If True (default False), print the byte offsets of each tag.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The contents of the file.

mne.io.get_channel_type_constants

---

## mne.io.write_fiducials#

**URL:** https://mne.tools/stable/generated/mne.io.write_fiducials.html

**Contents:**
- mne.io.write_fiducials#

Write fiducials to a fiff file.

Destination file name.

Iterator through digitizer points. Each point is a dictionary with the keys ‘kind’, ‘ident’ and ‘r’.

The coordinate frame of the points. If a string, must be one of 'meg', 'mri', 'mri_voxel', 'head', 'mri_tal', 'ras', 'fs_tal', 'ctf_head', 'ctf_meg', and 'unknown' If an integer, must be one of the constants defined as mne.io.constants.FIFF.FIFFV_COORD_....

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.io.read_fiducials

mne.get_montage_volume_labels

---

## mne.io.write_info#

**URL:** https://mne.tools/stable/generated/mne.io.write_info.html

**Contents:**
- mne.io.write_info#

Write measurement info in fif file.

The name of the file. Should end by -info.fif.

The mne.Info object with information about the sensors and methods of measurement.

The data_type in case it is necessary. Should be 4 (FIFFT_FLOAT), 5 (FIFFT_DOUBLE), or 16 (FIFFT_DAU_PACK16) for raw data.

If True, info[‘chs’][k][‘range’] will be set to unity.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

---

## mne.label.select_sources#

**URL:** https://mne.tools/stable/generated/mne.label.select_sources.html

**Contents:**
- mne.label.select_sources#
- Examples using mne.label.select_sources#

Select sources from a label.

The FreeSurfer subject name.

Define where the seed will be chosen. If str, can be ‘lh’ or ‘rh’, which correspond to left or right hemisphere, respectively.

Location to grow label from. If the location is an int, it represents the vertex number in the corresponding label. If it is a str, it can be either ‘random’ or ‘center’.

Extents (radius in mm) of the labels, i.e. maximum geodesic distance on the white matter surface from the seed. If 0, the resulting label will contain only one vertex.

Let the region grow outside the original label where location was defined.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Assign name to the new label.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

The surface used to simulated the label, defaults to the white surface.

The label that contains the selected sources.

This function selects a region of interest on the cortical surface based on a label (or a hemisphere). The sources are selected by growing a region around a seed which is selected randomly, is the center of the label, or is a specific vertex. The selected vertices can extend beyond the initial provided label. This can be prevented by setting grow_outside to False.

The selected sources are returned in the form of a new Label object. The values of the label contain the distance from the seed in millimeters.

Compare simulated and estimated source activity

Generate simulated source data

mne.grade_to_vertices

---

## mne.labels_to_stc#

**URL:** https://mne.tools/stable/generated/mne.labels_to_stc.html

**Contents:**
- mne.labels_to_stc#
- Examples using mne.labels_to_stc#

Convert a set of labels and values to a STC.

This function is meant to work like the opposite of extract_label_time_course.

If using a surface or mixed source space, this should be the Label’s for which to extract the time course. If working with whole-brain volume source estimates, this must be one of:

a string path to a FreeSurfer atlas for the subject (e.g., their ‘aparc.a2009s+aseg.mgz’) to extract time courses for all volumes in the atlas

a two-element list or tuple, the first element being a path to an atlas, and the second being a list or dict of volume_labels to extract (see mne.setup_volume_source_space() for details).

Changed in version 0.21.0: Support for volume source estimates.

The values in each label. Can be 1D or 2D.

The tmin to use for the STC.

The tstep to use for the STC.

The FreeSurfer subject name.

The source spaces for the source time courses. Can be omitted if using a surface source space, in which case the label vertices will determine the output STC vertices. Required if using a volumetric source space.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The values-in-labels converted to a STC.

Vertices that appear in more than one label will be averaged.

Visualize source time courses (stcs)

---

## mne.Label#

**URL:** https://mne.tools/stable/generated/mne.Label.html

**Contents:**
- mne.Label#
- Examples using mne.Label#

A FreeSurfer/MNE label with vertices restricted to one hemisphere.

Labels can be combined with the + operator:

Duplicate vertices are removed.

If duplicate vertices have conflicting position values, an error is raised.

Values of duplicate vertices are summed.

Vertex indices (0 based).

Locations in meters. If None, then zeros are used.

Values at the vertices. If None, then ones are used.

Hemisphere to which the label applies.

Kept as information but not used by the object itself.

Kept as information but not used by the object itself.

Kept as information but not used by the object itself.

Subject which this label belongs to. Should only be specified if it is not specified in the label.

Default label color and alpha (e.g., (1., 0., 0., 1.) for red).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Default label color, represented as RGBA tuple with values between 0 and 1.

Comment from the first line of the label file.

A name for the label. It is OK to change that attribute manually.

The label subject. It is best practice to set this to the proper value on initialization, but it can also be set manually.

Values at the vertices.

Vertex indices (0 based)

Return the number of vertices.

center_of_mass([subject, restrict_vertices, ...])

Compute the center of mass of the label.

compute_area([subject, subjects_dir, ...])

Compute the surface area of a label.

Copy the label instance.

distances_to_outside([subject, ...])

Compute the distance from each vertex to outside the label.

Fill the surface between sources for a source space label.

get_tris(tris[, vertices])

Get the source space's triangles inside the label.

get_vertices_used([vertices])

Get the source space's vertices inside the label.

morph([subject_from, subject_to, smooth, ...])

restrict(src[, name])

Restrict a label to a source space.

Write to disk as FreeSurfer *.label file.

smooth([subject, smooth, grade, ...])

split([parts, subject, subjects_dir, freesurfer])

Split the Label into two or more parts.

Return the number of vertices.

The number of vertices.

Compute the center of mass of the label.

This function computes the spatial center of mass on the surface as in [1].

Subject which this label belongs to. Should only be specified if it is not specified in the label.

If True, returned vertex will be one from the label. Otherwise, it could be any vertex from surf. If an array of int, the returned vertex will come from that array. If instance of SourceSpaces (as of 0.13), the returned vertex will be from the given source space. For most accuruate estimates, do not restrict vertices.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The surface to use for Euclidean distance center of mass finding. The default here is “sphere”, which finds the center of mass on the spherical surface to help avoid potential issues with cortical folding.

Vertex of the spatial center of mass for the inferred hemisphere, with each vertex weighted by its label value.

Eric Larson and Adrian K.C. Lee. The cortical dynamics underlying effective switching of auditory spatial attention. NeuroImage, 64:365–370, 2013. doi:10.1016/j.neuroimage.2012.09.006.

Compute the surface area of a label.

Subject which this label belongs to. Should only be specified if it is not specified in the label.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The surface along which to do the computations, defaults to 'white' (the gray-white matter boundary).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The area (in m²) of the label.

Examples using compute_area:

Corrupt known signal with point spread

Copy the label instance.

Compute the distance from each vertex to outside the label.

Subject which this label belongs to. Should only be specified if it is not specified in the label.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The surface along which to do the computations, defaults to 'white' (the gray-white matter boundary).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The distance from each vertex in self.vertices to exit the label.

For each vertex in the label, the nearest vertex outside the label.

Distances are computed along the cortical surface.

Examples using distances_to_outside:

Corrupt known signal with point spread

Fill the surface between sources for a source space label.

Source space in which the label was defined. If a source space is provided, the label is expanded to fill in surface vertices that lie between the vertices included in the source space. For the added vertices, pos is filled in with positions from the source space, and values is filled in from the closest source space vertex.

Name for the new Label (default is self.name).

The label covering the same vertices in source space but also including intermediate surface vertices.

Get the source space’s triangles inside the label.

The set of triangles corresponding to the vertices in a source space.

The set of vertices to compare the label to. If None, equals to np.arange(10242). Defaults to None.

The subset of tris used by the label.

Get the source space’s vertices inside the label.

The set of vertices to compare the label to. If None, equals to np.arange(10242). Defaults to None.

The vertices of the label corresponding used by the data.

Useful for transforming a label from one subject to another.

The name of the subject of the current label. If None, the initial subject will be taken from self.subject.

The name of the subject to morph the label to. This will be put in label.subject of the output label file.

Number of iterations for the smoothing of the surface data. Cannot be None here since not all vertices are used.

Resolution of the icosahedral mesh (typically 5). If None, all vertices will be used (potentially filling the surface). If a list, values will be morphed to the set of vertices specified in grade[0] and grade[1], assuming that these are vertices for the left and right hemispheres. Note that specifying the vertices (e.g., grade=[np.arange(10242), np.arange(10242)] for fsaverage on a standard grade 5 source space) can be substantially faster than computing vertex locations. If one array is used, it is assumed that all vertices belong to the hemisphere of the label. To create a label filling the surface, use None.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Morph a set of labels.

This function will set label.pos to be all zeros. If the positions on the new surface are required, consider using mne.read_surface with label.vertices.

Restrict a label to a source space.

The source spaces to use to restrict the label.

Name for the new Label (default is self.name).

The Label restricted to the set of source space vertices.

Write to disk as FreeSurfer *.label file.

Path to label file to produce.

Note that due to file specification limitations, the Label’s subject and color attributes are not saved to disk.

Useful for filling in labels made in a decimated source space for display.

Subject which this label belongs to. Should only be specified if it is not specified in the label.

Number of iterations for the smoothing of the surface data. Cannot be None here since not all vertices are used. For a grade of 5 (e.g., fsaverage), a smoothing of 2 will fill a label.

Resolution of the icosahedral mesh (typically 5). If None, all vertices will be used (potentially filling the surface). If a list, values will be morphed to the set of vertices specified in grade[0] and grade[1], assuming that these are vertices for the left and right hemispheres. Note that specifying the vertices (e.g., grade=[np.arange(10242), np.arange(10242)] for fsaverage on a standard grade 5 source space) can be substantially faster than computing vertex locations. If one array is used, it is assumed that all vertices belong to the hemisphere of the label. To create a label filling the surface, use None.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

This function will set label.pos to be all zeros. If the positions on the new surface are required, consider using mne.read_surface with label.vertices.

Split the Label into two or more parts.

Number of labels to create (default is 2), or tuple of strings specifying label names for new labels (from posterior to anterior), or ‘contiguous’ to split the label into connected components. If a number or ‘contiguous’ is specified, names of the new labels will be the input label’s name with div1, div2 etc. appended.

Subject which this label belongs to. Should only be specified if it is not specified in the label.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

By default (False) split_label uses an algorithm that is slightly optimized for performance and numerical precision. Set freesurfer to True in order to replicate label splits from FreeSurfer’s mris_divide_parcellation.

The labels, starting from the lowest to the highest end of the projection axis.

If using ‘contiguous’ split, you must ensure that the label being split uses the same triangular resolution as the surface mesh files in subjects_dir Also, some small fringe labels may be returned that are close (but not connected) to the large components.

The spatial split finds the label’s principal eigen-axis on the spherical surface, projects all label vertex coordinates onto this axis, and divides them at regular spatial intervals.

Compute MNE-dSPM inverse solution on single epochs

Compute sLORETA inverse solution on raw data

Extracting time course from source_estimate object

Generate a functional label from source estimates

Extracting the time series of activations in a label

Cortical Signal Suppression (CSS) for removal of cortical signals

Compare simulated and estimated source activity

Simulate raw data using subject anatomy

Generate simulated source data

Compute Power Spectral Density of inverse solution from single epochs

Compute power and phase lock in label of the source space

Compute source power spectral density (PSD) in a label

Plot a cortical parcellation

Corrupt known signal with point spread

mne.MixedSourceEstimate

---

## mne.label_sign_flip#

**URL:** https://mne.tools/stable/generated/mne.label_sign_flip.html

**Contents:**
- mne.label_sign_flip#
- Examples using mne.label_sign_flip#

Compute sign for label averaging.

The source space over which the label is defined.

Sign flip vector (contains 1 or -1).

Compute MNE-dSPM inverse solution on single epochs

---

## mne.make_ad_hoc_cov#

**URL:** https://mne.tools/stable/generated/mne.make_ad_hoc_cov.html

**Contents:**
- mne.make_ad_hoc_cov#
- Examples using mne.make_ad_hoc_cov#

Create an ad hoc noise covariance.

The mne.Info object with information about the sensors and methods of measurement.

Standard_deviation of the diagonal elements. If dict, keys should be 'grad' for gradiometers, 'mag' for magnetometers and 'eeg' for EEG channels. If None, default values will be used (see Notes).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The ad hoc diagonal noise covariance for the M/EEG data channels.

The default noise values are 5 fT/cm, 20 fT, and 0.2 µV for gradiometers, magnetometers, and EEG channels respectively.

Compare simulated and estimated source activity

Generate simulated raw data

Generate simulated source data

DICS for power mapping

---

## mne.make_bem_model#

**URL:** https://mne.tools/stable/generated/mne.make_bem_model.html

**Contents:**
- mne.make_bem_model#
- Examples using mne.make_bem_model#

Create a BEM model for a subject.

Use make_bem_solution() to turn the returned surfaces into a ConductorModel suitable for forward calculation.

To get a single layer bem corresponding to the –homog flag in the command line tool set the conductivity parameter to a float (e.g. 0.3).

The FreeSurfer subject name.

The surface ico downsampling to use, e.g. 5=20484, 4=5120, 3=1280. If None, no subsampling is applied.

The conductivities to use for each shell. Should be a single element for a one-layer model, or three elements for a three-layer model. Defaults to [0.3, 0.006, 0.3]. The MNE-C default for a single-layer model is [0.3].

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The BEM surfaces. Use make_bem_solution() to turn these into a ConductorModel suitable for forward calculation.

Head model and forward computation

Fixing BEM and head surfaces

Working with CTF data: the Brainstorm auditory dataset

mne.forward.restrict_forward_to_stc

mne.make_bem_solution

---

## mne.make_bem_solution#

**URL:** https://mne.tools/stable/generated/mne.make_bem_solution.html

**Contents:**
- mne.make_bem_solution#
- Examples using mne.make_bem_solution#

Create a BEM solution using the linear collocation approach.

The BEM surfaces to use (from mne.make_bem_model()).

Can be 'mne' (default) to use MNE-Python, or 'openmeeg' to use the OpenMEEG package.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Compute source power spectral density (PSD) of VectorView and OPM data

Head model and forward computation

Working with CTF data: the Brainstorm auditory dataset

mne.make_forward_dipole

---

## mne.make_field_map#

**URL:** https://mne.tools/stable/generated/mne.make_field_map.html

**Contents:**
- mne.make_field_map#
- Examples using mne.make_field_map#

Compute surface maps used for field display in 3D.

The measurement file. Need to have info attribute.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation. If trans is None, an identity matrix is assumed. "auto" (default) will load trans from the FreeSurfer directory specified by subject and subjects_dir parameters.

Changed in version 0.19: Support for 'fsaverage' argument.

The subject name corresponding to FreeSurfer environment variable SUBJECT. If None, map for EEG data will not be available.

The path to the freesurfer subjects reconstructions. It corresponds to Freesurfer environment variable SUBJECTS_DIR.

If None, a map for each available channel type will be returned. Else only the specified type will be used.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used. 'fast' should be sufficient for most applications.

Should be 'helmet' or 'head' to specify in which surface to compute the MEG field map. The default value is 'helmet'.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto', which means a head-digitization-based origin fit. Default is (0., 0., 0.04).

Changed in version 1.12: In 1.12 the default value is “auto”. In 1.11 and prior versions, it is (0., 0., 0.04).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

The upsampling factor to use for the helmet mesh. The default (1) does no upsampling. Larger integers lead to more densely sampled helmet surfaces, and the number of vertices increases as a factor of 4**(upsampling-1).

Head source(s) to use. See the source option of mne.get_head_surf() for more information.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The surface maps to be used for field plots. The list contains separate ones for MEG and EEG (if both MEG and EEG are present).

Plot the MNE brain and helmet

Visualizing Evoked data

Using the event system to link figures

mne.make_forward_solution

mne.make_sphere_model

---

## mne.make_fixed_length_events#

**URL:** https://mne.tools/stable/generated/mne.make_fixed_length_events.html

**Contents:**
- mne.make_fixed_length_events#
- Examples using mne.make_fixed_length_events#

Make a set of events separated by a fixed duration.

A raw object to use the data from.

The id to use (default 1).

Time of first event (in seconds).

Maximum time of last event (in seconds). If None, events extend to the end of the recording.

The duration to separate events by (in seconds).

If True (default), times will have first_samp added to them, as in mne.find_events(). This behavior is not desirable if the returned events will be combined with event times that already have first_samp added to them, e.g. event times that come from mne.find_events().

The overlap between events (in seconds). Must be 0 <= overlap < duration.

The identity and timing of experimental events, around which the epochs were created. See events for more information.

Continuous Target Decoding with SPoC

Compute spatial filters with Spatio-Spectral Decomposition (SSD)

Overview of MEG/EEG analysis with MNE-Python

Parsing events from raw data

Rejecting bad data spans and breaks

Creating MNE-Python data structures from scratch

mne.make_fixed_length_epochs

---

## mne.make_forward_dipole#

**URL:** https://mne.tools/stable/generated/mne.make_forward_dipole.html

**Contents:**
- mne.make_forward_dipole#
- Examples using mne.make_forward_dipole#

Convert dipole object to source estimate and calculate forward operator.

The instance of Dipole is converted to a discrete source space, which is then combined with a BEM or a sphere model and the sensor information in info to form a forward operator.

The source estimate object (with the forward operator) can be projected to sensor-space using mne.simulation.simulate_evoked().

If the (unique) time points of the dipole object are unevenly spaced, the first output will be a list of single-timepoint source estimates.

Dipole object containing position, orientation and amplitude of one or more dipoles. Multiple simultaneous dipoles may be defined by assigning them identical times. Alternatively, multiple simultaneous dipoles may also be specified as a list of Dipole objects.

Changed in version 1.1: Added support for a list of mne.Dipole instances.

The BEM filename (str) or a loaded sphere model (dict).

The measurement information dictionary. It is sensor-information etc., e.g., from a real data file.

The head<->MRI transform filename. Must be provided unless BEM is a sphere model.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

What to do if MEG sensors are inside the outer skin surface. If ‘raise’ (default), an error is raised. If ‘warn’ or ‘ignore’, the forward solution is computed anyway and a warning is or isn’t emitted, respectively.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The forward solution corresponding to the source estimate(s).

The dipoles converted to a discrete set of points and associated time courses. If the time points of the dipole are unevenly spaced, a list of single-timepoint source estimates are returned.

Computing source timecourses with an XFit-like multi-dipole model

Source localization with equivalent current dipole (ECD) fit

mne.make_bem_solution

mne.make_forward_solution

---

## mne.make_forward_solution#

**URL:** https://mne.tools/stable/generated/mne.make_forward_solution.html

**Contents:**
- mne.make_forward_solution#
- Examples using mne.make_forward_solution#

Calculate a forward solution for a subject.

The mne.Info object with information about the sensors and methods of measurement. If path-like, it should be a str or pathlib.Path to a file with measurement information (e.g. mne.io.Raw).

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation. If trans is None, an identity matrix is assumed.

Changed in version 0.19: Support for 'fsaverage' argument.

Either a path to a source space file or a loaded or generated SourceSpaces.

Filename of the BEM (e.g., "sample-5120-5120-5120-bem-sol.fif") to use, or a loaded ConductorModel. See make_bem_model() and make_bem_solution() to create a mne.bem.ConductorModel.

If True (default), include MEG computations.

If True (default), include EEG computations.

Minimum distance of sources from inner skull surface (in mm).

If True, do not include reference channels in compensation. This option should be True for KIT files, since forward computation with reference channels is not currently supported.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

What to do if MEG sensors are inside the outer skin surface. If ‘raise’ (default), an error is raised. If ‘warn’ or ‘ignore’, the forward solution is computed anyway and a warning is or isn’t emitted, respectively.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The forward solution.

The --grad option from MNE-C (to compute gradients) is not implemented here.

To create a fixed-orientation forward solution, use this function followed by mne.convert_forward_solution().

If the BEM solution was computed with OpenMEEG in mne.make_bem_solution(), then OpenMEEG will automatically be used to compute the forward solution.

Changed in version 1.2: Added support for OpenMEEG-based forward solution calculations.

From raw data to dSPM on SPM Faces dataset

Use source space morphing

Compute MNE inverse solution on evoked data with a mixed source space

Plot point-spread functions (PSFs) for a volume

Compute source power spectral density (PSD) of VectorView and OPM data

Head model and forward computation

EEG forward operator with a template MRI

EEG source localization given electrode locations on an MRI

Working with CTF data: the Brainstorm auditory dataset

Setting the EEG reference

Preprocessing optically pumped magnetometer (OPM) MEG data

mne.make_forward_dipole

---

## mne.make_sphere_model#

**URL:** https://mne.tools/stable/generated/mne.make_sphere_model.html

**Contents:**
- mne.make_sphere_model#
- Examples using mne.make_sphere_model#

Create a spherical model for forward solution calculation.

Head center to use (in head coordinates). If ‘auto’, the head center will be calculated from the digitization points in info.

If float, compute spherical shells for EEG using the given radius. If 'auto', estimate an appropriate radius from the dig points in the Info provided by the argument info. If None, exclude shells (single layer sphere model).

The mne.Info object with information about the sensors and methods of measurement. Only needed if r0 or head_radius are 'auto'.

Relative radii for the spherical shells.

Sigma values for the spherical shells.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resulting spherical conductor model.

The default model has:

These correspond to compartments (with relative radii in m and conductivities σ in S/m) for the brain, CSF, skull, and scalp, respectively.

Kernel OPM phantom data

Plot sensor denoising using oversampled temporal projection

Plotting sensor layouts of EEG systems

Source alignment and coordinate frames

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

Setting the EEG reference

mne.morph_source_spaces

---

## mne.merge_events#

**URL:** https://mne.tools/stable/generated/mne.merge_events.html

**Contents:**
- mne.merge_events#
- Examples using mne.merge_events#

Merge a set of events.

The ids of events to merge.

If True (default), old event ids are replaced. Otherwise, new events will be added to the old event list.

Rather than merging events you can use hierarchical event_id in Epochs. For example, here:

And the condition ‘auditory’ would correspond to either 1 or 2.

Here is quick example of the behavior:

Regression-based baseline correction

mne.make_fixed_length_epochs

---

## mne.minimum_norm.apply_inverse#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse.html

**Contents:**
- mne.minimum_norm.apply_inverse#
- Examples using mne.minimum_norm.apply_inverse#

Apply inverse operator to evoked data.

The regularization parameter.

Use minimum norm [1], dSPM (default) [2], sLORETA [3], or eLORETA [4].

Pooling is performed by taking the norm of loose/free orientations. In case of a fixed source space no norm is computed leading to signed source activity.

Only the normal to the cortical surface is kept. This is only implemented when working with loose orientations.

No pooling of the orientations is done, and the vector result will be returned in the form of a mne.VectorSourceEstimate object.

If True, do not call prepare_inverse_operator().

Restricts the source estimates to a given label. If None, source estimates will be computed for the entire source space.

Additional options for eLORETA. See Notes for details.

If True (default False), return the residual evoked data. Cannot be used with method=='eLORETA'.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Only used when the inverse is free orientation (loose=1.), not in surface orientation, and pick_ori='normal'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimates.

The residual evoked data, only returned if return_residual is True.

Apply inverse operator to raw object.

Apply inverse operator to epochs object.

Apply inverse operator to epochs tfr object.

Apply inverse operator to covariance object.

Currently only the method='eLORETA' has additional options. It performs an iterative fit with a convergence criterion, so you can pass a method_params dict with string keys mapping to values for:

The convergence epsilon (default 1e-6).

The maximum number of iterations (default 20). If less regularization is applied, more iterations may be necessary.

Force all eLORETA weights for each direction for a given location equal. The default is None, which means True for loose-orientation inverses and False for free- and fixed-orientation inverses. See below.

The eLORETA paper [4] defines how to compute inverses for fixed- and free-orientation inverses. In the free orientation case, the X/Y/Z orientation triplet for each location is effectively multiplied by a 3x3 weight matrix. This is the behavior obtained with force_equal=False parameter.

However, other noise normalization methods (dSPM, sLORETA) multiply all orientations for a given location by a single value. Using force_equal=True mimics this behavior by modifying the iterative algorithm to choose uniform weights (equivalent to a 3x3 diagonal matrix with equal entries).

It is necessary to use force_equal=True with loose orientation inverses (e.g., loose=0.2), otherwise the solution resembles a free-orientation inverse (loose=1.0). It is thus recommended to use force_equal=True for loose orientation and force_equal=False for free orientation inverses. This is the behavior used when the parameter force_equal=None (default behavior).

Matti S. Hämäläinen and Ilmoniemi Ilmoniemi, Risto J. Interpreting magnetic fields of the brain: minimum norm estimates. Medical & Biological Engineering & Computing, 32(1):35–42, 1994. doi:10.1007/BF02512476.

Anders M. Dale, Arthur K. Liu, Bruce R. Fischl, Randy L. Buckner, John W. Belliveau, Jeffrey D. Lewine, and Eric Halgren. Dynamic statistical parametric mapping: combining fMRI and MEG for high-resolution imaging of cortical activity. Neuron, 26(1):55–67, 2000. doi:10.1016/S0896-6273(00)81138-1.

Roberto D. Pascual-Marqui. Standardized low-resolution brain electromagnetic tomography (sLORETA): technical details. Methods and Findings in Experimental and Clinical Pharmacology, 24(D):5–12, 2002. URL: https://pubmed.ncbi.nlm.nih.gov/12575463/.

Roberto D. Pascual-Marqui, Dietrich Lehmann, Martha Koukkou, Kieko Kochi, Peter Anderer, Bernd Saletu, Hideaki Tanaka, Koichi Hirata, E. Roy John, Leslie Prichep, Rolando Biscay-Lirio, and Toshihiko Kinoshita. Assessing interactions in the brain with exact low-resolution electromagnetic tomography. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 369(1952):3768–3784, 2011. doi:10.1098/rsta.2011.0081.

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Compute MNE-dSPM inverse solution on single epochs

Compute MNE-dSPM inverse solution on evoked data in volume source space

Generate a functional label from source estimates

Extracting the time series of activations in a label

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Morph volumetric source estimate

Computing source timecourses with an XFit-like multi-dipole model

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Plotting the full vector-valued MNE solution

Compare simulated and estimated source activity

Simulate raw data using subject anatomy

Overview of MEG/EEG analysis with MNE-Python

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Visualize source time courses (stcs)

EEG source localization given electrode locations on an MRI

Working with CTF data: the Brainstorm auditory dataset

Preprocessing optically pumped magnetometer (OPM) MEG data

Corrupt known signal with point spread

DICS for power mapping

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.minimum_norm.InverseOperator

mne.minimum_norm.apply_inverse_cov

---

## mne.minimum_norm.apply_inverse_cov#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse_cov.html

**Contents:**
- mne.minimum_norm.apply_inverse_cov#
- Examples using mne.minimum_norm.apply_inverse_cov#

Apply inverse operator to covariance data.

Covariance data, computed on the time segment for which to compute source power.

The mne.Info object with information about the sensors and methods of measurement. Used specify the channels to include.

Number of averages used to regularize the solution.

The regularization parameter.

Use minimum norm, dSPM (default), sLORETA, or eLORETA.

Pooling is performed by taking the norm of loose/free orientations. In case of a fixed source space no norm is computed leading to signed source activity.

Only the normal to the cortical surface is kept. This is only implemented when working with loose orientations.

If True, do not call prepare_inverse_operator().

Restricts the source estimates to a given label. If None, source estimates will be computed for the entire source space.

Additional options for eLORETA. See Notes for details.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimates.

Apply inverse operator to evoked object.

Apply inverse operator to raw object.

Apply inverse operator to epochs object.

Apply inverse operator to epochs tfr object.

This code is based on the original research code from [1] and has been useful to correct for individual field spread using source localization in the context of predictive modeling.

David Sabbagh, Pierre Ablin, Gaël Varoquaux, Alexandre Gramfort, and Denis A. Engemann. Predictive regression modeling with meg/eeg: from source power to signals and cognitive states. NeuroImage, 2020. doi:10.1016/j.neuroimage.2020.116893.

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute source power estimate by projecting the covariance with MNE

Computing various MNE solutions

mne.minimum_norm.apply_inverse

mne.minimum_norm.apply_inverse_epochs

---

## mne.minimum_norm.apply_inverse_raw#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse_raw.html

**Contents:**
- mne.minimum_norm.apply_inverse_raw#
- Examples using mne.minimum_norm.apply_inverse_raw#

Apply inverse operator to Raw data.

The regularization parameter.

Use minimum norm, dSPM (default), sLORETA, or eLORETA.

Restricts the source estimates to a given label. If None, source estimates will be computed for the entire source space.

Index of first time sample (index not time is seconds).

Index of first time sample not to include (index not time is seconds).

Number of averages used to regularize the solution. Set to 1 on raw data.

Linear function applied to sensor space time series.

Pooling is performed by taking the norm of loose/free orientations. In case of a fixed source space no norm is computed leading to signed source activity.

Only the normal to the cortical surface is kept. This is only implemented when working with loose orientations.

No pooling of the orientations is done, and the vector result will be returned in the form of a mne.VectorSourceEstimate object.

If not None, the computation of the inverse and the combination of the current components is performed in segments of length buffer_size samples. While slightly slower, this is useful for long datasets as it reduces the memory requirements by approx. a factor of 3 (assuming buffer_size << data length). Note that this setting has no effect for fixed-orientation inverse operators.

If True, do not call prepare_inverse_operator().

Additional options for eLORETA. See Notes of apply_inverse().

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Only used when the inverse is free orientation (loose=1.), not in surface orientation, and pick_ori='normal'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimates.

Apply inverse operator to evoked object.

Apply inverse operator to epochs object.

Apply inverse operator to epochs tfr object.

Apply inverse operator to covariance object.

Compute sLORETA inverse solution on raw data

mne.minimum_norm.apply_inverse_epochs

mne.minimum_norm.apply_inverse_tfr_epochs

---

## mne.minimum_norm.compute_rank_inverse#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.compute_rank_inverse.html

**Contents:**
- mne.minimum_norm.compute_rank_inverse#

Compute the rank of a linear inverse operator (MNE, dSPM, etc.).

The inverse operator.

The rank of the inverse operator.

mne.minimum_norm.compute_source_psd_epochs

mne.minimum_norm.estimate_snr

---

## mne.minimum_norm.compute_source_psd#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.compute_source_psd.html

**Contents:**
- mne.minimum_norm.compute_source_psd#
- Examples using mne.minimum_norm.compute_source_psd#

Compute source power spectral density (PSD).

The inverse operator.

The regularization parameter.

Use minimum norm, dSPM (default), sLORETA, or eLORETA.

The beginning of the time interval of interest (in seconds). Use 0. for the beginning of the file.

The end of the time interval of interest (in seconds). If None stop at the end of the file.

The lower frequency of interest.

The upper frequency of interest.

Window size for the FFT. Should be a power of 2.

The overlap fraction between windows. Should be between 0 and 1. 0 means no overlap.

If “normal”, rather than pooling the orientations by taking the norm, only the radial component is kept. This is only implemented when working with loose orientations.

Restricts the source estimates to a given label.

The number of averages used to scale the noise covariance matrix.

If True, the true dimension of data is estimated before running the time-frequency transforms. It reduces the computation times e.g. with a dataset that was maxfiltered (true dim is 64).

If True, do not call prepare_inverse_operator().

Additional options for eLORETA. See Notes of apply_inverse().

Split inverse operator into inv_split parts in order to save memory.

The bandwidth of the multi taper windowing function in Hz. Can also be a string (e.g., ‘hann’) to use a single window.

For backward compatibility, the default is ‘hann’.

Use adaptive weights to combine the tapered spectra into PSD (slow, use n_jobs >> 1 to speed up computation).

Only use tapers with more than 90% spectral concentration within bandwidth.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. It is only used if adaptive=True.

If True, return the sensor PSDs as an EvokedArray.

If True (default False), return output it decibels.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The PSD of each of the sources.

The PSD of each sensor. Only returned if return_sensor is True.

Each window is multiplied by a window before processing, so using a non-zero overlap is recommended.

This function is different from compute_source_psd_epochs() in that:

bandwidth='hann' by default, skipping multitaper estimation

For convenience it wraps mne.make_fixed_length_events() and mne.Epochs.

Otherwise the two should produce identical results.

Compute source power spectral density (PSD) in a label

Compute source power spectral density (PSD) of VectorView and OPM data

mne.minimum_norm.apply_inverse_tfr_epochs

mne.minimum_norm.compute_source_psd_epochs

---

## mne.minimum_norm.estimate_snr#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.estimate_snr.html

**Contents:**
- mne.minimum_norm.estimate_snr#

Estimate the SNR as a function of time for evoked data.

The inverse operator.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The SNR estimated from the whitened data (i.e., GFP of whitened data).

The SNR estimated using the mismatch between the unregularized solution and the regularized solution.

snr_est is estimated by using different amounts of inverse regularization and checking the mismatch between predicted and measured whitened data.

In more detail, given our whitened inverse obtained from SVD:

The values in the diagonal matrix \(\Gamma\) are expressed in terms of the chosen regularization \(\lambda^2 \sim 1/\rm{SNR}^2\) and singular values \(\lambda_k\) as:

We also know that our predicted data is given by:

And thus our predicted whitened data is just:

Where \(\Pi\) is diagonal with entries entries:

If we use no regularization, note that \(\Pi\) is just the identity matrix. Here we test the squared magnitude of the difference between unregularized solution and regularized solutions, choosing the biggest regularization that achieves a \(\chi^2\)-test significance of 0.001.

mne.minimum_norm.compute_rank_inverse

mne.minimum_norm.make_inverse_operator

---

## mne.minimum_norm.get_cross_talk#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.get_cross_talk.html

**Contents:**
- mne.minimum_norm.get_cross_talk#
- Examples using mne.minimum_norm.get_cross_talk#

Get cross-talk (CTFs) function for vertices.

Source space used to compute resolution matrix. Must be an InverseOperator if vector=True and a surface source space is used.

Source for indices for which to compute PSFs or CTFs. If mode is None, PSFs/CTFs will be returned for all indices. If mode is not None, the corresponding summary measure will be computed across all PSFs/CTFs available from idx. Can be:

list of integers : Compute PSFs/CTFs for all indices to source space vertices specified in idx.

list of Label : Compute PSFs/CTFs for source space vertices in specified labels.

Compute summary of PSFs/CTFs across all indices specified in ‘idx’. Can be:

None : Output individual PSFs/CTFs for each specific vertex (Default).

‘mean’ : Mean of PSFs/CTFs across vertices.

‘max’ : PSFs/CTFs with maximum norm across vertices. Returns the n_comp largest PSFs/CTFs.

‘svd’ : SVD components across PSFs/CTFs across vertices. Returns the n_comp first SVD components.

Number of PSF/CTF components to return for mode=’max’ or mode=’svd’. Default n_comp=1.

Whether and how to normalise the PSFs and CTFs. This will be applied before computing summaries as specified in ‘mode’. Can be:

None : Use un-normalized PSFs/CTFs (Default).

‘max’ : Normalize to maximum absolute value across all PSFs/CTFs.

‘norm’ : Normalize to maximum norm across all PSFs/CTFs.

Whether or not to return the explained variances across the specified vertices for individual SVD components. This is only valid if mode='svd'. Default to False.

Whether to return PSF/CTF as vector source estimate (3 values per location) or source estimate object (1 intensity value per location). Only allowed to be True if corresponding dimension of resolution matrix is 3 * n_dipoles. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The PSFs or CTFs as STC objects. All PSFs/CTFs will be returned as successive samples in STC objects, in the order they are specified in idx. STCs for different labels willbe returned as a list. If resmat was computed with n_orient_inv==3 for CTFs or n_orient_fwd==3 for PSFs then 3 functions per vertex will be returned as successive samples (i.e. one function per orientation). If vector=False (default) and resmat was computed with n_orient_inv==3 for PSFs or n_orient_fwd==3 for CTFs, then the three values per vertex will be combined into one intensity value per vertex in a SourceEstimate object. If vector=True, PSFs or CTFs with 3 values per vertex (one per orientation) will be returned in a VectorSourceEstimate object.

The explained variances of the first n_comp SVD components across the PSFs/CTFs for the specified vertices. Arrays for multiple labels are returned as list. Only returned if mode='svd' and return_pca_vars=True.

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

mne.minimum_norm.resolution_metrics

mne.minimum_norm.get_point_spread

---

## mne.minimum_norm.get_point_spread#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.get_point_spread.html

**Contents:**
- mne.minimum_norm.get_point_spread#
- Examples using mne.minimum_norm.get_point_spread#

Get point-spread (PSFs) functions for vertices.

Source space used to compute resolution matrix. Must be an InverseOperator if vector=True and a surface source space is used.

Source for indices for which to compute PSFs or CTFs. If mode is None, PSFs/CTFs will be returned for all indices. If mode is not None, the corresponding summary measure will be computed across all PSFs/CTFs available from idx. Can be:

list of integers : Compute PSFs/CTFs for all indices to source space vertices specified in idx.

list of Label : Compute PSFs/CTFs for source space vertices in specified labels.

Compute summary of PSFs/CTFs across all indices specified in ‘idx’. Can be:

None : Output individual PSFs/CTFs for each specific vertex (Default).

‘mean’ : Mean of PSFs/CTFs across vertices.

‘max’ : PSFs/CTFs with maximum norm across vertices. Returns the n_comp largest PSFs/CTFs.

‘svd’ : SVD components across PSFs/CTFs across vertices. Returns the n_comp first SVD components.

Number of PSF/CTF components to return for mode=’max’ or mode=’svd’. Default n_comp=1.

Whether and how to normalise the PSFs and CTFs. This will be applied before computing summaries as specified in ‘mode’. Can be:

None : Use un-normalized PSFs/CTFs (Default).

‘max’ : Normalize to maximum absolute value across all PSFs/CTFs.

‘norm’ : Normalize to maximum norm across all PSFs/CTFs.

Whether or not to return the explained variances across the specified vertices for individual SVD components. This is only valid if mode='svd'. Default to False.

Whether to return PSF/CTF as vector source estimate (3 values per location) or source estimate object (1 intensity value per location). Only allowed to be True if corresponding dimension of resolution matrix is 3 * n_dipoles. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The PSFs or CTFs as STC objects. All PSFs/CTFs will be returned as successive samples in STC objects, in the order they are specified in idx. STCs for different labels willbe returned as a list. If resmat was computed with n_orient_inv==3 for CTFs or n_orient_fwd==3 for PSFs then 3 functions per vertex will be returned as successive samples (i.e. one function per orientation). If vector=False (default) and resmat was computed with n_orient_inv==3 for PSFs or n_orient_fwd==3 for CTFs, then the three values per vertex will be combined into one intensity value per vertex in a SourceEstimate object. If vector=True, PSFs or CTFs with 3 values per vertex (one per orientation) will be returned in a VectorSourceEstimate object.

The explained variances of the first n_comp SVD components across the PSFs/CTFs for the specified vertices. Arrays for multiple labels are returned as list. Only returned if mode='svd' and return_pca_vars=True.

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Plot point-spread functions (PSFs) for a volume

mne.minimum_norm.get_cross_talk

mne.inverse_sparse.mixed_norm

---

## mne.minimum_norm.InverseOperator#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.InverseOperator.html

**Contents:**
- mne.minimum_norm.InverseOperator#
- Examples using mne.minimum_norm.InverseOperator#

InverseOperator class to represent info from inverse operator.

Name of channels attached to the inverse operator.

Info attached to the inverse operator.

True if the dictionary has the specified key, else False.

Implement iter(self).

Return a copy of the InverseOperator.

fromkeys(iterable[, value])

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

setdefault(key[, default])

Insert key with a value of default if key is not in the dictionary.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

True if the dictionary has the specified key, else False.

Implement iter(self).

Name of channels attached to the inverse operator.

Return a copy of the InverseOperator.

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

Info attached to the inverse operator.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

Pairs are returned in LIFO (last-in, first-out) order. Raises KeyError if the dict is empty.

Insert key with a value of default if key is not in the dictionary.

Return the value for key if key is in the dictionary, else default.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Decoding source space data

Compute MNE-dSPM inverse solution on single epochs

Compute sLORETA inverse solution on raw data

Compute MNE-dSPM inverse solution on evoked data in volume source space

Generate a functional label from source estimates

Extracting the time series of activations in a label

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Compute source power estimate by projecting the covariance with MNE

Morph volumetric source estimate

Computing source timecourses with an XFit-like multi-dipole model

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Plot point-spread functions (PSFs) for a volume

Reading an inverse operator

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Estimate data SNR using an inverse

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Plotting the full vector-valued MNE solution

Compare simulated and estimated source activity

Simulate raw data using subject anatomy

Compute Power Spectral Density of inverse solution from single epochs

Compute power and phase lock in label of the source space

Compute source power spectral density (PSD) in a label

Compute induced power in the source space with dSPM

Plot the MNE brain and helmet

Overview of MEG/EEG analysis with MNE-Python

Getting started with mne.Report

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Visualize source time courses (stcs)

EEG source localization given electrode locations on an MRI

Working with CTF data: the Brainstorm auditory dataset

Preprocessing optically pumped magnetometer (OPM) MEG data

Corrupt known signal with point spread

DICS for power mapping

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.minimum_norm.apply_inverse

---

## mne.minimum_norm.make_inverse_operator#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.make_inverse_operator.html

**Contents:**
- mne.minimum_norm.make_inverse_operator#
- Examples using mne.minimum_norm.make_inverse_operator#

Assemble inverse operator.

The mne.Info object with information about the sensors and methods of measurement. Specifies the channels to include. Bad channels (in info['bads']) are not used.

Forward operator. See make_forward_solution() to create the operator.

The noise covariance matrix. See compute_raw_covariance() and compute_covariance() to compute the noise covariance matrix on Raw and Epochs respectively.

Value that weights the source variances of the dipole components that are parallel (tangential) to the cortical surface. Can be:

If 0, then the solution is computed with fixed orientation. If 1, it corresponds to free orientations.

Uses 0.2 for surface source spaces (unless fixed is True) and 1.0 for other source spaces (volume or mixed).

Mapping from the key for a given source space type (surface, volume, discrete) to the loose value. Useful mostly for mixed source spaces.

How to weight (or normalize) the forward using a depth prior. If float (default 0.8), it acts as the depth weighting exponent (exp) to use None is equivalent to 0, meaning no depth weighting is performed. It can also be a dict containing keyword arguments to pass to mne.forward.compute_depth_prior() (see docstring for details and defaults). This is effectively ignored when method='eLORETA'.

Changed in version 0.20: Depth bias ignored for method='eLORETA'.

Use fixed source orientations normal to the cortical mantle. If True, the loose parameter must be "auto" or 0. If 'auto', the loose value is used.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

For different sets of options (loose, depth, fixed) to work, the forward operator must have been loaded using a certain configuration (i.e., with force_fixed and surf_ori set appropriately). For example, given the desired inverse type (with representative choices of loose = 0.2 and depth = 0.8 shown in the table in various places, as these are the defaults for those parameters):

Forward parameters allowed

Also note that, if the source space (as stored in the forward solution) has patch statistics computed, these are used to improve the depth weighting. Thus slightly different results are to be expected with and without this information.

For depth weighting, 0.8 is generally good for MEG, and between 2 and 5 is good for EEG, see Lin et al.[1].

Fa-Hsuan Lin, Thomas Witzel, Seppo P. Ahlfors, Steven M. Stufflebeam, John W. Belliveau, and Matti S. Hämäläinen. Assessing and improving the spatial accuracy in MEG source localization by depth-weighted minimum-norm estimates. NeuroImage, 31(1):160–171, 2006. doi:10.1016/j.neuroimage.2005.11.054.

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Compute source power estimate by projecting the covariance with MNE

Computing source timecourses with an XFit-like multi-dipole model

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Plot point-spread functions (PSFs) for a volume

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Compare simulated and estimated source activity

Simulate raw data using subject anatomy

Compute source power spectral density (PSD) of VectorView and OPM data

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

EEG source localization given electrode locations on an MRI

Working with CTF data: the Brainstorm auditory dataset

Preprocessing optically pumped magnetometer (OPM) MEG data

DICS for power mapping

mne.minimum_norm.estimate_snr

mne.minimum_norm.prepare_inverse_operator

---

## mne.minimum_norm.make_inverse_resolution_matrix#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.make_inverse_resolution_matrix.html

**Contents:**
- mne.minimum_norm.make_inverse_resolution_matrix#
- Examples using mne.minimum_norm.make_inverse_resolution_matrix#

Compute resolution matrix for linear inverse operator.

Inverse method to use (MNE, dSPM, sLORETA).

The regularisation parameter.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Resolution matrix (inverse operator times forward operator). The result of applying the inverse operator to the forward operator. If source orientations are not fixed, all source components will be computed (i.e. for n_orient_inv > 1 or n_orient_fwd > 1). The columns of the resolution matrix are the point-spread functions (PSFs) and the rows are the cross-talk functions (CTFs).

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Plot point-spread functions (PSFs) for a volume

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

mne.minimum_norm.write_inverse_operator

mne.minimum_norm.resolution_metrics

---

## mne.minimum_norm.prepare_inverse_operator#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.prepare_inverse_operator.html

**Contents:**
- mne.minimum_norm.prepare_inverse_operator#

Prepare an inverse operator for actually computing the inverse.

The inverse operator structure read from a file.

Number of averages (scales the noise covariance).

The regularization factor. Recommended to be 1 / SNR**2.

Use minimum norm, dSPM (default), sLORETA, or eLORETA.

Additional options for eLORETA. See Notes of apply_inverse().

If True (default), copy the inverse. False will not copy. Can be “non-src” to avoid copying the source space, which typically is not modified and can be large in memory.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Prepared inverse operator.

mne.minimum_norm.make_inverse_operator

mne.minimum_norm.read_inverse_operator

---

## mne.minimum_norm.read_inverse_operator#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.read_inverse_operator.html

**Contents:**
- mne.minimum_norm.read_inverse_operator#
- Examples using mne.minimum_norm.read_inverse_operator#

Read the inverse operator decomposition from a FIF file.

The name of the FIF file, which ends with -inv.fif or -inv.fif.gz.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The inverse operator.

Decoding source space data

Compute MNE-dSPM inverse solution on single epochs

Compute sLORETA inverse solution on raw data

Compute MNE-dSPM inverse solution on evoked data in volume source space

Generate a functional label from source estimates

Extracting the time series of activations in a label

Morph volumetric source estimate

Visualize source leakage among labels using a circular graph

Reading an inverse operator

Estimate data SNR using an inverse

Plotting the full vector-valued MNE solution

Compute Power Spectral Density of inverse solution from single epochs

Compute power and phase lock in label of the source space

Compute source power spectral density (PSD) in a label

Compute induced power in the source space with dSPM

Plot the MNE brain and helmet

Overview of MEG/EEG analysis with MNE-Python

Visualize source time courses (stcs)

Corrupt known signal with point spread

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.minimum_norm.prepare_inverse_operator

mne.minimum_norm.source_band_induced_power

---

## mne.minimum_norm.resolution_metrics#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.resolution_metrics.html

**Contents:**
- mne.minimum_norm.resolution_metrics#
- Examples using mne.minimum_norm.resolution_metrics#

Compute spatial resolution metrics for linear solvers.

The resolution matrix. If not a square matrix and if the number of rows is a multiple of number of columns (e.g. free or loose orientations), then the Euclidean length per source location is computed (e.g. if inverse operator with free orientations was applied to forward solution with fixed orientations).

Source space object from forward or inverse operator.

Whether to compute metrics for columns (point-spread functions, PSFs) or rows (cross-talk functions, CTFs) of the resolution matrix.

The resolution metric to compute. Allowed options are:

Localization-based metrics:

'peak_err' Peak localization error (PLE), Euclidean distance between peak and true source location.

'cog_err' Centre-of-gravity localisation error (CoG), Euclidean distance between CoG and true source location.

Spatial-extent-based metrics:

'sd_ext' Spatial deviation (e.g. [1][2]).

'maxrad_ext' Maximum radius to 50% of max amplitude.

Amplitude-based metrics:

'peak_amp' Ratio between absolute maximum amplitudes of peaks per location and maximum peak across locations.

'sum_amp' Ratio between sums of absolute amplitudes.

Amplitude fraction threshold for spatial extent metric ‘maxrad_ext’. Defaults to 0.5.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resolution metric.

For details, see [1][2].

Molins A, Stufflebeam S. M., Brown E. N., and Hämäläinen M. S. Quantification of the benefit from integrating MEG and EEG data in minimum l2-norm estimation. Neuroimage, 42(3):1069–1077, 2008. doi:10.1016/j.neuroimage.2008.05.064.

Olaf Hauk, Matti Stenroos, and Matthias Treder. Towards an objective evaluation of EEG/MEG source estimation methods: the linear tool kit. bioRxiv, 2019. doi:10.1101/672956.

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

mne.minimum_norm.make_inverse_resolution_matrix

mne.minimum_norm.get_cross_talk

---

## mne.minimum_norm.source_band_induced_power#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.source_band_induced_power.html

**Contents:**
- mne.minimum_norm.source_band_induced_power#
- Examples using mne.minimum_norm.source_band_induced_power#

Compute source space induced power in given frequency bands.

The inverse operator.

Example : bands = dict(alpha=[8, 9]).

Restricts the source estimates to a given label or list of labels. If labels are provided in a list, power will be averaged over vertices.

The regularization parameter of the minimum norm.

Use minimum norm, dSPM (default), sLORETA, or eLORETA.

The number of averages used to scale the noise covariance matrix.

Number of cycles. Fixed number or one per frequency.

Delta frequency within bands.

Do convolutions in time or frequency domain with FFT.

Temporal decimation factor.

The time interval to apply baseline correction. If None do not apply it. If baseline is (a, b) the interval is between “a (s)” and “b (s)”. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) all the time interval is used.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

If True, the true dimension of data is estimated before running the time-frequency transforms. It reduces the computation times e.g. with a dataset that was maxfiltered (true dim is 64).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

If True, do not call prepare_inverse_operator().

Additional options for eLORETA. See Notes of apply_inverse().

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Only used when the inverse is free orientation (loose=1.), not in surface orientation, and pick_ori='normal'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The estimated source space induced power estimates in shape (n_vertices, n_frequencies, n_samples) if label=None or label=label. For lists of one or more labels, the induced power estimate has shape (n_labels, n_frequencies, n_samples).

Compute induced power in the source space with dSPM

mne.minimum_norm.read_inverse_operator

mne.minimum_norm.source_induced_power

---

## mne.minimum_norm.source_induced_power#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.source_induced_power.html

**Contents:**
- mne.minimum_norm.source_induced_power#
- Examples using mne.minimum_norm.source_induced_power#

Compute induced power and phase lock.

Computation can optionally be restricted in a label.

The inverse operator.

Array of frequencies of interest.

Restricts the source estimates to a given label or list of labels. If labels are provided in a list, power will be averaged over vertices within each label.

The regularization parameter of the minimum norm.

Use minimum norm, dSPM (default), sLORETA, or eLORETA.

The number of averages used to scale the noise covariance matrix.

Number of cycles. Fixed number or one per frequency.

Temporal decimation factor.

Do convolutions in time or frequency domain with FFT.

If “normal”, rather than pooling the orientations by taking the norm, only the radial component is kept. This is only implemented when working with loose orientations.

The time interval to apply baseline correction. If None do not apply it. If baseline is (a, b) the interval is between “a (s)” and “b (s)”. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) all the time interval is used.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

If True, the true dimension of data is estimated before running the time-frequency transforms. It reduces the computation times e.g. with a dataset that was maxfiltered (true dim is 64).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

If True, return the phase-locking value array. Else, only return power.

Make sure the wavelets are zero mean.

If True, do not call prepare_inverse_operator().

Additional options for eLORETA. See Notes of apply_inverse().

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Only used when the inverse is free orientation (loose=1.), not in surface orientation, and pick_ori='normal'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The induced power array with shape (n_sources, n_freqs, n_samples) if label=None or label=label. For lists of one or more labels, the induced power estimate has shape (n_labels, n_frequencies, n_samples).

The phase-locking value array with shape (n_sources, n_freqs, n_samples). Only returned if return_plv=True.

Compute power and phase lock in label of the source space

mne.minimum_norm.source_band_induced_power

mne.minimum_norm.write_inverse_operator

---

## mne.minimum_norm.write_inverse_operator#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.write_inverse_operator.html

**Contents:**
- mne.minimum_norm.write_inverse_operator#

Write an inverse operator to a FIF file.

The name of the FIF file, which ends with -inv.fif or -inv.fif.gz.

The inverse operator.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.minimum_norm.source_induced_power

mne.minimum_norm.make_inverse_resolution_matrix

---

## mne.MixedSourceEstimate#

**URL:** https://mne.tools/stable/generated/mne.MixedSourceEstimate.html

**Contents:**
- mne.MixedSourceEstimate#
- Examples using mne.MixedSourceEstimate#

Container for mixed surface and volume source estimates.

The data in source space. The data can either be a single array or a tuple with two arrays: “kernel” shape (n_vertices, n_sensors) and “sens_data” shape (n_sensors, n_times). In this case, the source space data corresponds to np.dot(kernel, sens_data).

Vertex numbers corresponding to the data. The list contains arrays with one array per source space.

Time point of the first sample in data.

Time step between successive samples in data.

The FreeSurfer subject name. While not necessary, it is safer to set the subject parameter to avoid analysis errors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A timestamp for each sample.

Vertex numbers corresponding to the data. The list contains arrays with one array per source space.

Numpy array of source estimate data.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

apply_baseline([baseline, verbose])

Baseline correct source estimate data.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of vertices.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

bin(width[, tstart, tstop, func])

Return a source estimate object with data summarized over time bins.

Return copy of source estimate instance.

crop([tmin, tmax, include_tmax])

Restrict SourceEstimate to a time interval.

extract_label_time_course(labels, src[, ...])

Extract label time courses for lists of labels.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_peak([tmin, tmax, mode, vert_as_index, ...])

Get location and latency of peak amplitude.

Make a summary stc file with mean over time points.

plot([subject, surface, hemi, colormap, ...])

resample(sfreq, *[, npad, method, window, ...])

save(fname[, ftype, overwrite, verbose])

Save the full source estimate to an HDF5 file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

Take the square root.

Make a summary stc file with sum over time points.

Return the cortical surface source estimate.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

transform(func[, idx, tmin, tmax, copy])

Apply linear transform.

transform_data(func[, idx, tmin_idx, tmax_idx])

Get data after a linear (time) transform has been applied.

Return the volume surface source estimate.

A container for surface source estimates.

A container for vector surface source estimates.

A container for volume source estimates.

A container for Volume vector source estimates.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

Baseline correct source estimate data.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each source individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire source estimate data.

Baseline correction is appropriate when signal and noise are approximately additive, and the noise level can be estimated from the baseline interval. This can be the case for non-normalized source activities (e.g. signed and unsigned MNE), but it is not the case for normalized estimates (e.g. signal-to-noise ratios, dSPM, sLORETA).

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected source estimate object.

Baseline correction can be done multiple times.

Apply a function to a subset of vertices.

The function fun is applied to the vertices defined in picks. The source estimate object’s data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to vertices in picks).

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) because it will apply vertex-wise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if vertice_wise=False as the workload is split across vertices.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The SourceEstimate object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‘auto’, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal “x_a(t)” of “x(t)” is:

where “F” is the Fourier transform, “U” the unit step function, and “y” the Hilbert transform of “x”. One usage of the analytic signal is the computation of the envelope signal, which is given by “e(t) = abs(x_a(t))”. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Return a source estimate object with data summarized over time bins.

Time bins of width seconds. This method is intended for visualization only. No filter is applied to the data before binning, making the method inappropriate as a tool for downsampling data.

Width of the individual bins in seconds.

Time point where the first bin starts. The default is the first time point of the stc.

Last possible time point contained in a bin (if the last bin would be shorter than width it is dropped). The default is the last time point of the stc.

Function that is applied to summarize the data. Needs to accept a numpy.array as first input and an axis keyword argument.

The binned source estimate.

Return copy of source estimate instance.

A copy of the source estimate.

Restrict SourceEstimate to a time interval.

The first time point in seconds. If None the first present is used.

The last time point in seconds. If None the last present is used.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The cropped source estimate.

Numpy array of source estimate data.

Extract label time courses for lists of labels.

This function will extract one time course for each label. The way the time courses are extracted depends on the mode parameter.

If using a surface or mixed source space, this should be the Label’s for which to extract the time course. If working with whole-brain volume source estimates, this must be one of:

a string path to a FreeSurfer atlas for the subject (e.g., their ‘aparc.a2009s+aseg.mgz’) to extract time courses for all volumes in the atlas

a two-element list or tuple, the first element being a path to an atlas, and the second being a list or dict of volume_labels to extract (see mne.setup_volume_source_space() for details).

Changed in version 0.21.0: Support for volume source estimates.

The source spaces for the source time courses.

Extraction mode, see Notes.

False (default) will emit an error if there are labels that have no vertices in the source estimate. True and 'ignore' will return all-zero time courses for labels that do not have any vertices in the source estimate, and True will emit a warning while and “ignore” will just log a message.

Changed in version 0.21.0: Support for “ignore”.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Extracted time course for each label and source estimate.

Extract time courses for multiple STCs.

Valid values for mode are:

Maximum absolute value across vertices at each time point within each label.

Average across vertices at each time point within each label. Ignores orientation of sources for standard source estimates, which varies across the cortical surface, which can lead to cancellation. Vector source estimates are always in XYZ / RAS orientation, and are thus already geometrically aligned.

Finds the dominant direction of source space normal vector orientations within each label, applies a sign-flip to time series at vertices whose orientation is more than 90° different from the dominant direction, and then averages across vertices at each time point within each label.

Applies singular value decomposition to the time courses within each label, and uses the first right-singular vector as the representative label time course. This signal is scaled so that its power matches the average (per-vertex) power within the label, and sign-flipped by multiplying by np.sign(u @ flip), where u is the first left-singular vector and flip is the same sign-flip vector used when mode='mean_flip'. This sign-flip ensures that extracting time courses from the same label in similar STCs does not result in 180° direction/phase changes.

Uses 'mean_flip' when a standard source estimate is applied, and 'mean' when a vector source estimate is supplied.

No aggregation is performed, and an array of shape (n_vertices, n_times) is returned.

New in v0.21: Support for 'auto', vector, and volume source estimates.

The only modes that work for vector and volume source estimates are 'mean', 'max', and 'auto'.

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Get location and latency of peak amplitude.

The minimum point in time to be considered for peak getting.

The maximum point in time to be considered for peak getting.

How to deal with the sign of the data. If ‘pos’ only positive values will be considered. If ‘neg’ only negative values will be considered. If ‘abs’ absolute values will be considered. Defaults to ‘abs’.

Whether to return the vertex index (True) instead of of its ID (False, default).

Whether to return the time index (True) instead of the latency (False, default).

The vertex exhibiting the maximum response, either ID or index.

The latency in seconds.

Make a summary stc file with mean over time points.

The FreeSurfer subject name. If None, stc.subject will be used.

The type of surface (inflated, white etc.).

Hemisphere id (ie 'lh', 'rh', 'both', or 'split'). In the case of 'both', both hemispheres are shown in the same window. In the case of 'split' hemispheres are displayed side-by-side in different viewing panes.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255. The default (‘auto’) uses 'hot' for one-sided data and ‘mne’ for two-sided data.

Format of the time label (a format string, a function that maps floating point time values to strings, or None for no label). The default is 'auto', which will use time=%0.2f ms if there is more than one time point.

The amount of smoothing.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Alpha value to apply globally to the overlay. Has no effect with mpl backend.

Display time viewer GUI. Can also be ‘auto’, which will mean True for the PyVista backend and False otherwise.

Changed in version 0.20.0: “auto” mode added.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

If None, a new figure will be created. If multiple views or a split view is requested, this must be a list of the appropriate length. If int is provided it will be used to identify the PyVista figure by it’s id or create a new figure with the given id. If an instance of matplotlib figure, mpl backend is used for plotting.

View to use. Using multiple views (list) is not supported for mpl backend. See Brain.show_view for valid string options.

When plotting a standard SourceEstimate (not volume, mixed, or vector) and using the PyVista backend, views='flat' is also supported to plot cortex as a flatmap.

Using multiple views (list) is not supported by the matplotlib backend.

Changed in version 0.21.0: Support for flatmaps.

If True, display colorbar on scene.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bounds for colormap.

Lower, middle, and upper bound for colormap. Positive values will be mirrored directly across zero during colormap construction to obtain negative control points.

Only one of lims or pos_lims should be provided. Only sequential colormaps should be used with lims, and only divergent colormaps should be used with pos_lims.

Specifies how binarized curvature values are rendered. Either the name of a preset Brain cortex colorscheme (one of 'classic', 'bone', 'low_contrast', or 'high_contrast'), or the name of a colormap, or a tuple with values (colormap, min, max, reverse) to fully specify the curvature colors. Has no effect with the matplotlib backend.

The size of the window, in pixels. can be one number to specify a square window, or the (width, height) of a rectangular window. Has no effect with mpl backend.

Color of the background of the display window.

Color of the foreground of the display window. Has no effect with mpl backend. None will choose white or black based on the background color.

The time to display on the plot initially. None to display the first time sample (default).

Whether time is represented in seconds (“s”, default) or milliseconds (“ms”).

Which backend to use. If 'auto' (default), tries to plot with pyvistaqt, but resorts to matplotlib if no 3d backend is available.

Only affects the matplotlib backend. The spacing to use for the source space. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, or 'all' for all points. In general, you can speed up the plotting by selecting a sparser source space. Defaults to ‘oct6’.

Title for the figure window. If None, the subject name will be used.

If True, enable interactive picking of a point on the surface of the brain and plot its time course. This feature is only available with the PyVista 3d backend, and requires time_viewer=True. Defaults to ‘auto’, which will use True if and only if time_viewer=True, the backend is PyVista, and there is more than one time point. If float (between zero and one), it specifies what proportion of the total window should be devoted to traces (True is equivalent to 0.25, i.e., it will occupy the bottom 1/4 of the figure).

The source space corresponding to the source estimate. Only necessary if the STC is a volume or mixed source estimate.

Options for volumetric source estimate plotting, with key/value pairs:

Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks better at the cost of speed. None (default) uses the volume source space resolution, which is often something like 7 or 5 mm, without resampling.

Can be “mip” (default) for maximum intensity projection or “composite” for composite blending using alpha values.

Alpha for the volumetric rendering. Defaults are 0.4 for vector source estimates and 1.0 for scalar source estimates.

Alpha for the surface enclosing the volume(s). None (default) will use half the volume alpha. Set to zero to avoid plotting the surface.

Alpha for a silhouette along the outside of the volume. None (default) will use 0.25 * surface_alpha.

The line width to use for the silhouette. Default is 2.

A float input (default 1.) or None will be used for the 'resolution' entry.

Can be “vertical” (default) or “horizontal”. When using “horizontal” mode, the PyVista backend must be used and hemi cannot be “split”.

Additional arguments to brain.add_data (e.g., dict(time_label_size=10)).

Additional arguments to the mne.viz.Brain constructor (e.g., dict(silhouette=True)).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

An instance of mne.viz.Brain or matplotlib figure.

Flatmaps are available by default for fsaverage but not for other subjects reconstructed by FreeSurfer. We recommend using mne.compute_source_morph() to morph source estimates to fsaverage for flatmap plotting. If you want to construct your own flatmap for a given subject, these links might help:

https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferOccipitalFlattenedPatch

https://openwetware.org/wiki/Beauchamp:FreeSurfer

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be “auto” to use a padding that will result in a power-of-two size (can be much faster).

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn(). The default (“auto”) means 'reflect_limited' for method='fft' and 'reflect' for method='polyphase'.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled source estimate.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent – check your data!

Note that the sample rate of the original data is inferred from tstep.

Save the full source estimate to an HDF5 file.

The file name to write the source estimate to, should end in '-stc.h5'.

File format to use. Currently, the only allowed values is "h5".

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [1] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627–1639, 1964. doi:10.1021/ac60214a047.

Sample rate of the data.

Take the square root.

A copy of the SourceEstimate with sqrt(data).

Make a summary stc file with sum over time points.

Return the cortical surface source estimate.

The surface source estimate.

Examples using surface:

Compute MNE inverse solution on evoked data with a mixed source space

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

A timestamp for each sample.

Export data in tabular structure as a pandas DataFrame.

Vertices are converted to columns in the DataFrame. By default, an additional column “time” is added, unless index='time' (in which case time values form the DataFrame’s index).

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) — i.e., converts EEG to µV, magnetometers to fT, and gradiometers to fT/cm.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and vertex. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Apply linear transform.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first two dimensions of the transformed data should be (i) vertices and (ii) time. See Notes for details.

Indices of source time courses for which to compute transform. If None, all time courses are used.

First time point to include (ms). If None, self.tmin is used.

Last time point to include (ms). If None, self.tmax is used.

If True, return a new instance of SourceEstimate instead of modifying the input inplace.

The transformed stc or, in the case of transforms which yield N-dimensional output (where N > 2), a list of stcs. For a list, copy must be True.

Transforms which yield 3D output (e.g. time-frequency transforms) are valid, so long as the first two dimensions are vertices and time. In this case, the copy parameter must be True and a list of SourceEstimates, rather than a single instance of SourceEstimate, will be returned, one for each index of the 3rd dimension of the transformed data. In the case of transforms yielding 2D output (e.g. filtering), the user has the option of modifying the input inplace (copy = False) or returning a new instance of SourceEstimate (copy = True) with the transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

Get data after a linear (time) transform has been applied.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first return value is the transformed data, remaining outputs are ignored. The first dimension of the transformed data has to be the same as the first dimension of the input data.

Indicices of source time courses for which to compute transform. If None, all time courses are used.

Index of first time point to include. If None, the index of the first time point is used.

Index of the first time point not to include. If None, time points up to (and including) the last time point are included.

The transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

The change in time between two consecutive samples (1 / sfreq).

Return the volume surface source estimate.

The volume source estimate.

Examples using volume:

Compute MNE inverse solution on evoked data with a mixed source space

Compute MNE inverse solution on evoked data with a mixed source space

mne.MixedVectorSourceEstimate

---

## mne.MixedVectorSourceEstimate#

**URL:** https://mne.tools/stable/generated/mne.MixedVectorSourceEstimate.html

**Contents:**
- mne.MixedVectorSourceEstimate#
- Examples using mne.MixedVectorSourceEstimate#

Container for volume source estimates.

The data in source space. Each dipole contains three vectors that denote the dipole strength in X, Y and Z directions over time.

Vertex numbers corresponding to the data.

Time point of the first sample in data.

Time step between successive samples in data.

The FreeSurfer subject name. While not necessary, it is safer to set the subject parameter to avoid analysis errors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A timestamp for each sample.

The indices of the dipoles in the source space.

Numpy array of source estimate data.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

apply_baseline([baseline, verbose])

Baseline correct source estimate data.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of vertices.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

bin(width[, tstart, tstop, func])

Return a source estimate object with data summarized over time bins.

Return copy of source estimate instance.

crop([tmin, tmax, include_tmax])

Restrict SourceEstimate to a time interval.

extract_label_time_course(labels, src[, ...])

Extract label time courses for lists of labels.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_peak([tmin, tmax, mode, vert_as_index, ...])

Get location and latency of peak amplitude.

Compute magnitude of activity without directionality.

Make a summary stc file with mean over time points.

plot([subject, hemi, colormap, time_label, ...])

Plot VectorSourceEstimate with PyVista.

project(directions[, src, use_cps])

Project the data for each vertex in a given direction.

resample(sfreq, *[, npad, method, window, ...])

save(fname[, ftype, overwrite, verbose])

Save the full source estimate to an HDF5 file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

Take the square root.

Make a summary stc file with sum over time points.

Return the cortical surface source estimate.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

transform(func[, idx, tmin, tmax, copy])

Apply linear transform.

transform_data(func[, idx, tmin_idx, tmax_idx])

Get data after a linear (time) transform has been applied.

Return the volume surface source estimate.

A container for mixed surface + volume source estimates.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

Baseline correct source estimate data.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each source individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire source estimate data.

Baseline correction is appropriate when signal and noise are approximately additive, and the noise level can be estimated from the baseline interval. This can be the case for non-normalized source activities (e.g. signed and unsigned MNE), but it is not the case for normalized estimates (e.g. signal-to-noise ratios, dSPM, sLORETA).

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected source estimate object.

Baseline correction can be done multiple times.

Apply a function to a subset of vertices.

The function fun is applied to the vertices defined in picks. The source estimate object’s data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to vertices in picks).

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) because it will apply vertex-wise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if vertice_wise=False as the workload is split across vertices.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The SourceEstimate object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‘auto’, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal “x_a(t)” of “x(t)” is:

where “F” is the Fourier transform, “U” the unit step function, and “y” the Hilbert transform of “x”. One usage of the analytic signal is the computation of the envelope signal, which is given by “e(t) = abs(x_a(t))”. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Return a source estimate object with data summarized over time bins.

Time bins of width seconds. This method is intended for visualization only. No filter is applied to the data before binning, making the method inappropriate as a tool for downsampling data.

Width of the individual bins in seconds.

Time point where the first bin starts. The default is the first time point of the stc.

Last possible time point contained in a bin (if the last bin would be shorter than width it is dropped). The default is the last time point of the stc.

Function that is applied to summarize the data. Needs to accept a numpy.array as first input and an axis keyword argument.

The binned source estimate.

Return copy of source estimate instance.

A copy of the source estimate.

Restrict SourceEstimate to a time interval.

The first time point in seconds. If None the first present is used.

The last time point in seconds. If None the last present is used.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The cropped source estimate.

Numpy array of source estimate data.

Extract label time courses for lists of labels.

This function will extract one time course for each label. The way the time courses are extracted depends on the mode parameter.

If using a surface or mixed source space, this should be the Label’s for which to extract the time course. If working with whole-brain volume source estimates, this must be one of:

a string path to a FreeSurfer atlas for the subject (e.g., their ‘aparc.a2009s+aseg.mgz’) to extract time courses for all volumes in the atlas

a two-element list or tuple, the first element being a path to an atlas, and the second being a list or dict of volume_labels to extract (see mne.setup_volume_source_space() for details).

Changed in version 0.21.0: Support for volume source estimates.

The source spaces for the source time courses.

Extraction mode, see Notes.

False (default) will emit an error if there are labels that have no vertices in the source estimate. True and 'ignore' will return all-zero time courses for labels that do not have any vertices in the source estimate, and True will emit a warning while and “ignore” will just log a message.

Changed in version 0.21.0: Support for “ignore”.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Extracted time course for each label and source estimate.

Extract time courses for multiple STCs.

Valid values for mode are:

Maximum absolute value across vertices at each time point within each label.

Average across vertices at each time point within each label. Ignores orientation of sources for standard source estimates, which varies across the cortical surface, which can lead to cancellation. Vector source estimates are always in XYZ / RAS orientation, and are thus already geometrically aligned.

Finds the dominant direction of source space normal vector orientations within each label, applies a sign-flip to time series at vertices whose orientation is more than 90° different from the dominant direction, and then averages across vertices at each time point within each label.

Applies singular value decomposition to the time courses within each label, and uses the first right-singular vector as the representative label time course. This signal is scaled so that its power matches the average (per-vertex) power within the label, and sign-flipped by multiplying by np.sign(u @ flip), where u is the first left-singular vector and flip is the same sign-flip vector used when mode='mean_flip'. This sign-flip ensures that extracting time courses from the same label in similar STCs does not result in 180° direction/phase changes.

Uses 'mean_flip' when a standard source estimate is applied, and 'mean' when a vector source estimate is supplied.

No aggregation is performed, and an array of shape (n_vertices, n_times) is returned.

New in v0.21: Support for 'auto', vector, and volume source estimates.

The only modes that work for vector and volume source estimates are 'mean', 'max', and 'auto'.

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Get location and latency of peak amplitude.

The minimum point in time to be considered for peak getting.

The maximum point in time to be considered for peak getting.

How to deal with the sign of the data. If ‘pos’ only positive values will be considered. If ‘neg’ only negative values will be considered. If ‘abs’ absolute values will be considered. Defaults to ‘abs’.

Whether to return the vertex index (True) instead of of its ID (False, default).

Whether to return the time index (True) instead of the latency (False, default).

The vertex exhibiting the maximum response, either ID or index.

The latency in seconds.

Compute magnitude of activity without directionality.

The source estimate without directionality information.

Make a summary stc file with mean over time points.

Plot VectorSourceEstimate with PyVista.

A “glass brain” is drawn and all dipoles defined in the source estimate are shown using arrows, depicting the direction and magnitude of the current moment at the dipole. Additionally, an overlay is plotted on top of the cortex with the magnitude of the current.

The FreeSurfer subject name. If None, stc.subject will be used.

The hemisphere to display.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255. This should be a sequential colormap.

Format of the time label (a format string, a function that maps floating point time values to strings, or None for no label). The default is 'auto', which will use time=%0.2f ms if there is more than one time point.

The amount of smoothing.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Alpha value to apply globally to the surface meshes. Defaults to 0.4.

Alpha value to apply globally to the overlay. Defaults to brain_alpha.

Alpha value to apply globally to the vector glyphs. Defaults to 1.

Scaling factor for the vector glyphs. By default, an attempt is made to automatically determine a sane value.

Display time viewer GUI. Can be “auto”, which is True for the PyVista backend and False otherwise.

Changed in version 0.20: Added “auto” option and default.

The path to the freesurfer subjects reconstructions. It corresponds to Freesurfer environment variable SUBJECTS_DIR.

If None, a new figure will be created. If multiple views or a split view is requested, this must be a list of the appropriate length. If int is provided it will be used to identify the PyVista figure by it’s id or create a new figure with the given id.

View to use. Using multiple views (list) is not supported for mpl backend. See Brain.show_view for valid string options.

If True, display colorbar on scene.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bound for colormap.

Unlike stc.plot, it cannot use pos_lims, as the surface plot must show the magnitude.

Specifies how binarized curvature values are rendered. either the name of a preset Brain cortex colorscheme (one of ‘classic’, ‘bone’, ‘low_contrast’, or ‘high_contrast’), or the name of a colormap, or a tuple with values (colormap, min, max, reverse) to fully specify the curvature colors.

The size of the window, in pixels. can be one number to specify a square window, or the (width, height) of a rectangular window.

Color of the background of the display window.

Color of the foreground of the display window. None will choose black or white based on the background color.

The time to display on the plot initially. None to display the first time sample (default).

Whether time is represented in seconds (“s”, default) or milliseconds (“ms”).

Title for the figure window. If None, the subject name will be used.

If True, enable interactive picking of a point on the surface of the brain and plot its time course. This feature is only available with the PyVista 3d backend, and requires time_viewer=True. Defaults to ‘auto’, which will use True if and only if time_viewer=True, the backend is PyVista, and there is more than one time point. If float (between zero and one), it specifies what proportion of the total window should be devoted to traces (True is equivalent to 0.25, i.e., it will occupy the bottom 1/4 of the figure).

The source space corresponding to the source estimate. Only necessary if the STC is a volume or mixed source estimate.

Options for volumetric source estimate plotting, with key/value pairs:

Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks better at the cost of speed. None (default) uses the volume source space resolution, which is often something like 7 or 5 mm, without resampling.

Can be “mip” (default) for maximum intensity projection or “composite” for composite blending using alpha values.

Alpha for the volumetric rendering. Defaults are 0.4 for vector source estimates and 1.0 for scalar source estimates.

Alpha for the surface enclosing the volume(s). None (default) will use half the volume alpha. Set to zero to avoid plotting the surface.

Alpha for a silhouette along the outside of the volume. None (default) will use 0.25 * surface_alpha.

The line width to use for the silhouette. Default is 2.

A float input (default 1.) or None will be used for the 'resolution' entry.

Can be “vertical” (default) or “horizontal”. When using “horizontal” mode, the PyVista backend must be used and hemi cannot be “split”.

Additional arguments to brain.add_data (e.g., dict(time_label_size=10)).

Additional arguments to the mne.viz.Brain constructor (e.g., dict(silhouette=True)).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A instance of mne.viz.Brain.

If the current magnitude overlay is not desired, set overlay_alpha=0 and smoothing_steps=1.

Compute MNE inverse solution on evoked data with a mixed source space

Project the data for each vertex in a given direction.

Project onto the source space normals.

SVD will be used to project onto the direction of maximal power for each source.

Projection directions for each source.

The source spaces corresponding to the source estimate. Not used when directions is an array, optional when directions='pca'.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True). Should be the same value that was used when the forward model was computed (typically True).

The projected source estimate.

The directions that were computed (or just used).

When using SVD, there is a sign ambiguity for the direction of maximal power. When src is None, the direction is chosen that makes the resulting time waveform sum positive (i.e., have positive amplitudes). When src is provided, the directions are flipped in the direction of the source normals, i.e., outward from cortex for surface source spaces and in the +Z / superior direction for volume source spaces.

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be “auto” to use a padding that will result in a power-of-two size (can be much faster).

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn(). The default (“auto”) means 'reflect_limited' for method='fft' and 'reflect' for method='polyphase'.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled source estimate.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent – check your data!

Note that the sample rate of the original data is inferred from tstep.

Save the full source estimate to an HDF5 file.

The file name to write the source estimate to, should end in '-stc.h5'.

File format to use. Currently, the only allowed values is "h5".

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [1] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627–1639, 1964. doi:10.1021/ac60214a047.

Sample rate of the data.

Take the square root.

A copy of the SourceEstimate with sqrt(data).

Make a summary stc file with sum over time points.

Return the cortical surface source estimate.

The surface source estimate.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

A timestamp for each sample.

Export data in tabular structure as a pandas DataFrame.

Vertices are converted to columns in the DataFrame. By default, an additional column “time” is added, unless index='time' (in which case time values form the DataFrame’s index).

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) — i.e., converts EEG to µV, magnetometers to fT, and gradiometers to fT/cm.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and vertex. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Apply linear transform.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first two dimensions of the transformed data should be (i) vertices and (ii) time. See Notes for details.

Indices of source time courses for which to compute transform. If None, all time courses are used.

First time point to include (ms). If None, self.tmin is used.

Last time point to include (ms). If None, self.tmax is used.

If True, return a new instance of SourceEstimate instead of modifying the input inplace.

The transformed stc or, in the case of transforms which yield N-dimensional output (where N > 2), a list of stcs. For a list, copy must be True.

Transforms which yield 3D output (e.g. time-frequency transforms) are valid, so long as the first two dimensions are vertices and time. In this case, the copy parameter must be True and a list of SourceEstimates, rather than a single instance of SourceEstimate, will be returned, one for each index of the 3rd dimension of the transformed data. In the case of transforms yielding 2D output (e.g. filtering), the user has the option of modifying the input inplace (copy = False) or returning a new instance of SourceEstimate (copy = True) with the transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

Get data after a linear (time) transform has been applied.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first return value is the transformed data, remaining outputs are ignored. The first dimension of the transformed data has to be the same as the first dimension of the input data.

Indicices of source time courses for which to compute transform. If None, all time courses are used.

Index of first time point to include. If None, the index of the first time point is used.

Index of the first time point not to include. If None, time points up to (and including) the last time point are included.

The transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

The change in time between two consecutive samples (1 / sfreq).

Return the volume surface source estimate.

The volume source estimate.

Compute MNE inverse solution on evoked data with a mixed source space

mne.MixedSourceEstimate

---

## mne.morph_labels#

**URL:** https://mne.tools/stable/generated/mne.morph_labels.html

**Contents:**
- mne.morph_labels#

Morph a set of labels.

This is useful when morphing a set of non-overlapping labels (such as those obtained with read_labels_from_annot()) from one subject to another.

The subject to morph labels to.

The subject to morph labels from. Can be None if the labels have the .subject property defined.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Surface used to obtain vertex locations, e.g., 'white', 'pial'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

This does not use the same algorithm as Freesurfer, so the results morphing (e.g., from 'fsaverage' to your subject) might not match what Freesurfer produces during recon-all.

mne.random_parcellation

---

## mne.morph_source_spaces#

**URL:** https://mne.tools/stable/generated/mne.morph_source_spaces.html

**Contents:**
- mne.morph_source_spaces#
- Examples using mne.morph_source_spaces#

Morph an existing source space to a different subject.

This can be used in place of morphing source estimates for multiple subjects, but there may be consequences in terms of dipole topology.

Surface source spaces to morph.

The destination subject.

The brain surface to use for the new source space.

The “from” subject. For most source spaces this shouldn’t need to be provided, since it is stored in the source space itself.

Path to SUBJECTS_DIR if it is not set in the environment.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The morphed source spaces.

Use source space morphing

mne.make_sphere_model

---

## mne.open_docs#

**URL:** https://mne.tools/stable/generated/mne.open_docs.html

**Contents:**
- mne.open_docs#

Launch a new web browser tab with the MNE documentation.

Can be “api” (default), “tutorials”, or “examples”. The default can be changed by setting the configuration value MNE_DOCS_KIND.

Can be “stable” (default) or “dev”. The default can be changed by setting the configuration value MNE_DOCS_VERSION.

---

## mne.open_report#

**URL:** https://mne.tools/stable/generated/mne.open_report.html

**Contents:**
- mne.open_report#
- Examples using mne.open_report#

Read a saved report or, if it doesn’t exist yet, create a new one.

The returned report can be used as a context manager, in which case any changes to the report are saved when exiting the context block.

The file containing the report, stored in the HDF5 format. If the file does not exist yet, a new report is created that will be saved to the specified file.

When creating a new report, any named parameters other than fname are passed to the __init__ function of the Report object. When reading an existing report, the parameters are checked with the loaded report and an exception is raised when they don’t match.

Getting started with mne.Report

Logging and Configuration

---

## mne.parse_config#

**URL:** https://mne.tools/stable/generated/mne.parse_config.html

**Contents:**
- mne.parse_config#

Parse a config file (like .ave and .cov files).

Each condition is indexed by the event type. A condition contains as keys:

mne.get_volume_labels_from_src

mne.read_labels_from_annot

---

## mne.pick_channels#

**URL:** https://mne.tools/stable/generated/mne.pick_channels.html

**Contents:**
- mne.pick_channels#
- Examples using mne.pick_channels#

Pick channels by names.

Returns the indices of ch_names in include but not in exclude.

List of channels to include (if empty include all available).

This is to be treated as a set. The order of this list is not used or maintained in sel.

List of channels to exclude (if empty do not exclude any channel). Defaults to [].

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Indices of good channels.

EEG analysis - Event-Related Potentials (ERPs)

The Info data structure

KIT phantom dataset tutorial

Working with eye tracker data in MNE-Python

Non-parametric 1 sample cluster statistic on single trial power

mne.match_channel_orders

mne.pick_channels_cov

---

## mne.pick_channels_cov#

**URL:** https://mne.tools/stable/generated/mne.pick_channels_cov.html

**Contents:**
- mne.pick_channels_cov#

Pick channels from covariance matrix.

List of channels to include (if empty, include all available).

Channels to exclude (if empty, do not exclude any). Defaults to ‘bads’.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

If True (the default), return a copy of the covariance matrix with the modified channels. If False, channels are modified in-place.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Covariance solution restricted to selected channels.

mne.pick_channels_forward

---

## mne.pick_channels_forward#

**URL:** https://mne.tools/stable/generated/mne.pick_channels_forward.html

**Contents:**
- mne.pick_channels_forward#

Pick channels from forward operator.

List of channels to include (if empty, include all available). Defaults to [].

Channels to exclude (if empty, do not exclude any). Defaults to []. If ‘bads’, then exclude bad channels in orig.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

If True (default), make a copy.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Forward solution restricted to selected channels. If include and exclude are empty it returns orig without copy.

mne.pick_channels_cov

mne.pick_channels_regexp

---

## mne.pick_channels_regexp#

**URL:** https://mne.tools/stable/generated/mne.pick_channels_regexp.html

**Contents:**
- mne.pick_channels_regexp#
- Examples using mne.pick_channels_regexp#

Pick channels using regular expression.

Returns the indices of the good channels in ch_names.

The regular expression. See python standard module for regular expressions.

Indices of good channels.

The Info data structure

Handling bad channels

Repairing artifacts with ICA

Repairing artifacts with SSP

Preprocessing optically pumped magnetometer (OPM) MEG data

mne.pick_channels_forward

---

## mne.pick_events#

**URL:** https://mne.tools/stable/generated/mne.pick_events.html

**Contents:**
- mne.pick_events#
- Examples using mne.pick_events#

The identity and timing of experimental events, around which the epochs were created. See events for more information.

A event id to include or a list of them. If None all events are included.

A event id to exclude or a list of them. If None no event is excluded. If include is not None the exclude parameter is ignored.

If True (default is False), events have a step format according to the argument output=’step’ in the function find_events(). In this case, the two last columns are considered in inclusion/ exclusion criteria.

Visualizing epoched data

---

## mne.pick_info#

**URL:** https://mne.tools/stable/generated/mne.pick_info.html

**Contents:**
- mne.pick_info#
- Examples using mne.pick_info#

Restrict an info structure to a selection of channels.

The mne.Info object with information about the sensors and methods of measurement.

Indices of channels to include. If None, all channels are included.

If copy is False, info is modified inplace.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Info structure restricted to a selection of channels.

Use source space morphing

Plotting topographic arrowmaps of evoked data

Working with sEEG data

Modifying data in-place

The Info data structure

DICS for power mapping

mne.pick_types_forward

mne.read_vectorview_selection

---

## mne.pick_types#

**URL:** https://mne.tools/stable/generated/mne.pick_types.html

**Contents:**
- mne.pick_types#
- Examples using mne.pick_types#

Pick channels by type and names.

The mne.Info object with information about the sensors and methods of measurement.

If True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‘auto’, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‘hbo’ (to include channels measuring oxyhemoglobin) or ‘hbr’ (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‘eyegaze’ (to include eye position channels) or ‘pupil’ (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‘bads’ (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Indices of good channels.

Brainstorm raw (median nerve) dataset

Optically pumped magnetometer (OPM) data

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Representational Similarity Analysis

Decoding source space data

Decoding sensor space data with generalization across time and conditions

Analysis of evoked response using ICA and PCA reduction techniques

XDAWN Decoding From EEG data

Display sensitivity maps for EEG and MEG sensors

Use source space morphing

Compute MNE-dSPM inverse solution on single epochs

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute cross-talk functions for LCMV beamformers

Cortical Signal Suppression (CSS) for removal of cortical signals

Define target events based on time lag, plot evoked response

Show EOG artifact timing

Find MEG reference channel artifacts

Generate simulated evoked data

Permutation F-test on sensor data with 1D cluster level

FDR correction on T-test on sensor data

Regression on continuous data (rER[P/F])

Permutation T-test on sensor data

Compute a cross-spectral density (CSD) matrix

Compute Power Spectral Density of inverse solution from single epochs

Compute power and phase lock in label of the source space

Compute source power spectral density (PSD) in a label

Compute induced power in the source space with dSPM

Temporal whitening with AR model

Plotting topographic arrowmaps of evoked data

Plot custom topographies for MEG sensors

Visualizing Evoked data

The Info data structure

KIT phantom dataset tutorial

Overview of artifact detection

Handling bad channels

Rejecting bad data spans and breaks

Filtering and resampling data

Repairing artifacts with regression

Repairing artifacts with SSP

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Preprocessing optically pumped magnetometer (OPM) MEG data

The Raw data structure: continuous data

DICS for power mapping

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

Frequency and time-frequency sensor analysis

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

mne.pick_channels_regexp

mne.pick_types_forward

---

## mne.pick_types_forward#

**URL:** https://mne.tools/stable/generated/mne.pick_types_forward.html

**Contents:**
- mne.pick_types_forward#
- Examples using mne.pick_types_forward#

Pick by channel type and names from a forward operator.

If True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include CTF / 4D reference channels.

If True include stereotactic EEG channels.

If True include electrocorticography channels.

If True include deep brain stimulation channels.

List of additional channels to include. If empty do not include any.

List of channels to exclude. If empty do not exclude any (default). If ‘bads’, exclude channels in orig[‘info’][‘bads’].

Forward solution restricted to selected channel types.

Compute spatial resolution metrics to compare MEG with EEG+MEG

Cortical Signal Suppression (CSS) for removal of cortical signals

Generate simulated evoked data

---

## mne.Projection#

**URL:** https://mne.tools/stable/generated/mne.Projection.html

**Contents:**
- mne.Projection#
- Examples using mne.Projection#

Dictionary-like object holding a projection vector.

Projection vectors are stored in a list in inst.info["projs"]. Each projection vector has 5 keys: active, data, desc, explained_var, kind.

This class is generally not meant to be instantiated directly, use compute_proj_* functions instead.

The projector description.

Whether or not the projector has been applied.

The proportion of explained variance.

plot_topomap(info, *[, sensors, show_names, ...])

Plot topographic maps of SSP projections.

Plot topographic maps of SSP projections.

The mne.Info object with information about the sensors and methods of measurement. Used to determine the layout.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all projectors of the same channel type (instead of separately for each projector), using the min/max of the data for that channel type. If vlim is "joint", info must not be None. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of projectors. Default is None.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Getting started with mne.Report

Background on projectors and projections

mne.compute_proj_epochs

---

## mne.random_parcellation#

**URL:** https://mne.tools/stable/generated/mne.random_parcellation.html

**Contents:**
- mne.random_parcellation#

Generate random cortex parcellation by growing labels.

This function generates a number of labels which don’t intersect and cover the whole surface. Regions are growing around randomly chosen seeds.

The FreeSurfer subject name.

Total number of cortical parcels.

Hemisphere id (ie 'lh', 'rh', 'both'). In the case of 'both', both hemispheres are processed with (n_parcel // 2) parcels per hemisphere.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The surface along which to do the computations, defaults to 'white' (the gray-white matter boundary).

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

Random cortex parcellation.

mne.read_source_morph

---

## mne.read_annotations#

**URL:** https://mne.tools/stable/generated/mne.read_annotations.html

**Contents:**
- mne.read_annotations#
- Examples using mne.read_annotations#

Read annotations from a file.

This function reads a .fif, .fif.gz, .vmrk, .amrk, .edf, .bdf, .gdf, .txt, .csv, .cnt, .cef, or .set file and makes an mne.Annotations object.

The sampling frequency in the file. This parameter is necessary for *.vmrk, *.amrk, and *.cef files as Annotations are expressed in seconds and *.vmrk/*.amrk/*.cef files are in samples. For any other file format, sfreq is omitted. If set to ‘auto’ then the sfreq is taken from the respective info file of the same name with according file extension (*.vhdr/*.ahdr for brainvision; *.dap for Curry 7; *.cdt.dpa for Curry 8). So data.vmrk/amrk looks for sfreq in data.vhdr/ahdr, data.cef looks in data.dap and data.cdt.cef looks in data.cdt.dpa.

This parameter is only used in EEGLAB (*.set) and omitted otherwise. If your *.set file contains non-ascii characters, sometimes reading it may fail and give rise to error message stating that “buffer is too small”. uint16_codec allows to specify what codec (for example: 'latin1' or 'utf-8') should be used when reading character arrays and can therefore help you solve this problem.

Encoding of annotations channel(s). Default is “utf8” (the only correct encoding according to the EDF+ standard). Only used when reading EDF annotations.

If True, ignore marker types in BrainVision files (and only use their descriptions). Defaults to False.

The annotations stored in a .csv require the onset columns to be timestamps. If you have onsets as floats (in seconds), you should use the .txt extension.

Sleep stage classification from polysomnography (PSG) data

Annotating continuous data

mne.concatenate_epochs

---

## mne.read_bem_solution#

**URL:** https://mne.tools/stable/generated/mne.read_bem_solution.html

**Contents:**
- mne.read_bem_solution#
- Examples using mne.read_bem_solution#

Read the BEM solution from a file.

The file containing the BEM solution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Optically pumped magnetometer (OPM) data

Computing source timecourses with an XFit-like multi-dipole model

Compute source power spectral density (PSD) of VectorView and OPM data

EEG forward operator with a template MRI

mne.read_labels_from_annot

mne.read_bem_surfaces

---

## mne.read_bem_surfaces#

**URL:** https://mne.tools/stable/generated/mne.read_bem_surfaces.html

**Contents:**
- mne.read_bem_surfaces#
- Examples using mne.read_bem_surfaces#

Read the BEM surfaces from a FIF file.

The name of the file containing the surfaces.

Calculate and add cortical patch statistics to the surfaces.

If int, only read and return the surface with the given s_id. An error will be raised if it doesn’t exist. If None, all surfaces are read and returned.

What to do if the surface is found to have topological defects. Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when one or more defects are found. Note that a lot of computations in MNE-Python assume the surfaces to be topologically correct, topological defects may still make other computations (e.g., mne.make_bem_model and mne.make_bem_solution) fail irrespective of this parameter.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of dictionaries that each contain a surface. If s_id is not None, only the requested surface will be returned.

Fixing BEM and head surfaces

mne.read_bem_solution

---

## mne.read_cov#

**URL:** https://mne.tools/stable/generated/mne.read_cov.html

**Contents:**
- mne.read_cov#
- Examples using mne.read_cov#

Read a noise covariance from a FIF file.

The path-like of file containing the covariance matrix. It should end with -cov.fif or -cov.fif.gz.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The noise covariance matrix.

Decoding source space data

Source localization with a custom inverse solver

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Computing source timecourses with an XFit-like multi-dipole model

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Plot point-spread functions (PSFs) for a volume

Compute Rap-Music on evoked data

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Reading/Writing a noise covariance matrix

Cortical Signal Suppression (CSS) for removal of cortical signals

Generate simulated evoked data

Simulate raw data using subject anatomy

The role of dipole orientations in distributed source localization

Computing various MNE solutions

mne.read_bem_surfaces

---

## mne.read_dipole#

**URL:** https://mne.tools/stable/generated/mne.read_dipole.html

**Contents:**
- mne.read_dipole#
- Examples using mne.read_dipole#

Read a dipole object from a file.

Non-fixed-position mne.Dipole objects are usually saved in .[b]dip format. Fixed-position mne.DipoleFixed objects are usually saved in FIF format.

The name of the .[b]dip or .fif[.gz] file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Dipole object containing position, orientation and amplitude of one or more dipoles. Multiple simultaneous dipoles may be defined by assigning them identical times. Alternatively, multiple simultaneous dipoles may also be specified as a list of Dipole objects.

Changed in version 1.1: Added support for a list of mne.Dipole instances.

Changed in version 0.20: Support for reading bdip (Xfit binary) format.

Computing source timecourses with an XFit-like multi-dipole model

Plotting with mne.viz.Brain

---

## mne.read_events#

**URL:** https://mne.tools/stable/generated/mne.read_events.html

**Contents:**
- mne.read_events#
- Examples using mne.read_events#

Read events from fif or text file.

See Parsing events from raw data and Working with events for more information about events.

Name of the input file. If the extension is .fif, events are read assuming the file is in FIF format, otherwise (e.g., .eve, .lst, .txt) events are read as coming from text. Note that new format event files do not contain the "time" column (used to be the second column).

A event id to include or a list of them. If None all events are included.

A event id to exclude or a list of them. If None no event is excluded. If include is not None the exclude parameter is ignored.

The value of the digital mask to apply to the stim channel values. If None (default), no masking is performed.

The type of operation between the mask and the trigger. Choose ‘and’ (default) for MNE-C masking behavior.

If True, event_id will be returned. This is only possible for -annot.fif files produced with MNE-C mne_browse_raw.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The identity and timing of experimental events, around which the epochs were created. See events for more information.

Dictionary of {str: int} mappings of event IDs.

This function will discard the offset line (i.e., first line with zero event number) if it is present in a text file.

For more information on mask and mask_type, see mne.find_events().

Decoding source space data

Decoding sensor space data with generalization across time and conditions

Analysis of evoked response using ICA and PCA reduction techniques

XDAWN Decoding From EEG data

Compute effect-matched-spatial filtering (EMS)

Linear classifier on sensor data with plot patterns and filters

Compute MNE-dSPM inverse solution on single epochs

Define target events based on time lag, plot evoked response

Simulate raw data using subject anatomy

Permutation F-test on sensor data with 1D cluster level

FDR correction on T-test on sensor data

Permutation T-test on sensor data

Compute a cross-spectral density (CSD) matrix

Compute Power Spectral Density of inverse solution from single epochs

Visualize channel over epochs as an image

Whitening evoked data with a noise covariance

Compare evoked responses for different conditions

Exporting Epochs to Pandas DataFrames

EEG analysis - Event-Related Potentials (ERPs)

Getting started with mne.Report

Rejecting bad data spans and breaks

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.read_epochs_fieldtrip

---

## mne.read_forward_solution#

**URL:** https://mne.tools/stable/generated/mne.read_forward_solution.html

**Contents:**
- mne.read_forward_solution#
- Examples using mne.read_forward_solution#

Read a forward solution a.k.a. lead field.

The file name, which should end with -fwd.fif, -fwd.fif.gz, _fwd.fif, _fwd.fif.gz, -fwd.h5, or _fwd.h5.

List of names of channels to include. If empty all channels are included.

List of names of channels to exclude. If empty include all channels.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The forward solution.

Forward solutions, which are derived from an original forward solution with free orientation, are always stored on disk as forward solution with free orientation in X/Y/Z RAS coordinates. To apply any transformation to the forward operator (surface orientation, fixed orientation) please apply convert_forward_solution() after reading the forward solution with read_forward_solution().

Forward solutions, which are derived from an original forward solution with fixed orientation, are stored on disk as forward solution with fixed surface-based orientations. Please note that the transformation to surface-based, fixed orientation cannot be reverted after loading the forward solution with read_forward_solution().

Optically pumped magnetometer (OPM) data

Display sensitivity maps for EEG and MEG sensors

Source localization with a custom inverse solver

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute source power estimate by projecting the covariance with MNE

Morph surface source estimate

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Compute Rap-Music on evoked data

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Cortical Signal Suppression (CSS) for removal of cortical signals

Compare simulated and estimated source activity

Generate simulated evoked data

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

Sensitivity map of SSP projections

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Source reconstruction using an LCMV beamformer

Working with CTF data: the Brainstorm auditory dataset

Corrupt known signal with point spread

DICS for power mapping

mne.read_freesurfer_lut

---

## mne.read_freesurfer_lut#

**URL:** https://mne.tools/stable/generated/mne.read_freesurfer_lut.html

**Contents:**
- mne.read_freesurfer_lut#

Read a Freesurfer-formatted LUT.

The filename. Can be None to read the standard Freesurfer LUT.

Mapping from label names to IDs.

Mapping from label names to colors.

mne.read_forward_solution

---

## mne.read_labels_from_annot#

**URL:** https://mne.tools/stable/generated/mne.read_labels_from_annot.html

**Contents:**
- mne.read_labels_from_annot#
- Examples using mne.read_labels_from_annot#

Read labels from a FreeSurfer annotation file.

Note: Only cortical labels will be returned.

The FreeSurfer subject name.

The parcellation to use, e.g., 'aparc' or 'aparc.a2009s'.

The hemisphere from which to read the parcellation, can be 'lh', 'rh', or 'both'.

Surface used to obtain vertex locations, e.g., 'white', 'pial'.

Filename of the .annot file. If not None, only this file is read and the arguments parc and hemi are ignored.

Regular expression or substring to select particular labels from the parcellation. E.g. 'superior' will return all labels in which this substring is contained.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

If true, labels will be sorted by name before being returned.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The labels, sorted by label name (ascending).

Generate a functional label from source estimates

Compute MNE inverse solution on evoked data with a mixed source space

Visualize source leakage among labels using a circular graph

Cortical Signal Suppression (CSS) for removal of cortical signals

Compare simulated and estimated source activity

Simulate raw data using subject anatomy

Generate simulated source data

Plot a cortical parcellation

Corrupt known signal with point spread

mne.read_bem_solution

---

## mne.read_label#

**URL:** https://mne.tools/stable/generated/mne.read_label.html

**Contents:**
- mne.read_label#
- Examples using mne.read_label#

Read FreeSurfer Label file.

Subject which this label belongs to. Should only be specified if it is not specified in the label. It is good practice to set this attribute to avoid combining incompatible labels and SourceEstimates (e.g., ones from other subjects). Note that due to file specification limitations, the subject name isn’t saved to or loaded from files written to disk.

Default label color and alpha (e.g., (1., 0., 0., 1.) for red). Note that due to file specification limitations, the color isn’t saved to or loaded from files written to disk.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Instance of Label object with attributes:

comment: comment from the first line of the label file

vertices: vertex indices (0 based, column 1)

pos: locations in meters (columns 2 - 4 divided by 1000)

values: values at the vertices (column 5)

Compute MNE-dSPM inverse solution on single epochs

Compute sLORETA inverse solution on raw data

Extracting time course from source_estimate object

Extracting the time series of activations in a label

Generate simulated evoked data

Compute Power Spectral Density of inverse solution from single epochs

Compute power and phase lock in label of the source space

Compute source power spectral density (PSD) in a label

mne.read_forward_solution

---

## mne.read_lta#

**URL:** https://mne.tools/stable/generated/mne.read_lta.html

**Contents:**
- mne.read_lta#

Read a Freesurfer linear transform array file.

The transform filename.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The affine transformation described by the lta file.

---

## mne.read_morph_map#

**URL:** https://mne.tools/stable/generated/mne.read_morph_map.html

**Contents:**
- mne.read_morph_map#

Morph maps can be generated with mne_make_morph_maps. If one isn’t available, it will be generated automatically and saved to the subjects_dir/morph_maps directory.

Name of the original subject as named in the SUBJECTS_DIR.

Name of the subject on which to morph as named in the SUBJECTS_DIR.

Path to SUBJECTS_DIR is not set in the environment.

Morph across hemisphere. Currently only implemented for subject_to == subject_from. See notes of mne.compute_source_morph().

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The morph maps for the 2 hemispheres.

---

## mne.read_proj#

**URL:** https://mne.tools/stable/generated/mne.read_proj.html

**Contents:**
- mne.read_proj#
- Examples using mne.read_proj#

Read projections from a FIF file.

The name of file containing the projections vectors. It should end with -proj.fif or -proj.fif.gz.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The list of projection vectors.

Generate simulated evoked data

Temporal whitening with AR model

Sensitivity map of SSP projections

Visualizing epoched data

Working with CTF data: the Brainstorm auditory dataset

Background on projectors and projections

mne.read_reject_parameters

---

## mne.read_reject_parameters#

**URL:** https://mne.tools/stable/generated/mne.read_reject_parameters.html

**Contents:**
- mne.read_reject_parameters#

Read rejection parameters from .cov or .ave config file.

The rejection parameters.

mne.read_source_estimate

---

## mne.read_source_estimate#

**URL:** https://mne.tools/stable/generated/mne.read_source_estimate.html

**Contents:**
- mne.read_source_estimate#
- Examples using mne.read_source_estimate#

Read a source estimate object.

Path to (a) source-estimate file(s).

Name of the subject the source estimate(s) is (are) from. It is good practice to set this attribute to avoid combining incompatible labels and SourceEstimates (e.g., ones from other subjects). Note that due to file specification limitations, the subject name isn’t saved to or loaded from files written to disk.

The source estimate object loaded from file.

for volume source estimates, fname should provide the path to a single file named '*-vl.stc` or '*-vol.stc'

for surface source estimates, fname should either provide the path to the file corresponding to a single hemisphere ('*-lh.stc', '*-rh.stc') or only specify the asterisk part in these patterns. In any case, the function expects files for both hemisphere with names following this pattern.

for vector surface source estimates, only HDF5 files are supported.

for mixed source estimates, only HDF5 files are supported.

for single time point .w files, fname should follow the same pattern as for surface estimates, except that files are named '*-lh.w' and '*-rh.w'.

Extracting time course from source_estimate object

Morph surface source estimate

Plotting with mne.viz.Brain

Cross-hemisphere comparison

The SourceEstimate data structure

Visualize source time courses (stcs)

2 samples permutation test on source data with spatio-temporal clustering

Make figures more publication ready

Using the event system to link figures

mne.read_reject_parameters

mne.read_source_spaces

---

## mne.read_source_morph#

**URL:** https://mne.tools/stable/generated/mne.read_source_morph.html

**Contents:**
- mne.read_source_morph#

Load the morph for source estimates from a file.

Path to the file containing the morph source estimates.

mne.random_parcellation

---

## mne.read_source_spaces#

**URL:** https://mne.tools/stable/generated/mne.read_source_spaces.html

**Contents:**
- mne.read_source_spaces#
- Examples using mne.read_source_spaces#

Read the source spaces from a FIF file.

The name of the file, which should end with -src.fif or -src.fif.gz.

Calculate and add cortical patch statistics to the surfaces.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Use source space morphing

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Morph surface source estimate

Morph volumetric source estimate

Working with sEEG data

Working with ECoG data

Source alignment and coordinate frames

EEG forward operator with a template MRI

How MNE uses FreeSurfer’s outputs

Source reconstruction using an LCMV beamformer

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.read_source_estimate

---

## mne.read_surface#

**URL:** https://mne.tools/stable/generated/mne.read_surface.html

**Contents:**
- mne.read_surface#
- Examples using mne.read_surface#

Load a Freesurfer surface mesh in triangular format.

The name of the file containing the surface.

Read metadata as key-value pairs. Only works when reading a FreeSurfer surface file. For .obj files this dictionary will be empty.

‘head’ : array of int

‘volume’ : array of int, shape (3,)

‘voxelsize’ : array of float, shape (3,)

‘xras’ : array of float, shape (3,)

‘yras’ : array of float, shape (3,)

‘zras’ : array of float, shape (3,)

‘cras’ : array of float, shape (3,)

If True, a dictionary with surface parameters is returned.

File format to use. Can be ‘freesurfer’ to read a FreeSurfer surface file, or ‘obj’ to read a Wavefront .obj file (common format for importing in other software), or ‘auto’ to attempt to infer from the file name. Defaults to ‘auto’.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Triangulation (each line contains indices for three points which together form a face).

If read_metadata is true, key-value pairs found in the geometry file.

The surface parameters. Only returned if return_dict is True.

Source alignment and coordinate frames

How MNE uses FreeSurfer’s outputs

Fixing BEM and head surfaces

mne.read_source_spaces

---

## mne.read_talxfm#

**URL:** https://mne.tools/stable/generated/mne.read_talxfm.html

**Contents:**
- mne.read_talxfm#
- Examples using mne.read_talxfm#

Compute MRI-to-MNI transform from FreeSurfer talairach.xfm file.

The FreeSurfer subject name.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The affine transformation from MRI to MNI space for the subject.

Working with sEEG data

How MNE uses FreeSurfer’s outputs

---

## mne.read_trans#

**URL:** https://mne.tools/stable/generated/mne.read_trans.html

**Contents:**
- mne.read_trans#
- Examples using mne.read_trans#

Read a -trans.fif file.

The name of the file.

If True, return all transformations in the file. False (default) will only return the first.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The transformation dictionary from the fif file.

Plotting with mne.viz.Brain

Plotting EEG sensors on the scalp

Source alignment and coordinate frames

How MNE uses FreeSurfer’s outputs

The role of dipole orientations in distributed source localization

Working with CTF data: the Brainstorm auditory dataset

---

## mne.read_tri#

**URL:** https://mne.tools/stable/generated/mne.read_tri.html

**Contents:**
- mne.read_tri#

Read triangle definitions from an ascii file.

Path to surface ASCII file (ending with '.tri').

Assume the ASCII file vertex ordering is clockwise instead of counterclockwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Triangulation (each line contains indices for three points which together form a face).

mne.write_labels_to_annot

---

## mne.read_vectorview_selection#

**URL:** https://mne.tools/stable/generated/mne.read_vectorview_selection.html

**Contents:**
- mne.read_vectorview_selection#
- Examples using mne.read_vectorview_selection#

Read Neuromag Vector View channel selection from a file.

Name of the selection. If a list, the selections are combined. Supported selections are: 'Vertex', 'Left-temporal', 'Right-temporal', 'Left-parietal', 'Right-parietal', 'Left-occipital', 'Right-occipital', 'Left-frontal' and 'Right-frontal'. Selections can also be matched and combined by spcecifying common substrings. For example, name='temporal will produce a combination of 'Left-temporal' and 'Right-temporal'.

Filename of the selection file (if None, built-in selections are used).

The mne.Info object with information about the sensors and methods of measurement. Used to determine which channel naming convention to use, e.g. 'MEG 0111' (with space) for old Neuromag systems and 'MEG0111' (without space) for new ones.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List with channel names in the selection.

Computing source timecourses with an XFit-like multi-dipole model

DICS for power mapping

Non-parametric 1 sample cluster statistic on single trial power

---

## mne.rename_channels#

**URL:** https://mne.tools/stable/generated/mne.rename_channels.html

**Contents:**
- mne.rename_channels#

The mne.Info object with information about the sensors and methods of measurement. Note: modified in place.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.read_vectorview_selection

---

## mne.Report#

**URL:** https://mne.tools/stable/generated/mne.Report.html

**Contents:**
- mne.Report#
- Examples using mne.Report#

Object for rendering HTML.

Name of the file containing the info dictionary.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Name of the file containing the noise covariance.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied in the following way to each channel:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire time period.

For Epochs, this algorithm is run on each epoch individually. Defaults to None, i.e. no baseline correction.

Default image format to use (default is 'auto', which will use 'webp' if available and 'png' otherwise). 'svg' uses vector graphics, so fidelity is higher but can increase file size and browser image rendering time as well.

Changed in version 1.3: Added support for 'webp' format, removed support for GIF, and set the default to 'auto'.

If True, include PSD plots for raw files. Can be False (default) to omit, True to plot, or a dict to pass as kwargs to mne.time_frequency.Spectrum.plot().

Changed in version 1.4: kwargs are sent to spectrum.plot instead of raw.plot_psd.

Whether to include topographic plots of SSP projectors, if present in the data. Defaults to False.

Maximum image width in pixels.

Maximum image resolution in dots per inch.

Tuple of elements to collapse by default. Defaults to an empty tuple. For now the only option it can contain is “section”.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Name of the file containing the info dictionary.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Name of the file containing the noise covariance.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied in the following way to each channel:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire time period.

For Epochs, this algorithm is run on each epoch individually. Defaults to None, i.e. no baseline correction.

Default image format to use.

If True, include PSD plots for raw files. Can be False (default) to omit, True to plot, or a dict to pass as kwargs to mne.time_frequency.Spectrum.plot().

Changed in version 1.4: kwargs are sent to spectrum.plot instead of raw.plot_psd.

Whether to include topographic plots of SSP projectors, if present in the data. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of HTML representations for all content elements.

Dictionary containing elements included in head.

List of file names rendered.

language setting for the HTML file.

Maximum image width in pixels.

Maximum image resolution in dots per inch.

Tuple of elements to collapse by default. See above.

Return the number of files processed by the report.

add_bem(subject, title, *[, subjects_dir, ...])

Render a visualization of the boundary element model (BEM) surfaces.

add_code(code, title, *[, language, tags, ...])

Add a code snippet (e.g., an analysis script) to the report.

add_covariance(cov, *, info, title[, tags, ...])

Add covariance to the report.

Add custom CSS to the report.

Add custom JavaScript to the report.

add_epochs(epochs, title, *[, psd, projs, ...])

Add Epochs to the report.

add_events(events, title, *[, event_id, ...])

Add events to the report.

add_evokeds(evokeds, *[, titles, noise_cov, ...])

Add Evoked objects to the report.

add_figure(fig, title, *[, caption, ...])

Add figures to the report.

add_forward(forward, title, *[, subject, ...])

Add a forward solution.

add_html(html, title, *[, tags, section, ...])

Add HTML content to the report.

add_ica(ica, title, *, inst[, picks, ...])

Add (a fitted) ICA to the report.

add_image(image, title, *[, caption, tags, ...])

Add an image (e.g., PNG or JPEG pictures) to the report.

add_inverse_operator(inverse_operator, title, *)

Add an inverse operator.

add_projs(*, info, title[, projs, ...])

Render (SSP) projection vectors.

add_raw(raw, title, *[, psd, projs, ...])

Add Raw objects to the report.

add_stc(stc, title, *[, subject, ...])

Add a SourceEstimate (STC) to the report.

add_sys_info(title, *[, tags, replace])

Add a MNE-Python system information to the report.

add_trans(trans, *, info, title[, subject, ...])

Add a coregistration visualization to the report.

Return a deepcopy of the report.

Get the content of the report.

parse_folder(data_path[, pattern, n_jobs, ...])

Render all the files in the folder.

remove(*[, title, tags, remove_all])

Remove elements from the report.

Reorder the report content.

save([fname, open_browser, overwrite, ...])

Save the report and optionally open it in browser.

See Getting started with mne.Report for an introduction to using mne.Report.

Return the number of files processed by the report.

The number of files processed.

Render a visualization of the boundary element model (BEM) surfaces.

The FreeSurfer subject name.

The title corresponding to the BEM image.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Use this decimation factor for generating MRI/BEM images (since it can be time consuming).

The width of the MRI images (in pixels). Larger values will have clearer surface lines, but will create larger HTML files. Typically a factor of 2 more than the number of MRI voxels along each dimension (typically 512, default) is reasonable.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Tags to add for later interactive filtering. Must not contain spaces.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_bem:

Getting started with mne.Report

Add a code snippet (e.g., an analysis script) to the report.

The code to add to the report as a string, or the path to a file as a pathlib.Path object.

Paths must be passed as pathlib.Path object, since strings will be treated as literal code.

The title corresponding to the code.

The programming language of code. This will be used for syntax highlighting. Can be 'auto' to try to auto-detect the language.

Tags to add for later interactive filtering. Must not contain spaces.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_code:

Getting started with mne.Report

Add covariance to the report.

The Covariance to add to the report.

The Info corresponding to cov.

The title corresponding to the Covariance object.

Tags to add for later interactive filtering. Must not contain spaces.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_covariance:

Getting started with mne.Report

Add custom CSS to the report.

Style definitions to add to the report. The content of this string will be embedded between HTML <style> and </style> tags.

Add custom JavaScript to the report.

JavaScript code to add to the report. The content of this string will be embedded between HTML <script> and </script> tags.

Add Epochs to the report.

The epochs to add to the report.

If a float, the duration of data to use for creation of PSD plots, in seconds. PSD will be calculated on as many epochs as required to cover at least this duration. Epochs will be picked across the entire time range in equally-spaced distance.

In rare edge cases, we may not be able to create a grid of equally-spaced epochs that cover the entire requested time range. In these situations, a warning will be emitted, informing you about the duration that’s actually being used.

If True, add PSD plots based on all epochs. If False, do not add PSD plots.

Whether to add SSP projector plots if projectors are present in the data. If None, use projs from Report creation.

Keyword arguments to pass to the “epochs image”-generating function (mne.Epochs.plot_image()). Keys are channel types, values are dicts containing kwargs to pass. For example, to use the rejection limits per channel type you could pass:

Keyword arguments to pass to the topomap-generating functions.

The drop reasons to ignore when creating the drop log bar plot. All epochs for which a drop reason listed here appears in epochs.drop_log will be excluded from the drop log plot.

Tags to add for later interactive filtering. Must not contain spaces.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_epochs:

Getting started with mne.Report

Add events to the report.

An MNE-Python events array.

The title corresponding to the events.

A dictionary mapping event names (keys) to event codes (values).

The sampling frequency used while recording.

The first sample point in the recording. This corresponds to raw.first_samp on files created with Elekta/Neuromag systems.

Dictionary of event_id integers as keys and colors as values. This parameter is directly passed to mne.viz.plot_events().

Tags to add for later interactive filtering. Must not contain spaces.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_events:

Getting started with mne.Report

Add Evoked objects to the report.

The evoked data to add to the report. Multiple Evoked objects – as returned from mne.read_evokeds – can be passed as a list.

The titles corresponding to the evoked data. If None, the content of evoked.comment from each evoked will be used as title.

A noise covariance matrix. If provided, will be used to whiten the evokeds. If None, will fall back to the cov_fname provided upon report creation.

Whether to add SSP projector plots if projectors are present in the data. If None, use projs from Report creation.

The number of equidistant time points to render. If None, will render each Evoked at 21 time points, unless the data contains fewer time points, in which case all will be rendered.

Tags to add for later interactive filtering. Must not contain spaces.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Keyword arguments to pass to the topomap-generating functions.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Examples using add_evokeds:

Getting started with mne.Report

Add figures to the report.

One or more figures to add to the report. All figures must be an instance of matplotlib.figure.Figure, mne.viz.Figure3D, or numpy.ndarray. If multiple figures are passed, they will be added as “slides” that can be navigated using buttons and a slider element.

The title corresponding to the figure(s).

The caption(s) to add to the figure(s).

The image format to be used for the report, can be 'png', 'svg', or 'gif'. None (default) will use the default specified during Report instantiation.

Tags to add for later interactive filtering. Must not contain spaces.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_figure:

Getting started with mne.Report

Add a forward solution.

The forward solution to add to the report.

The title corresponding to forward solution.

The name of the FreeSurfer subject forward belongs to. If None, will use the value of subject passed on report creation.

The FreeSurfer SUBJECTS_DIR.

If True, plot the source space of the forward solution.

Tags to add for later interactive filtering. Must not contain spaces.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_forward:

Getting started with mne.Report

Add HTML content to the report.

The HTML content to add.

The title corresponding to html.

Tags to add for later interactive filtering. Must not contain spaces.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_html:

Getting started with mne.Report

Add (a fitted) ICA to the report.

The fitted ICA to add.

The data to use for visualization of the effects of ICA cleaning. To only plot the ICA component topographies, explicitly pass None.

Indices of the independent components (ICs) to visualize. If an integer, represents the index of the IC to pick. Multiple ICs can be selected using a list of int or a slice. The indices are 0-indexed, so picks=1 will pick the second IC: ICA001. None will pick all independent components in the order fitted. This only affects the behavior of the component topography and properties plots.

Evoked signal based on ECG and EOG epochs, respectively. If passed, will be used to visualize the effects of artifact rejection.

The scores produced by mne.preprocessing.ICA.find_bads_ecg() and mne.preprocessing.ICA.find_bads_eog(), respectively. If passed, will be used to visualize the scoring for each ICA component.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Tags to add for later interactive filtering. Must not contain spaces.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_ica:

Getting started with mne.Report

Add an image (e.g., PNG or JPEG pictures) to the report.

Title corresponding to the images.

If not None, the caption to add to the image.

Tags to add for later interactive filtering. Must not contain spaces.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_image:

Getting started with mne.Report

Add an inverse operator.

The inverse operator to add to the report.

The title corresponding to the inverse operator object.

The name of the FreeSurfer subject inverse_op belongs to If None, will use the value of subject passed on report creation.

The FreeSurfer SUBJECTS_DIR.

If True, plot the source space of the inverse operator.

Tags to add for later interactive filtering. Must not contain spaces.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_inverse_operator:

Getting started with mne.Report

Render (SSP) projection vectors.

An Info structure or the path of a file containing one.

The title corresponding to the Projection object.

The projection vectors to add to the report. Can be the path to a file that will be loaded via mne.read_proj. If None, the projectors are taken from info['projs'].

Keyword arguments to pass to the topomap-generating functions.

Tags to add for later interactive filtering. Must not contain spaces.

If True (default False), plot the projectors using mne.viz.plot_projs_joint(), otherwise use mne.viz.plot_projs_topomap(). If True, then info must be an instance of mne.Evoked.

Channels to show alongside the projected time courses. Typically these are the ground-truth channels for an artifact (e.g., 'eog' or 'ecg'). Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick no channels. Only used when joint=True.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_projs:

Getting started with mne.Report

Add Raw objects to the report.

The data to add to the report.

The title corresponding to the raw object.

Whether to add PSD plots. Overrides the raw_psd parameter passed when initializing the Report. If None, use raw_psd from Report creation.

Whether to add SSP projector plots if projectors are present in the data. If None, use projs from Report creation.

Whether to add butterfly plots of the data. Can be useful to spot problematic channels. If True, 10 equally-spaced 1-second segments will be plotted. If an integer, specifies the number of 1-second segments to plot. Larger numbers may take a considerable amount of time if the data contains many sensors. You can disable butterfly plots altogether by passing False.

Scaling factors for the traces. If a dictionary where any value is 'auto', the scaling factor is set to match the 99.5th percentile of the respective data. If 'auto', all scalings (for all channel types) are set to 'auto'. If any values are 'auto' and the data is not preloaded, a subset up to 100 MB will be loaded. If None, defaults to:

A particular scaling value s corresponds to half of the visualized signal range around zero (i.e. from 0 to +s or from 0 to -s). For example, the default scaling of 20e-6 (20µV) for EEG signals means that the visualized range will be 40 µV (20 µV in the positive direction and 20 µV in the negative direction).

Tags to add for later interactive filtering. Must not contain spaces.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Keyword arguments to pass to the topomap-generating functions.

Examples using add_raw:

Getting started with mne.Report

Add a SourceEstimate (STC) to the report.

The SourceEstimate to add to the report.

The name of the FreeSurfer subject the STC belongs to. The name is not stored with the STC data and therefore needs to be specified. If None, will use the value of subject passed on report creation.

The FreeSurfer SUBJECTS_DIR.

The number of equidistant time points to render. If None, will render stc at 51 time points, unless the data contains fewer time points, in which case all will be rendered.

Tags to add for later interactive filtering. Must not contain spaces.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

Dictionary of keyword arguments to pass to mne.SourceEstimate.plot. Only used when plotting in 3D mode.

Examples using add_stc:

Getting started with mne.Report

Add a MNE-Python system information to the report.

This is a convenience method that captures the output of mne.sys_info and adds it to the report.

Tags to add for later interactive filtering. Must not contain spaces.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Add a coregistration visualization to the report.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation. If trans is None, an identity matrix is assumed. “auto” will load trans from the FreeSurfer directory specified by subject and subjects_dir parameters.

Changed in version 1.10: Support for ‘fsaverage’ argument.

The Info corresponding to trans.

The name of the FreeSurfer subject the trans belongs to. The name is not stored with the trans and therefore needs to be specified. If None, will use the value of subject passed on report creation.

The FreeSurfer SUBJECTS_DIR.

The level of opacity to apply to the head surface. If a float, must be between 0 and 1 (inclusive), where 1 means fully opaque. If None, will use the MNE-Python default value. See also plot_kwargs.

Coordinate frame used for plotting. See mne.viz.plot_alignment() and plot_kwargs.

Plotting arguments to be passed to mne.viz.plot_alignment(). If alpha is not None, it will override a potential plot_kwargs["alpha"]. The coord_frame key word argument always overrides a potential plot_kwargs["coord_frame"]. If None, this defaults to dict(dig=True, meg=("helmet", "sensors"), show_axes=True).

Tags to add for later interactive filtering. Must not contain spaces.

The name of the section (or content block) to add the content to. This feature is useful for grouping multiple related content elements together under a single, collapsible section. Each content element will retain its own title and functionality, but not appear separately in the table of contents. Hence, using sections is a way to declutter the table of contents, and to easy navigation of the report.

If True, content already present that has the same title and section will be replaced. Defaults to False, which will cause duplicate entries in the table of contents if an entry for title already exists.

Examples using add_trans:

Getting started with mne.Report

Return a deepcopy of the report.

Get the content of the report.

The title of each content element.

The tags for each content element, one list per element.

The HTML contents for each element.

A list of HTML representations for all content elements.

Render all the files in the folder.

Path to the folder containing data whose HTML report will be created.

Filename global pattern(s) to include in the report. For example, ['\*raw.fif', '\*ave.fif'] will include Raw as well as Evoked files. If None, include all supported file formats.

Changed in version 0.23: Include supported non-FIFF files by default.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Use this decimation factor for generating MRI/BEM images (since it can be time consuming).

If True, sort the content based on tags in the order: raw -> events -> epochs -> evoked -> covariance -> coregistration -> bem -> forward-solution -> inverse-operator -> source-estimate.

What to do if a file cannot be rendered. Can be 'ignore', 'warn' (default), or 'raise'.

The image format to be used for the report, can be 'png', 'svg', or 'gif'. None (default) will use the default specified during Report instantiation.

If True (default), try to render the BEM.

If True (default False), plot the source space when adding a forward or inverse.

The number of equidistant time points to render for Evoked and SourceEstimate data, respectively. If None, will render each Evoked at 21 and each SourceEstimate at 51 time points, unless the respective data contains fewer time points, in which case all will be rendered.

Whether to render butterfly plots for (decimated) Raw data.

Dictionary of keyword arguments to pass to mne.SourceEstimate.plot. Only used when plotting in 3D mode.

Keyword arguments to pass to the topomap-generating functions.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Examples using parse_folder:

Getting started with mne.Report

Remove elements from the report.

The element to remove is searched for by its title. Optionally, tags may be specified as well to narrow down the search to elements that have the supplied tags.

The title of the element(s) to remove.

If supplied, restrict the operation to elements with the supplied tags.

Controls the behavior if multiple elements match the search criteria. If False (default) only the element last added to the report will be removed. If True, all matches will be removed.

The indices of the elements that were removed, or None if no element matched the search criteria. A tuple will always be returned if remove_all was set to True and at least one element was removed.

Changed in version 0.24.0: Returns tuple if remove_all is True.

Reorder the report content.

The indices of the new order (as if you were reordering an array). For example if there are 4 elements in the report, order=[3, 0, 1, 2] would take the last element and move it to the front. In other words, elements = [elements[ii] for ii in order]].

Save the report and optionally open it in browser.

Output filename. If the name ends with .h5 or .hdf5, the report is saved in HDF5 format, so it can later be loaded again with open_report(). For any other suffix, the report will be saved in HTML format. If None and Report.parse_folder() was not called, the report is saved as report.html in the current working directory. If None and Report.parse_folder() was used, the report is saved as report.html inside the data_path supplied to Report.parse_folder().

Whether to open the rendered HTML report in the default web browser after saving. This is ignored when writing an HDF5 file.

If True (default False), overwrite the destination file if it exists.

If True, sort the content based on tags before saving in the order: raw -> events -> epochs -> evoked -> covariance -> coregistration -> bem -> forward-solution -> inverse-operator -> source-estimate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The file name to which the report was saved.

Getting started with mne.Report

A sorted tuple of all tags currently used in the report.

Getting started with mne.Report

---

## mne.scale_bem#

**URL:** https://mne.tools/stable/generated/mne.scale_bem.html

**Contents:**
- mne.scale_bem#

Name of the scaled MRI subject (the destination mri subject).

Name of the bem file. For example, to scale fsaverage-inner_skull-bem.fif, the bem_name would be “inner_skull-bem”.

The subject from which to read the source space. If None, subject_from is read from subject_to’s config file.

Scaling factor. Has to be specified if subjects_from is specified, otherwise it is read from subject_to’s config file.

Override the SUBJECTS_DIR environment variable.

What to do if the surface is found to have topological defects. Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when one or more defects are found. Note that a lot of computations in MNE-Python assume the surfaces to be topologically correct, topological defects may still make other computations (e.g., mne.make_bem_model and mne.make_bem_solution) fail irrespective of this parameter.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

---

## mne.scale_labels#

**URL:** https://mne.tools/stable/generated/mne.scale_labels.html

**Contents:**
- mne.scale_labels#

Scale labels to match a brain that was previously created by scaling.

Name of the scaled MRI subject (the destination brain).

Pattern for finding the labels relative to the label directory in the MRI subject directory (e.g., “lh.BA3a.label” will scale “fsaverage/label/lh.BA3a.label”; “aparc/*.label” will find all labels in the “fsaverage/label/aparc” directory). With None, scale all labels.

Overwrite any label file that already exists for subject_to (otherwise existing labels are skipped).

Name of the original MRI subject (the brain that was scaled to create subject_to). If None, the value is read from subject_to’s cfg file.

Scaling parameter. If None, the value is read from subject_to’s cfg file.

Override the SUBJECTS_DIR environment variable.

mne.scale_source_space

---

## mne.scale_mri#

**URL:** https://mne.tools/stable/generated/mne.scale_mri.html

**Contents:**
- mne.scale_mri#
- Examples using mne.scale_mri#

Create a scaled copy of an MRI subject.

Name of the subject providing the MRI.

New subject name for which to save the scaled MRI.

The scaling factor (one or 3 parameters).

If an MRI already exists for subject_to, overwrite it.

Override the SUBJECTS_DIR environment variable.

Do not scale the MRI fiducials. If False (default), an OSError will be raised if no fiducials file can be found.

Also scale all labels (default True).

Copy *.annot files to the new location (default False).

What to do if the surface is found to have topological defects. Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when one or more defects are found. Note that a lot of computations in MNE-Python assume the surfaces to be topologically correct, topological defects may still make other computations (e.g., mne.make_bem_model and mne.make_bem_solution) fail irrespective of this parameter.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Add a scaled BEM to a scaled MRI.

Add labels to a scaled MRI.

Add a source space to a scaled MRI.

This function will automatically call scale_bem(), scale_labels(), and scale_source_space() based on expected filename patterns in the subject directory.

Using an automated approach to coregistration

---

## mne.scale_source_space#

**URL:** https://mne.tools/stable/generated/mne.scale_source_space.html

**Contents:**
- mne.scale_source_space#

Scale a source space for an mri created with scale_mri().

Name of the scaled MRI subject (the destination mri subject).

Source space name. Can be a spacing parameter (e.g., '7', 'ico4', 'oct6') or a file name of a source space file relative to the bem directory; if the file name contains the subject name, it should be indicated as “{subject}” in src_name (e.g., "{subject}-my_source_space-src.fif").

The subject from which to read the source space. If None, subject_from is read from subject_to’s config file.

Scaling factor. Has to be specified if subjects_from is specified, otherwise it is read from subject_to’s config file.

Override the SUBJECTS_DIR environment variable.

Number of jobs to run in parallel if recomputing distances (only applies if scale is an array of length 3, and will not use more cores than there are source spaces).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

When scaling volume source spaces, the source (vertex) locations are scaled, but the reference to the MRI volume is left unchanged. Transforms are updated so that source estimates can be plotted on the original MRI volume.

mne.transforms.apply_volume_registration

---

## mne.sensitivity_map#

**URL:** https://mne.tools/stable/generated/mne.sensitivity_map.html

**Contents:**
- mne.sensitivity_map#
- Examples using mne.sensitivity_map#

Compute sensitivity map.

Such maps are used to know how much sources are visible by a type of sensor, and how much projections shadow some sources.

The forward operator.

List of projection vectors.

The type of sensors to use.

The type of sensitivity map computed. See manual. Should be 'free', 'fixed', 'ratio', 'radiality', 'angle', 'remaining', or 'dampening' corresponding to the argument --map 1, 2, 3, 4, 5, 6, 7 of the command mne_sensitivity_map.

List of channels to exclude. If empty do not exclude any (default). If 'bads', exclude channels in fwd['info']['bads'].

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The sensitivity map as a SourceEstimate or VolSourceEstimate instance for visualization.

When mode is 'fixed' or 'free', the sensitivity map is normalized by its maximum value.

Display sensitivity maps for EEG and MEG sensors

Use source space morphing

Sensitivity map of SSP projections

mne.morph_source_spaces

mne.setup_source_space

---

## mne.set_bipolar_reference#

**URL:** https://mne.tools/stable/generated/mne.set_bipolar_reference.html

**Contents:**
- mne.set_bipolar_reference#
- Examples using mne.set_bipolar_reference#

Re-reference selected channels using a bipolar referencing scheme.

A bipolar reference takes the difference between two channels (the anode minus the cathode) and adds it as a new virtual channel. The original channels will be dropped by default.

Multiple anodes and cathodes can be specified, in which case multiple virtual channels will be created. The 1st cathode will be subtracted from the 1st anode, the 2nd cathode from the 2nd anode, etc.

By default, the virtual channels will be annotated with channel-info and -location of the anodes and coil types will be set to EEG_BIPOLAR.

Data containing the unreferenced channels.

The name(s) of the channel(s) to use as anode in the bipolar reference.

The name(s) of the channel(s) to use as cathode in the bipolar reference.

The channel name(s) for the virtual channel(s) containing the resulting signal. By default, bipolar channels are named after the anode and cathode, but it is recommended to supply a more meaningful name.

This parameter can be used to supply a dictionary (or a dictionary for each bipolar channel) containing channel information to merge in, overwriting the default values. Defaults to None.

Whether to drop the anode/cathode channels from the instance.

Whether to operate on a copy of the data (True) or modify it in-place (False). Defaults to True.

If a bipolar channel is created from a bad anode or a bad cathode, mne warns if on_bad=”warns”, raises ValueError if on_bad=”raise”, and does nothing if on_bad=”ignore”. For “warn” and “ignore”, the new bipolar channel will be marked as bad. Defaults to on_bad=”warns”.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data with the specified channels re-referenced.

Convenience function for creating an EEG reference.

If the anodes contain any EEG channels, this function removes any pre-existing average reference projections.

During source localization, the EEG signal should have an average reference.

The data must be preloaded.

Using contralateral referencing for EEG

Setting the EEG reference

mne.add_reference_channels

mne.set_eeg_reference

---

## mne.set_cache_dir#

**URL:** https://mne.tools/stable/generated/mne.set_cache_dir.html

**Contents:**
- mne.set_cache_dir#

Set the directory to be used for temporary file storage.

This directory is used by joblib to store memmapped arrays, which reduces memory requirements and speeds up parallel computation.

Directory to use for temporary file storage. None disables temporary file storage.

mne.set_memmap_min_size

---

## mne.set_config#

**URL:** https://mne.tools/stable/generated/mne.set_config.html

**Contents:**
- mne.set_config#
- Examples using mne.set_config#

Set a MNE-Python preference key in the config file and environment.

The preference key to set.

The value to assign to the preference key. If None, the key is deleted.

The folder that contains the .mne config folder. If None, it is found automatically.

If True (default), update os.environ in addition to updating the MNE-Python config file.

FreeSurfer MRI reconstruction

Configuring MNE-Python

---

## mne.set_eeg_reference#

**URL:** https://mne.tools/stable/generated/mne.set_eeg_reference.html

**Contents:**
- mne.set_eeg_reference#
- Examples using mne.set_eeg_reference#

Specify which reference to use for EEG data.

Use this function to explicitly specify the desired reference for EEG. This can be either an existing electrode or a new virtual channel. This function will re-reference the data according to the desired reference.

Note that it is also possible to re-reference the signal using a Laplacian (LAP) “reference-free” transformation using the compute_current_source_density() function.

Instance of Raw or Epochs with EEG channels and reference channel(s).

The name(s) of the channel(s) used to construct the reference for every channel of ch_type.

'average' to apply an average reference (default)

'REST' to use the Reference Electrode Standardization Technique infinity reference [1].

A dictionary mapping names of data channels to (lists of) names of reference channels. For example, {‘A1’: ‘A3’} would replace the data in channel ‘A1’ with the difference between ‘A1’ and ‘A3’. To take the average of multiple channels as reference, supply a list of channel names as the dictionary value, e.g. {‘A1’: [‘A2’, ‘A3’]} would replace channel A1 with A1 - mean(A2, A3).

An empty list, in which case MNE will not attempt any re-referencing of the data

Specifies whether the data will be copied (True) or modified in-place (False). Defaults to True.

If ref_channels='average' this argument specifies if the average reference should be computed as a projection (True) or not (False; default). If projection=True, the average reference is added as a projection and is not applied to the data (it can be applied afterwards with the apply_proj method). If projection=False, the average reference is directly applied to the data. If ref_channels is not 'average', projection must be set to False (the default in this case).

The name of the channel type to apply the reference to. Valid channel types are 'auto', 'eeg', 'ecog', 'seeg', 'dbs'. If 'auto', the first channel type of eeg, ecog, seeg or dbs that is found (in that order) will be selected.

Changed in version 1.2: list-of-str is now supported with projection=True.

Forward solution to use. Only used with ref_channels='REST'.

How to handle list-of-str ch_type. If False (default), one projector is created per channel type. If True, one projector is created across all channel types. This is only used when projection=True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data with EEG channels re-referenced. If ref_channels="average" and projection=True a projection will be added instead of directly re-referencing the data.

Array of reference data subtracted from EEG channels. This will be None if projection=True, or if ref_channels is "REST" or a dict.

Convenience function for creating bipolar references.

Some common referencing schemes and the corresponding value for the ref_channels parameter:

A new virtual reference electrode is created by averaging the current EEG signal by setting ref_channels='average'. Bad EEG channels are automatically excluded if they are properly set in info['bads'].

Set ref_channels to a list containing the name of the channel that will act as the new reference, for example ref_channels=['Cz'].

A new virtual reference electrode is created by computing the average of the current EEG signal recorded from two or more selected channels. Set ref_channels to a list of channel names, indicating which channels to use. For example, to apply an average mastoid reference, when using the 10-20 naming scheme, set ref_channels=['M1', 'M2'].

The given EEG electrodes are referenced to a point at infinity using the lead fields in forward, which helps standardize the signals.

Set ref_channels to a dictionary mapping source channel names (str) to the reference channel names (str or list of str). Unlike the other approaches where the same reference is applied globally, you can set different references for different channels with this method. For example, to re-reference channel ‘A1’ to ‘A2’ and ‘B1’ to the average of ‘B2’ and ‘B3’, set ref_channels={'A1': 'A2', 'B1': ['B2', 'B3']}. Warnings are issued when a mapping involves bad channels or channels of different types.

If a reference is requested that is not the average reference, this function removes any pre-existing average reference projections.

During source localization, the EEG signal should have an average reference.

In order to apply a reference, the data must be preloaded. This is not necessary if ref_channels='average' and projection=True.

For an average or REST reference, bad EEG channels are automatically excluded if they are properly set in info['bads'].

D. Yao. A method to standardize a reference of scalp EEG recordings to a point at infinity. Physiological Measurement, 22(4):693–711, 2001. doi:10.1088/0967-3334/22/4/305.

Modifying data in-place

Importing data from EEG devices

mne.set_bipolar_reference

mne.filter.construct_iir_filter

---

## mne.set_log_file#

**URL:** https://mne.tools/stable/generated/mne.set_log_file.html

**Contents:**
- mne.set_log_file#

Set the log to print to a file.

Filename of the log to print to. If None, stdout is used. To suppress log outputs, use set_log_level(‘WARNING’).

Format of the output messages. See the following for examples:

https://docs.python.org/dev/howto/logging.html

e.g., “%(asctime)s - %(levelname)s - %(message)s”.

Overwrite the log file (if it exists). Otherwise, statements will be appended to the log (default). None is the same as False, but additionally raises a warning to notify the user that log entries will be appended.

---

## mne.set_log_level#

**URL:** https://mne.tools/stable/generated/mne.set_log_level.html

**Contents:**
- mne.set_log_level#

Set the logging level.

The verbosity of messages to print. If a str, it can be either DEBUG, INFO, WARNING, ERROR, or CRITICAL. Note that these are for convenience and are equivalent to passing in logging.DEBUG, etc. For bool, True is the same as ‘INFO’, False is the same as ‘WARNING’. If None, the environment variable MNE_LOGGING_LEVEL is read, and if it doesn’t exist, defaults to INFO.

If True, return the old verbosity level.

If int, enable (>=1) or disable (0) the printing of stack frame information using formatting. Default (None) does not change the formatting. This can add overhead so is meant only for debugging.

The old level. Only returned if return_old_level is True.

---

## mne.set_memmap_min_size#

**URL:** https://mne.tools/stable/generated/mne.set_memmap_min_size.html

**Contents:**
- mne.set_memmap_min_size#

Set the minimum size for memmaping of arrays for parallel processing.

Threshold on the minimum size of arrays that triggers automated memory mapping for parallel processing, e.g., ‘1M’ for 1 megabyte. Use None to disable memmaping of large arrays.

---

## mne.simulation.add_chpi#

**URL:** https://mne.tools/stable/generated/mne.simulation.add_chpi.html

**Contents:**
- mne.simulation.add_chpi#

Add cHPI activations to raw data.

The raw instance to be modified.

Path to the position estimates file. Should be in the format of the files produced by MaxFilter. If dict, keys should be the time points and entries should be 4x4 dev_head_t matrices. If None, the original head position (from info['dev_head_t']) will be used. If tuple, should have the same format as data returned by head_pos_to_trans_rot_t. If array, should be of the form returned by mne.chpi.read_head_pos().

Either 'hann', 'cos2' (default), 'linear', or 'zero', the type of forward-solution interpolation to use between forward solutions at different head positions.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in place.

mne.simulation.add_ecg

---

## mne.simulation.add_ecg#

**URL:** https://mne.tools/stable/generated/mne.simulation.add_ecg.html

**Contents:**
- mne.simulation.add_ecg#
- Examples using mne.simulation.add_ecg#

Add ECG noise to raw data.

The raw instance to modify.

Path to the position estimates file. Should be in the format of the files produced by MaxFilter. If dict, keys should be the time points and entries should be 4x4 dev_head_t matrices. If None, the original head position (from info['dev_head_t']) will be used. If tuple, should have the same format as data returned by head_pos_to_trans_rot_t. If array, should be of the form returned by mne.chpi.read_head_pos().

Either 'hann', 'cos2' (default), 'linear', or 'zero', the type of forward-solution interpolation to use between forward solutions at different head positions.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state. The random generator state used for blink, ECG, and sensor noise randomization.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in place.

The ECG artifacts are generated by:

Random inter-beat intervals are drawn from a uniform distribution of times corresponding to 40 and 80 beats per minute.

The activation function is the sum of three Hanning windows with varying durations and scales to make a more complex waveform.

The activated dipole is located one (estimated) head radius to the left (-x) of head center and three head radii below (+z) head center; this dipole is oriented in the +x direction.

Activations only affect MEG channels.

The scale-factor of the activation function was chosen based on visual inspection to yield amplitudes generally consistent with those seen in experimental data. Noisy versions of the activation will be stored in the first EOG channel in the raw instance, if it exists.

Generate simulated raw data

Simulate raw data using subject anatomy

mne.simulation.add_chpi

mne.simulation.add_eog

---

## mne.simulation.add_eog#

**URL:** https://mne.tools/stable/generated/mne.simulation.add_eog.html

**Contents:**
- mne.simulation.add_eog#
- Examples using mne.simulation.add_eog#

Add blink noise to raw data.

The raw instance to modify.

Path to the position estimates file. Should be in the format of the files produced by MaxFilter. If dict, keys should be the time points and entries should be 4x4 dev_head_t matrices. If None, the original head position (from info['dev_head_t']) will be used. If tuple, should have the same format as data returned by head_pos_to_trans_rot_t. If array, should be of the form returned by mne.chpi.read_head_pos().

Either 'hann', 'cos2' (default), 'linear', or 'zero', the type of forward-solution interpolation to use between forward solutions at different head positions.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state. The random generator state used for blink, ECG, and sensor noise randomization.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in place.

The blink artifacts are generated by:

Random activation times are drawn from an inhomogeneous poisson process whose blink rate oscillates between 4.5 blinks/minute and 17 blinks/minute based on the low (reading) and high (resting) blink rates from [1].

The activation kernel is a 250 ms Hanning window.

Two activated dipoles are located in the z=0 plane (in head coordinates) at ±30 degrees away from the y axis (nasion).

Activations affect MEG and EEG channels.

The scale-factor of the activation function was chosen based on visual inspection to yield amplitudes generally consistent with those seen in experimental data. Noisy versions of the activation will be stored in the first EOG channel in the raw instance, if it exists.

Anna Rita Bentivoglio, Susan B. Bressman, Emanuele Cassetta, Donatella Carretta, Pietro Tonali, and Alberto Albanese. Analysis of blink rate patterns in normal subjects. Movement Disorders, 12(6):1028–1034, 1997. doi:10.1002/mds.870120629.

Generate simulated raw data

Simulate raw data using subject anatomy

mne.simulation.add_ecg

mne.simulation.add_noise

---

## mne.simulation.add_noise#

**URL:** https://mne.tools/stable/generated/mne.simulation.add_noise.html

**Contents:**
- mne.simulation.add_noise#
- Examples using mne.simulation.add_noise#

Create noise as a multivariate Gaussian.

The spatial covariance of the noise is given from the cov matrix.

Instance to which to add noise.

The noise covariance.

IIR filter coefficients (denominator).

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified to have additional noise.

Only channels in both inst.info['ch_names'] and cov['names'] will have noise added to them.

This function operates inplace on inst.

Compare simulated and estimated source activity

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

DICS for power mapping

mne.simulation.add_eog

mne.simulation.simulate_evoked

---

## mne.simulation.metrics.cosine_score#

**URL:** https://mne.tools/stable/generated/mne.simulation.metrics.cosine_score.html

**Contents:**
- mne.simulation.metrics.cosine_score#
- Examples using mne.simulation.metrics.cosine_score#

Compute cosine similarity between 2 source estimates.

The source estimates containing correct values.

The source estimates containing estimated values e.g. obtained with a source imaging method.

If True the metric is computed for each sample separately. If False, the metric is spatio-temporal.

The metric. float if per_sample is False, else array with the values computed for each time point.

Compare simulated and estimated source activity

mne.simulation.SourceSimulator

mne.simulation.metrics.region_localization_error

---

## mne.simulation.metrics.f1_score#

**URL:** https://mne.tools/stable/generated/mne.simulation.metrics.f1_score.html

**Contents:**
- mne.simulation.metrics.f1_score#
- Examples using mne.simulation.metrics.f1_score#

Compute the F1 score, also known as balanced F-score or F-measure.

The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:

Threshold is used first for data binarization.

The source estimates containing correct values.

The source estimates containing estimated values e.g. obtained with a source imaging method.

The threshold to apply to source estimates before computing the f1 score. If a string the threshold is a percentage and it should end with the percent character.

If True the metric is computed for each sample separately. If False, the metric is spatio-temporal.

The metric. float if per_sample is False, else array with the values computed for each time point.

Compare simulated and estimated source activity

mne.simulation.metrics.region_localization_error

mne.simulation.metrics.precision_score

---

## mne.simulation.metrics.peak_position_error#

**URL:** https://mne.tools/stable/generated/mne.simulation.metrics.peak_position_error.html

**Contents:**
- mne.simulation.metrics.peak_position_error#
- Examples using mne.simulation.metrics.peak_position_error#

Compute the peak position error.

The peak position error measures the distance between the center-of-mass of the estimated and the true source.

where \(r_{true}\) is a true dipole position, \(r_i\) and \(|s_i|\) denote respectively the position and amplitude of i-th dipole in source estimate.

Threshold is used on estimated source for focusing the metric to strong amplitudes and omitting the low-amplitude values.

The source estimates containing correct values.

The source estimates containing estimated values e.g. obtained with a source imaging method.

The source space on which the source estimates are defined.

The threshold to apply to source estimates before computing the recall. If a string the threshold is a percentage and it should end with the percent character.

If True the metric is computed for each sample separately. If False, the metric is spatio-temporal.

The metric. float if per_sample is False, else array with the values computed for each time point.

These metrics are documented in [1] and [2].

Matti Stenroos and Olaf Hauk. Minimum-norm cortical source estimation in layered head models is robust against skull conductivity error. NeuroImage, 81:265–272, November 2013. doi:10.1016/j.neuroimage.2013.04.086.

Fa-Hsuan Lin, Thomas Witzel, Seppo P. Ahlfors, Steven M. Stufflebeam, John W. Belliveau, and Matti S. Hämäläinen. Assessing and improving the spatial accuracy in MEG source localization by depth-weighted minimum-norm estimates. NeuroImage, 31(1):160–171, 2006. doi:10.1016/j.neuroimage.2005.11.054.

Compare simulated and estimated source activity

mne.simulation.metrics.spatial_deviation_error

---

## mne.simulation.metrics.precision_score#

**URL:** https://mne.tools/stable/generated/mne.simulation.metrics.precision_score.html

**Contents:**
- mne.simulation.metrics.precision_score#
- Examples using mne.simulation.metrics.precision_score#

Compute the precision.

The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.

The best value is 1 and the worst value is 0.

Threshold is used first for data binarization.

The source estimates containing correct values.

The source estimates containing estimated values e.g. obtained with a source imaging method.

The threshold to apply to source estimates before computing the precision. If a string the threshold is a percentage and it should end with the percent character.

If True the metric is computed for each sample separately. If False, the metric is spatio-temporal.

The metric. float if per_sample is False, else array with the values computed for each time point.

Compare simulated and estimated source activity

mne.simulation.metrics.f1_score

mne.simulation.metrics.recall_score

---

## mne.simulation.metrics.recall_score#

**URL:** https://mne.tools/stable/generated/mne.simulation.metrics.recall_score.html

**Contents:**
- mne.simulation.metrics.recall_score#
- Examples using mne.simulation.metrics.recall_score#

The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.

The best value is 1 and the worst value is 0.

Threshold is used first for data binarization.

The source estimates containing correct values.

The source estimates containing estimated values e.g. obtained with a source imaging method.

The threshold to apply to source estimates before computing the recall. If a string the threshold is a percentage and it should end with the percent character.

If True the metric is computed for each sample separately. If False, the metric is spatio-temporal.

The metric. float if per_sample is False, else array with the values computed for each time point.

Compare simulated and estimated source activity

mne.simulation.metrics.precision_score

mne.simulation.metrics.roc_auc_score

---

## mne.simulation.metrics.region_localization_error#

**URL:** https://mne.tools/stable/generated/mne.simulation.metrics.region_localization_error.html

**Contents:**
- mne.simulation.metrics.region_localization_error#
- Examples using mne.simulation.metrics.region_localization_error#

Compute region localization error (RLE) between 2 source estimates.

where \(I\) and \(\hat{I}\) denote respectively the original and estimated indexes of active sources, \(Q\) and \(\hat{Q}\) are the numbers of original and estimated active sources. \(r_k\) denotes the position of the k-th source dipole in space and \(||\cdot||\) is an Euclidean norm in \(\mathbb{R}^3\).

The source estimates containing correct values.

The source estimates containing estimated values e.g. obtained with a source imaging method.

The source space on which the source estimates are defined.

The threshold to apply to source estimates before computing the dipole localization error. If a string the threshold is a percentage and it should end with the percent character.

If True the metric is computed for each sample separately. If False, the metric is spatio-temporal.

The metric. float if per_sample is False, else array with the values computed for each time point.

Papers [1] and [2] use term Dipole Localization Error (DLE) for the same formula. Paper [3] uses term Error Distance (ED) for the same formula. To unify the terminology and to avoid confusion with other cases of using term DLE but for different metric [4], we use term Region Localization Error (RLE).

Kostiantyn Maksymenko, Bernard Giusiano, Nicolas Roehri, Christian-G. Bénar, and Jean-Michel Badier. Strategies for statistical thresholding of source localization maps in magnetoencephalography and estimating source extent. Journal of Neuroscience Methods, 290:95–104, October 2017. doi:10.1016/j.jneumeth.2017.07.015.

H. Becker, L. Albera, P. Comon, J. -C. Nunes, R. Gribonval, J. Fleureau, P. Guillotel, and I. Merlet. SISSY: An efficient and automatic algorithm for the analysis of EEG sources based on structured sparsity. NeuroImage, 157:157–172, August 2017. doi:10.1016/j.neuroimage.2017.05.046.

Jun Yao and Julius P. A. Dewald. Evaluation of different cortical source localization methods using simulated and experimental EEG data. NeuroImage, 25(2):369–382, April 2005. doi:10.1016/j.neuroimage.2004.11.036.

Molins A, Stufflebeam S. M., Brown E. N., and Hämäläinen M. S. Quantification of the benefit from integrating MEG and EEG data in minimum l2-norm estimation. Neuroimage, 42(3):1069–1077, 2008. doi:10.1016/j.neuroimage.2008.05.064.

Compare simulated and estimated source activity

mne.simulation.metrics.cosine_score

mne.simulation.metrics.f1_score

---

## mne.simulation.metrics.roc_auc_score#

**URL:** https://mne.tools/stable/generated/mne.simulation.metrics.roc_auc_score.html

**Contents:**
- mne.simulation.metrics.roc_auc_score#

Compute ROC AUC between 2 source estimates.

ROC stands for receiver operating curve and AUC is Area under the curve. When computing this metric the stc_true must be thresholded as any non-zero value will be considered as a positive.

The ROC-AUC metric is computed between amplitudes of the source estimates, i.e. after taking the absolute values.

The source estimates containing correct values.

The source estimates containing estimated values e.g. obtained with a source imaging method.

If True the metric is computed for each sample separately. If False, the metric is spatio-temporal.

The metric. float if per_sample is False, else array with the values computed for each time point.

mne.simulation.metrics.recall_score

mne.simulation.metrics.spatial_deviation_error

---

## mne.simulation.metrics.spatial_deviation_error#

**URL:** https://mne.tools/stable/generated/mne.simulation.metrics.spatial_deviation_error.html

**Contents:**
- mne.simulation.metrics.spatial_deviation_error#
- Examples using mne.simulation.metrics.spatial_deviation_error#

Compute the spatial deviation.

The spatial deviation characterizes the spread of the estimate source around the true source.

where \(r_{true}\) is a true dipole position, \(r_i\) and \(|s_i|\) denote respectively the position and amplitude of i-th dipole in source estimate.

Threshold is used on estimated source for focusing the metric to strong amplitudes and omitting the low-amplitude values.

The source estimates containing correct values.

The source estimates containing estimated values e.g. obtained with a source imaging method.

The source space on which the source estimates are defined.

The threshold to apply to source estimates before computing the recall. If a string the threshold is a percentage and it should end with the percent character.

If True the metric is computed for each sample separately. If False, the metric is spatio-temporal.

The metric. float if per_sample is False, else array with the values computed for each time point.

These metrics are documented in [1] and [2].

Matti Stenroos and Olaf Hauk. Minimum-norm cortical source estimation in layered head models is robust against skull conductivity error. NeuroImage, 81:265–272, November 2013. doi:10.1016/j.neuroimage.2013.04.086.

Fa-Hsuan Lin, Thomas Witzel, Seppo P. Ahlfors, Steven M. Stufflebeam, John W. Belliveau, and Matti S. Hämäläinen. Assessing and improving the spatial accuracy in MEG source localization by depth-weighted minimum-norm estimates. NeuroImage, 31(1):160–171, 2006. doi:10.1016/j.neuroimage.2005.11.054.

Compare simulated and estimated source activity

mne.simulation.metrics.roc_auc_score

mne.simulation.metrics.peak_position_error

---

## mne.simulation.select_source_in_label#

**URL:** https://mne.tools/stable/generated/mne.simulation.select_source_in_label.html

**Contents:**
- mne.simulation.select_source_in_label#

Select source positions using a label.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

The label location to choose. Can be ‘random’ (default) or ‘center’ to use mne.Label.center_of_mass() (restricting to vertices both in the label and in the source space). Note that for ‘center’ mode the label values are used as weights.

The subject the label is defined for. Only used with location='center'.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The surface to use for Euclidean distance center of mass finding. The default here is “sphere”, which finds the center of mass on the spherical surface to help avoid potential issues with cortical folding.

Selected source coefficients on the left hemisphere.

Selected source coefficients on the right hemisphere.

mne.simulation.simulate_sparse_stc

mne.simulation.SourceSimulator

---

## mne.simulation.simulate_raw#

**URL:** https://mne.tools/stable/generated/mne.simulation.simulate_raw.html

**Contents:**
- mne.simulation.simulate_raw#
- Examples using mne.simulation.simulate_raw#

Head movements can optionally be simulated using the head_pos parameter.

The mne.Info object with information about the sensors and methods of measurement. Used for simulation.

Changed in version 0.18: Support for mne.Info.

The source estimates to use to simulate data. Each must have the same sample rate as the raw data, and the vertices of all stcs in the iterable must match. Each entry in the iterable can also be a tuple of (SourceEstimate, ndarray) to allow specifying the stim channel (e.g., STI001) data accompany the source estimate. See Notes for details.

Changed in version 0.18: Support for tuple, iterable of tuple or SourceEstimate, or SourceSimulator.

Either a transformation filename (usually made using mne_analyze) or an info dict (usually opened using read_trans()). If string, an ending of .fif or .fif.gz will be assumed to be in FIF format, any other ending will be assumed to be a text file with a 4x4 transformation matrix (like the --trans MNE-C option). If trans is None, an identity transform will be used.

Source space corresponding to the stc. If string, should be a source space filename. Can also be an instance of loaded or generated SourceSpaces. Can be None if forward is provided.

BEM solution corresponding to the stc. If string, should be a BEM solution filename (e.g., “sample-5120-5120-5120-bem-sol.fif”). Can be None if forward is provided.

Path to the position estimates file. Should be in the format of the files produced by MaxFilter. If dict, keys should be the time points and entries should be 4x4 dev_head_t matrices. If None, the original head position (from info['dev_head_t']) will be used. If tuple, should have the same format as data returned by head_pos_to_trans_rot_t. If array, should be of the form returned by mne.chpi.read_head_pos(). See for example [1].

Minimum distance between sources and the inner skull boundary to use during forward calculation.

Either 'hann', 'cos2' (default), 'linear', or 'zero', the type of forward-solution interpolation to use between forward solutions at different head positions.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

The forward operator to use. If None (default) it will be computed using bem, trans, and src. If not None, bem, trans, and src are ignored.

The first_samp property in the output Raw instance.

The maximum number of STC iterations to allow. This is a sanity parameter to prevent accidental blowups.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The simulated raw file.

Stim channel encoding

By default, the stimulus channel will have the head position number (starting at 1) stored in the trigger channel (if available) at the t=0 point in each repetition of the stc. If stc is a tuple of (SourceEstimate, ndarray) the array values will be placed in the stim channel aligned with the mne.SourceEstimate.

In the most advanced case where stc is an iterable of tuples the output will be concatenated in time as:

Eric Larson and Samu Taulu. The importance of properly compensating for head movements during MEG acquisition across different age groups. Brain Topography, 30(2):172–181, 2017. doi:10.1007/s10548-016-0523-1.

Compare simulated and estimated source activity

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

DICS for power mapping

mne.simulation.simulate_evoked

mne.simulation.simulate_stc

---

## mne.simulation.simulate_sparse_stc#

**URL:** https://mne.tools/stable/generated/mne.simulation.simulate_sparse_stc.html

**Contents:**
- mne.simulation.simulate_sparse_stc#
- Examples using mne.simulation.simulate_sparse_stc#

Generate sparse (n_dipoles) sources time courses from data_fun.

This function randomly selects n_dipoles vertices in the whole cortex or one single vertex (randomly in or in the center of) each label if labels is not None. It uses data_fun to generate waveforms for each vertex.

Number of dipoles to simulate.

Function to generate the waveforms. The default is a 100 nAm, 10 Hz sinusoid as 1e-7 * np.sin(20 * pi * t). The function should take as input the array of time samples in seconds and return an array of the same length containing the time courses.

The labels. The default is None, otherwise its size must be n_dipoles.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

The label location to choose. Can be 'random' (default) or 'center' to use mne.Label.center_of_mass(). Note that for 'center' mode the label values are used as weights.

The subject the label is defined for. Only used with location='center'.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The surface to use for Euclidean distance center of mass finding. The default here is “sphere”, which finds the center of mass on the spherical surface to help avoid potential issues with cortical folding.

The generated source time courses.

Cortical Signal Suppression (CSS) for removal of cortical signals

Generate simulated evoked data

Generate simulated raw data

mne.simulation.simulate_stc

mne.simulation.select_source_in_label

---

## mne.simulation.simulate_stc#

**URL:** https://mne.tools/stable/generated/mne.simulation.simulate_stc.html

**Contents:**
- mne.simulation.simulate_stc#
- Examples using mne.simulation.simulate_stc#

Simulate sources time courses from waveforms and labels.

This function generates a source estimate with extended sources by filling the labels with the waveforms given in stc_data.

The beginning of the timeseries.

The time step (1 / sampling frequency).

Function to apply to the label values to obtain the waveform scaling for each vertex in the label. If None (default), uniform scaling is used.

Allow overlapping labels or not. Default value is False.

The generated source time courses.

Corrupt known signal with point spread

mne.simulation.simulate_raw

mne.simulation.simulate_sparse_stc

---

## mne.simulation.SourceSimulator#

**URL:** https://mne.tools/stable/generated/mne.simulation.SourceSimulator.html

**Contents:**
- mne.simulation.SourceSimulator#
- Examples using mne.simulation.SourceSimulator#

Class to generate simulated Source Estimates.

Time step between successive samples in data. Default is 0.001 s.

Time interval during which the simulation takes place in seconds. If None, it is computed using existing events and waveform lengths.

First sample from which the simulation takes place, as an integer. Comparable to the first_samp property of Raw objects. Default is 0.

Duration of the simulation in same units as tstep.

Number of time samples in the simulation.

Iterate over 1 second STCs.

add_data(label, waveform, events)

Add data to the simulation.

get_stc([start_sample, stop_sample])

Simulate a SourceEstimate from the provided data.

get_stim_channel([start_sample, stop_sample])

Get the stim channel from the provided data.

Iterate over 1 second STCs.

Add data to the simulation.

Data should be added in the form of a triplet of Label (Where) - Waveform(s) (What) - Event(s) (When)

The label (as created for example by mne.read_label). If the label does not match any sources in the SourceEstimate, a ValueError is raised.

The waveform(s) describing the activity on the label vertices. If list, it must have the same length as events.

Events associated to the waveform(s) to specify when the activity should occur.

Examples using add_data:

Compare simulated and estimated source activity

Simulate raw data using subject anatomy

Generate simulated source data

Duration of the simulation in same units as tstep.

Simulate a SourceEstimate from the provided data.

Returns a SourceEstimate object constructed according to the simulation parameters which should be added through function add_data. If both start_sample and stop_sample are not specified, the entire duration is used.

First sample in chunk. If None the value of the first_samp attribute is used. Defaults to None.

The final sample of the returned STC. If None, then all samples past start_sample are returned.

The generated source time courses.

Examples using get_stc:

Compare simulated and estimated source activity

Simulate raw data using subject anatomy

Get the stim channel from the provided data.

Returns the stim channel data according to the simulation parameters which should be added through the add_data method. If both start_sample and stop_sample are not specified, the entire duration is used.

First sample in chunk. Default is the value of the first_samp attribute.

The final sample of the returned stc. If None, then all samples from start_sample onward are returned.

The stimulation channel data.

Number of time samples in the simulation.

Compare simulated and estimated source activity

Simulate raw data using subject anatomy

Generate simulated source data

mne.simulation.select_source_in_label

mne.simulation.metrics.cosine_score

---

## mne.SourceEstimate#

**URL:** https://mne.tools/stable/generated/mne.SourceEstimate.html

**Contents:**
- mne.SourceEstimate#
- Examples using mne.SourceEstimate#

Container for surface source estimates.

The data in source space. When it is a single array, the left hemisphere is stored in data[:len(vertices[0])] and the right hemisphere is stored in data[-len(vertices[1]):]. When data is a tuple, it contains two arrays:

“kernel” shape (n_vertices, n_sensors) and

“sens_data” shape (n_sensors, n_times).

In this case, the source space data corresponds to np.dot(kernel, sens_data).

Vertex numbers corresponding to the data. The first element of the list contains vertices of left hemisphere and the second element contains vertices of right hemisphere.

Time point of the first sample in data.

Time step between successive samples in data.

The FreeSurfer subject name. While not necessary, it is safer to set the subject parameter to avoid analysis errors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A timestamp for each sample.

The indices of the dipoles in the left and right source space.

Numpy array of source estimate data.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

apply_baseline([baseline, verbose])

Baseline correct source estimate data.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of vertices.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

bin(width[, tstart, tstop, func])

Return a source estimate object with data summarized over time bins.

center_of_mass([subject, hemi, ...])

Compute the center of mass of activity.

Return copy of source estimate instance.

crop([tmin, tmax, include_tmax])

Restrict SourceEstimate to a time interval.

estimate_snr(info, fwd, cov[, verbose])

Compute time-varying SNR in the source space.

Expand SourceEstimate to include more vertices.

extract_label_time_course(labels, src[, ...])

Extract label time courses for lists of labels.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_peak([hemi, tmin, tmax, mode, ...])

Get location and latency of peak amplitude.

Get a source estimate object restricted to a label.

Make a summary stc file with mean over time points.

plot([subject, surface, hemi, colormap, ...])

resample(sfreq, *[, npad, method, window, ...])

save(fname[, ftype, overwrite, verbose])

Save the source estimates to a file.

save_as_surface(fname, src, *[, scale, scale_rr])

Save a surface source estimate (stc) as a GIFTI file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

Take the square root.

Make a summary stc file with sum over time points.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

to_original_src(src_orig[, subject_orig, ...])

Get a source estimate from morphed source to the original subject.

transform(func[, idx, tmin, tmax, copy])

Apply linear transform.

transform_data(func[, idx, tmin_idx, tmax_idx])

Get data after a linear (time) transform has been applied.

A container for vector surface source estimates.

A container for volume source estimates.

A container for volume vector source estimates.

A container for mixed surface + volume source estimates.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

Baseline correct source estimate data.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each source individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire source estimate data.

Baseline correction is appropriate when signal and noise are approximately additive, and the noise level can be estimated from the baseline interval. This can be the case for non-normalized source activities (e.g. signed and unsigned MNE), but it is not the case for normalized estimates (e.g. signal-to-noise ratios, dSPM, sLORETA).

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected source estimate object.

Baseline correction can be done multiple times.

Examples using apply_baseline:

Compute source level time-frequency timecourses using a DICS beamformer

Apply a function to a subset of vertices.

The function fun is applied to the vertices defined in picks. The source estimate object’s data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to vertices in picks).

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) because it will apply vertex-wise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if vertice_wise=False as the workload is split across vertices.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The SourceEstimate object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‘auto’, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal “x_a(t)” of “x(t)” is:

where “F” is the Fourier transform, “U” the unit step function, and “y” the Hilbert transform of “x”. One usage of the analytic signal is the computation of the envelope signal, which is given by “e(t) = abs(x_a(t))”. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Return a source estimate object with data summarized over time bins.

Time bins of width seconds. This method is intended for visualization only. No filter is applied to the data before binning, making the method inappropriate as a tool for downsampling data.

Width of the individual bins in seconds.

Time point where the first bin starts. The default is the first time point of the stc.

Last possible time point contained in a bin (if the last bin would be shorter than width it is dropped). The default is the last time point of the stc.

Function that is applied to summarize the data. Needs to accept a numpy.array as first input and an axis keyword argument.

The binned source estimate.

Compute the center of mass of activity.

This function computes the spatial center of mass on the surface as well as the temporal center of mass as in [1].

All activity must occur in a single hemisphere, otherwise an error is raised. The “mass” of each point in space for computing the spatial center of mass is computed by summing across time, and vice-versa for each point in time in computing the temporal center of mass. This is useful for quantifying spatio-temporal cluster locations, especially when combined with mne.vertex_to_mni().

The subject the stc is defined for.

Calculate the center of mass for the left (0) or right (1) hemisphere. If None, one of the hemispheres must be all zeroes, and the center of mass will be calculated for the other hemisphere (useful for getting COM for clusters).

If True, returned vertex will be one from stc. Otherwise, it could be any vertex from surf. If an array of int, the returned vertex will come from that array. If instance of SourceSpaces (as of 0.13), the returned vertex will be from the given source space. For most accuruate estimates, do not restrict vertices.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The surface to use for Euclidean distance center of mass finding. The default here is “sphere”, which finds the center of mass on the spherical surface to help avoid potential issues with cortical folding.

Vertex of the spatial center of mass for the inferred hemisphere, with each vertex weighted by the sum of the stc across time. For a boolean stc, then, this would be weighted purely by the duration each vertex was active.

Hemisphere the vertex was taken from.

Time of the temporal center of mass (weighted by the sum across source vertices).

Eric Larson and Adrian K.C. Lee. The cortical dynamics underlying effective switching of auditory spatial attention. NeuroImage, 64:365–370, 2013. doi:10.1016/j.neuroimage.2012.09.006.

Examples using center_of_mass:

Extracting time course from source_estimate object

Return copy of source estimate instance.

A copy of the source estimate.

Generate a functional label from source estimates

Compute source power spectral density (PSD) of VectorView and OPM data

Restrict SourceEstimate to a time interval.

The first time point in seconds. If None the first present is used.

The last time point in seconds. If None the last present is used.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The cropped source estimate.

Plotting with mne.viz.Brain

Permutation t-test on source data with spatio-temporal clustering

Numpy array of source estimate data.

Compute time-varying SNR in the source space.

This function should only be used with source estimates with units nanoAmperes (i.e., MNE-like solutions, not dSPM or sLORETA). See also [2].

This function currently only works properly for fixed orientation.

The mne.Info object with information about the sensors and methods of measurement.

The forward solution used to create the source estimate.

The noise covariance used to estimate the resting cortical activations. Should be an evoked covariance, not empty room.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimate with the SNR computed.

We define the SNR in decibels for each source location at each time point as:

where \(\\b_k\) is the signal on sensor \(k\) provided by the forward model for a source with unit amplitude, \(a\) is the source amplitude, \(N\) is the number of sensors, and \(s_k^2\) is the noise variance on sensor \(k\).

Daniel M. Goldenholz, Seppo P. Ahlfors, Matti S. Hämäläinen, Dahlia Sharon, Mamiko Ishitobi, Lucia M. Vaina, and Steven M. Stufflebeam. Mapping the signal-to-noise-ratios of cortical sources in magnetoencephalography and electroencephalography. Human Brain Mapping, 30(4):1077–1086, 2009. doi:10.1002/hbm.20571.

Examples using estimate_snr:

Computing source space SNR

Expand SourceEstimate to include more vertices.

This will add rows to stc.data (zero-filled) and modify stc.vertices to include all vertices in stc.vertices and the input vertices.

New vertices to add. Can also contain old values.

The modified stc (note: method operates inplace).

Extract label time courses for lists of labels.

This function will extract one time course for each label. The way the time courses are extracted depends on the mode parameter.

If using a surface or mixed source space, this should be the Label’s for which to extract the time course. If working with whole-brain volume source estimates, this must be one of:

a string path to a FreeSurfer atlas for the subject (e.g., their ‘aparc.a2009s+aseg.mgz’) to extract time courses for all volumes in the atlas

a two-element list or tuple, the first element being a path to an atlas, and the second being a list or dict of volume_labels to extract (see mne.setup_volume_source_space() for details).

Changed in version 0.21.0: Support for volume source estimates.

The source spaces for the source time courses.

Extraction mode, see Notes.

False (default) will emit an error if there are labels that have no vertices in the source estimate. True and 'ignore' will return all-zero time courses for labels that do not have any vertices in the source estimate, and True will emit a warning while and “ignore” will just log a message.

Changed in version 0.21.0: Support for “ignore”.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Extracted time course for each label and source estimate.

Extract time courses for multiple STCs.

Valid values for mode are:

Maximum absolute value across vertices at each time point within each label.

Average across vertices at each time point within each label. Ignores orientation of sources for standard source estimates, which varies across the cortical surface, which can lead to cancellation. Vector source estimates are always in XYZ / RAS orientation, and are thus already geometrically aligned.

Finds the dominant direction of source space normal vector orientations within each label, applies a sign-flip to time series at vertices whose orientation is more than 90° different from the dominant direction, and then averages across vertices at each time point within each label.

Applies singular value decomposition to the time courses within each label, and uses the first right-singular vector as the representative label time course. This signal is scaled so that its power matches the average (per-vertex) power within the label, and sign-flipped by multiplying by np.sign(u @ flip), where u is the first left-singular vector and flip is the same sign-flip vector used when mode='mean_flip'. This sign-flip ensures that extracting time courses from the same label in similar STCs does not result in 180° direction/phase changes.

Uses 'mean_flip' when a standard source estimate is applied, and 'mean' when a vector source estimate is supplied.

No aggregation is performed, and an array of shape (n_vertices, n_times) is returned.

New in v0.21: Support for 'auto', vector, and volume source estimates.

The only modes that work for vector and volume source estimates are 'mean', 'max', and 'auto'.

Examples using extract_label_time_course:

Generate a functional label from source estimates

Extracting the time series of activations in a label

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Get location and latency of peak amplitude.

The hemi to be considered. If None, the entire source space is considered.

The minimum point in time to be considered for peak getting.

The maximum point in time to be considered for peak getting.

How to deal with the sign of the data. If ‘pos’ only positive values will be considered. If ‘neg’ only negative values will be considered. If ‘abs’ absolute values will be considered. Defaults to ‘abs’.

Whether to return the vertex index (True) instead of of its ID (False, default).

Whether to return the time index (True) instead of the latency (False, default).

The vertex exhibiting the maximum response, either ID or index.

The time point of the maximum response, either latency in seconds or index.

Examples using get_peak:

The SourceEstimate data structure

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Get a source estimate object restricted to a label.

SourceEstimate contains the time course of activation of all sources inside the label.

The label (as created for example by mne.read_label). If the label does not match any sources in the SourceEstimate, a ValueError is raised.

The source estimate restricted to the given label.

Examples using in_label:

Compute MNE-dSPM inverse solution on single epochs

Extracting time course from source_estimate object

Generate a functional label from source estimates

Extracting the time series of activations in a label

Left hemisphere data.

Left hemisphere vertno.

Make a summary stc file with mean over time points.

The FreeSurfer subject name. If None, stc.subject will be used.

The type of surface (inflated, white etc.).

Hemisphere id (ie 'lh', 'rh', 'both', or 'split'). In the case of 'both', both hemispheres are shown in the same window. In the case of 'split' hemispheres are displayed side-by-side in different viewing panes.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255. The default (‘auto’) uses 'hot' for one-sided data and ‘mne’ for two-sided data.

Format of the time label (a format string, a function that maps floating point time values to strings, or None for no label). The default is 'auto', which will use time=%0.2f ms if there is more than one time point.

The amount of smoothing.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Alpha value to apply globally to the overlay. Has no effect with mpl backend.

Display time viewer GUI. Can also be ‘auto’, which will mean True for the PyVista backend and False otherwise.

Changed in version 0.20.0: “auto” mode added.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

If None, a new figure will be created. If multiple views or a split view is requested, this must be a list of the appropriate length. If int is provided it will be used to identify the PyVista figure by it’s id or create a new figure with the given id. If an instance of matplotlib figure, mpl backend is used for plotting.

View to use. Using multiple views (list) is not supported for mpl backend. See Brain.show_view for valid string options.

When plotting a standard SourceEstimate (not volume, mixed, or vector) and using the PyVista backend, views='flat' is also supported to plot cortex as a flatmap.

Using multiple views (list) is not supported by the matplotlib backend.

Changed in version 0.21.0: Support for flatmaps.

If True, display colorbar on scene.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bounds for colormap.

Lower, middle, and upper bound for colormap. Positive values will be mirrored directly across zero during colormap construction to obtain negative control points.

Only one of lims or pos_lims should be provided. Only sequential colormaps should be used with lims, and only divergent colormaps should be used with pos_lims.

Specifies how binarized curvature values are rendered. Either the name of a preset Brain cortex colorscheme (one of 'classic', 'bone', 'low_contrast', or 'high_contrast'), or the name of a colormap, or a tuple with values (colormap, min, max, reverse) to fully specify the curvature colors. Has no effect with the matplotlib backend.

The size of the window, in pixels. can be one number to specify a square window, or the (width, height) of a rectangular window. Has no effect with mpl backend.

Color of the background of the display window.

Color of the foreground of the display window. Has no effect with mpl backend. None will choose white or black based on the background color.

The time to display on the plot initially. None to display the first time sample (default).

Whether time is represented in seconds (“s”, default) or milliseconds (“ms”).

Which backend to use. If 'auto' (default), tries to plot with pyvistaqt, but resorts to matplotlib if no 3d backend is available.

Only affects the matplotlib backend. The spacing to use for the source space. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, or 'all' for all points. In general, you can speed up the plotting by selecting a sparser source space. Defaults to ‘oct6’.

Title for the figure window. If None, the subject name will be used.

If True, enable interactive picking of a point on the surface of the brain and plot its time course. This feature is only available with the PyVista 3d backend, and requires time_viewer=True. Defaults to ‘auto’, which will use True if and only if time_viewer=True, the backend is PyVista, and there is more than one time point. If float (between zero and one), it specifies what proportion of the total window should be devoted to traces (True is equivalent to 0.25, i.e., it will occupy the bottom 1/4 of the figure).

The source space corresponding to the source estimate. Only necessary if the STC is a volume or mixed source estimate.

Options for volumetric source estimate plotting, with key/value pairs:

Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks better at the cost of speed. None (default) uses the volume source space resolution, which is often something like 7 or 5 mm, without resampling.

Can be “mip” (default) for maximum intensity projection or “composite” for composite blending using alpha values.

Alpha for the volumetric rendering. Defaults are 0.4 for vector source estimates and 1.0 for scalar source estimates.

Alpha for the surface enclosing the volume(s). None (default) will use half the volume alpha. Set to zero to avoid plotting the surface.

Alpha for a silhouette along the outside of the volume. None (default) will use 0.25 * surface_alpha.

The line width to use for the silhouette. Default is 2.

A float input (default 1.) or None will be used for the 'resolution' entry.

Can be “vertical” (default) or “horizontal”. When using “horizontal” mode, the PyVista backend must be used and hemi cannot be “split”.

Additional arguments to brain.add_data (e.g., dict(time_label_size=10)).

Additional arguments to the mne.viz.Brain constructor (e.g., dict(silhouette=True)).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

An instance of mne.viz.Brain or matplotlib figure.

Flatmaps are available by default for fsaverage but not for other subjects reconstructed by FreeSurfer. We recommend using mne.compute_source_morph() to morph source estimates to fsaverage for flatmap plotting. If you want to construct your own flatmap for a given subject, these links might help:

https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferOccipitalFlattenedPatch

https://openwetware.org/wiki/Beauchamp:FreeSurfer

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Decoding source space data

Display sensitivity maps for EEG and MEG sensors

Use source space morphing

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Generate a functional label from source estimates

Compute source power estimate by projecting the covariance with MNE

Morph surface source estimate

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Plotting the full vector-valued MNE solution

Simulate raw data using subject anatomy

Compute Power Spectral Density of inverse solution from single epochs

Sensitivity map of SSP projections

Cross-hemisphere comparison

Working with ECoG data

Overview of MEG/EEG analysis with MNE-Python

The SourceEstimate data structure

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Visualize source time courses (stcs)

EEG source localization given electrode locations on an MRI

Working with CTF data: the Brainstorm auditory dataset

Preprocessing optically pumped magnetometer (OPM) MEG data

Corrupt known signal with point spread

DICS for power mapping

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

Make figures more publication ready

Using the event system to link figures

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be “auto” to use a padding that will result in a power-of-two size (can be much faster).

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn(). The default (“auto”) means 'reflect_limited' for method='fft' and 'reflect' for method='polyphase'.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled source estimate.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent – check your data!

Note that the sample rate of the original data is inferred from tstep.

Examples using resample:

2 samples permutation test on source data with spatio-temporal clustering

Right hemisphere data.

Right hemisphere vertno.

Save the source estimates to a file.

The stem of the file name. The file names used for surface source spaces are obtained by adding "-lh.stc" and "-rh.stc" (or "-lh.w" and "-rh.w") to the stem provided, for the left and the right hemisphere, respectively.

File format to use. Allowed values are "stc" (default), "w", and "h5". The "w" format only supports a single time point.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Compute sLORETA inverse solution on raw data

Compute source power spectral density (PSD) in a label

Compute induced power in the source space with dSPM

Save a surface source estimate (stc) as a GIFTI file.

Filename basename to save files as. Will write anatomical GIFTI plus time series GIFTI for both lh/rh, for example "basename" will write "basename.lh.gii", "basename.lh.time.gii", "basename.rh.gii", and "basename.rh.time.gii".

The source space of the forward solution.

Scale factor to apply to the data (functional) values.

Scale factor for the source vertex positions. The default (1e3) will scale from meters to millimeters, which is more standard for GIFTI files.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [3] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627–1639, 1964. doi:10.1021/ac60214a047.

Sample rate of the data.

Take the square root.

A copy of the SourceEstimate with sqrt(data).

Make a summary stc file with sum over time points.

Compute source power spectral density (PSD) of VectorView and OPM data

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

A timestamp for each sample.

Export data in tabular structure as a pandas DataFrame.

Vertices are converted to columns in the DataFrame. By default, an additional column “time” is added, unless index='time' (in which case time values form the DataFrame’s index).

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) — i.e., converts EEG to µV, magnetometers to fT, and gradiometers to fT/cm.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and vertex. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Get a source estimate from morphed source to the original subject.

The original source spaces that were morphed to the current subject.

The original subject. For most source spaces this shouldn’t need to be provided, since it is stored in the source space itself.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The transformed source estimate.

Examples using to_original_src:

Use source space morphing

Apply linear transform.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first two dimensions of the transformed data should be (i) vertices and (ii) time. See Notes for details.

Indices of source time courses for which to compute transform. If None, all time courses are used.

First time point to include (ms). If None, self.tmin is used.

Last time point to include (ms). If None, self.tmax is used.

If True, return a new instance of SourceEstimate instead of modifying the input inplace.

The transformed stc or, in the case of transforms which yield N-dimensional output (where N > 2), a list of stcs. For a list, copy must be True.

Transforms which yield 3D output (e.g. time-frequency transforms) are valid, so long as the first two dimensions are vertices and time. In this case, the copy parameter must be True and a list of SourceEstimates, rather than a single instance of SourceEstimate, will be returned, one for each index of the 3rd dimension of the transformed data. In the case of transforms yielding 2D output (e.g. filtering), the user has the option of modifying the input inplace (copy = False) or returning a new instance of SourceEstimate (copy = True) with the transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

Get data after a linear (time) transform has been applied.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first return value is the transformed data, remaining outputs are ignored. The first dimension of the transformed data has to be the same as the first dimension of the input data.

Indicices of source time courses for which to compute transform. If None, all time courses are used.

Index of first time point to include. If None, the index of the first time point is used.

Index of the first time point not to include. If None, time points up to (and including) the last time point are included.

The transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

The change in time between two consecutive samples (1 / sfreq).

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Decoding source space data

Display sensitivity maps for EEG and MEG sensors

Use source space morphing

Compute MNE-dSPM inverse solution on single epochs

Compute sLORETA inverse solution on raw data

Source localization with a custom inverse solver

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Extracting time course from source_estimate object

Generate a functional label from source estimates

Extracting the time series of activations in a label

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute source power estimate by projecting the covariance with MNE

Morph surface source estimate

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Plotting the full vector-valued MNE solution

Cortical Signal Suppression (CSS) for removal of cortical signals

Compare simulated and estimated source activity

Generate simulated evoked data

Generate simulated raw data

Simulate raw data using subject anatomy

Compute Power Spectral Density of inverse solution from single epochs

Compute source power spectral density (PSD) in a label

Compute source power spectral density (PSD) of VectorView and OPM data

Compute induced power in the source space with dSPM

Plotting with mne.viz.Brain

Sensitivity map of SSP projections

Cross-hemisphere comparison

Working with ECoG data

FreeSurfer MRI reconstruction

Overview of MEG/EEG analysis with MNE-Python

Getting started with mne.Report

The SourceEstimate data structure

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Visualize source time courses (stcs)

EEG source localization given electrode locations on an MRI

Working with CTF data: the Brainstorm auditory dataset

Preprocessing optically pumped magnetometer (OPM) MEG data

Corrupt known signal with point spread

DICS for power mapping

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

Make figures more publication ready

Using the event system to link figures

mne.MixedVectorSourceEstimate

mne.VectorSourceEstimate

---

## mne.SourceMorph#

**URL:** https://mne.tools/stable/generated/mne.SourceMorph.html

**Contents:**
- mne.SourceMorph#
- Examples using mne.SourceMorph#

Morph source space data from one subject to another.

This class should not be instantiated directly via mne.SourceMorph(...). Instead, use one of the functions listed in the See Also section below.

Name of the subject from which to morph as named in the SUBJECTS_DIR.

Name of the subject on which to morph as named in the SUBJECTS_DIR. The default is ‘fsaverage’. If morphing a volume source space, subject_to can be the path to a MRI volume. Can also be a list of two arrays if morphing to hemisphere surfaces.

Kind of source estimate. E.g. 'volume' or 'surface'.

See mne.compute_source_morph().

Number of levels (len(niter_affine)) and number of iterations per level - for each successive stage of iterative refinement - to perform the affine transform.

Number of levels (len(niter_sdr)) and number of iterations per level - for each successive stage of iterative refinement - to perform the Symmetric Diffeomorphic Registration (sdr) transform [1].

See mne.compute_source_morph().

See mne.compute_source_morph().

Morph across hemisphere.

The sparse surface morphing matrix for spherical surface based morphing [2].

The destination surface vertices.

The volume MRI shape.

The volume MRI affine.

The transformation that is applied before the before sdr_morph.

The class that applies the the symmetric diffeomorphic registration (SDR) morph.

Additional source data necessary to perform morphing.

The volumetric morph matrix, if compute_vol_morph_mat() was used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

apply(stc_from[, output, mri_resolution, ...])

Morph source space data.

compute_vol_morph_mat(*[, verbose])

Compute the sparse matrix representation of the volumetric morph.

save(fname[, overwrite, verbose])

Save the morph for source estimates to a file.

Brian B. Avants, Charles L. Epstein, Murray C. Grossman, and James C. Gee. Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain. Medical Image Analysis, 12(1):26–41, 2008. doi:10.1016/j.media.2007.06.004.

Douglas N. Greve, Lise Van der Haegen, Qing Cai, Steven Stufflebeam, Mert R. Sabuncu, Bruce Fischl, and Marc Brysbaert. A surface-based analysis of language lateralization and cortical asymmetry. Journal of Cognitive Neuroscience, 25(9):1477–1492, 2013. doi:10.1162/jocn_a_00405.

Morph source space data.

The source estimate to morph.

Can be 'stc' (default) or possibly 'nifti1', or 'nifti2' when working with a volume source space defined on a regular grid.

If True the image is saved in MRI resolution. Default False.

Whether the image to world registration should be in mri space. The default (None) is mri_space=mri_resolution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The morphed source estimates.

Examples using apply:

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Morph surface source estimate

Morph volumetric source estimate

Cross-hemisphere comparison

Source reconstruction using an LCMV beamformer

2 samples permutation test on source data with spatio-temporal clustering

Compute the sparse matrix representation of the volumetric morph.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in-place).

For a volumetric morph, this will compute the morph for an identity source volume, i.e., with one source vertex active at a time, and store the result as a sparse morphing matrix. This takes a long time (minutes) to compute initially, but drastically speeds up apply() for STCs, so it can be beneficial when many time points or many morphs (i.e., greater than the number of volumetric src_from vertices) will be performed.

When calling save(), this sparse morphing matrix is saved with the instance, so this only needs to be called once. This function does nothing if the morph matrix has already been computed, or if there is no volume morphing necessary.

Examples using compute_vol_morph_mat:

Morph volumetric source estimate

Save the morph for source estimates to a file.

The path to the file. '-morph.h5' will be added if fname does not end with '.h5'.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Morph volumetric source estimate

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Morph surface source estimate

Morph volumetric source estimate

Cross-hemisphere comparison

Source reconstruction using an LCMV beamformer

2 samples permutation test on source data with spatio-temporal clustering

mne.VolVectorSourceEstimate

mne.compute_source_morph

---

## mne.SourceSpaces#

**URL:** https://mne.tools/stable/generated/mne.SourceSpaces.html

**Contents:**
- mne.SourceSpaces#
- Examples using mne.SourceSpaces#

Represent a list of source space.

This class acts like a list of dictionaries containing the source space information, one entry in the list per source space type. See Notes for details.

This class should not be created or modified by the end user. Use mne.setup_source_space(), mne.setup_volume_source_space(), or mne.read_source_spaces() to create SourceSpaces.

A list of dictionaries containing the source space information.

Dictionary with information about the creation of the source space file. Has keys 'working_dir' and 'command_line'.

The kind of source space.

Dictionary with information about the creation of the source space file. Has keys 'working_dir' and 'command_line'.

Combine source spaces.

__getitem__(*args, **kwargs)

Make a copy of the source spaces.

export_volume(fname[, include_surfaces, ...])

Export source spaces to nifti or mgz file.

plot([head, brain, skull, subjects_dir, ...])

Plot the source space.

save(fname[, overwrite, verbose])

Save the source spaces to a fif file.

Setup a surface source space.

Setup a volume source space.

Read source spaces from a file.

Each element in SourceSpaces (e.g., src[0]) is a dictionary. For example, a surface source space will have len(src) == 2, one entry for each hemisphere. A volume source space will have len(src) == 1 if it uses a single monolithic grid, or len(src) == len(volume_label) when created with a list-of-atlas-labels. A mixed source space consists of both surface and volumetric source spaces in a single SourceSpaces object.

Each of those dictionaries can be accessed using standard Python dict access using the string keys listed below (e.g., src[0]['type'] == 'surf'). The relevant key/value pairs depend on the source space type:

Relevant to all source spaces

The following are always present:

The FIF ID, either FIFF.FIFFV_MNE_SURF_LEFT_HEMI or FIFF.FIFFV_MNE_SURF_RIGHT_HEMI for surfaces, or FIFF.FIFFV_MNE_SURF_UNKNOWN for volume source spaces.

The type of source space, one of {'surf', 'vol', 'discrete'}.

Number of vertices in the dense surface or complete volume.

The coordinate frame, usually FIFF.FIFFV_COORD_MRI.

The dense surface or complete volume vertex locations.

The dense surface or complete volume normals.

The number of points in the subsampled surface.

An integer array defining whether each dense surface vertex is used (1) or unused (0).

The vertex numbers of the dense surface or complete volume that are used (i.e., np.where(src[0]['inuse'])[0]).

The FreeSurfer subject name.

Surface source spaces

Surface source spaces created using mne.setup_source_space() can have the following additional entries (which will be missing, or have values of None or 0 for volumetric source spaces):

Number of triangles in the dense surface triangulation.

The dense surface triangulation.

The number of triangles in the subsampled surface.

The subsampled surface triangulation.

The distances (euclidean for volume, along the cortical surface for surfaces) between source points.

The maximum distance allowed for inclusion in nearest.

For each vertex in the subsampled surface, the indices of the vertices in the dense surface that it represents (i.e., is closest to of all subsampled indices), e.g. for the left hemisphere (here constructed for sample with spacing='oct-6'), which vertices did we choose? Note the first is 14:

And which dense surface verts did our vertno[0] (14 on dense) represent?

The patch indices that have been retained (if relevant, following forward computation. After just mne.setup_source_space(), this will be np.arange(src[0]['nuse']). After forward computation, some vertices can be excluded, in which case this tells you which patches (of the original np.arange(nuse)) are still in use. So if some vertices have been excluded, the line above for pinfo for completeness should be (noting that the first subsampled vertex ([0]) represents the following dense vertices):

For each vertex on the dense surface, this gives the vertex index (in the dense surface) that each dense surface vertex is closest to of the vertices chosen for subsampling. This is essentially the reverse map off pinfo, e.g.:

Based on pinfo above, this should be 14:

The distances corresponding to nearest.

Volume source spaces created using mne.setup_volume_source_space() can have the following additional entries (which will be missing, or have values of None or 0 for surface source spaces):

The MRI dimensions (in voxels).

The 26-neighborhood information for each vertex.

The linear interpolator to go from the subsampled volume vertices to the high-resolution volume.

The shape of the subsampled grid.

The transformation from MRI surface RAS (FIFF.FIFFV_COORD_MRI) to MRI scanner RAS (FIFF.FIFFV_MNE_COORD_RAS).

The transformation from subsampled source space voxel to MRI surface RAS.

The transformation from the original MRI voxel (FIFF.FIFFV_MNE_COORD_MRI_VOXEL) space to MRI surface RAS.

The MRI volume name, e.g. 'subjects_dir/subject/mri/T1.mgz'.

The MRI atlas segmentation name (e.g., 'Left-Cerebellum-Cortex' from the parameter volume_label).

Source spaces also have some attributes that are accessible via . access, like src.kind.

Combine source spaces.

Make a copy of the source spaces.

The copied source spaces.

Export source spaces to nifti or mgz file.

Name of nifti or mgz file to write.

If True, include surface source spaces.

If True, include discrete source spaces.

If 'mri' the volume is defined in the coordinate system of the original T1 image. If 'surf' the coordinate system of the FreeSurfer surface is used (Surface RAS).

Either a transformation filename (usually made using mne_analyze) or an info dict (usually opened using read_trans()). If string, an ending of .fif or .fif.gz will be assumed to be in FIF format, any other ending will be assumed to be a text file with a 4x4 transformation matrix (like the --trans MNE-C option. Must be provided if source spaces are in head coordinates and include_surfaces and mri_resolution are True.

If True, the image is saved in MRI resolution (e.g. 256 x 256 x 256), and each source region (surface or segmentation volume) filled in completely. If “sparse”, only a single voxel in the high-resolution MRI is filled in for each source point.

Changed in version 0.21.0: Support for "sparse" was added.

If True, assigns a numeric value to each source space that corresponds to a color on the freesurfer lookup table.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

This method requires nibabel.

Examples using export_volume:

Compute MNE inverse solution on evoked data with a mixed source space

Plot the source space.

If True, show head surface.

If True, show the brain surfaces. Can also be a str for surface type (e.g., 'pial', same as True). Default is None, which means 'white' for surface source spaces and False otherwise.

Whether to plot skull surface. If string, common choices would be 'inner_skull', or 'outer_skull'. Can also be a list to plot multiple skull surfaces. If a list of dicts, each dict must contain the complete surface info (such as you get from mne.make_bem_model()). True is an alias of ‘outer_skull’. The subjects bem and bem/flash folders are searched for the ‘surf’ files. Defaults to None, which is False for surface source spaces, and True otherwise.

Path to SUBJECTS_DIR if it is not set in the environment.

The full path to the head<->MRI transform *-trans.fif file produced during coregistration. If trans is None, an identity matrix is assumed. This is only needed when the source space is in head coordinates.

PyVista scene in which to plot the alignment. If None, creates a new 600x600 pixel figure with black background.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Compute MNE inverse solution on evoked data with a mixed source space

Save the source spaces to a fif file.

File to write, which should end with -src.fif or -src.fif.gz.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Display sensitivity maps for EEG and MEG sensors

Generate a left cerebellum volume source space

Use source space morphing

Compute MNE-dSPM inverse solution on evoked data in volume source space

Generate a functional label from source estimates

Extracting the time series of activations in a label

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Morph surface source estimate

Morph volumetric source estimate

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) for a volume

Reading an inverse operator

Compare simulated and estimated source activity

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

Working with sEEG data

Working with ECoG data

FreeSurfer MRI reconstruction

Source alignment and coordinate frames

Head model and forward computation

EEG forward operator with a template MRI

How MNE uses FreeSurfer’s outputs

The SourceEstimate data structure

Source reconstruction using an LCMV beamformer

Visualize source time courses (stcs)

Setting the EEG reference

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.add_source_space_distances

---

## mne.source_space.compute_distance_to_sensors#

**URL:** https://mne.tools/stable/generated/mne.source_space.compute_distance_to_sensors.html

**Contents:**
- mne.source_space.compute_distance_to_sensors#
- Examples using mne.source_space.compute_distance_to_sensors#

Compute distances between vertices and sensors.

The object with vertex positions for which to compute distances to sensors.

The mne.Info object with information about the sensors and methods of measurement. Must contain sensor positions to which distances shall be computed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The Euclidean distances of source space vertices with respect to sensors.

Display sensitivity maps for EEG and MEG sensors

mne.transform_surface_to

mne.source_space.get_decimated_surfaces

---

## mne.source_space.get_decimated_surfaces#

**URL:** https://mne.tools/stable/generated/mne.source_space.get_decimated_surfaces.html

**Contents:**
- mne.source_space.get_decimated_surfaces#

Get the decimated surfaces from a source space.

The source space with decimated surfaces.

The decimated surfaces present in the source space. Each dict which contains ‘rr’ and ‘tris’ keys for vertices positions and triangle indices.

mne.source_space.compute_distance_to_sensors

---

## mne.spatial_dist_adjacency#

**URL:** https://mne.tools/stable/generated/mne.spatial_dist_adjacency.html

**Contents:**
- mne.spatial_dist_adjacency#

Compute adjacency from distances in a source space.

The source space must have distances between vertices computed, such that src[‘dist’] exists and is useful. This can be obtained with a call to mne.setup_source_space() with the add_dist=True option.

Maximal geodesic distance (in m) between vertices in the source space to consider neighbors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The adjacency matrix describing the spatial graph structure.

mne.stats.erp.compute_sme

mne.spatial_src_adjacency

---

## mne.spatial_inter_hemi_adjacency#

**URL:** https://mne.tools/stable/generated/mne.spatial_inter_hemi_adjacency.html

**Contents:**
- mne.spatial_inter_hemi_adjacency#

Get vertices on each hemisphere that are close to the other hemisphere.

The source space. Must be surface type.

Maximal Euclidean distance (in m) between vertices in one hemisphere compared to the other to consider neighbors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The adjacency matrix describing the spatial graph structure. Typically this should be combined (addititively) with another existing intra-hemispheric adjacency matrix, e.g. computed using geodesic distances.

mne.spatial_tris_adjacency

mne.spatio_temporal_src_adjacency

---

## mne.spatial_src_adjacency#

**URL:** https://mne.tools/stable/generated/mne.spatial_src_adjacency.html

**Contents:**
- mne.spatial_src_adjacency#
- Examples using mne.spatial_src_adjacency#

Compute adjacency for a source space activation.

The source space. It can be a surface source space or a volume source space.

Maximal geodesic distance (in m) between vertices in the source space to consider neighbors. If None, immediate neighbors are extracted from an ico surface.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The adjacency matrix describing the spatial graph structure.

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.spatial_dist_adjacency

mne.spatial_tris_adjacency

---

## mne.spatial_tris_adjacency#

**URL:** https://mne.tools/stable/generated/mne.spatial_tris_adjacency.html

**Contents:**
- mne.spatial_tris_adjacency#

Compute adjacency from triangles.

N x 3 array defining triangles.

Reassign vertex indices based on unique values. Useful to process a subset of triangles. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The adjacency matrix describing the spatial graph structure.

mne.spatial_src_adjacency

mne.spatial_inter_hemi_adjacency

---

## mne.spatio_temporal_dist_adjacency#

**URL:** https://mne.tools/stable/generated/mne.spatio_temporal_dist_adjacency.html

**Contents:**
- mne.spatio_temporal_dist_adjacency#

Compute adjacency from distances in a source space and time instants.

The source space must have distances between vertices computed, such that src[‘dist’] exists and is useful. This can be obtained with a call to mne.setup_source_space() with the add_dist=True option.

Number of time points.

Maximal geodesic distance (in m) between vertices in the source space to consider neighbors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The adjacency matrix describing the spatio-temporal graph structure. If N is the number of vertices in the source space, the N first nodes in the graph are the vertices are time 1, the nodes from 2 to 2N are the vertices during time 2, etc.

mne.spatio_temporal_tris_adjacency

---

## mne.spatio_temporal_src_adjacency#

**URL:** https://mne.tools/stable/generated/mne.spatio_temporal_src_adjacency.html

**Contents:**
- mne.spatio_temporal_src_adjacency#

Compute adjacency for a source space activation over time.

The source space. It can be a surface source space or a volume source space.

Number of time instants.

Maximal geodesic distance (in m) between vertices in the source space to consider neighbors. If None, immediate neighbors are extracted from an ico surface.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The adjacency matrix describing the spatio-temporal graph structure. If N is the number of vertices in the source space, the N first nodes in the graph are the vertices are time 1, the nodes from 2 to 2N are the vertices during time 2, etc.

mne.spatial_inter_hemi_adjacency

mne.spatio_temporal_tris_adjacency

---

## mne.spatio_temporal_tris_adjacency#

**URL:** https://mne.tools/stable/generated/mne.spatio_temporal_tris_adjacency.html

**Contents:**
- mne.spatio_temporal_tris_adjacency#

Compute adjacency from triangles and time instants.

N x 3 array defining triangles.

Number of time points.

Reassign vertex indices based on unique values. Useful to process a subset of triangles. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The adjacency matrix describing the spatio-temporal graph structure. If N is the number of vertices in the source space, the N first nodes in the graph are the vertices are time 1, the nodes from 2 to 2N are the vertices during time 2, etc.

mne.spatio_temporal_src_adjacency

mne.spatio_temporal_dist_adjacency

---

## mne.split_label#

**URL:** https://mne.tools/stable/generated/mne.split_label.html

**Contents:**
- mne.split_label#

Split a Label into two or more parts.

Label which is to be split (Label object or path to a label file).

A sequence of strings specifying label names for the new labels (from posterior to anterior), or the number of new labels to create (default is 2). If a number is specified, names of the new labels will be the input label’s name with div1, div2 etc. appended.

Subject which this label belongs to. Should only be specified if it is not specified in the label.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

By default (False) split_label uses an algorithm that is slightly optimized for performance and numerical precision. Set freesurfer to True in order to replicate label splits from FreeSurfer’s mris_divide_parcellation.

The labels, starting from the lowest to the highest end of the projection axis.

Works by finding the label’s principal eigen-axis on the spherical surface, projecting all label vertex coordinates onto this axis and dividing them at regular spatial intervals.

mne.read_source_morph

---

## mne.stats.bonferroni_correction#

**URL:** https://mne.tools/stable/generated/mne.stats.bonferroni_correction.html

**Contents:**
- mne.stats.bonferroni_correction#
- Examples using mne.stats.bonferroni_correction#

P-value correction with Bonferroni method.

Set of p-values of the individual tests.

True if a hypothesis is rejected, False if not.

P-values adjusted for multiple hypothesis testing to limit FDR.

FDR correction on T-test on sensor data

Statistical inference

mne.stats.linear_regression_raw

mne.stats.fdr_correction

---

## mne.stats.bootstrap_confidence_interval#

**URL:** https://mne.tools/stable/generated/mne.stats.bootstrap_confidence_interval.html

**Contents:**
- mne.stats.bootstrap_confidence_interval#
- Examples using mne.stats.bootstrap_confidence_interval#

Get confidence intervals from non-parametric bootstrap.

The input data on which to calculate the confidence interval.

Level of the confidence interval between 0 and 1.

Number of bootstraps.

Can be “mean”, “median”, or a callable operating along axis=0.

The seed at which to initialize the bootstrap.

Containing the lower boundary of the CI at cis[0, ...] and the upper boundary of the CI at cis[1, ...].

Explore event-related dynamics for specific frequency bands

mne.stats.summarize_clusters_stc

mne.stats.erp.compute_sme

---

## mne.stats.combine_adjacency#

**URL:** https://mne.tools/stable/generated/mne.stats.combine_adjacency.html

**Contents:**
- mne.stats.combine_adjacency#
- Examples using mne.stats.combine_adjacency#

Create a sparse binary adjacency/neighbors matrix.

The adjacency along each dimension. Each entry can be:

A square binary adjacency matrix for the given dimension. For example created by mne.channels.find_ch_adjacency().

The number of elements along the given dimension. A lattice adjacency will be generated, which is a binary matrix reflecting that element N of an array is adjacent to elements at indices N - 1 and N + 1.

The square adjacency matrix, where the shape n_features corresponds to the product of the length of all dimensions. For example len(times) * len(freqs) * len(chans).

For 4-dimensional data with shape (n_obs, n_times, n_freqs, n_chans), you can specify no connections among elements in a particular dimension by passing a matrix of zeros. For example:

Non-parametric 1 sample cluster statistic on single trial power

Spatiotemporal permutation F-test on full sensor data

mne.stats.fdr_correction

mne.stats.permutation_cluster_test

---

## mne.stats.erp.compute_sme#

**URL:** https://mne.tools/stable/generated/mne.stats.erp.compute_sme.html

**Contents:**
- mne.stats.erp.compute_sme#

Compute standardized measurement error (SME).

The standardized measurement error [1] can be used as a universal measure of data quality in ERP studies.

The epochs containing the data for which to compute the SME.

Start time (in s) of the time window used for SME computation. If None, use the start of the epoch.

Stop time (in s) of the time window used for SME computation. If None, use the end of the epoch.

SME in given time window for each channel.

Currently, only the mean value in the given time window is supported, meaning that the resulting SME is only valid in studies which quantify the amplitude of an ERP component as the mean within the time window (as opposed to e.g. the peak, which would require bootstrapping).

Steven J. Luck, Andrew X. Stewart, Aaron M. Simmons, and Mijke Rhemtulla. Standardized measurement error: a universal metric of data quality for averaged event-related potentials. Psychophysiology, 58(6):e13793, 2021. doi:10.1111/psyp.13793.

Given an Epochs object, the SME for the entire epoch duration can be computed as follows:

However, the SME is best used to estimate the precision of a specific ERP measure, specifically the mean amplitude of an ERP component in a time window of interest. For example, the SME for the mean amplitude of the P3 component in the 300-500 ms time window could be computed as follows:

Usually, it will be more informative to compute the SME for specific conditions separately. This can be done by selecting the epochs of interest as follows:

Note that the SME will be reported for each channel separately. If you are only interested in a single channel (or a subset of channels), select the channels before computing the SME:

Selecting both conditions and channels is also possible:

In any case, the output will be a NumPy array with the SME value for each channel.

mne.stats.bootstrap_confidence_interval

mne.spatial_dist_adjacency

---

## mne.stats.fdr_correction#

**URL:** https://mne.tools/stable/generated/mne.stats.fdr_correction.html

**Contents:**
- mne.stats.fdr_correction#
- Examples using mne.stats.fdr_correction#

P-value correction with False Discovery Rate (FDR).

Correction for multiple comparison using FDR [1].

This covers Benjamini/Hochberg for independent or positively correlated and Benjamini/Yekutieli for general or negatively correlated tests.

Set of p-values of the individual tests.

If ‘indep’ it implements Benjamini/Hochberg for independent or if ‘negcorr’ it corresponds to Benjamini/Yekutieli.

True if a hypothesis is rejected, False if not.

P-values adjusted for multiple hypothesis testing to limit FDR.

Christopher R. Genovese, Nicole A. Lazar, and Thomas Nichols. Thresholding of statistical maps in functional neuroimaging using the false discovery rate. NeuroImage, 15(4):870–878, 2002. doi:https://doi.org/10.1006/nimg.2001.1037.

FDR correction on T-test on sensor data

Analysing continuous features with binning and regression in sensor space

Statistical inference

Mass-univariate twoway repeated measures ANOVA on single trial power

mne.stats.bonferroni_correction

mne.stats.combine_adjacency

---

## mne.stats.f_mway_rm#

**URL:** https://mne.tools/stable/generated/mne.stats.f_mway_rm.html

**Contents:**
- mne.stats.f_mway_rm#
- Examples using mne.stats.f_mway_rm#

Compute M-way repeated measures ANOVA for fully balanced designs.

3D array where the first two dimensions are compliant with a subjects X conditions scheme where the first factor repeats slowest:

The last dimensions is thought to carry the observations for mass univariate analysis.

The number of levels per factor.

A string denoting the effect to be returned. The following mapping is currently supported (example with 2 factors):

'A': main effect of A

'B': main effect of B

'A:B': interaction effect

'A+B': both main effects

'A*B': all three effects

'all': all effects (equals ‘A*B’ in a 2 way design)

If list, effect names are used: ['A', 'B', 'A:B'].

The correction method to be employed if one factor has more than two levels. If True, sphericity correction using the Greenhouse-Geisser method will be applied.

If True, return p-values corresponding to F-values.

An array of F-statistics with length corresponding to the number of effects estimated. The shape depends on the number of effects estimated.

If not requested via return_pvals, defaults to an empty array.

Mass-univariate twoway repeated measures ANOVA on single trial power

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.stats.f_threshold_mway_rm

---

## mne.stats.f_oneway#

**URL:** https://mne.tools/stable/generated/mne.stats.f_oneway.html

**Contents:**
- mne.stats.f_oneway#

Perform a 1-way ANOVA.

The one-way ANOVA tests the null hypothesis that 2 or more groups have the same population mean. The test is applied to samples from two or more groups, possibly with differing sizes [1].

This is a modified version of scipy.stats.f_oneway() that avoids computing the associated p-value.

The sample measurements should be given as arguments.

The computed F-value of the test.

The ANOVA test has important assumptions that must be satisfied in order for the associated p-value to be valid.

The samples are independent

Each sample is from a normally distributed population

The population standard deviations of the groups are all equal. This property is known as homoscedasticity.

If these assumptions are not true for a given set of data, it may still be possible to use the Kruskal-Wallis H-test (scipy.stats.kruskal()) although with some loss of power.

The algorithm is from Heiman [2], pp.394-7.

Richard Lowry. One-way analysis of variance for independent samples. 2014. URL: http://vassarstats.net/textbook/.

Gary W. Heiman. Research Methods in Psychology. Houghton Mifflin Company, Boston, 3 edition, 2002. ISBN 978-0-618-17028-9.

mne.stats.ttest_ind_no_p

---

## mne.stats.f_threshold_mway_rm#

**URL:** https://mne.tools/stable/generated/mne.stats.f_threshold_mway_rm.html

**Contents:**
- mne.stats.f_threshold_mway_rm#
- Examples using mne.stats.f_threshold_mway_rm#

Compute F-value thresholds for a two-way ANOVA.

The number of subjects to be analyzed.

The number of levels per factor.

A string denoting the effect to be returned. The following mapping is currently supported:

'A': main effect of A

'B': main effect of B

'A:B': interaction effect

'A+B': both main effects

'A*B': all three effects

The p-value to be thresholded.

List of F-values for each effect if the number of effects requested > 2, else float.

Mass-univariate twoway repeated measures ANOVA on single trial power

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.stats.linear_regression

---

## mne.stats.linear_regression#

**URL:** https://mne.tools/stable/generated/mne.stats.linear_regression.html

**Contents:**
- mne.stats.linear_regression#
- Examples using mne.stats.linear_regression#

Fit Ordinary Least Squares (OLS) regression.

The data to be regressed. Contains all the trials, sensors, and time points for the regression. For Source Estimates, accepts either a list or a generator object.

The regressors to be used. Must be a 2d array with as many rows as the first dimension of the data. The first column of this matrix will typically consist of ones (intercept column).

Optional parameter to name the regressors (i.e., the columns in the design matrix). If provided, the length must correspond to the number of columns present in design matrix (including the intercept, if present). Otherwise, the default names are 'x0', 'x1', 'x2', …, 'x(n-1)' for n regressors.

For each regressor (key), a namedtuple is provided with the following attributes:

beta : regression coefficients

stderr : standard error of regression coefficients

t_val : t statistics (beta / stderr)

p_val : two-sided p-value of t statistic under the t distribution

mlog10_p_val : -log₁₀-transformed p-value.

The tuple members are numpy arrays. The shape of each numpy array is the shape of the data minus the first dimension; e.g., if the shape of the original data was (n_observations, n_channels, n_timepoints), then the shape of each of the arrays will be (n_channels, n_timepoints).

Single trial linear regression analysis with the LIMO dataset

Analysing continuous features with binning and regression in sensor space

Regression-based baseline correction

mne.stats.f_threshold_mway_rm

mne.stats.linear_regression_raw

---

## mne.stats.linear_regression_raw#

**URL:** https://mne.tools/stable/generated/mne.stats.linear_regression_raw.html

**Contents:**
- mne.stats.linear_regression_raw#
- Examples using mne.stats.linear_regression_raw#

Estimate regression-based evoked potentials/fields by linear modeling.

This models the full M/EEG time course, including correction for overlapping potentials and allowing for continuous/scalar predictors. Internally, this constructs a predictor matrix X of size n_samples * (n_conds * window length), solving the linear system Y = bX and returning b as evoked-like time series split by condition. See [1].

A raw object. Note: be very careful about data that is not downsampled, as the resulting matrices can be enormous and easily overload your computer. Typically, 100 Hz sampling rate is appropriate - or using the decim keyword (see below).

An array where the first column corresponds to samples in raw and the last to integer codes in event_id.

As in Epochs; a dictionary where the values may be integers or iterables of integers, corresponding to the 3rd column of events, and the keys are condition names. If None, uses all events in the events array.

If float, gives the lower limit (in seconds) for the time window for which all event types’ effects are estimated. If a dict, can be used to specify time windows for specific event types: keys correspond to keys in event_id and/or covariates; for missing values, the default (-.1) is used.

If float, gives the upper limit (in seconds) for the time window for which all event types’ effects are estimated. If a dict, can be used to specify time windows for specific event types: keys correspond to keys in event_id and/or covariates; for missing values, the default (1.) is used.

If dict-like (e.g., a pandas DataFrame), values have to be array-like and of the same length as the rows in events. Keys correspond to additional event types/conditions to be estimated and are matched with the time points given by the first column of events. If None, only binary events (from event_id) are used.

For cleaning raw data before the regression is performed: set up rejection parameters based on peak-to-peak amplitude in continuously selected subepochs. If None, no rejection is done. If dict, keys are types (‘grad’ | ‘mag’ | ‘eeg’ | ‘eog’ | ‘ecg’) and values are the maximal peak-to-peak values to select rejected epochs, e.g.:

For cleaning raw data before the regression is performed: set up rejection parameters based on flatness of the signal. If None, no rejection is done. If a dict, keys are (‘grad’ | ‘mag’ | ‘eeg’ | ‘eog’ | ‘ecg’) and values are minimal peak-to-peak values to select rejected epochs.

Length of windows for peak-to-peak detection for raw data cleaning.

Decimate by choosing only a subsample of data points. Highly recommended for data recorded at high sampling frequencies, as otherwise huge intermediate matrices have to be created and inverted.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Either a function which takes as its inputs the sparse predictor matrix X and the observation matrix Y, and returns the coefficient matrix b; or a string. X is of shape (n_times, n_predictors * time_window_length). y is of shape (n_channels, n_times). If str, must be 'cholesky', in which case the solver used is linalg.solve(dot(X.T, X), dot(X.T, y)).

A dict where the keys correspond to conditions and the values are Evoked objects with the ER[F/P]s. These can be used exactly like any other Evoked object, including e.g. plotting or statistics.

Nathaniel J. Smith and Marta Kutas. Regression-based estimation of ERP waveforms: II. Nonlinear effects, overlap correction, and practical considerations: rERPS II. Psychophysiology, 52(2):169–181, 2015. doi:10.1111/psyp.12320.

Regression on continuous data (rER[P/F])

mne.stats.linear_regression

mne.stats.bonferroni_correction

---

## mne.stats.permutation_cluster_1samp_test#

**URL:** https://mne.tools/stable/generated/mne.stats.permutation_cluster_1samp_test.html

**Contents:**
- mne.stats.permutation_cluster_1samp_test#
- Examples using mne.stats.permutation_cluster_1samp_test#

Non-parametric cluster-level paired t-test.

For details, see [1][2].

The data to be clustered. The first dimension should correspond to the difference between paired samples (observations) in two conditions. The subarrays X[k] can be 1D (e.g., time series), 2D (e.g., time series over channels), or 3D (e.g., time-frequencies over channels) associated with the kth observation. For spatiotemporal data, see also mne.stats.spatio_temporal_cluster_1samp_test().

The so-called “cluster forming threshold” in the form of a test statistic (note: this is not an alpha level / “p-value”). If numeric, vertices with data values more extreme than threshold will be used to form clusters. If None, a t-threshold will be chosen automatically that corresponds to a p-value of 0.05 for the given number of observations (only valid when using a t-statistic). If threshold is a dict (with keys 'start' and 'step') then threshold-free cluster enhancement (TFCE) will be used (see the TFCE example and [3]). See Notes for an example on how to compute a threshold based on a particular p-value for one-tailed or two-tailed tests.

The number of permutations to compute. Can be ‘all’ to perform an exact test.

If tail is 1, the statistic is thresholded above threshold. If tail is -1, the statistic is thresholded below threshold. If tail is 0, the statistic is thresholded on both sides of the distribution.

Function called to calculate the test statistic. Must accept 1D-array as input and return a 1D array. If None (the default), uses mne.stats.ttest_1samp_no_p.

Defines adjacency between locations in the data, where “locations” can be spatial vertices, frequency bins, time points, etc. For spatial vertices (i.e. sensor space data), see mne.channels.find_ch_adjacency() or mne.spatial_inter_hemi_adjacency(). For source space data, see mne.spatial_src_adjacency() or mne.spatio_temporal_src_adjacency(). If False, assumes no adjacency (each location is treated as independent and unconnected). If None, a regular lattice adjacency is assumed, connecting each location to its neighbor(s) along the last dimension of X (or the last two dimensions if X is 2D). If adjacency is a matrix, it is assumed to be symmetric (only the upper triangular half is used) and must be square with dimension equal to X.shape[-1] (for 2D data) or X.shape[-1] * X.shape[-2] (for 3D data) or (optionally) X.shape[-1] * X.shape[-2] * X.shape[-3] (for 4D data). The function mne.stats.combine_adjacency may be useful for 4D data.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

Maximum distance between samples along the second axis of X to be considered adjacent (typically the second axis is the “time” dimension). Only used when adjacency has shape (n_vertices, n_vertices), that is, when adjacency is only specified for sensors (e.g., via mne.channels.find_ch_adjacency()), and not via sensors and further dimensions such as time points (e.g., via an additional call of mne.stats.combine_adjacency()).

Mask to apply to the data to exclude certain points from clustering (e.g., medial wall vertices). Should be the same shape as X. If None, no points are excluded.

To perform a step-down-in-jumps test, pass a p-value for clusters to exclude from each successive iteration. Default is zero, perform no step-down test (since no clusters will be smaller than this value). Setting this to a reasonable value, e.g. 0.05, can increase sensitivity but costs computation time.

Power to raise the statistical values (usually t-values) by before summing (sign will be retained). Note that t_power=0 will give a count of locations in each cluster, t_power=1 will weight each location by its statistical score.

Output format of clusters within a list. If 'mask', returns a list of boolean arrays, each with the same shape as the input data (or slices if the shape is 1D and adjacency is None), with True values indicating locations that are part of a cluster. If 'indices', returns a list of tuple of ndarray, where each ndarray contains the indices of locations that together form the given cluster along the given dimension. Note that for large datasets, 'indices' may use far less memory than 'mask'. Default is 'indices'.

Whether to check if the connectivity matrix can be separated into disjoint sets before clustering. This may lead to faster clustering, especially if the second dimension of X (usually the “time” dimension) is large.

Block size to use when computing test statistics. This can significantly reduce memory usage when n_jobs > 1 and memory sharing between processes is enabled (see mne.set_cache_dir()), because X will be shared between processes and each process only needs to allocate space for a small block of locations at a time.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

T-statistic observed for all variables.

List type defined by out_type above.

P-value for each cluster.

Max cluster level stats observed under permutation.

From an array of paired observations, e.g. a difference in signal amplitudes or power spectra in two conditions, calculate if the data distributions in the two conditions are significantly different. The procedure uses a cluster analysis with permutation test for calculating corrected p-values. Randomized data are generated with random sign flips. See [1] for more information.

Because a 1-sample t-test on the difference in observations is mathematically equivalent to a paired t-test, internally this function computes a 1-sample t-test (by default) and uses sign flipping (always) to perform permutations. This might not be suitable for the case where there is truly a single observation under test; see Statistical inference.

For computing a threshold based on a p-value, use the conversion from scipy.stats.rv_continuous.ppf():

For a one-tailed test (tail=1), don’t divide the p-value by 2. For testing the lower tail (tail=-1), don’t subtract pval from 1.

If n_permutations exceeds the maximum number of possible permutations given the number of observations, then n_permutations and seed will be ignored since an exact test (full permutation test) will be performed (this is the case when n_permutations >= 2 ** (n_observations - (tail == 0))).

If no initial clusters are found because all points in the true distribution are below the threshold, then clusters, cluster_pv, and H0 will all be empty arrays.

Eric Maris and Robert Oostenveld. Nonparametric statistical testing of EEG- and MEG-data. Journal of Neuroscience Methods, 164(1):177–190, 2007. doi:10.1016/j.jneumeth.2007.03.024.

Jona Sassenhagen and Dejan Draschkow. Cluster-based permutation tests of meg/eeg data do not establish significance of effect latency or location. Psychophysiology, 56(6):e13335, 2019. doi:10.1111/psyp.13335.

Stephen M. Smith and Thomas E. Nichols. Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference. NeuroImage, 44(1):83–98, 2009. doi:10.1016/j.neuroimage.2008.03.061.

Compute and visualize ERDS maps

Statistical inference

Non-parametric 1 sample cluster statistic on single trial power

mne.stats.permutation_cluster_test

mne.stats.permutation_t_test

---

## mne.stats.permutation_cluster_test#

**URL:** https://mne.tools/stable/generated/mne.stats.permutation_cluster_test.html

**Contents:**
- mne.stats.permutation_cluster_test#
- Examples using mne.stats.permutation_cluster_test#

Cluster-level statistical permutation test.

For a list of NumPy arrays of data, calculate some statistics corrected for multiple comparisons using permutations and cluster-level correction. Each element of the list X should contain the data for one group of observations (e.g., 2D arrays for time series, 3D arrays for time-frequency power values). Permutations are generated with random partitions of the data. For details, see [1][2].

The data to be clustered. Each array in X should contain the observations for one group. The first dimension of each array is the number of observations from that group; remaining dimensions comprise the size of a single observation. For example if X = [X1, X2] with X1.shape = (20, 50, 4) and X2.shape = (17, 50, 4), then X has 2 groups with respectively 20 and 17 observations in each, and each data point is of shape (50, 4). Note: that the last dimension of each element of X should correspond to the dimension represented in the adjacency parameter (e.g., spectral data should be provided as (observations, frequencies, channels/vertices)).

The so-called “cluster forming threshold” in the form of a test statistic (note: this is not an alpha level / “p-value”). If numeric, vertices with data values more extreme than threshold will be used to form clusters. If None, an F-threshold will be chosen automatically that corresponds to a p-value of 0.05 for the given number of observations (only valid when using an F-statistic). If threshold is a dict (with keys 'start' and 'step') then threshold-free cluster enhancement (TFCE) will be used (see the TFCE example and [3]). See Notes for an example on how to compute a threshold based on a particular p-value for one-tailed or two-tailed tests.

The number of permutations to compute.

If tail is 1, the statistic is thresholded above threshold. If tail is -1, the statistic is thresholded below threshold. If tail is 0, the statistic is thresholded on both sides of the distribution.

Function called to calculate the test statistic. Must accept 1D-array as input and return a 1D array. If None (the default), uses mne.stats.f_oneway.

Defines adjacency between locations in the data, where “locations” can be spatial vertices, frequency bins, time points, etc. For spatial vertices (i.e. sensor space data), see mne.channels.find_ch_adjacency() or mne.spatial_inter_hemi_adjacency(). For source space data, see mne.spatial_src_adjacency() or mne.spatio_temporal_src_adjacency(). If False, assumes no adjacency (each location is treated as independent and unconnected). If None, a regular lattice adjacency is assumed, connecting each location to its neighbor(s) along the last dimension of each group X[k] (or the last two dimensions if X[k] is 2D). If adjacency is a matrix, it is assumed to be symmetric (only the upper triangular half is used) and must be square with dimension equal to X[k].shape[-1] (for 2D data) or X[k].shape[-1] * X[k].shape[-2] (for 3D data) or (optionally) X[k].shape[-1] * X[k].shape[-2] * X[k].shape[-3] (for 4D data). The function mne.stats.combine_adjacency may be useful for 4D data.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

Maximum distance between samples along the second axis of X to be considered adjacent (typically the second axis is the “time” dimension). Only used when adjacency has shape (n_vertices, n_vertices), that is, when adjacency is only specified for sensors (e.g., via mne.channels.find_ch_adjacency()), and not via sensors and further dimensions such as time points (e.g., via an additional call of mne.stats.combine_adjacency()).

Mask to apply to the data to exclude certain points from clustering (e.g., medial wall vertices). Should be the same shape as X. If None, no points are excluded.

To perform a step-down-in-jumps test, pass a p-value for clusters to exclude from each successive iteration. Default is zero, perform no step-down test (since no clusters will be smaller than this value). Setting this to a reasonable value, e.g. 0.05, can increase sensitivity but costs computation time.

Power to raise the statistical values (usually F-values) by before summing (sign will be retained). Note that t_power=0 will give a count of locations in each cluster, t_power=1 will weight each location by its statistical score.

Output format of clusters within a list. If 'mask', returns a list of boolean arrays, each with the same shape as the input data (or slices if the shape is 1D and adjacency is None), with True values indicating locations that are part of a cluster. If 'indices', returns a list of tuple of ndarray, where each ndarray contains the indices of locations that together form the given cluster along the given dimension. Note that for large datasets, 'indices' may use far less memory than 'mask'. Default is 'indices'.

Whether to check if the connectivity matrix can be separated into disjoint sets before clustering. This may lead to faster clustering, especially if the second dimension of X (usually the “time” dimension) is large.

Block size to use when computing test statistics. This can significantly reduce memory usage when n_jobs > 1 and memory sharing between processes is enabled (see mne.set_cache_dir()), because X will be shared between processes and each process only needs to allocate space for a small block of locations at a time.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Statistic (F by default) observed for all variables.

List type defined by out_type above.

P-value for each cluster.

Max cluster level stats observed under permutation.

For computing a threshold based on a p-value, use the conversion from scipy.stats.rv_continuous.ppf():

Eric Maris and Robert Oostenveld. Nonparametric statistical testing of EEG- and MEG-data. Journal of Neuroscience Methods, 164(1):177–190, 2007. doi:10.1016/j.jneumeth.2007.03.024.

Jona Sassenhagen and Dejan Draschkow. Cluster-based permutation tests of meg/eeg data do not establish significance of effect latency or location. Psychophysiology, 56(6):e13335, 2019. doi:10.1111/psyp.13335.

Stephen M. Smith and Thomas E. Nichols. Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference. NeuroImage, 44(1):83–98, 2009. doi:10.1016/j.neuroimage.2008.03.061.

Permutation F-test on sensor data with 1D cluster level

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

mne.stats.combine_adjacency

mne.stats.permutation_cluster_1samp_test

---

## mne.stats.permutation_t_test#

**URL:** https://mne.tools/stable/generated/mne.stats.permutation_t_test.html

**Contents:**
- mne.stats.permutation_t_test#
- Examples using mne.stats.permutation_t_test#

One sample/paired sample permutation test based on a t-statistic.

This function can perform the test on one variable or simultaneously on multiple variables. When applying the test to multiple variables, the “tmax” method is used for adjusting the p-values of each variable for multiple comparisons. Like Bonferroni correction, this method adjusts p-values in a way that controls the family-wise error rate. However, the permutation method will be more powerful than Bonferroni correction when different variables in the test are correlated (see [1]).

Samples (observations) by number of tests (variables).

Number of permutations. If n_permutations is ‘all’ all possible permutations are tested. It’s the exact test, that can be untractable when the number of samples is big (e.g. > 20). If n_permutations >= 2**n_samples then the exact test is performed.

If tail is 1, the alternative hypothesis is that the mean of the data is greater than 0 (upper tailed test). If tail is 0, the alternative hypothesis is that the mean of the data is different than 0 (two tailed test). If tail is -1, the alternative hypothesis is that the mean of the data is less than 0 (lower tailed test).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

T-statistic observed for all variables.

P-values for all the tests (a.k.a. variables).

T-statistic obtained by permutations and t-max trick for multiple comparison.

If n_permutations >= 2 ** (n_samples - (tail == 0)), n_permutations and seed will be ignored since an exact test (full permutation test) will be performed.

Thomas E. Nichols and Andrew P. Holmes. Nonparametric permutation tests for functional neuroimaging: a primer with examples. Human Brain Mapping, 15(1):1–25, 2002. doi:10.1002/hbm.1058.

Permutation T-test on sensor data

Statistical inference

mne.stats.permutation_cluster_1samp_test

mne.stats.spatio_temporal_cluster_test

---

## mne.stats.spatio_temporal_cluster_1samp_test#

**URL:** https://mne.tools/stable/generated/mne.stats.spatio_temporal_cluster_1samp_test.html

**Contents:**
- mne.stats.spatio_temporal_cluster_1samp_test#
- Examples using mne.stats.spatio_temporal_cluster_1samp_test#

Non-parametric cluster-level paired t-test for spatio-temporal data.

This function provides a convenient wrapper for mne.stats.permutation_cluster_1samp_test(), for use with data organized in the form (observations × time × space), (observations × frequencies × space), or optionally (observations × time × frequencies × space). For details, see [1][2].

The data to be clustered. The first dimension should correspond to the difference between paired samples (observations) in two conditions. The second, and optionally third, dimensions correspond to the time or time-frequency data. And, the last dimension should be spatial.

The so-called “cluster forming threshold” in the form of a test statistic (note: this is not an alpha level / “p-value”). If numeric, vertices with data values more extreme than threshold will be used to form clusters. If None, a t-threshold will be chosen automatically that corresponds to a p-value of 0.05 for the given number of observations (only valid when using a t-statistic). If threshold is a dict (with keys 'start' and 'step') then threshold-free cluster enhancement (TFCE) will be used (see the TFCE example and [3]). See Notes for an example on how to compute a threshold based on a particular p-value for one-tailed or two-tailed tests.

The number of permutations to compute. Can be ‘all’ to perform an exact test.

If tail is 1, the statistic is thresholded above threshold. If tail is -1, the statistic is thresholded below threshold. If tail is 0, the statistic is thresholded on both sides of the distribution.

Function called to calculate the test statistic. Must accept 1D-array as input and return a 1D array. If None (the default), uses mne.stats.ttest_1samp_no_p.

Defines adjacency between locations in the data, where “locations” can be spatial vertices, frequency bins, time points, etc. For spatial vertices (i.e. sensor space data), see mne.channels.find_ch_adjacency() or mne.spatial_inter_hemi_adjacency(). For source space data, see mne.spatial_src_adjacency() or mne.spatio_temporal_src_adjacency(). If False, assumes no adjacency (each location is treated as independent and unconnected). If None, a regular lattice adjacency is assumed, connecting each spatial location to its neighbor(s) along the last dimension of X. If adjacency is a matrix, it is assumed to be symmetric (only the upper triangular half is used) and must be square with dimension equal to X.shape[-1] (n_vertices) or X.shape[-1] * X.shape[-2] (n_times * n_vertices) or (optionally) X.shape[-1] * X.shape[-2] * X.shape[-3] (n_times * n_freqs * n_vertices). If spatial adjacency is uniform in time, it is recommended to use a square matrix with dimension X.shape[-1] (n_vertices) to save memory and computation, and to use max_step to define the extent of temporal adjacency to consider when clustering.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

Maximum distance between samples along the second axis of X to be considered adjacent (typically the second axis is the “time” dimension). Only used when adjacency has shape (n_vertices, n_vertices), that is, when adjacency is only specified for sensors (e.g., via mne.channels.find_ch_adjacency()), and not via sensors and further dimensions such as time points (e.g., via an additional call of mne.stats.combine_adjacency()).

List of spatial indices to exclude from clustering.

To perform a step-down-in-jumps test, pass a p-value for clusters to exclude from each successive iteration. Default is zero, perform no step-down test (since no clusters will be smaller than this value). Setting this to a reasonable value, e.g. 0.05, can increase sensitivity but costs computation time.

Power to raise the statistical values (usually t-values) by before summing (sign will be retained). Note that t_power=0 will give a count of locations in each cluster, t_power=1 will weight each location by its statistical score.

Output format of clusters within a list. If 'mask', returns a list of boolean arrays, each with the same shape as the input data (or slices if the shape is 1D and adjacency is None), with True values indicating locations that are part of a cluster. If 'indices', returns a list of tuple of ndarray, where each ndarray contains the indices of locations that together form the given cluster along the given dimension. Note that for large datasets, 'indices' may use far less memory than 'mask'. Default is 'indices'.

Whether to check if the connectivity matrix can be separated into disjoint sets before clustering. This may lead to faster clustering, especially if the second dimension of X (usually the “time” dimension) is large.

Block size to use when computing test statistics. This can significantly reduce memory usage when n_jobs > 1 and memory sharing between processes is enabled (see mne.set_cache_dir()), because X will be shared between processes and each process only needs to allocate space for a small block of locations at a time.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

T-statistic observed for all variables.

List type defined by out_type above.

P-value for each cluster.

Max cluster level stats observed under permutation.

For computing a threshold based on a p-value, use the conversion from scipy.stats.rv_continuous.ppf():

For a one-tailed test (tail=1), don’t divide the p-value by 2. For testing the lower tail (tail=-1), don’t subtract pval from 1.

Eric Maris and Robert Oostenveld. Nonparametric statistical testing of EEG- and MEG-data. Journal of Neuroscience Methods, 164(1):177–190, 2007. doi:10.1016/j.jneumeth.2007.03.024.

Jona Sassenhagen and Dejan Draschkow. Cluster-based permutation tests of meg/eeg data do not establish significance of effect latency or location. Psychophysiology, 56(6):e13335, 2019. doi:10.1111/psyp.13335.

Stephen M. Smith and Thomas E. Nichols. Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference. NeuroImage, 44(1):83–98, 2009. doi:10.1016/j.neuroimage.2008.03.061.

Permutation t-test on source data with spatio-temporal clustering

mne.stats.spatio_temporal_cluster_test

mne.stats.summarize_clusters_stc

---

## mne.stats.spatio_temporal_cluster_test#

**URL:** https://mne.tools/stable/generated/mne.stats.spatio_temporal_cluster_test.html

**Contents:**
- mne.stats.spatio_temporal_cluster_test#
- Examples using mne.stats.spatio_temporal_cluster_test#

Non-parametric cluster-level test for spatio-temporal data.

This function provides a convenient wrapper for mne.stats.permutation_cluster_test(), for use with data organized in the form (observations × time × space), (observations × time × space), or optionally (observations × time × frequencies × space). For more information, see [1][2].

The data to be clustered. Each array in X should contain the observations for one group. The first dimension of each array is the number of observations from that group (and may vary between groups). The second, and optionally third, dimensions correspond to the time or time-frequency data. And, the last dimension should be spatial. All dimensions except the first should match across all groups.

The so-called “cluster forming threshold” in the form of a test statistic (note: this is not an alpha level / “p-value”). If numeric, vertices with data values more extreme than threshold will be used to form clusters. If None, an F-threshold will be chosen automatically that corresponds to a p-value of 0.05 for the given number of observations (only valid when using an F-statistic). If threshold is a dict (with keys 'start' and 'step') then threshold-free cluster enhancement (TFCE) will be used (see the TFCE example and [3]). See Notes for an example on how to compute a threshold based on a particular p-value for one-tailed or two-tailed tests.

The number of permutations to compute.

If tail is 1, the statistic is thresholded above threshold. If tail is -1, the statistic is thresholded below threshold. If tail is 0, the statistic is thresholded on both sides of the distribution.

Function called to calculate the test statistic. Must accept 1D-array as input and return a 1D array. If None (the default), uses mne.stats.f_oneway.

Defines adjacency between locations in the data, where “locations” can be spatial vertices, frequency bins, time points, etc. For spatial vertices (i.e. sensor space data), see mne.channels.find_ch_adjacency() or mne.spatial_inter_hemi_adjacency(). For source space data, see mne.spatial_src_adjacency() or mne.spatio_temporal_src_adjacency(). If False, assumes no adjacency (each location is treated as independent and unconnected). If None, a regular lattice adjacency is assumed, connecting each spatial location to its neighbor(s) along the last dimension of each group X[k]. If adjacency is a matrix, it is assumed to be symmetric (only the upper triangular half is used) and must be square with dimension equal to X[k].shape[-1] (n_vertices) or X[k].shape[-1] * X[k].shape[-2] (n_times * n_vertices) or (optionally) X[k].shape[-1] * X[k].shape[-2] * X[k].shape[-3] (n_times * n_freqs * n_vertices). If spatial adjacency is uniform in time, it is recommended to use a square matrix with dimension X[k].shape[-1] (n_vertices) to save memory and computation, and to use max_step to define the extent of temporal adjacency to consider when clustering.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

Maximum distance between samples along the second axis of X to be considered adjacent (typically the second axis is the “time” dimension). Only used when adjacency has shape (n_vertices, n_vertices), that is, when adjacency is only specified for sensors (e.g., via mne.channels.find_ch_adjacency()), and not via sensors and further dimensions such as time points (e.g., via an additional call of mne.stats.combine_adjacency()).

List of spatial indices to exclude from clustering.

To perform a step-down-in-jumps test, pass a p-value for clusters to exclude from each successive iteration. Default is zero, perform no step-down test (since no clusters will be smaller than this value). Setting this to a reasonable value, e.g. 0.05, can increase sensitivity but costs computation time.

Power to raise the statistical values (usually F-values) by before summing (sign will be retained). Note that t_power=0 will give a count of locations in each cluster, t_power=1 will weight each location by its statistical score.

Output format of clusters within a list. If 'mask', returns a list of boolean arrays, each with the same shape as the input data (or slices if the shape is 1D and adjacency is None), with True values indicating locations that are part of a cluster. If 'indices', returns a list of tuple of ndarray, where each ndarray contains the indices of locations that together form the given cluster along the given dimension. Note that for large datasets, 'indices' may use far less memory than 'mask'. Default is 'indices'.

Whether to check if the connectivity matrix can be separated into disjoint sets before clustering. This may lead to faster clustering, especially if the second dimension of X (usually the “time” dimension) is large.

Block size to use when computing test statistics. This can significantly reduce memory usage when n_jobs > 1 and memory sharing between processes is enabled (see mne.set_cache_dir()), because X will be shared between processes and each process only needs to allocate space for a small block of locations at a time.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Statistic (F by default) observed for all variables.

List type defined by out_type above.

P-value for each cluster.

Max cluster level stats observed under permutation.

For computing a threshold based on a p-value, use the conversion from scipy.stats.rv_continuous.ppf():

Eric Maris and Robert Oostenveld. Nonparametric statistical testing of EEG- and MEG-data. Journal of Neuroscience Methods, 164(1):177–190, 2007. doi:10.1016/j.jneumeth.2007.03.024.

Jona Sassenhagen and Dejan Draschkow. Cluster-based permutation tests of meg/eeg data do not establish significance of effect latency or location. Psychophysiology, 56(6):e13335, 2019. doi:10.1111/psyp.13335.

Stephen M. Smith and Thomas E. Nichols. Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference. NeuroImage, 44(1):83–98, 2009. doi:10.1016/j.neuroimage.2008.03.061.

Visualising statistical significance thresholds on EEG data

Spatiotemporal permutation F-test on full sensor data

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.stats.permutation_t_test

mne.stats.spatio_temporal_cluster_1samp_test

---

## mne.stats.summarize_clusters_stc#

**URL:** https://mne.tools/stable/generated/mne.stats.summarize_clusters_stc.html

**Contents:**
- mne.stats.summarize_clusters_stc#
- Examples using mne.stats.summarize_clusters_stc#

Assemble summary SourceEstimate from spatiotemporal cluster results.

This helps visualizing results from spatio-temporal-clustering permutation tests.

The output from clustering permutation tests.

The significance threshold for inclusion of clusters.

The time step between samples of the original STC, in seconds (i.e., 1 / stc.sfreq). Defaults to 1, which will yield a colormap indicating cluster duration measured in samples rather than seconds.

The time of the first sample.

The name of the subject.

The vertex numbers associated with the source space locations. Defaults to None. If None, equals [np.arange(10242), np.arange(10242)]. Can also be an instance of SourceSpaces to get vertex numbers from.

Changed in version 0.21: Added support for SourceSpaces.

A summary of the clusters. The first time point in this SourceEstimate object is the summation of all the clusters. Subsequent time points contain each individual cluster. The magnitude of the activity corresponds to the duration spanned by the cluster (duration units are determined by tstep).

Changed in version 0.21: Added support for volume and mixed source estimates.

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

mne.stats.spatio_temporal_cluster_1samp_test

mne.stats.bootstrap_confidence_interval

---

## mne.stats.ttest_1samp_no_p#

**URL:** https://mne.tools/stable/generated/mne.stats.ttest_1samp_no_p.html

**Contents:**
- mne.stats.ttest_1samp_no_p#
- Examples using mne.stats.ttest_1samp_no_p#

Perform one-sample t-test.

This is a modified version of scipy.stats.ttest_1samp() that avoids a (relatively) time-consuming p-value calculation, and can adjust for implausibly small variance values [1].

Array to return t-values for.

The variance estimate will be given by var + sigma * max(var) or var + sigma, depending on “method”. By default this is 0 (no adjustment). See Notes for details.

If ‘relative’, the minimum variance estimate will be sigma * max(var), if ‘absolute’ the minimum variance estimate will be sigma.

T-values, potentially adjusted using the hat method.

To use the “hat” adjustment method [1], a value of sigma=1e-3 may be a reasonable choice.

Gerard R. Ridgway, Vladimir Litvak, Guillaume Flandin, Karl J. Friston, and Will D. Penny. The problem of low variance voxels in statistical parametric mapping; a new hat avoids a ‘haircut’. NeuroImage, 59(3):2131–2141, 2012. doi:10.1016/j.neuroimage.2011.10.027.

Statistical inference

mne.stats.ttest_ind_no_p

---

## mne.stats.ttest_ind_no_p#

**URL:** https://mne.tools/stable/generated/mne.stats.ttest_ind_no_p.html

**Contents:**
- mne.stats.ttest_ind_no_p#

Independent samples t-test without p calculation.

This is a modified version of scipy.stats.ttest_ind(). It operates along the first axis. The sigma parameter provides an optional “hat” adjustment (see ttest_1samp_no_p() and [1]).

Assume equal variance. See scipy.stats.ttest_ind().

The regularization. See ttest_1samp_no_p().

Gerard R. Ridgway, Vladimir Litvak, Guillaume Flandin, Karl J. Friston, and Will D. Penny. The problem of low variance voxels in statistical parametric mapping; a new hat avoids a ‘haircut’. NeuroImage, 59(3):2131–2141, 2012. doi:10.1016/j.neuroimage.2011.10.027.

mne.stats.ttest_1samp_no_p

---

## mne.stc_near_sensors#

**URL:** https://mne.tools/stable/generated/mne.stc_near_sensors.html

**Contents:**
- mne.stc_near_sensors#
- Examples using mne.stc_near_sensors#

Create a STC from ECoG, sEEG and DBS sensor data.

The evoked data. Must contain ECoG, sEEG or DBS channels.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation. If trans is None, an identity matrix is assumed.

Changed in version 0.19: Support for ‘fsaverage’ argument.

Distance (m) defining the activation “ball” of the sensor.

Can be "sum" to do a linear sum of weights, "weighted" to make this a weighted sum, "nearest" to use only the weight of the nearest sensor, or "single" to do a distance-weight of the nearest sensor. Default is "sum". See Notes.

Changed in version 0.24: Added “weighted” option.

If True, project the sensors to the nearest 'pial surface vertex before computing distances. Only used when doing a surface projection.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

If a surface source space is used, make sure that surface='pial' was used during construction, or that you set surface='pial' here.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good sEEG, ECoG, and DBS channels.

The surface to use. If src=None, defaults to the pial surface. Otherwise, the source space surface will be used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The surface source estimate. If src is None, a surface source estimate will be produced, and the number of vertices will equal the number of pial-surface vertices that were close enough to the sensors to take on a non-zero volue. If src is not None, a surface, volume, or mixed source estimate will be produced (depending on the kind of source space passed) and the vertices will match those of src (i.e., there may be me many all-zero values in stc.data).

For surface projections, this function projects the ECoG sensors to the pial surface (if project), then the activation at each pial surface vertex is given by the mode:

Activation is the sum across each sensor weighted by the fractional distance from each sensor. A sensor with zero distance gets weight 1 and a sensor at distance meters away (or larger) gets weight 0. If distance is less than half the distance between any two sensors, this will be the same as 'single'.

Same as 'sum' except that only the nearest sensor is used, rather than summing across sensors within the distance radius. As 'nearest' for vertices with distance zero to the projected sensor.

The value is given by the value of the nearest sensor, up to a distance (beyond which it is zero).

The value is given by the same as sum but the total weight for each vertex is 1. (i.e., it’s a weighted sum based on proximity).

If creating a Volume STC, src must be passed in, and this function will project sEEG and DBS sensors to nearby surrounding vertices. Then the activation at each volume vertex is given by the mode in the same way as ECoG surface projections.

Working with sEEG data

Working with ECoG data

mne.transform_surface_to

---

## mne.stc_to_label#

**URL:** https://mne.tools/stable/generated/mne.stc_to_label.html

**Contents:**
- mne.stc_to_label#
- Examples using mne.stc_to_label#

Compute a label from the non-zero sources in an stc object.

The source estimates.

The source space over which the source estimates are defined. If it’s a string it should the subject name (e.g. fsaverage). Can be None if stc.subject is not None.

Fill in vertices on the cortical surface that are not in the source space based on the closest source space vertex (requires src to be a SourceSpace).

If True a list of connected labels will be returned in each hemisphere. The labels are ordered in decreasing order depending of the maximum value in the stc.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The generated labels. If connected is False, it returns a list of Labels (one per hemisphere). If no Label is available in a hemisphere, None is returned. If connected is True, it returns for each hemisphere a list of connected labels ordered in decreasing order depending of the maximum value in the stc. If no Label is available in an hemisphere, an empty list is returned.

Generate a functional label from source estimates

---

## mne.surface.complete_surface_info#

**URL:** https://mne.tools/stable/generated/mne.surface.complete_surface_info.html

**Contents:**
- mne.surface.complete_surface_info#

Complete surface information.

If True (default False), add neighbor vertex information.

If True (default), make a copy. If False, operate in-place.

If True (default), compute triangle neighbors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The transformed surface.

mne.setup_volume_source_space

mne.surface.read_curvature

---

## mne.surface.read_curvature#

**URL:** https://mne.tools/stable/generated/mne.surface.read_curvature.html

**Contents:**
- mne.surface.read_curvature#
- Examples using mne.surface.read_curvature#

Load in curvature values from the ?h.curv file.

Input path to the .curv file.

Specify if the output array is to hold binary values. Defaults to True.

The curvature values loaded from the user given file.

How MNE uses FreeSurfer’s outputs

mne.surface.complete_surface_info

---

## mne.sys_info#

**URL:** https://mne.tools/stable/generated/mne.sys_info.html

**Contents:**
- mne.sys_info#
- Examples using mne.sys_info#

Print system information.

This function prints system information useful when triaging bugs.

The file to write to. Will be passed to print(). Can be None to use sys.stdout.

If True, print paths for each module.

Show dependencies relevant for users (default) or for developers (i.e., output includes additional dependencies).

Include Unicode symbols in output. If “auto”, corresponds to True on Linux and macOS, and False on Windows.

If True (default), attempt to check that the version of MNE-Python is up to date with the latest release on GitHub. Can be a float to give a different timeout (in sec) from the default (2 sec).

Configuring MNE-Python

mne.set_memmap_min_size

---

## mne.time_frequency.AverageTFRArray#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.AverageTFRArray.html

**Contents:**
- mne.time_frequency.AverageTFRArray#
- Examples using mne.time_frequency.AverageTFRArray#

Data object for precomputed spectrotemporal representations of averaged data.

The mne.Info object with information about the sensors and methods of measurement.

The time values in seconds.

The frequencies in Hz.

The number of averaged TFRs.

Comment on the data, e.g., the experimental condition(s) averaged.

Comment on the method used to compute the data, e.g., "hilbert". Default is None.

The weights for each taper. Must be provided if data has a taper dimension, such as for complex or phase multitaper data.

Start and end of the baseline period (in seconds).

Comment on the data, e.g., the experimental condition(s) averaged.

The frequencies at which power estimates were computed.

The mne.Info object with information about the sensors and methods of measurement.

The method used to compute the time-frequency power estimates.

The number of epochs that were averaged to yield the result. This may reflect epochs averaged before time-frequency analysis (as in epochs.average(...).compute_tfr(...)) or after time-frequency analysis (as in epochs.compute_tfr(...).average(...)).

Sampling frequency of the data.

The weights used for each taper in the time-frequency estimates.

Add two TFR instances.

__contains__(ch_type)

Check channel type membership.

Multiply a TFR instance by a scalar.

Subtract two TFR instances.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

apply_baseline(baseline[, mode, verbose])

Baseline correct the data.

Return copy of the TFR instance.

crop([tmin, tmax, fmin, fmax, include_tmax])

Crop data to a given time interval in place.

decimate(decim[, offset, verbose])

Decimate the time-series data.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, tmin, ...])

Get time-frequency data in NumPy array format.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, exclude, tmin, tmax, fmin, ...])

Plot TFRs as two-dimensional time-frequency images.

plot_joint(*[, timefreqs, picks, exclude, ...])

Plot TFRs as a two-dimensional image with topomap highlights.

plot_topo([picks, baseline, mode, tmin, ...])

Plot a TFR image for each channel in a sensor layout arrangement.

plot_topomap([tmin, tmax, fmin, fmax, ...])

Plot topographic maps of specific time-frequency intervals of TFR data.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save time-frequency data to disk (in HDF5 format).

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, long_format, ...])

Export data in tabular structure as a pandas DataFrame.

Add two TFR instances.

The TFR instance to add. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Multiply a TFR instance by a scalar.

The number to multiply by.

A new TFR instance, of the same type as self.

Subtract two TFR instances.

The TFR instance to subtract. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won’t be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Baseline correct the data.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Start and end of the baseline period (in seconds).

The current gradient compensation grade.

Return copy of the TFR instance.

A copy of the object.

Crop data to a given time interval in place.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Lowest frequency of selection in Hz.

Highest frequency of selection in Hz.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The modified instance.

The time-frequency-resolved power estimates.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / “decimation” refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [1], p. 172; which cites [2]):

“… a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).”

Hence “decimation” in MNE is what is considered “compression” in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

The frequencies at which power estimates were computed.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get time-frequency data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Whether to return the time values for the requested time range. Default is False.

Whether to return the frequency bin values for the requested frequency range. Default is False.

Whether to return the taper numbers. Default is False.

The requested data in a NumPy array.

The time values for the requested data range. Only returned if return_times is True.

The frequency values for the requested data range. Only returned if return_freqs is True.

The taper numbers. Only returned if return_tapers is True. Will be None if a taper dimension is not present in the data.

Returns a copy of the underlying data (not a view).

The method used to compute the time-frequency power estimates.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=”bads” when picks=”meg”).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(…).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(…).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‘auto’, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‘hbo’ (to include channels measuring oxyhemoglobin) or ‘hbr’ (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‘eyegaze’ (to include eye position channels) or ‘pupil’ (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‘bads’ (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot TFRs as two-dimensional time-frequency images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’) (default)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(data).

How to aggregate across channels. If None, plot one figure per selected channel. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to None.

Changed in version 1.3: Added support for callable.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The scale of the y (frequency) axis. ‘linear’ gives linear y axis, ‘log’ gives log-spaced y axis and ‘auto’ detects if frequencies are log-spaced and if so sets the y axis to ‘log’. Default is ‘auto’.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Whether to add a colorbar to the plot. Default is True.

Title for the plot. If "auto", will use the channel name (if combine is None) or state the number and method of combined channels used to generate the plot. If None, no title is shown. Default is None.

An array of boolean values, of the same shape as the data. Data that corresponds to False entries in the mask are plotted differently, as determined by mask_style, mask_alpha, and mask_cmap. Useful for, e.g., highlighting areas of statistical significance.

How to distinguish the masked/unmasked regions of the plot. If "contour", a line is drawn around the areas where the mask is True. If "mask", areas where the mask is False will be (partially) transparent, as determined by mask_alpha. If "both", both a contour and transparency are used. Default is None, which is silently ignored if mask is None and is interpreted like "both" otherwise.

Colormap to use for masked areas of the plot. If a str, must be a valid Matplotlib colormap name. If None, cmap is used for both masked and unmasked areas. Ignored if mask is None. Default is 'Greys'.

Relative opacity of the masked region versus the unmasked region, given as a float between 0 and 1 (i.e., 0 means masked areas are not visible at all). Defaults to 0.1.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of picks. If combine is not None, axes must either be an instance of Axes, or a list of length 1. Default is None.

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of figures containing the time-frequency power.

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Plot TFRs as a two-dimensional image with topomap highlights.

The time-frequency point(s) for which topomaps will be plotted. See Notes.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any). Default is an empty tuple which includes all channels.

How to aggregate across channels. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to "mean".

Changed in version 1.3: Added support for callable.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’) (default)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(data).

The scale of the y (frequency) axis. ‘linear’ gives linear y axis, ‘log’ gives log-spaced y axis and ‘auto’ detects if frequencies are log-spaced and if so sets the y axis to ‘log’. Default is ‘auto’.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. To specify the colormap separately for the topomap annotations, see topomap_args. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

Whether to add a colorbar to the plot (for the topomap annotations). Not compatible with user-defined axes. Default is True.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

Keyword arguments to pass to mne.viz.plot_topomap(). axes and show are ignored. If times is not in this dict, automatic peak detection is used. Beyond that, if None, no customizable arguments will be passed. Defaults to None (i.e., an empty dict).

Keyword arguments to pass to mne.time_frequency.AverageTFR.plot(). axes and show are ignored. Defaults to None (i.e., and empty dict).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

timefreqs has three different modes: tuples, dicts, and auto. For (list of) tuple(s) mode, each tuple defines a pair (time, frequency) in s and Hz on the TFR plot. For example, to look at 10 Hz activity 1 second into the epoch and 3 Hz activity 300 ms into the epoch,

If provided as a dictionary, (time, frequency) tuples are keys and (time_window, frequency_window) tuples are the values — indicating the width of the windows (centered on the time and frequency indicated by the key) to be averaged over. For example,

would translate into a window that spans 0.95 to 1.05 seconds and 9 to 11 Hz. If None, a single topomap will be plotted at the absolute peak across the time-frequency representation.

Plot a TFR image for each channel in a sensor layout arrangement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’) (default)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

Lower and upper bounds of the colormap, in the same units as the data. If vmin and vmax are both None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0). If only one of vmin, vmax is None, will use min(data) or max(data), respectively.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

The title of the generated figure. If None (default), no title is displayed.

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(data).

Whether to add a colorbar to the plot. Default is True.

Scaling factor for adjusting the relative size of the layout on the canvas.

Show the figure if True.

Matplotlib border style to be used for each sensor plot.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

The scale of the y (frequency) axis. ‘linear’ gives linear y axis, ‘log’ gives log-spaced y axis and ‘auto’ detects if frequencies are log-spaced and if so sets the y axis to ‘log’. Default is ‘auto’.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

Plot topographic maps of specific time-frequency intervals of TFR data.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The time interval to apply rescaling / baseline correction. If None do not apply it. If baseline is (a, b) the interval is between “a (s)” and “b (s)”. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) the whole time interval is used.

Perform baseline correction by

subtracting the mean baseline power (‘mean’)

dividing by the mean baseline power (‘ratio’)

dividing by the mean baseline power and taking the log (‘logratio’)

subtracting the mean baseline power followed by dividing by the mean baseline power (‘percent’)

subtracting the mean baseline power and dividing by the standard deviation of the baseline power (‘zscore’)

dividing by the mean baseline power, taking the log, and dividing by the standard deviation of the baseline power (‘zlogratio’)

If None no baseline correction is applied.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created. Default is None.

Show the figure if True.

The figure containing the topography.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save time-frequency data to disk (in HDF5 format).

Path of file to save to, which should end with -tfr.h5 or -tfr.hdf5.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Sampling frequency of the data.

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

The time points present in the data (in seconds).

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, additional columns 'time', 'freq', 'taper', 'epoch', and 'condition' (epoch event description) are added, unless index is not None (in which case the columns specified in index will be used to form the DataFrame’s index instead). 'epoch', and 'condition' are not supported for AverageTFR. 'taper' is only supported when a taper dimensions is present, such as for complex or phase multitaper data.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). If a list of two or more string values, a pandas.MultiIndex will be created. Valid string values are 'time', 'freq', 'taper', 'epoch', and 'condition' for EpochsTFR and 'time', 'freq', and 'taper' for AverageTFR. Defaults to None.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point, channel, epoch number, and condition. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

The weights used for each taper in the time-frequency estimates.

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

mne.time_frequency.AverageTFR

mne.time_frequency.BaseTFR

---

## mne.time_frequency.combine_spectrum#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.combine_spectrum.html

**Contents:**
- mne.time_frequency.combine_spectrum#

Merge spectral data by weighted addition.

Create a new mne.time_frequency.Spectrum instance, using a combination of the supplied instances as its data. By default, the mean (weighted by trials) is used. Subtraction can be performed by passing negative weights (e.g., [1, -1]). Data must have the same channels and the same frequencies.

The Spectrum objects.

The weights to apply to the data of each Spectrum instance, or a string describing the weighting strategy to apply: ‘nave’ computes sum-to-one weights proportional to each object’s nave attribute; ‘equal’ weights each Spectrum by 1 / len(all_spectrum).

The new spectral data.

mne.time_frequency.EpochsSpectrumArray

mne.time_frequency.combine_tfr

---

## mne.time_frequency.combine_tfr#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.combine_tfr.html

**Contents:**
- mne.time_frequency.combine_tfr#

Merge AverageTFR data by weighted addition.

Create a new mne.time_frequency.AverageTFR instance, using a combination of the supplied instances as its data. By default, the mean (weighted by trials) is used. Subtraction can be performed by passing negative weights (e.g., [1, -1]). Data must have the same channels and the same time instants.

The weights to apply to the data of each AverageTFR instance. Can also be 'nave' to weight according to tfr.nave, or 'equal' to use equal weighting (each weighted as 1/N).

Aggregating multitaper TFR datasets with a taper dimension such as for complex or phase data is not supported.

mne.time_frequency.combine_spectrum

mne.time_frequency.csd_tfr

---

## mne.time_frequency.CrossSpectralDensity#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.CrossSpectralDensity.html

**Contents:**
- mne.time_frequency.CrossSpectralDensity#
- Examples using mne.time_frequency.CrossSpectralDensity#

Cross-spectral density.

Given a list of time series, the CSD matrix denotes for each pair of time series, the cross-spectral density. This matrix is symmetric and internally stored as a vector.

This object can store multiple CSD matrices: one for each frequency. Use .get_data(freq) to obtain an CSD matrix as an ndarray.

For each frequency, the cross-spectral density matrix in vector format.

List of string names for each channel.

Frequency or frequencies for which the CSD matrix was calculated. When averaging across frequencies (see the CrossSpectralDensity.mean() function), this will be a list of lists that contains for each frequency bin, the frequencies that were averaged. Frequencies should always be sorted.

The number of FFT points or samples that have been used in the computation of this CSD.

Start of the time window for which CSD was calculated in seconds. Can be None (the default) to indicate no timing information is available.

End of the time window for which CSD was calculated in seconds. Can be None (the default) to indicate no timing information is available.

List of projectors to apply to timeseries data when using this CSD object to compute a DICS beamformer. Defaults to None, which means no projectors will be applied.

Number of time series defined in this CSD object.

Subselect frequencies.

Return number of frequencies.

Return copy of the CrossSpectralDensity object.

get_data([frequency, index, as_cov])

Get the CSD matrix for a given frequency as NumPy array.

Calculate the mean CSD in the given frequency range(s).

pick_channels(ch_names[, ordered])

Pick channels from this cross-spectral density matrix.

pick_frequency([freq, index])

Get a CrossSpectralDensity object with only the given frequency.

plot([info, mode, colorbar, cmap, n_cols, show])

save(fname, *[, overwrite, verbose])

Save the CSD to an HDF5 file.

Calculate the sum CSD in the given frequency range(s).

Subselect frequencies.

Array of frequency indices to subselect.

A new CSD instance with the subset of frequencies.

Return number of frequencies.

The number of frequencies.

Return copy of the CrossSpectralDensity object.

A copy of the object.

Get the CSD matrix for a given frequency as NumPy array.

If there is only one matrix defined in the CSD object, calling this method without any parameters will return it. If multiple matrices are defined, use either the frequency or index parameter to select one.

Return the CSD matrix for a specific frequency. Only available when no averaging across frequencies has been done.

Return the CSD matrix for the frequency or frequency-bin with the given index.

Whether to return the data as a numpy array (False, the default), or pack it in a mne.Covariance object (True).

The CSD matrix corresponding to the requested frequency.

Calculate the mean CSD in the given frequency range(s).

Lower bound of the frequency range in Hertz. Defaults to the lowest frequency available. When a list of frequencies is given, these are used as the lower bounds (inclusive) of frequency bins and the mean is taken for each bin.

Upper bound of the frequency range in Hertz. Defaults to the highest frequency available. When a list of frequencies is given, these are used as the upper bounds (inclusive) of frequency bins and the mean is taken for each bin.

The CSD matrix, averaged across the given frequency range(s).

Compute source power using DICS beamformer

Compute a cross-spectral density (CSD) matrix

Number of time series defined in this CSD object.

Pick channels from this cross-spectral density matrix.

List of channels to keep. All other channels are dropped.

If True (default False), ensure that the order of the channels matches the order of ch_names.

The modified cross-spectral density object.

Get a CrossSpectralDensity object with only the given frequency.

Return the CSD matrix for a specific frequency. Only available when no averaging across frequencies has been done.

Return the CSD matrix for the frequency or frequency-bin with the given index.

A CSD object containing a single CSD matrix that corresponds to the requested frequency or frequency-bin.

A sub-plot is created for each frequency. If an info object is passed to the function, different channel types are plotted in different figures.

The mne.Info object with information about the sensors and methods of measurement. Used to split the figure by channel-type, if provided. By default, the CSD matrix is plotted as a whole.

Whether to plot the cross-spectral density (‘csd’, the default), or the coherence (‘coh’) between the channels.

Whether to show a colorbar. Defaults to True.

The matplotlib colormap to use. Defaults to None, which means the colormap will default to matplotlib’s default.

CSD matrices are plotted in a grid. This parameter controls how many matrix to plot side by side before starting a new row. By default, a number will be chosen to make the grid as square as possible.

Whether to show the figure. Defaults to True.

The figures created by this function.

Save the CSD to an HDF5 file.

The name of the file to save the CSD to. The extension '.h5' will be appended if the given filename doesn’t have it already.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

For reading CSD objects from a file.

Calculate the sum CSD in the given frequency range(s).

If the exact given frequencies are not available, the nearest frequencies will be chosen.

Lower bound of the frequency range in Hertz. Defaults to the lowest frequency available. When a list of frequencies is given, these are used as the lower bounds (inclusive) of frequency bins and the sum is taken for each bin.

Upper bound of the frequency range in Hertz. Defaults to the highest frequency available. When a list of frequencies is given, these are used as the upper bounds (inclusive) of frequency bins and the sum is taken for each bin.

The CSD matrix, summed across the given frequency range(s).

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute a cross-spectral density (CSD) matrix

DICS for power mapping

mne.time_frequency.RawTFRArray

mne.time_frequency.Spectrum

---

## mne.time_frequency.csd_array_fourier#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.csd_array_fourier.html

**Contents:**
- mne.time_frequency.csd_array_fourier#

Estimate cross-spectral density from an array using short-time fourier.

The time series data consisting of n_epochs separate observations of signals with n_channels time-series of length n_times.

Sampling frequency of observations.

Time of the first sample relative to the onset of the epoch, in seconds. Defaults to 0.

Minimum frequency of interest, in Hertz.

Maximum frequency of interest, in Hertz.

Minimum time instant to consider, in seconds. If None start at first sample.

Maximum time instant to consider, in seconds. If None end at last sample.

A name for each time series. If None (the default), the series will be named ‘SERIES###’.

Length of the FFT. If None, the exact number of samples between tmin and tmax will be used.

List of projectors to store in the CSD object. Defaults to None, which means no projectors are stored.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The computed cross-spectral density.

mne.time_frequency.read_spectrum

mne.time_frequency.csd_array_multitaper

---

## mne.time_frequency.csd_array_morlet#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.csd_array_morlet.html

**Contents:**
- mne.time_frequency.csd_array_morlet#

Estimate cross-spectral density from an array using Morlet wavelets.

The time series data consisting of n_epochs separate observations of signals with n_channels time-series of length n_times.

Sampling frequency of observations.

The frequencies of interest, in Hertz.

Time of the first sample relative to the onset of the epoch, in seconds. Defaults to 0.

Minimum time instant to consider, in seconds. If None start at first sample.

Maximum time instant to consider, in seconds. If None end at last sample.

A name for each time series. If None (the default), the series will be named ‘SERIES###’.

Number of cycles to use when constructing Morlet wavelets. Fixed number or one per frequency. Defaults to 7.

Whether to use FFT-based convolution to compute the wavelet transform. Defaults to True.

To reduce memory usage, decimation factor during time-frequency decomposition. Defaults to 1 (no decimation).

If int, uses tfr[…, ::decim]. If slice, uses tfr[…, decim].

List of projectors to store in the CSD object. Defaults to None, which means the projectors defined in the Epochs object will be copied.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The computed cross-spectral density.

mne.time_frequency.csd_array_multitaper

mne.time_frequency.dpss_windows

---

## mne.time_frequency.csd_array_multitaper#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.csd_array_multitaper.html

**Contents:**
- mne.time_frequency.csd_array_multitaper#

Estimate cross-spectral density from an array using a multitaper method.

The time series data consisting of n_epochs separate observations of signals with n_channels time-series of length n_times.

Sampling frequency of observations.

Time of the first sample relative to the onset of the epoch, in seconds. Defaults to 0.

Minimum frequency of interest, in Hertz.

Maximum frequency of interest, in Hertz.

Minimum time instant to consider, in seconds. If None start at first sample.

Maximum time instant to consider, in seconds. If None end at last sample.

A name for each time series. If None (the default), the series will be named ‘SERIES###’.

Length of the FFT. If None, the exact number of samples between tmin and tmax will be used.

The bandwidth of the multitaper windowing function in Hz.

Use adaptive weights to combine the tapered spectra into PSD.

Only use tapers with more than 90% spectral concentration within bandwidth.

List of projectors to store in the CSD object. Defaults to None, which means no projectors are stored.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Maximum number of iterations to reach convergence when combining the tapered spectra with adaptive weights (see argument adaptive). This argument has not effect if adaptive is set to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The computed cross-spectral density.

mne.time_frequency.csd_array_fourier

mne.time_frequency.csd_array_morlet

---

## mne.time_frequency.csd_fourier#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.csd_fourier.html

**Contents:**
- mne.time_frequency.csd_fourier#
- Examples using mne.time_frequency.csd_fourier#

Estimate cross-spectral density from an array using short-time fourier.

The epochs to compute the CSD for.

Minimum frequency of interest, in Hertz.

Maximum frequency of interest, in Hertz.

Minimum time instant to consider, in seconds. If None start at first sample.

Maximum time instant to consider, in seconds. If None end at last sample.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FFT. If None, the exact number of samples between tmin and tmax will be used.

List of projectors to store in the CSD object. Defaults to None, which means the projectors defined in the Epochs object will be copied.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The computed cross-spectral density.

Compute a cross-spectral density (CSD) matrix

mne.time_frequency.csd_tfr

mne.time_frequency.csd_multitaper

---

## mne.time_frequency.csd_morlet#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.csd_morlet.html

**Contents:**
- mne.time_frequency.csd_morlet#
- Examples using mne.time_frequency.csd_morlet#

Estimate cross-spectral density from epochs using Morlet wavelets.

The epochs to compute the CSD for.

The frequencies of interest, in Hertz.

Minimum time instant to consider, in seconds. If None start at first sample.

Maximum time instant to consider, in seconds. If None end at last sample.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Number of cycles to use when constructing Morlet wavelets. Fixed number or one per frequency. Defaults to 7.

Whether to use FFT-based convolution to compute the wavelet transform. Defaults to True.

To reduce memory usage, decimation factor during time-frequency decomposition. Defaults to 1 (no decimation).

If int, uses tfr[…, ::decim]. If slice, uses tfr[…, decim].

List of projectors to store in the CSD object. Defaults to None, which means the projectors defined in the Epochs object will be copied.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The computed cross-spectral density.

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute a cross-spectral density (CSD) matrix

DICS for power mapping

mne.time_frequency.csd_multitaper

mne.time_frequency.pick_channels_csd

---

## mne.time_frequency.csd_multitaper#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.csd_multitaper.html

**Contents:**
- mne.time_frequency.csd_multitaper#
- Examples using mne.time_frequency.csd_multitaper#

Estimate cross-spectral density from epochs using a multitaper method.

The epochs to compute the CSD for.

Minimum frequency of interest, in Hertz.

Maximum frequency of interest, in Hertz.

Minimum time instant to consider, in seconds. If None start at first sample.

Maximum time instant to consider, in seconds. If None end at last sample.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FFT. If None, the exact number of samples between tmin and tmax will be used.

The bandwidth of the multitaper windowing function in Hz.

Use adaptive weights to combine the tapered spectra into PSD.

Only use tapers with more than 90% spectral concentration within bandwidth.

List of projectors to store in the CSD object. Defaults to None, which means the projectors defined in the Epochs object will by copied.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The computed cross-spectral density.

Compute a cross-spectral density (CSD) matrix

mne.time_frequency.csd_fourier

mne.time_frequency.csd_morlet

---

## mne.time_frequency.csd_tfr#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.csd_tfr.html

**Contents:**
- mne.time_frequency.csd_tfr#
- Examples using mne.time_frequency.csd_tfr#

Compute covariance matrices across frequencies for TFR epochs.

The time-frequency resolved epochs over which to compute the covariance.

Minimum time instant to consider, in seconds. If None start at first sample.

Maximum time instant to consider, in seconds. If None end at last sample.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

List of projectors to store in the CSD object. Defaults to None, which means the projectors defined in the EpochsTFR object will be copied.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Cross-spectral density restricted to selected channels.

Compute source level time-frequency timecourses using a DICS beamformer

mne.time_frequency.combine_tfr

mne.time_frequency.csd_fourier

---

## mne.time_frequency.dpss_windows#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.dpss_windows.html

**Contents:**
- mne.time_frequency.dpss_windows#

Compute Discrete Prolate Spheroidal Sequences.

Will give of orders [0,Kmax-1] for a given frequency-spacing multiple NW and sequence length N.

Standardized half bandwidth corresponding to 2 * half_bw = BW*f0 = BW*N/dt but with dt taken as 1.

Number of DPSS windows to return is Kmax (orders 0 through Kmax-1).

Whether to generate a symmetric window (True, for filter design) or a periodic window (False, for spectral analysis). Default is True.

Window normalization method. If 'approximate' or 'subsample', windows are normalized by the maximum, and a correction scale-factor for even-length windows is applied either using N**2/(N**2+half_nbw) (“approximate”) or a FFT-based subsample shift (“subsample”). 2 uses the L2 norm. None (the default) uses "approximate" when Kmax=None and 2 otherwise.

Keep only tapers with eigenvalues > 0.9.

The v array contains DPSS windows shaped (Kmax, N). e are the eigenvalues.

Tridiagonal form of DPSS calculation from [1].

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371–1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

mne.time_frequency.csd_array_morlet

mne.time_frequency.fwhm

---

## mne.time_frequency.fit_iir_model_raw#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.fit_iir_model_raw.html

**Contents:**
- mne.time_frequency.fit_iir_model_raw#
- Examples using mne.time_frequency.fit_iir_model_raw#

Fit an AR model to raw data and creates the corresponding IIR filter.

The computed filter is fitted to data from all of the picked channels, with frequency response given by the standard IIR formula:

Order of the FIR filter.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The beginning of time interval in seconds.

The end of time interval in seconds.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Numerator filter coefficients.

Denominator filter coefficients.

Generate simulated evoked data

Temporal whitening with AR model

mne.time_frequency.read_csd

mne.time_frequency.tfr_morlet

---

## mne.time_frequency.fwhm#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.fwhm.html

**Contents:**
- mne.time_frequency.fwhm#

Compute the full-width half maximum of a Morlet wavelet.

Uses the formula from Cohen[1].

The oscillation frequency of the wavelet.

The duration of the wavelet, expressed as the number of oscillation cycles.

The full-width half maximum of the wavelet.

Michael X Cohen. A better way to define and describe Morlet wavelets for time-frequency analysis. NeuroImage, 199:81–86, 2019. doi:10.1016/j.neuroimage.2019.05.048.

mne.time_frequency.dpss_windows

mne.time_frequency.morlet

---

## mne.time_frequency.istft#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.istft.html

**Contents:**
- mne.time_frequency.istft#

ISTFT Inverse Short-Term Fourier Transform using a sine window.

The STFT coefficients for positive frequencies.

Step between successive windows in samples (must be a multiple of 2, a divider of wsize and smaller than wsize/2) (default: wsize/2).

Length of returned signal. If None Tx = n_step * tstep.

Array containing the inverse STFT signal.

mne.time_frequency.stft

mne.time_frequency.stftfreq

---

## mne.time_frequency.morlet#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.morlet.html

**Contents:**
- mne.time_frequency.morlet#
- Examples using mne.time_frequency.morlet#

Compute Morlet wavelets for the given frequency range.

The sampling Frequency.

Frequencies to compute Morlet wavelets for.

Number of cycles. Can be a fixed number (float) or one per frequency (array-like).

It controls the width of the wavelet ie its temporal resolution. If sigma is None the temporal resolution is adapted with the frequency like for all wavelet transform. The higher the frequency the shorter is the wavelet. If sigma is fixed the temporal resolution is fixed like for the short time Fourier transform and the number of oscillations increases with the frequency.

Make sure the wavelet has a mean of zero.

The wavelets time series. If freqs was a float, a single ndarray is returned instead of a list of ndarray.

The Morlet wavelets follow the formulation in Tallon-Baudry et al.[1].

Convolution of a signal with a Morlet wavelet will impose temporal smoothing that is determined by the duration of the wavelet. In MNE-Python, the duration of the wavelet is determined by the sigma parameter, which gives the standard deviation of the wavelet’s Gaussian envelope (our wavelets extend to ±5 standard deviations to ensure values very close to zero at the endpoints). Some authors (e.g., Cohen[2]) recommend specifying and reporting wavelet duration in terms of the full-width half-maximum (FWHM) of the wavelet’s Gaussian envelope. The FWHM is related to sigma by the following identity: \(\mathrm{FWHM} = \sigma \times 2 \sqrt{2 \ln{2}}\) (or the equivalent in Python code: fwhm = sigma * 2 * np.sqrt(2 * np.log(2))). If sigma is not provided, it is computed from n_cycles as \(\frac{\mathtt{n\_cycles}}{2 \pi f}\) where \(f\) is the frequency of the wavelet oscillation (given by freqs). Thus when sigma=None the FWHM will be given by

(cf. eq. 4 in [2]). To create wavelets with a chosen FWHM, one can compute:

to get an array of values for n_cycles that yield the desired FWHM at each frequency in freqs. If you want different FWHM values at each frequency, do the same computation with desired_fwhm as an array of the same shape as freqs.

Catherine Tallon-Baudry, Olivier Bertrand, Claude Delpuech, and Jacques Pernier. Oscillatory Gamma-Band (30–70 Hz) Activity Induced by a Visual Search Task in Humans. Journal of Neuroscience, pages 722–734, 1997. doi:10.1523/JNEUROSCI.17-02-00722.1997.

Michael X Cohen. A better way to define and describe Morlet wavelets for time-frequency analysis. NeuroImage, 199:81–86, 2019. doi:10.1016/j.neuroimage.2019.05.048.

Let’s show a simple example of the relationship between n_cycles and the FWHM using mne.time_frequency.fwhm():

Background information on filtering

mne.time_frequency.fwhm

mne.time_frequency.stft

---

## mne.time_frequency.pick_channels_csd#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.pick_channels_csd.html

**Contents:**
- mne.time_frequency.pick_channels_csd#

Pick channels from cross-spectral density matrix.

The CSD object to select the channels from.

List of channels to include (if empty, include all available).

Channels to exclude (if empty, do not exclude any).

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

If True (the default), return a copy of the CSD matrix with the modified channels. If False, channels are modified in-place.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Cross-spectral density restricted to selected channels.

mne.time_frequency.csd_morlet

mne.time_frequency.read_csd

---

## mne.time_frequency.psd_array_multitaper#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.psd_array_multitaper.html

**Contents:**
- mne.time_frequency.psd_array_multitaper#

Compute power spectral density (PSD) using a multi-taper method.

The power spectral density is computed with DPSS tapers [1].

The data to compute PSD from.

The sampling frequency.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

Frequency bandwidth of the multi-taper window function in Hz. For a given frequency, frequencies at ± bandwidth / 2 are smoothed together. The default value is a bandwidth of 8 * (sfreq / n_times).

Use adaptive weights to combine the tapered spectra into PSD (slow, use n_jobs >> 1 to speed up computation).

Only use tapers with more than 90% spectral concentration within bandwidth.

Normalization strategy. If “full”, the PSD will be normalized by the sampling rate as well as the length of the signal (as in Nitime). Default is 'length'.

If True, the mean is subtracted from each segment before computing its spectrum.

The format of the returned psds array, 'complex' or 'power':

'power' : the power spectral density is returned.

'complex' : the complex fourier coefficients are returned per taper.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Maximum number of iterations to reach convergence when combining the tapered spectra with adaptive weights (see argument adaptive). This argument has not effect if adaptive is set to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The power spectral densities. All dimensions up to the last (or the last two if output='complex') will be the same as input.

The frequency points in Hz of the PSD.

The weights used for averaging across tapers. Only returned if output='complex'.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371–1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

mne.time_frequency.stftfreq

mne.time_frequency.psd_array_welch

---

## mne.time_frequency.psd_array_welch#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.psd_array_welch.html

**Contents:**
- mne.time_frequency.psd_array_welch#
- Examples using mne.time_frequency.psd_array_welch#

Compute power spectral density (PSD) using Welch’s method.

Welch’s method is described in Welch[1].

The data to compute PSD from.

The sampling frequency.

The lower frequency of interest.

The upper frequency of interest.

The length of FFT used, must be >= n_per_seg (default: 256). The segments will be zero-padded if n_fft > n_per_seg.

The number of points of overlap between segments. Will be adjusted to be <= n_per_seg. The default value is 0.

Length of each Welch segment (windowed with a Hamming window). Defaults to None, which sets n_per_seg equal to n_fft.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

How to average the segments. If mean (default), calculate the arithmetic mean. If median, calculate the median, corrected for its bias relative to the mean. If None, returns the unaggregated segments.

Windowing function to use. See scipy.signal.get_window().

If True, the mean is subtracted from each segment before computing its spectrum.

The format of the returned psds array, 'complex' or 'power':

'power' : the power spectral density is returned.

'complex' : the complex fourier coefficients are returned per window.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The power spectral densities. If average='mean or average='median', the returned array will have the same shape as the input data plus an additional frequency dimension. If average=None, the returned array will have the same shape as the input data plus two additional dimensions corresponding to frequencies and the unaggregated segments, respectively.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70–73, 1967. doi:10.1109/TAU.1967.1161901.

Compute spatial filters with Spatio-Spectral Decomposition (SSD)

Creating MNE-Python data structures from scratch

mne.time_frequency.psd_array_multitaper

mne.time_frequency.tfr_array_morlet

---

## mne.time_frequency.RawTFRArray#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.RawTFRArray.html

**Contents:**
- mne.time_frequency.RawTFRArray#

Data object for precomputed spectrotemporal representations of continuous data.

The mne.Info object with information about the sensors and methods of measurement.

The time values in seconds.

The frequencies in Hz.

Comment on the method used to compute the data, e.g., "hilbert". Default is None.

The weights for each taper. Must be provided if data has a taper dimension, such as for complex or phase multitaper data.

Start and end of the baseline period (in seconds).

The frequencies at which power estimates were computed.

The mne.Info object with information about the sensors and methods of measurement.

The method used to compute the time-frequency power estimates.

Sampling frequency of the data.

The weights used for each taper in the time-frequency estimates.

Add two TFR instances.

__contains__(ch_type)

Check channel type membership.

Multiply a TFR instance by a scalar.

Subtract two TFR instances.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

apply_baseline(baseline[, mode, verbose])

Baseline correct the data.

Return copy of the TFR instance.

crop([tmin, tmax, fmin, fmax, include_tmax])

Crop data to a given time interval in place.

decimate(decim[, offset, verbose])

Decimate the time-series data.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, tmin, ...])

Get time-frequency data in NumPy array format.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, exclude, tmin, tmax, fmin, ...])

Plot TFRs as two-dimensional time-frequency images.

plot_joint(*[, timefreqs, picks, exclude, ...])

Plot TFRs as a two-dimensional image with topomap highlights.

plot_topo([picks, baseline, mode, tmin, ...])

Plot a TFR image for each channel in a sensor layout arrangement.

plot_topomap([tmin, tmax, fmin, fmax, ...])

Plot topographic maps of specific time-frequency intervals of TFR data.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save time-frequency data to disk (in HDF5 format).

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, long_format, ...])

Export data in tabular structure as a pandas DataFrame.

Add two TFR instances.

The TFR instance to add. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Indexing is similar to a NumPy array; see Notes.

The last axis is always time, the next-to-last axis is always frequency, and the first axis is always channel. If method='multitaper' and output='complex' then the second axis will be taper index.

Integer-, list-, and slice-based indexing is possible:

raw_tfr[[0, 2]] gives the whole time-frequency plane for the first and third channels.

raw_tfr[..., :3, :] gives the first 3 frequency bins and all times for all channels (and tapers, if present).

raw_tfr[..., :100] gives the first 100 time samples in all frequency bins for all channels (and tapers).

raw_tfr[(4, 7)] is the same as raw_tfr[4, 7].

Unlike Raw objects (which returns a tuple of the requested data values and the corresponding times), accessing RawTFR values via subscript does not return the corresponding frequency bin values. If you need them, use RawTFR.freqs[freq_indices] or RawTFR.get_data(..., return_freqs=True).

Multiply a TFR instance by a scalar.

The number to multiply by.

A new TFR instance, of the same type as self.

Subtract two TFR instances.

The TFR instance to subtract. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won’t be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Baseline correct the data.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Start and end of the baseline period (in seconds).

The current gradient compensation grade.

Return copy of the TFR instance.

A copy of the object.

Crop data to a given time interval in place.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Lowest frequency of selection in Hz.

Highest frequency of selection in Hz.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The modified instance.

The time-frequency-resolved power estimates.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / “decimation” refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [1], p. 172; which cites [2]):

“… a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).”

Hence “decimation” in MNE is what is considered “compression” in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

The frequencies at which power estimates were computed.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get time-frequency data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Whether to return the time values for the requested time range. Default is False.

Whether to return the frequency bin values for the requested frequency range. Default is False.

Whether to return the taper numbers. Default is False.

The requested data in a NumPy array.

The time values for the requested data range. Only returned if return_times is True.

The frequency values for the requested data range. Only returned if return_freqs is True.

The taper numbers. Only returned if return_tapers is True. Will be None if a taper dimension is not present in the data.

Returns a copy of the underlying data (not a view).

The method used to compute the time-frequency power estimates.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=”bads” when picks=”meg”).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(…).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(…).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‘auto’, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‘hbo’ (to include channels measuring oxyhemoglobin) or ‘hbr’ (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‘eyegaze’ (to include eye position channels) or ‘pupil’ (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‘bads’ (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot TFRs as two-dimensional time-frequency images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’) (default)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(data).

How to aggregate across channels. If None, plot one figure per selected channel. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to None.

Changed in version 1.3: Added support for callable.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The scale of the y (frequency) axis. ‘linear’ gives linear y axis, ‘log’ gives log-spaced y axis and ‘auto’ detects if frequencies are log-spaced and if so sets the y axis to ‘log’. Default is ‘auto’.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Whether to add a colorbar to the plot. Default is True.

Title for the plot. If "auto", will use the channel name (if combine is None) or state the number and method of combined channels used to generate the plot. If None, no title is shown. Default is None.

An array of boolean values, of the same shape as the data. Data that corresponds to False entries in the mask are plotted differently, as determined by mask_style, mask_alpha, and mask_cmap. Useful for, e.g., highlighting areas of statistical significance.

How to distinguish the masked/unmasked regions of the plot. If "contour", a line is drawn around the areas where the mask is True. If "mask", areas where the mask is False will be (partially) transparent, as determined by mask_alpha. If "both", both a contour and transparency are used. Default is None, which is silently ignored if mask is None and is interpreted like "both" otherwise.

Colormap to use for masked areas of the plot. If a str, must be a valid Matplotlib colormap name. If None, cmap is used for both masked and unmasked areas. Ignored if mask is None. Default is 'Greys'.

Relative opacity of the masked region versus the unmasked region, given as a float between 0 and 1 (i.e., 0 means masked areas are not visible at all). Defaults to 0.1.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of picks. If combine is not None, axes must either be an instance of Axes, or a list of length 1. Default is None.

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of figures containing the time-frequency power.

Plot TFRs as a two-dimensional image with topomap highlights.

The time-frequency point(s) for which topomaps will be plotted. See Notes.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any). Default is an empty tuple which includes all channels.

How to aggregate across channels. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to "mean".

Changed in version 1.3: Added support for callable.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’) (default)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(data).

The scale of the y (frequency) axis. ‘linear’ gives linear y axis, ‘log’ gives log-spaced y axis and ‘auto’ detects if frequencies are log-spaced and if so sets the y axis to ‘log’. Default is ‘auto’.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. To specify the colormap separately for the topomap annotations, see topomap_args. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

Whether to add a colorbar to the plot (for the topomap annotations). Not compatible with user-defined axes. Default is True.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

Keyword arguments to pass to mne.viz.plot_topomap(). axes and show are ignored. If times is not in this dict, automatic peak detection is used. Beyond that, if None, no customizable arguments will be passed. Defaults to None (i.e., an empty dict).

Keyword arguments to pass to mne.time_frequency.AverageTFR.plot(). axes and show are ignored. Defaults to None (i.e., and empty dict).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

timefreqs has three different modes: tuples, dicts, and auto. For (list of) tuple(s) mode, each tuple defines a pair (time, frequency) in s and Hz on the TFR plot. For example, to look at 10 Hz activity 1 second into the epoch and 3 Hz activity 300 ms into the epoch,

If provided as a dictionary, (time, frequency) tuples are keys and (time_window, frequency_window) tuples are the values — indicating the width of the windows (centered on the time and frequency indicated by the key) to be averaged over. For example,

would translate into a window that spans 0.95 to 1.05 seconds and 9 to 11 Hz. If None, a single topomap will be plotted at the absolute peak across the time-frequency representation.

Plot a TFR image for each channel in a sensor layout arrangement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’) (default)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

Lower and upper bounds of the colormap, in the same units as the data. If vmin and vmax are both None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0). If only one of vmin, vmax is None, will use min(data) or max(data), respectively.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

The title of the generated figure. If None (default), no title is displayed.

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(data).

Whether to add a colorbar to the plot. Default is True.

Scaling factor for adjusting the relative size of the layout on the canvas.

Show the figure if True.

Matplotlib border style to be used for each sensor plot.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

The scale of the y (frequency) axis. ‘linear’ gives linear y axis, ‘log’ gives log-spaced y axis and ‘auto’ detects if frequencies are log-spaced and if so sets the y axis to ‘log’. Default is ‘auto’.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

Plot topographic maps of specific time-frequency intervals of TFR data.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The time interval to apply rescaling / baseline correction. If None do not apply it. If baseline is (a, b) the interval is between “a (s)” and “b (s)”. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) the whole time interval is used.

Perform baseline correction by

subtracting the mean baseline power (‘mean’)

dividing by the mean baseline power (‘ratio’)

dividing by the mean baseline power and taking the log (‘logratio’)

subtracting the mean baseline power followed by dividing by the mean baseline power (‘percent’)

subtracting the mean baseline power and dividing by the standard deviation of the baseline power (‘zscore’)

dividing by the mean baseline power, taking the log, and dividing by the standard deviation of the baseline power (‘zlogratio’)

If None no baseline correction is applied.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created. Default is None.

Show the figure if True.

The figure containing the topography.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save time-frequency data to disk (in HDF5 format).

Path of file to save to, which should end with -tfr.h5 or -tfr.hdf5.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Sampling frequency of the data.

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

The time points present in the data (in seconds).

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, additional columns 'time', 'freq', 'taper', 'epoch', and 'condition' (epoch event description) are added, unless index is not None (in which case the columns specified in index will be used to form the DataFrame’s index instead). 'epoch', and 'condition' are not supported for AverageTFR. 'taper' is only supported when a taper dimensions is present, such as for complex or phase multitaper data.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). If a list of two or more string values, a pandas.MultiIndex will be created. Valid string values are 'time', 'freq', 'taper', 'epoch', and 'condition' for EpochsTFR and 'time', 'freq', and 'taper' for AverageTFR. Defaults to None.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point, channel, epoch number, and condition. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

The weights used for each taper in the time-frequency estimates.

mne.time_frequency.RawTFR

mne.time_frequency.CrossSpectralDensity

---

## mne.time_frequency.RawTFR#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.RawTFR.html

**Contents:**
- mne.time_frequency.RawTFR#

Data object for spectrotemporal representations of continuous data.

The preferred means of creating RawTFR objects from Raw objects is via the instance method compute_tfr(). Direct class instantiation is not supported.

The data from which to compute the time-frequency representation.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [1]. None (the default) only works when using __setstate__ and will raise an error otherwise.

The frequencies at which to compute the power estimates. Must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Whether to omit bad spans of data before spectrotemporal power estimation. If True, spans with annotations whose description begins with bad will be represented with np.nan in the time-frequency representation.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet() and tfr_array_multitaper() for additional details.

The frequencies at which power estimates were computed.

The mne.Info object with information about the sensors and methods of measurement.

The method used to compute the time-frequency power estimates.

The weights used for each taper in the time-frequency estimates.

Add two TFR instances.

__contains__(ch_type)

Check channel type membership.

Multiply a TFR instance by a scalar.

Subtract two TFR instances.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

apply_baseline(baseline[, mode, verbose])

Baseline correct the data.

Return copy of the TFR instance.

crop([tmin, tmax, fmin, fmax, include_tmax])

Crop data to a given time interval in place.

decimate(decim[, offset, verbose])

Decimate the time-series data.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, tmin, ...])

Get time-frequency data in NumPy array format.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, exclude, tmin, tmax, fmin, ...])

Plot TFRs as two-dimensional time-frequency images.

plot_joint(*[, timefreqs, picks, exclude, ...])

Plot TFRs as a two-dimensional image with topomap highlights.

plot_topo([picks, baseline, mode, tmin, ...])

Plot a TFR image for each channel in a sensor layout arrangement.

plot_topomap([tmin, tmax, fmin, fmax, ...])

Plot topographic maps of specific time-frequency intervals of TFR data.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save time-frequency data to disk (in HDF5 format).

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, long_format, ...])

Export data in tabular structure as a pandas DataFrame.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371–1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Add two TFR instances.

The TFR instance to add. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Indexing is similar to a NumPy array; see Notes.

The last axis is always time, the next-to-last axis is always frequency, and the first axis is always channel. If method='multitaper' and output='complex' then the second axis will be taper index.

Integer-, list-, and slice-based indexing is possible:

raw_tfr[[0, 2]] gives the whole time-frequency plane for the first and third channels.

raw_tfr[..., :3, :] gives the first 3 frequency bins and all times for all channels (and tapers, if present).

raw_tfr[..., :100] gives the first 100 time samples in all frequency bins for all channels (and tapers).

raw_tfr[(4, 7)] is the same as raw_tfr[4, 7].

Unlike Raw objects (which returns a tuple of the requested data values and the corresponding times), accessing RawTFR values via subscript does not return the corresponding frequency bin values. If you need them, use RawTFR.freqs[freq_indices] or RawTFR.get_data(..., return_freqs=True).

Multiply a TFR instance by a scalar.

The number to multiply by.

A new TFR instance, of the same type as self.

Subtract two TFR instances.

The TFR instance to subtract. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won’t be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Baseline correct the data.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Start and end of the baseline period (in seconds).

The current gradient compensation grade.

Return copy of the TFR instance.

A copy of the object.

Crop data to a given time interval in place.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Lowest frequency of selection in Hz.

Highest frequency of selection in Hz.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The modified instance.

The time-frequency-resolved power estimates.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / “decimation” refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [2], p. 172; which cites [3]):

“… a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).”

Hence “decimation” in MNE is what is considered “compression” in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

The frequencies at which power estimates were computed.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get time-frequency data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Whether to return the time values for the requested time range. Default is False.

Whether to return the frequency bin values for the requested frequency range. Default is False.

Whether to return the taper numbers. Default is False.

The requested data in a NumPy array.

The time values for the requested data range. Only returned if return_times is True.

The frequency values for the requested data range. Only returned if return_freqs is True.

The taper numbers. Only returned if return_tapers is True. Will be None if a taper dimension is not present in the data.

Returns a copy of the underlying data (not a view).

The method used to compute the time-frequency power estimates.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=”bads” when picks=”meg”).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(…).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(…).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‘auto’, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‘hbo’ (to include channels measuring oxyhemoglobin) or ‘hbr’ (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‘eyegaze’ (to include eye position channels) or ‘pupil’ (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‘bads’ (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot TFRs as two-dimensional time-frequency images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’) (default)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(data).

How to aggregate across channels. If None, plot one figure per selected channel. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to None.

Changed in version 1.3: Added support for callable.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The scale of the y (frequency) axis. ‘linear’ gives linear y axis, ‘log’ gives log-spaced y axis and ‘auto’ detects if frequencies are log-spaced and if so sets the y axis to ‘log’. Default is ‘auto’.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Whether to add a colorbar to the plot. Default is True.

Title for the plot. If "auto", will use the channel name (if combine is None) or state the number and method of combined channels used to generate the plot. If None, no title is shown. Default is None.

An array of boolean values, of the same shape as the data. Data that corresponds to False entries in the mask are plotted differently, as determined by mask_style, mask_alpha, and mask_cmap. Useful for, e.g., highlighting areas of statistical significance.

How to distinguish the masked/unmasked regions of the plot. If "contour", a line is drawn around the areas where the mask is True. If "mask", areas where the mask is False will be (partially) transparent, as determined by mask_alpha. If "both", both a contour and transparency are used. Default is None, which is silently ignored if mask is None and is interpreted like "both" otherwise.

Colormap to use for masked areas of the plot. If a str, must be a valid Matplotlib colormap name. If None, cmap is used for both masked and unmasked areas. Ignored if mask is None. Default is 'Greys'.

Relative opacity of the masked region versus the unmasked region, given as a float between 0 and 1 (i.e., 0 means masked areas are not visible at all). Defaults to 0.1.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of picks. If combine is not None, axes must either be an instance of Axes, or a list of length 1. Default is None.

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of figures containing the time-frequency power.

Plot TFRs as a two-dimensional image with topomap highlights.

The time-frequency point(s) for which topomaps will be plotted. See Notes.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any). Default is an empty tuple which includes all channels.

How to aggregate across channels. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to "mean".

Changed in version 1.3: Added support for callable.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’) (default)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(data).

The scale of the y (frequency) axis. ‘linear’ gives linear y axis, ‘log’ gives log-spaced y axis and ‘auto’ detects if frequencies are log-spaced and if so sets the y axis to ‘log’. Default is ‘auto’.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. To specify the colormap separately for the topomap annotations, see topomap_args. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

Whether to add a colorbar to the plot (for the topomap annotations). Not compatible with user-defined axes. Default is True.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

Keyword arguments to pass to mne.viz.plot_topomap(). axes and show are ignored. If times is not in this dict, automatic peak detection is used. Beyond that, if None, no customizable arguments will be passed. Defaults to None (i.e., an empty dict).

Keyword arguments to pass to mne.time_frequency.AverageTFR.plot(). axes and show are ignored. Defaults to None (i.e., and empty dict).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

timefreqs has three different modes: tuples, dicts, and auto. For (list of) tuple(s) mode, each tuple defines a pair (time, frequency) in s and Hz on the TFR plot. For example, to look at 10 Hz activity 1 second into the epoch and 3 Hz activity 300 ms into the epoch,

If provided as a dictionary, (time, frequency) tuples are keys and (time_window, frequency_window) tuples are the values — indicating the width of the windows (centered on the time and frequency indicated by the key) to be averaged over. For example,

would translate into a window that spans 0.95 to 1.05 seconds and 9 to 11 Hz. If None, a single topomap will be plotted at the absolute peak across the time-frequency representation.

Plot a TFR image for each channel in a sensor layout arrangement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‘mean’) (default)

dividing by the mean of baseline values (‘ratio’)

dividing by the mean of baseline values and taking the log (‘logratio’)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‘percent’)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‘zscore’)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‘zlogratio’)

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

Lower and upper bounds of the colormap, in the same units as the data. If vmin and vmax are both None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0). If only one of vmin, vmax is None, will use min(data) or max(data), respectively.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

The title of the generated figure. If None (default), no title is displayed.

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(data).

Whether to add a colorbar to the plot. Default is True.

Scaling factor for adjusting the relative size of the layout on the canvas.

Show the figure if True.

Matplotlib border style to be used for each sensor plot.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

The scale of the y (frequency) axis. ‘linear’ gives linear y axis, ‘log’ gives log-spaced y axis and ‘auto’ detects if frequencies are log-spaced and if so sets the y axis to ‘log’. Default is ‘auto’.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

Plot topographic maps of specific time-frequency intervals of TFR data.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The time interval to apply rescaling / baseline correction. If None do not apply it. If baseline is (a, b) the interval is between “a (s)” and “b (s)”. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) the whole time interval is used.

Perform baseline correction by

subtracting the mean baseline power (‘mean’)

dividing by the mean baseline power (‘ratio’)

dividing by the mean baseline power and taking the log (‘logratio’)

subtracting the mean baseline power followed by dividing by the mean baseline power (‘percent’)

subtracting the mean baseline power and dividing by the standard deviation of the baseline power (‘zscore’)

dividing by the mean baseline power, taking the log, and dividing by the standard deviation of the baseline power (‘zlogratio’)

If None no baseline correction is applied.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created. Default is None.

Show the figure if True.

The figure containing the topography.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save time-frequency data to disk (in HDF5 format).

Path of file to save to, which should end with -tfr.h5 or -tfr.hdf5.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Sampling frequency of the data.

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

The time points present in the data (in seconds).

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, additional columns 'time', 'freq', 'taper', 'epoch', and 'condition' (epoch event description) are added, unless index is not None (in which case the columns specified in index will be used to form the DataFrame’s index instead). 'epoch', and 'condition' are not supported for AverageTFR. 'taper' is only supported when a taper dimensions is present, such as for complex or phase multitaper data.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). If a list of two or more string values, a pandas.MultiIndex will be created. Valid string values are 'time', 'freq', 'taper', 'epoch', and 'condition' for EpochsTFR and 'time', 'freq', and 'taper' for AverageTFR. Defaults to None.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point, channel, epoch number, and condition. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

The weights used for each taper in the time-frequency estimates.

mne.time_frequency.EpochsTFRArray

mne.time_frequency.RawTFRArray

---

## mne.time_frequency.read_csd#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.read_csd.html

**Contents:**
- mne.time_frequency.read_csd#

Read a CrossSpectralDensity object from an HDF5 file.

The name of the file to read the CSD from. The extension '.h5' will be appended if the given filename doesn’t have it already.

The CSD that was stored in the file.

For saving CSD objects.

mne.time_frequency.pick_channels_csd

mne.time_frequency.fit_iir_model_raw

---

## mne.time_frequency.read_spectrum#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.read_spectrum.html

**Contents:**
- mne.time_frequency.read_spectrum#

Load a mne.time_frequency.Spectrum object from disk.

Path to a spectrum file in HDF5 format, which should end with .h5 or .hdf5.

The loaded Spectrum object.

mne.time_frequency.write_tfrs

mne.time_frequency.csd_array_fourier

---

## mne.time_frequency.read_tfrs#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.read_tfrs.html

**Contents:**
- mne.time_frequency.read_tfrs#

Load a TFR object from disk.

Path to a TFR file in HDF5 format, which should end with -tfr.h5 or -tfr.hdf5.

The condition to load. If None, all conditions will be returned. Defaults to None.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The loaded time-frequency object.

mne.time_frequency.tfr_stockwell

mne.time_frequency.write_tfrs

---

## mne.time_frequency.SpectrumArray#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.SpectrumArray.html

**Contents:**
- mne.time_frequency.SpectrumArray#
- Examples using mne.time_frequency.SpectrumArray#

Data object for precomputed spectral data (in NumPy array format).

The spectra for each channel.

The mne.Info object with information about the sensors and methods of measurement.

The frequencies in Hz.

The name of the dimensions in the data, in the order they occur. Must contain 'channel' and 'freq'; if data are unaggregated estimates, also include either a 'segment' (e.g., Welch-like algorithms) or 'taper' (e.g., multitaper algorithms) dimension. If including 'taper', you should also pass a weights parameter.

Weights for the 'taper' dimension, if present (see dim_names).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The current gradient compensation grade.

__contains__(ch_type)

Check channel type membership.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

Return copy of the Spectrum instance.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, ...])

Get spectrum data in NumPy array format.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot(*[, picks, average, dB, amplitude, ...])

Plot power or amplitude spectra.

plot_topo(*[, dB, layout, color, ...])

Plot power spectral density, separately for each channel.

plot_topomap([bands, ch_type, normalize, ...])

Plot scalp topography of PSD for chosen frequency bands.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save spectrum data to disk (in HDF5 format).

to_data_frame([picks, index, copy, ...])

Export data in tabular structure as a pandas DataFrame.

Get the spectrum units for each channel type.

If the data passed in is real-valued, it is assumed to represent spectral power (not amplitude, phase, etc), and downstream methods (such as plot()) assume power data. If you pass in real-valued data that is not power, axis labels will be incorrect.

If the data passed in is complex-valued, it is assumed to represent Fourier coefficients. Downstream plotting methods will treat the data as such, attempting to convert this to power before visualisation. If you pass in complex-valued data that is not Fourier coefficients, axis labels will be incorrect.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Indexing is similar to a NumPy array; see Notes.

Integer-, list-, and slice-based indexing is possible:

spectrum[0] gives all frequency bins in the first channel

spectrum[:3] gives all frequency bins in the first 3 channels

spectrum[[0, 2], 5] gives the value in the sixth frequency bin of the first and third channels

spectrum[(4, 7)] is the same as spectrum[4, 7].

Unlike Raw objects (which returns a tuple of the requested data values and the corresponding times), accessing Spectrum values via subscript does not return the corresponding frequency bin values. If you need them, use spectrum.freqs[freq_indices] or spectrum.get_data(..., return_freqs=True).

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won’t be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

The current gradient compensation grade.

Return copy of the Spectrum instance.

A copy of the object.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get spectrum data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

Whether to return the frequency bin values for the requested frequency range. Default is False.

The requested data in a NumPy array.

The frequency values for the requested range. Only returned if return_freqs is True.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=”bads” when picks=”meg”).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(…).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(…).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‘auto’, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‘hbo’ (to include channels measuring oxyhemoglobin) or ‘hbr’ (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‘eyegaze’ (to include eye position channels) or ‘pupil’ (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‘bads’ (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (╎) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (⋮). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Changed in version 1.5: In version 1.5, the default behavior changed so that all data channels (not just “good” data channels) are shown by default.

Whether to average across channels before plotting. If True, interactive plotting of scalp topography is disabled, and parameters ci and ci_alpha control the style of the confidence band around the mean. Default is False.

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz), or 20 × log₁₀(spectral amplitude/√Hz) if amplitude=True.

Whether to plot an amplitude spectrum (True) or power spectrum (False).

Changed in version 1.8: In version 1.8, the default changed to amplitude=False.

Scale of the frequency axis. Default is 'linear'.

Type of confidence band drawn around the mean when average=True. If 'sd' the band spans ±1 standard deviation across channels. If 'range' the band spans the range across channels at each frequency. If a float, it indicates the (bootstrapped) confidence interval to display, and must satisfy 0 < ci <= 100. If None, no band is drawn. Default is sd.

Opacity of the confidence band. Must satisfy 0 <= ci_alpha <= 1. Default is 0.3.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Opacity of the spectrum line(s). If float, must satisfy 0 <= alpha <= 1. If None, opacity will be 1 when average=True and 0.1 when average=False. Default is None.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

Changed in version 1.5: In version 1.5, the default behavior changed from exclude='bads' to exclude=().

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

Figure with spectra plotted in separate subplots for each channel type.

Creating MNE-Python data structures from scratch

Plot power spectral density, separately for each channel.

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‘%0.3f’ if dB=False and ‘%0.1f’ if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

Figure showing one scalp topography per frequency band.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save spectrum data to disk (in HDF5 format).

Path of file to save to.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, an additional column “freq” is added, unless index='freq' (in which case frequency values form the DataFrame’s index).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If a str, a pandas.Index will be used (see Notes). If a list of two or more string values, a pandas.MultiIndex will be used. Defaults to None.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of frequency and channel. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Valid values for index depend on whether the Spectrum was created from continuous data (Raw, Evoked) or discontinuous data (Epochs). For continuous data, only None or 'freq' is supported. For discontinuous data, additional valid values are 'epoch' and 'condition', or a list comprising some of the valid string values (e.g., ['freq', 'epoch']).

Get the spectrum units for each channel type.

Whether to format the unit strings as LaTeX. Default is False.

Mapping from channel type to a string representation of the units for that channel type.

Creating MNE-Python data structures from scratch

mne.time_frequency.Spectrum

mne.time_frequency.EpochsSpectrum

---

## mne.time_frequency.Spectrum#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.Spectrum.html

**Contents:**
- mne.time_frequency.Spectrum#
- Examples using mne.time_frequency.Spectrum#

Data object for spectral representations of continuous data.

The preferred means of creating Spectrum objects from continuous or averaged data is via the instance methods mne.io.Raw.compute_psd() or mne.Evoked.compute_psd(). Direct class instantiation is not supported.

The data from which to compute the frequency spectrum.

Spectral estimation method. 'welch' uses Welch’s method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch’s method for continuous data and multitaper for Evoked data.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

Whether to apply SSP projection vectors before spectral estimation. Default is False.

If True, the mean is subtracted from each segment before computing its spectrum.

Whether to omit bad spans of data before spectral estimation. If True, spans with annotations whose description begins with bad will be omitted.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Frequencies at which the amplitude, power, or fourier coefficients have been computed.

The mne.Info object with information about the sensors and methods of measurement.

The method used to compute the spectrum.

The number of trials averaged together when generating the spectrum. None indicates no averaging is known to have occurred.

The weights for each taper. Only present if spectra computed with method='multitaper' and output='complex'.

__contains__(ch_type)

Check channel type membership.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

Return copy of the Spectrum instance.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, ...])

Get spectrum data in NumPy array format.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot(*[, picks, average, dB, amplitude, ...])

Plot power or amplitude spectra.

plot_topo(*[, dB, layout, color, ...])

Plot power spectral density, separately for each channel.

plot_topomap([bands, ch_type, normalize, ...])

Plot scalp topography of PSD for chosen frequency bands.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save spectrum data to disk (in HDF5 format).

to_data_frame([picks, index, copy, ...])

Export data in tabular structure as a pandas DataFrame.

Get the spectrum units for each channel type.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70–73, 1967. doi:10.1109/TAU.1967.1161901.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371–1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Indexing is similar to a NumPy array; see Notes.

Integer-, list-, and slice-based indexing is possible:

spectrum[0] gives all frequency bins in the first channel

spectrum[:3] gives all frequency bins in the first 3 channels

spectrum[[0, 2], 5] gives the value in the sixth frequency bin of the first and third channels

spectrum[(4, 7)] is the same as spectrum[4, 7].

Unlike Raw objects (which returns a tuple of the requested data values and the corresponding times), accessing Spectrum values via subscript does not return the corresponding frequency bin values. If you need them, use spectrum.freqs[freq_indices] or spectrum.get_data(..., return_freqs=True).

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won’t be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

The current gradient compensation grade.

Return copy of the Spectrum instance.

A copy of the object.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get spectrum data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

Whether to return the frequency bin values for the requested frequency range. Default is False.

The requested data in a NumPy array.

The frequency values for the requested range. Only returned if return_freqs is True.

Examples using get_data:

Plot custom topographies for MEG sensors

Frequency and time-frequency sensor analysis

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=”bads” when picks=”meg”).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Built-in plotting methods for Raw objects

LEGACY: New code should use inst.pick(…).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(…).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‘auto’, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‘hbo’ (to include channels measuring oxyhemoglobin) or ‘hbr’ (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‘eyegaze’ (to include eye position channels) or ‘pupil’ (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‘bads’ (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (╎) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (⋮). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Changed in version 1.5: In version 1.5, the default behavior changed so that all data channels (not just “good” data channels) are shown by default.

Whether to average across channels before plotting. If True, interactive plotting of scalp topography is disabled, and parameters ci and ci_alpha control the style of the confidence band around the mean. Default is False.

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz), or 20 × log₁₀(spectral amplitude/√Hz) if amplitude=True.

Whether to plot an amplitude spectrum (True) or power spectrum (False).

Changed in version 1.8: In version 1.8, the default changed to amplitude=False.

Scale of the frequency axis. Default is 'linear'.

Type of confidence band drawn around the mean when average=True. If 'sd' the band spans ±1 standard deviation across channels. If 'range' the band spans the range across channels at each frequency. If a float, it indicates the (bootstrapped) confidence interval to display, and must satisfy 0 < ci <= 100. If None, no band is drawn. Default is sd.

Opacity of the confidence band. Must satisfy 0 <= ci_alpha <= 1. Default is 0.3.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Opacity of the spectrum line(s). If float, must satisfy 0 <= alpha <= 1. If None, opacity will be 1 when average=True and 0.1 when average=False. Default is None.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).

Changed in version 1.5: In version 1.5, the default behavior changed from exclude='bads' to exclude=().

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

Figure with spectra plotted in separate subplots for each channel type.

KIT phantom dataset tutorial

Filtering and resampling data

Repairing artifacts with SSP

Built-in plotting methods for Raw objects

Creating MNE-Python data structures from scratch

The Spectrum and EpochsSpectrum classes: frequency-domain data

Plot power spectral density, separately for each channel.

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Examples using plot_topo:

Built-in plotting methods for Raw objects

The Spectrum and EpochsSpectrum classes: frequency-domain data

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 × log₁₀(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‘%0.3f’ if dB=False and ‘%0.1f’ if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

Figure showing one scalp topography per frequency band.

Examples using plot_topomap:

Built-in plotting methods for Raw objects

The Spectrum and EpochsSpectrum classes: frequency-domain data

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save spectrum data to disk (in HDF5 format).

Path of file to save to.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, an additional column “freq” is added, unless index='freq' (in which case frequency values form the DataFrame’s index).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If a str, a pandas.Index will be used (see Notes). If a list of two or more string values, a pandas.MultiIndex will be used. Defaults to None.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of frequency and channel. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Valid values for index depend on whether the Spectrum was created from continuous data (Raw, Evoked) or discontinuous data (Epochs). For continuous data, only None or 'freq' is supported. For discontinuous data, additional valid values are 'epoch' and 'condition', or a list comprising some of the valid string values (e.g., ['freq', 'epoch']).

Get the spectrum units for each channel type.

Whether to format the unit strings as LaTeX. Default is False.

Mapping from channel type to a string representation of the units for that channel type.

Plot custom topographies for MEG sensors

KIT phantom dataset tutorial

Filtering and resampling data

Repairing artifacts with SSP

Preprocessing optically pumped magnetometer (OPM) MEG data

Built-in plotting methods for Raw objects

Creating MNE-Python data structures from scratch

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency and time-frequency sensor analysis

mne.time_frequency.CrossSpectralDensity

mne.time_frequency.SpectrumArray

---

## mne.time_frequency.stftfreq#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.stftfreq.html

**Contents:**
- mne.time_frequency.stftfreq#

Compute frequencies of stft transformation.

Sampling frequency. If None the frequencies are given between 0 and pi otherwise it’s given in Hz.

The positive frequencies returned by stft.

mne.time_frequency.istft

mne.time_frequency.psd_array_multitaper

---

## mne.time_frequency.stft#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.stft.html

**Contents:**
- mne.time_frequency.stft#

STFT Short-Term Fourier Transform using a sine window.

The transformation is designed to be a tight frame that can be perfectly inverted. It only returns the positive frequencies.

Containing multi-channels signal.

Length of the STFT window in samples (must be a multiple of 4).

Step between successive windows in samples (must be a multiple of 2, a divider of wsize and smaller than wsize/2) (default: wsize/2).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

STFT coefficients for positive frequencies with n_step = ceil(T / tstep).

mne.time_frequency.morlet

mne.time_frequency.istft

---

## mne.time_frequency.tfr.cwt#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.tfr.cwt.html

**Contents:**
- mne.time_frequency.tfr.cwt#

Compute time-frequency decomposition with continuous wavelet transform.

Wavelets time series.

Use FFT for convolutions. Defaults to True.

Convention for convolution. ‘full’ is currently not implemented with use_fft=False. Defaults to 'same'.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The time-frequency decompositions.

Compute time-frequency decomposition with Morlet wavelets.

mne.time_frequency.tfr_array_stockwell

mne.time_frequency.tfr.morlet

---

## mne.time_frequency.tfr.morlet#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.tfr.morlet.html

**Contents:**
- mne.time_frequency.tfr.morlet#

Compute Morlet wavelets for the given frequency range.

The sampling Frequency.

Frequencies to compute Morlet wavelets for.

Number of cycles. Can be a fixed number (float) or one per frequency (array-like).

It controls the width of the wavelet ie its temporal resolution. If sigma is None the temporal resolution is adapted with the frequency like for all wavelet transform. The higher the frequency the shorter is the wavelet. If sigma is fixed the temporal resolution is fixed like for the short time Fourier transform and the number of oscillations increases with the frequency.

Make sure the wavelet has a mean of zero.

The wavelets time series. If freqs was a float, a single ndarray is returned instead of a list of ndarray.

The Morlet wavelets follow the formulation in Tallon-Baudry et al.[1].

Convolution of a signal with a Morlet wavelet will impose temporal smoothing that is determined by the duration of the wavelet. In MNE-Python, the duration of the wavelet is determined by the sigma parameter, which gives the standard deviation of the wavelet’s Gaussian envelope (our wavelets extend to ±5 standard deviations to ensure values very close to zero at the endpoints). Some authors (e.g., Cohen[2]) recommend specifying and reporting wavelet duration in terms of the full-width half-maximum (FWHM) of the wavelet’s Gaussian envelope. The FWHM is related to sigma by the following identity: \(\mathrm{FWHM} = \sigma \times 2 \sqrt{2 \ln{2}}\) (or the equivalent in Python code: fwhm = sigma * 2 * np.sqrt(2 * np.log(2))). If sigma is not provided, it is computed from n_cycles as \(\frac{\mathtt{n\_cycles}}{2 \pi f}\) where \(f\) is the frequency of the wavelet oscillation (given by freqs). Thus when sigma=None the FWHM will be given by

(cf. eq. 4 in [2]). To create wavelets with a chosen FWHM, one can compute:

to get an array of values for n_cycles that yield the desired FWHM at each frequency in freqs. If you want different FWHM values at each frequency, do the same computation with desired_fwhm as an array of the same shape as freqs.

Catherine Tallon-Baudry, Olivier Bertrand, Claude Delpuech, and Jacques Pernier. Oscillatory Gamma-Band (30–70 Hz) Activity Induced by a Visual Search Task in Humans. Journal of Neuroscience, pages 722–734, 1997. doi:10.1523/JNEUROSCI.17-02-00722.1997.

Michael X Cohen. A better way to define and describe Morlet wavelets for time-frequency analysis. NeuroImage, 199:81–86, 2019. doi:10.1016/j.neuroimage.2019.05.048.

Let’s show a simple example of the relationship between n_cycles and the FWHM using mne.time_frequency.fwhm():

mne.time_frequency.tfr.cwt

Connectivity Estimation

---

## mne.time_frequency.tfr_array_morlet#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.tfr_array_morlet.html

**Contents:**
- mne.time_frequency.tfr_array_morlet#
- Examples using mne.time_frequency.tfr_array_morlet#

Compute Time-Frequency Representation (TFR) using Morlet wavelets.

Same computation as tfr_morlet, but operates on NumPy arrays instead of Epochs objects.

Sampling frequency of the data.

The frequencies in Hz.

Number of cycles in the wavelet, either a fixed number or one per frequency. The number of cycles n_cycles and the frequencies of interest freqs define the temporal window length. See notes for additional information about the relationship between those arguments and about time and frequency smoothing.

If True, make sure the wavelets have a mean of zero. default False.

Changed in version 1.8: The default will change from zero_mean=False in 1.6 to True in 1.8.

Use the FFT for convolutions or not. default True.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

'complex' : single trial complex.

'power' : single trial power.

'phase' : single trial phase.

'avg_power' : average of single trial power.

'itc' : inter-trial coherence.

'avg_power_itc' : average of single trial power and inter-trial coherence across trials.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. The number of epochs to process at the same time. The parallelization is implemented across channels. Default 1.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Time frequency transform of data.

if output in ('complex', 'phase', 'power'), array of shape (n_epochs, n_chans, n_freqs, n_times)

else, array of shape (n_chans, n_freqs, n_times)

If output is 'avg_power_itc', the real values in out contain the average power and the imaginary values contain the ITC: \(out = power_{avg} + i * itc\).

The Morlet wavelets follow the formulation in Tallon-Baudry et al.[1].

In spectrotemporal analysis (as with traditional fourier methods), the temporal and spectral resolution are interrelated: longer temporal windows allow more precise frequency estimates; shorter temporal windows “smear” frequency estimates while providing more precise timing information.

Time-frequency representations are computed using a sliding temporal window. Either the temporal window has a fixed length independent of frequency, or the temporal window decreases in length with increased frequency.

Figure: Time and frequency smoothing. (a) For a fixed length temporal window the time and frequency smoothing remains fixed. (b) For temporal windows that decrease with frequency, the temporal smoothing decreases and the frequency smoothing increases with frequency. Source: FieldTrip tutorial: Time-frequency analysis using Hanning window, multitapers and wavelets.

In MNE-Python, the length of the Morlet wavelet is affected by the arguments freqs and n_cycles, which define the frequencies of interest and the number of cycles, respectively. For the time-frequency representation, the length of the wavelet is defined such that both tails of the wavelet extend five standard deviations from the midpoint of its Gaussian envelope and that there is a sample at time zero.

The length of the wavelet is thus \(10\times\mathtt{sfreq}\cdot\sigma-1\), which is equal to \(\frac{5}{\pi} \cdot \frac{\mathtt{n\_cycles} \cdot \mathtt{sfreq}}{\mathtt{freqs}} - 1\), where \(\sigma = \frac{\mathtt{n\_cycles}}{2\pi f}\) corresponds to the standard deviation of the wavelet’s Gaussian envelope. Note that the length of the wavelet must not exceed the length of your signal.

For more information on the Morlet wavelet, see mne.time_frequency.morlet().

Catherine Tallon-Baudry, Olivier Bertrand, Claude Delpuech, and Jacques Pernier. Oscillatory Gamma-Band (30–70 Hz) Activity Induced by a Visual Search Task in Humans. Journal of Neuroscience, pages 722–734, 1997. doi:10.1523/JNEUROSCI.17-02-00722.1997.

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

mne.time_frequency.psd_array_welch

mne.time_frequency.tfr_array_multitaper

---

## mne.time_frequency.tfr_array_stockwell#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.tfr_array_stockwell.html

**Contents:**
- mne.time_frequency.tfr_array_stockwell#

Compute power and intertrial coherence using Stockwell (S) transform.

Same computation as tfr_stockwell, but operates on NumPy arrays instead of Epochs objects.

See [1][2][3][4] for more information.

The signal to transform.

The sampling frequency.

The minimum frequency to include. If None defaults to the minimum fft frequency greater than zero.

The maximum frequency to include. If None defaults to the maximum fft.

The length of the windows used for FFT. If None, it defaults to the next power of 2 larger than the signal length.

The width of the Gaussian window. If < 1, increased temporal resolution, if > 1, increased frequency resolution. Defaults to 1. (classical S-Transform).

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

Return intertrial coherence (ITC) as well as averaged power.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The multitaper power of the Stockwell transformed data. The last two dimensions are frequency and time.

The intertrial coherence. Only returned if return_itc is True.

R. G. Stockwell. Why use the S-transform? In Luigi Rodino, Bert-Wolfgang Schulze, and M. W. Wong, editors, Pseudo-Differential Operators: Partial Differential Equations and Time-Frequency Analysis, number 52 in Fields Institute Communications, pages 279–309. American Mathematical Society, Providence, RI, 2007. doi:10.1090/fic/052.

Ali Moukadem, Zied Bouguila, Djaffar Ould Abdeslam, and Alain Dieterlen. Stockwell transform optimization applied on the detection of split in heart sounds. In Proceedings of EUSIPCO-2014, 2015–2019. Lisbon, 2014. IEEE. URL: https://ieeexplore.ieee.org/document/6952743.

Katherine L. Wheat, Piers L. Cornelissen, Stephen J. Frost, and Peter C. Hansen. During visual word recognition, phonology is accessed within 100 ms and may be mediated by a speech production code: evidence from magnetoencephalography. Journal of Neuroscience, 30(15):5229–5233, 2010. doi:10.1523/JNEUROSCI.4448-09.2010.

Kevin A. Jones, Bernice Porjesz, David Chorlian, Madhavi Rangaswamy, Chella Kamarajan, Ajayan Padmanabhapillai, Arthur Stimus, and Henri Begleiter. S-transform time-frequency analysis of P300 reveals deficits in individuals diagnosed with alcoholism. Clinical Neurophysiology, 117(10):2128–2143, 2006. doi:10.1016/j.clinph.2006.02.028.

mne.time_frequency.tfr_array_multitaper

mne.time_frequency.tfr.cwt

---

## mne.time_frequency.write_tfrs#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.write_tfrs.html

**Contents:**
- mne.time_frequency.write_tfrs#

Write a TFR dataset to hdf5.

The file name, which should end with -tfr.h5.

The (list of) TFR object(s) to save in one file. If tfr.comment is None, a sequential numeric string name will be generated on the fly, based on the order in which the TFR objects are passed. This can be used to selectively load single TFR objects from the file later.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.time_frequency.read_tfrs

mne.time_frequency.read_spectrum

---

## mne.transforms.angle_distance_between_rigid#

**URL:** https://mne.tools/stable/generated/mne.transforms.angle_distance_between_rigid.html

**Contents:**
- mne.transforms.angle_distance_between_rigid#

Compute the angle and distance between two rigid transforms.

First rigid transform.

Second rigid transform. If None, the identity transform is used.

Units for the angle output, either “rad” or “deg”.

Units for the distance output, either “m” or “mm”.

The angles between the two transforms.

The distances between the two transforms.

mne.transforms.Transform

mne.transforms.quat_to_rot

---

## mne.transforms.apply_volume_registration#

**URL:** https://mne.tools/stable/generated/mne.transforms.apply_volume_registration.html

**Contents:**
- mne.transforms.apply_volume_registration#

Apply volume registration.

Uses registration parameters computed by compute_volume_registration().

The image to morph (“from” volume).

The image to align with (“to” volume).

The affine that registers one volume to another.

The class that applies the the symmetric diffeomorphic registration (SDR) morph.

Interpolation to be used during the interpolation. Can be "linear" (default) or "nearest".

The constant value to assume exists outside the bounds of the moving image domain. Can be a string percentage like '1%' to use the given percentile of image data as the constant value.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The image after affine (and SDR, if provided) registration.

mne.scale_source_space

mne.transforms.apply_volume_registration_points

---

## mne.transforms.apply_volume_registration_points#

**URL:** https://mne.tools/stable/generated/mne.transforms.apply_volume_registration_points.html

**Contents:**
- mne.transforms.apply_volume_registration_points#

Apply volume registration.

Uses registration parameters computed by compute_volume_registration().

The mne.Info object with information about the sensors and methods of measurement.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation.

The image to morph (“from” volume).

The image to align with (“to” volume).

The affine that registers one volume to another.

The class that applies the the symmetric diffeomorphic registration (SDR) morph.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The mne.Info object with information about the sensors and methods of measurement.

The head->mri (surface RAS) transform for the static image.

mne.transforms.apply_volume_registration

mne.transforms.compute_volume_registration

---

## mne.transforms.compute_volume_registration#

**URL:** https://mne.tools/stable/generated/mne.transforms.compute_volume_registration.html

**Contents:**
- mne.transforms.compute_volume_registration#

Align two volumes using an affine and, optionally, SDR.

The image to morph (“from” volume).

The image to align with (“to” volume).

The volume registration steps to perform (a str for a single step, or tuple for a set of sequential steps). The following steps can be performed, and do so by matching mutual information between the images (unless otherwise noted):

Rigid-body, i.e., rotation and translation.

A full affine transformation, which includes translation, rotation, scaling, and shear.

Symmetric diffeomorphic registration [1], a non-linear similarity-matching algorithm.

The following string shortcuts can also be used:

All steps will be performed above in the order above, i.e., ('translation', 'rigid', 'affine', 'sdr').

The rigid steps (first two) will be performed, which registers the volume without distorting its underlying structure, i.e., ('translation', 'rigid'). This is useful for example when registering images from the same subject, such as CT and MR images.

The affine steps (first three) will be performed, i.e., omitting the SDR step.

The voxel size of volume for each spatial dimension in mm. If None (default), MRIs won’t be resliced (slow, but most accurate). Can be a tuple to provide separate zooms for each dimension (X/Y/Z), or a dict with keys ['translation', 'rigid', 'affine', 'sdr'] (each with values that are float`, tuple, or None) to provide separate reslicing/accuracy for the steps.

For each phase of the volume registration, niter is the number of iterations per successive stage of optimization. If a tuple is provided, it will be used for all steps (except center of mass, which does not iterate). It should have length 3 to correspond to sigmas=[3.0, 1.0, 0.0] and factors=[4, 2, 1] in the pipeline (see dipy.align.affine_registration for details). If a dictionary is provided, number of iterations can be set for each step as a key. Steps not in the dictionary will use the default value. The default (None) is equivalent to:

rigid=(100, 100, 10), affine=(100, 100, 10), sdr=(5, 5, 3))

The affine to initialize the registration with.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The affine that registers one volume to another.

The class that applies the the symmetric diffeomorphic registration (SDR) morph.

This function is heavily inspired by and extends dipy.align.affine_registration.

mne.transforms.apply_volume_registration_points

---

## mne.transforms.quat_to_rot#

**URL:** https://mne.tools/stable/generated/mne.transforms.quat_to_rot.html

**Contents:**
- mne.transforms.quat_to_rot#

Convert a set of quaternions to rotations.

The q1, q2, and q3 (x, y, z) parameters of a unit quaternion.

The corresponding rotation matrices.

mne.transforms.angle_distance_between_rigid

mne.transforms.rot_to_quat

---

## mne.transforms.read_ras_mni_t#

**URL:** https://mne.tools/stable/generated/mne.transforms.read_ras_mni_t.html

**Contents:**
- mne.transforms.read_ras_mni_t#
- Examples using mne.transforms.read_ras_mni_t#

Read a subject’s RAS to MNI transform.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The transform from RAS to MNI (in mm).

EEG source localization given electrode locations on an MRI

mne.transforms.rot_to_quat

---

## mne.transforms.rot_to_quat#

**URL:** https://mne.tools/stable/generated/mne.transforms.rot_to_quat.html

**Contents:**
- mne.transforms.rot_to_quat#

Convert a set of rotations to quaternions.

The rotation matrices to convert.

The q1, q2, and q3 (x, y, z) parameters of the corresponding unit quaternions.

mne.transforms.quat_to_rot

mne.transforms.read_ras_mni_t

---

## mne.transforms.Transform#

**URL:** https://mne.tools/stable/generated/mne.transforms.Transform.html

**Contents:**
- mne.transforms.Transform#

The starting coordinate frame. See notes for valid coordinate frames.

The ending coordinate frame. See notes for valid coordinate frames.

The transformation matrix. If None, an identity matrix will be used.

The “from” frame as a string.

The “to” frame as a string.

True if the dictionary has the specified key, else False.

Implement iter(self).

Make a copy of the transform.

fromkeys(iterable[, value])

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

save(fname, *[, overwrite, verbose])

Save the transform as -trans.fif file.

setdefault(key[, default])

Insert key with a value of default if key is not in the dictionary.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

Valid coordinate frames are 'meg', 'mri', 'mri_voxel', 'head', 'mri_tal', 'ras', 'fs_tal', 'ctf_head', 'ctf_meg', 'unknown'.

True if the dictionary has the specified key, else False.

Implement iter(self).

Make a copy of the transform.

The “from” frame as a string.

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

Pairs are returned in LIFO (last-in, first-out) order. Raises KeyError if the dict is empty.

Save the transform as -trans.fif file.

The name of the file, which should end in -trans.fif.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Insert key with a value of default if key is not in the dictionary.

Return the value for key if key is in the dictionary, else default.

The “to” frame as a string.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

mne.chpi.write_head_pos

mne.transforms.angle_distance_between_rigid

---

## mne.transform_surface_to#

**URL:** https://mne.tools/stable/generated/mne.transform_surface_to.html

**Contents:**
- mne.transform_surface_to#

Transform surface to the desired coordinate system.

Destination coordinate system. Can be an integer for using FIFF types.

Transformation to use (or a list of possible transformations to check).

If False (default), operate in-place.

Transformed source space.

mne.source_space.compute_distance_to_sensors

---

## mne.use_coil_def#

**URL:** https://mne.tools/stable/generated/mne.use_coil_def.html

**Contents:**
- mne.use_coil_def#
- Examples using mne.use_coil_def#

Use a custom coil definition file.

The filename of the coil definition file.

The context for using the coil definition.

This is meant to be used a context manager such as:

This allows using custom coil definitions with functions that require forward modeling.

Optically pumped magnetometer (OPM) data

Compute source power spectral density (PSD) of VectorView and OPM data

mne.surface.read_curvature

mne.bem.ConductorModel

---

## mne.use_log_level#

**URL:** https://mne.tools/stable/generated/mne.use_log_level.html

**Contents:**
- mne.use_log_level#
- Examples using mne.use_log_level#

Context manager for logging level.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

If int, enable (>=1) or disable (0) the printing of stack frame information using formatting. Default (None) does not change the formatting. This can add overhead so is meant only for debugging.

See the logging documentation for details.

Configuring MNE-Python

The Spectrum and EpochsSpectrum classes: frequency-domain data

---

## mne.utils.deprecated#

**URL:** https://mne.tools/stable/generated/mne.utils.deprecated.html

**Contents:**
- mne.utils.deprecated#

Mark a function, class, or method as deprecated (decorator).

Originally adapted from sklearn and http://wiki.python.org/moin/PythonDecoratorLibrary, then modified to make arguments populate properly following our verbose decorator methods based on decorator.

Extra information beyond just saying the class/function/method is deprecated. Should be a complete sentence (trailing period will be added automatically). Will be included in FutureWarning messages and in a sphinx warning box in the docstring.

---

## mne.utils.warn#

**URL:** https://mne.tools/stable/generated/mne.utils.warn.html

**Contents:**
- mne.utils.warn#

Emit a warning with trace outside the mne namespace.

This function takes arguments like warnings.warn, and sends messages using both warnings.warn and logger.warn. Warnings can be generated deep within nested function calls. In order to provide a more helpful warning, this function traverses the stack until it reaches a frame outside the mne namespace that caused the error.

The warning class. Defaults to RuntimeWarning.

The name of the module emitting the warning.

Namespaces to ignore when traversing the stack.

mne.cuda.get_cuda_memory

---

## mne.VectorSourceEstimate#

**URL:** https://mne.tools/stable/generated/mne.VectorSourceEstimate.html

**Contents:**
- mne.VectorSourceEstimate#
- Examples using mne.VectorSourceEstimate#

Container for vector surface source estimates.

For each vertex, the magnitude of the current is defined in the X, Y and Z directions.

The data in source space. Each dipole contains three vectors that denote the dipole strength in X, Y and Z directions over time.

Vertex numbers corresponding to the data. The first element of the list contains vertices of left hemisphere and the second element contains vertices of right hemisphere.

Time point of the first sample in data.

Time step between successive samples in data.

The FreeSurfer subject name. While not necessary, it is safer to set the subject parameter to avoid analysis errors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A timestamp for each sample.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

apply_baseline([baseline, verbose])

Baseline correct source estimate data.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of vertices.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

bin(width[, tstart, tstop, func])

Return a source estimate object with data summarized over time bins.

Return copy of source estimate instance.

crop([tmin, tmax, include_tmax])

Restrict SourceEstimate to a time interval.

Expand SourceEstimate to include more vertices.

extract_label_time_course(labels, src[, ...])

Extract label time courses for lists of labels.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_peak([hemi, tmin, tmax, mode, ...])

Get location and latency of peak amplitude.

Get a source estimate object restricted to a label.

Compute magnitude of activity without directionality.

Make a summary stc file with mean over time points.

plot([subject, hemi, colormap, time_label, ...])

Plot VectorSourceEstimate with PyVista.

project(directions[, src, use_cps])

Project the data for each vertex in a given direction.

resample(sfreq, *[, npad, method, window, ...])

save(fname[, ftype, overwrite, verbose])

Save the full source estimate to an HDF5 file.

save_as_surface(fname, src, *[, scale, scale_rr])

Save a surface source estimate (stc) as a GIFTI file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

Take the square root.

Make a summary stc file with sum over time points.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

to_original_src(src_orig[, subject_orig, ...])

Get a source estimate from morphed source to the original subject.

transform(func[, idx, tmin, tmax, copy])

Apply linear transform.

transform_data(func[, idx, tmin_idx, tmax_idx])

Get data after a linear (time) transform has been applied.

A container for surface source estimates.

A container for volume source estimates.

A container for mixed surface + volume source estimates.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

Baseline correct source estimate data.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each source individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire source estimate data.

Baseline correction is appropriate when signal and noise are approximately additive, and the noise level can be estimated from the baseline interval. This can be the case for non-normalized source activities (e.g. signed and unsigned MNE), but it is not the case for normalized estimates (e.g. signal-to-noise ratios, dSPM, sLORETA).

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected source estimate object.

Baseline correction can be done multiple times.

Apply a function to a subset of vertices.

The function fun is applied to the vertices defined in picks. The source estimate object’s data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to vertices in picks).

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) because it will apply vertex-wise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if vertice_wise=False as the workload is split across vertices.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The SourceEstimate object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‘auto’, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal “x_a(t)” of “x(t)” is:

where “F” is the Fourier transform, “U” the unit step function, and “y” the Hilbert transform of “x”. One usage of the analytic signal is the computation of the envelope signal, which is given by “e(t) = abs(x_a(t))”. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Return a source estimate object with data summarized over time bins.

Time bins of width seconds. This method is intended for visualization only. No filter is applied to the data before binning, making the method inappropriate as a tool for downsampling data.

Width of the individual bins in seconds.

Time point where the first bin starts. The default is the first time point of the stc.

Last possible time point contained in a bin (if the last bin would be shorter than width it is dropped). The default is the last time point of the stc.

Function that is applied to summarize the data. Needs to accept a numpy.array as first input and an axis keyword argument.

The binned source estimate.

Return copy of source estimate instance.

A copy of the source estimate.

Restrict SourceEstimate to a time interval.

The first time point in seconds. If None the first present is used.

The last time point in seconds. If None the last present is used.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The cropped source estimate.

Numpy array of source estimate data.

Expand SourceEstimate to include more vertices.

This will add rows to stc.data (zero-filled) and modify stc.vertices to include all vertices in stc.vertices and the input vertices.

New vertices to add. Can also contain old values.

The modified stc (note: method operates inplace).

Extract label time courses for lists of labels.

This function will extract one time course for each label. The way the time courses are extracted depends on the mode parameter.

If using a surface or mixed source space, this should be the Label’s for which to extract the time course. If working with whole-brain volume source estimates, this must be one of:

a string path to a FreeSurfer atlas for the subject (e.g., their ‘aparc.a2009s+aseg.mgz’) to extract time courses for all volumes in the atlas

a two-element list or tuple, the first element being a path to an atlas, and the second being a list or dict of volume_labels to extract (see mne.setup_volume_source_space() for details).

Changed in version 0.21.0: Support for volume source estimates.

The source spaces for the source time courses.

Extraction mode, see Notes.

False (default) will emit an error if there are labels that have no vertices in the source estimate. True and 'ignore' will return all-zero time courses for labels that do not have any vertices in the source estimate, and True will emit a warning while and “ignore” will just log a message.

Changed in version 0.21.0: Support for “ignore”.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Extracted time course for each label and source estimate.

Extract time courses for multiple STCs.

Valid values for mode are:

Maximum absolute value across vertices at each time point within each label.

Average across vertices at each time point within each label. Ignores orientation of sources for standard source estimates, which varies across the cortical surface, which can lead to cancellation. Vector source estimates are always in XYZ / RAS orientation, and are thus already geometrically aligned.

Finds the dominant direction of source space normal vector orientations within each label, applies a sign-flip to time series at vertices whose orientation is more than 90° different from the dominant direction, and then averages across vertices at each time point within each label.

Applies singular value decomposition to the time courses within each label, and uses the first right-singular vector as the representative label time course. This signal is scaled so that its power matches the average (per-vertex) power within the label, and sign-flipped by multiplying by np.sign(u @ flip), where u is the first left-singular vector and flip is the same sign-flip vector used when mode='mean_flip'. This sign-flip ensures that extracting time courses from the same label in similar STCs does not result in 180° direction/phase changes.

Uses 'mean_flip' when a standard source estimate is applied, and 'mean' when a vector source estimate is supplied.

No aggregation is performed, and an array of shape (n_vertices, n_times) is returned.

New in v0.21: Support for 'auto', vector, and volume source estimates.

The only modes that work for vector and volume source estimates are 'mean', 'max', and 'auto'.

Examples using extract_label_time_course:

Extracting the time series of activations in a label

Visualize source time courses (stcs)

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Get location and latency of peak amplitude.

The hemi to be considered. If None, the entire source space is considered.

The minimum point in time to be considered for peak getting.

The maximum point in time to be considered for peak getting.

How to deal with the sign of the data. If ‘pos’ only positive values will be considered. If ‘neg’ only negative values will be considered. If ‘abs’ absolute values will be considered. Defaults to ‘abs’.

Whether to return the vertex index (True) instead of of its ID (False, default).

Whether to return the time index (True) instead of the latency (False, default).

The vertex exhibiting the maximum response, either ID or index.

The time point of the maximum response, either latency in seconds or index.

Get a source estimate object restricted to a label.

SourceEstimate contains the time course of activation of all sources inside the label.

The label (as created for example by mne.read_label). If the label does not match any sources in the SourceEstimate, a ValueError is raised.

The source estimate restricted to the given label.

Examples using in_label:

Extracting the time series of activations in a label

Left hemisphere data.

Left hemisphere vertno.

Compute magnitude of activity without directionality.

The source estimate without directionality information.

Examples using magnitude:

Plotting the full vector-valued MNE solution

Make a summary stc file with mean over time points.

Plot VectorSourceEstimate with PyVista.

A “glass brain” is drawn and all dipoles defined in the source estimate are shown using arrows, depicting the direction and magnitude of the current moment at the dipole. Additionally, an overlay is plotted on top of the cortex with the magnitude of the current.

The FreeSurfer subject name. If None, stc.subject will be used.

The hemisphere to display.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255. This should be a sequential colormap.

Format of the time label (a format string, a function that maps floating point time values to strings, or None for no label). The default is 'auto', which will use time=%0.2f ms if there is more than one time point.

The amount of smoothing.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Alpha value to apply globally to the surface meshes. Defaults to 0.4.

Alpha value to apply globally to the overlay. Defaults to brain_alpha.

Alpha value to apply globally to the vector glyphs. Defaults to 1.

Scaling factor for the vector glyphs. By default, an attempt is made to automatically determine a sane value.

Display time viewer GUI. Can be “auto”, which is True for the PyVista backend and False otherwise.

Changed in version 0.20: Added “auto” option and default.

The path to the freesurfer subjects reconstructions. It corresponds to Freesurfer environment variable SUBJECTS_DIR.

If None, a new figure will be created. If multiple views or a split view is requested, this must be a list of the appropriate length. If int is provided it will be used to identify the PyVista figure by it’s id or create a new figure with the given id.

View to use. Using multiple views (list) is not supported for mpl backend. See Brain.show_view for valid string options.

If True, display colorbar on scene.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bound for colormap.

Unlike stc.plot, it cannot use pos_lims, as the surface plot must show the magnitude.

Specifies how binarized curvature values are rendered. either the name of a preset Brain cortex colorscheme (one of ‘classic’, ‘bone’, ‘low_contrast’, or ‘high_contrast’), or the name of a colormap, or a tuple with values (colormap, min, max, reverse) to fully specify the curvature colors.

The size of the window, in pixels. can be one number to specify a square window, or the (width, height) of a rectangular window.

Color of the background of the display window.

Color of the foreground of the display window. None will choose black or white based on the background color.

The time to display on the plot initially. None to display the first time sample (default).

Whether time is represented in seconds (“s”, default) or milliseconds (“ms”).

Title for the figure window. If None, the subject name will be used.

If True, enable interactive picking of a point on the surface of the brain and plot its time course. This feature is only available with the PyVista 3d backend, and requires time_viewer=True. Defaults to ‘auto’, which will use True if and only if time_viewer=True, the backend is PyVista, and there is more than one time point. If float (between zero and one), it specifies what proportion of the total window should be devoted to traces (True is equivalent to 0.25, i.e., it will occupy the bottom 1/4 of the figure).

The source space corresponding to the source estimate. Only necessary if the STC is a volume or mixed source estimate.

Options for volumetric source estimate plotting, with key/value pairs:

Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks better at the cost of speed. None (default) uses the volume source space resolution, which is often something like 7 or 5 mm, without resampling.

Can be “mip” (default) for maximum intensity projection or “composite” for composite blending using alpha values.

Alpha for the volumetric rendering. Defaults are 0.4 for vector source estimates and 1.0 for scalar source estimates.

Alpha for the surface enclosing the volume(s). None (default) will use half the volume alpha. Set to zero to avoid plotting the surface.

Alpha for a silhouette along the outside of the volume. None (default) will use 0.25 * surface_alpha.

The line width to use for the silhouette. Default is 2.

A float input (default 1.) or None will be used for the 'resolution' entry.

Can be “vertical” (default) or “horizontal”. When using “horizontal” mode, the PyVista backend must be used and hemi cannot be “split”.

Additional arguments to brain.add_data (e.g., dict(time_label_size=10)).

Additional arguments to the mne.viz.Brain constructor (e.g., dict(silhouette=True)).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A instance of mne.viz.Brain.

If the current magnitude overlay is not desired, set overlay_alpha=0 and smoothing_steps=1.

Plotting the full vector-valued MNE solution

Visualize source time courses (stcs)

Project the data for each vertex in a given direction.

Project onto the source space normals.

SVD will be used to project onto the direction of maximal power for each source.

Projection directions for each source.

The source spaces corresponding to the source estimate. Not used when directions is an array, optional when directions='pca'.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True). Should be the same value that was used when the forward model was computed (typically True).

The projected source estimate.

The directions that were computed (or just used).

When using SVD, there is a sign ambiguity for the direction of maximal power. When src is None, the direction is chosen that makes the resulting time waveform sum positive (i.e., have positive amplitudes). When src is provided, the directions are flipped in the direction of the source normals, i.e., outward from cortex for surface source spaces and in the +Z / superior direction for volume source spaces.

Examples using project:

Plotting the full vector-valued MNE solution

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be “auto” to use a padding that will result in a power-of-two size (can be much faster).

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn(). The default (“auto”) means 'reflect_limited' for method='fft' and 'reflect' for method='polyphase'.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled source estimate.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent – check your data!

Note that the sample rate of the original data is inferred from tstep.

Right hemisphere data.

Right hemisphere vertno.

Save the full source estimate to an HDF5 file.

The file name to write the source estimate to, should end in '-stc.h5'.

File format to use. Currently, the only allowed values is "h5".

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Save a surface source estimate (stc) as a GIFTI file.

Filename basename to save files as. Will write anatomical GIFTI plus time series GIFTI for both lh/rh, for example "basename" will write "basename.lh.gii", "basename.lh.time.gii", "basename.rh.gii", and "basename.rh.time.gii".

The source space of the forward solution.

Scale factor to apply to the data (functional) values.

Scale factor for the source vertex positions. The default (1e3) will scale from meters to millimeters, which is more standard for GIFTI files.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [1] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627–1639, 1964. doi:10.1021/ac60214a047.

Sample rate of the data.

Take the square root.

A copy of the SourceEstimate with sqrt(data).

Make a summary stc file with sum over time points.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

A timestamp for each sample.

Export data in tabular structure as a pandas DataFrame.

Vertices are converted to columns in the DataFrame. By default, an additional column “time” is added, unless index='time' (in which case time values form the DataFrame’s index).

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) — i.e., converts EEG to µV, magnetometers to fT, and gradiometers to fT/cm.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and vertex. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Get a source estimate from morphed source to the original subject.

The original source spaces that were morphed to the current subject.

The original subject. For most source spaces this shouldn’t need to be provided, since it is stored in the source space itself.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The transformed source estimate.

Apply linear transform.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first two dimensions of the transformed data should be (i) vertices and (ii) time. See Notes for details.

Indices of source time courses for which to compute transform. If None, all time courses are used.

First time point to include (ms). If None, self.tmin is used.

Last time point to include (ms). If None, self.tmax is used.

If True, return a new instance of SourceEstimate instead of modifying the input inplace.

The transformed stc or, in the case of transforms which yield N-dimensional output (where N > 2), a list of stcs. For a list, copy must be True.

Transforms which yield 3D output (e.g. time-frequency transforms) are valid, so long as the first two dimensions are vertices and time. In this case, the copy parameter must be True and a list of SourceEstimates, rather than a single instance of SourceEstimate, will be returned, one for each index of the 3rd dimension of the transformed data. In the case of transforms yielding 2D output (e.g. filtering), the user has the option of modifying the input inplace (copy = False) or returning a new instance of SourceEstimate (copy = True) with the transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

Get data after a linear (time) transform has been applied.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first return value is the transformed data, remaining outputs are ignored. The first dimension of the transformed data has to be the same as the first dimension of the input data.

Indicices of source time courses for which to compute transform. If None, all time courses are used.

Index of first time point to include. If None, the index of the first time point is used.

Index of the first time point not to include. If None, time points up to (and including) the last time point are included.

The transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

The change in time between two consecutive samples (1 / sfreq).

Extracting the time series of activations in a label

Plotting the full vector-valued MNE solution

Visualize source time courses (stcs)

mne.VolSourceEstimate

---

## mne.verbose#

**URL:** https://mne.tools/stable/generated/mne.verbose.html

**Contents:**
- mne.verbose#

Verbose decorator to allow functions to override log-level.

Function to be decorated by setting the verbosity level.

The decorated function.

This decorator is used to set the verbose level during a function or method call, such as mne.compute_covariance(). The verbose keyword argument can be ‘DEBUG’, ‘INFO’, ‘WARNING’, ‘ERROR’, ‘CRITICAL’, True (an alias for ‘INFO’), or False (an alias for ‘WARNING’). To set the global verbosity level for all functions, use mne.set_log_level().

This function also serves as a docstring filler.

You can use the verbose argument to set the verbose level on the fly:

---

## mne.vertex_to_mni#

**URL:** https://mne.tools/stable/generated/mne.vertex_to_mni.html

**Contents:**
- mne.vertex_to_mni#
- Examples using mne.vertex_to_mni#

Convert the array of vertices for a hemisphere to MNI coordinates.

Vertex number(s) to convert.

Hemisphere(s) the vertices belong to.

The FreeSurfer subject name.

Path to SUBJECTS_DIR if it is not set in the environment.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The MNI coordinates (in mm) of the vertices.

Extracting time course from source_estimate object

mne.transforms.compute_volume_registration

mne.coreg.Coregistration

---

## mne.viz.add_background_image#

**URL:** https://mne.tools/stable/generated/mne.viz.add_background_image.html

**Contents:**
- mne.viz.add_background_image#

Add a background image to a plot.

Adds the image specified in im to the figure fig. This is generally meant to be done with topo plots, though it could work for any plot.

This modifies the figure and/or axes in place.

The figure you wish to add a bg image to.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow. Defaults to None.

Set the aspect ratio of any axes in fig to the value in set_ratios. Defaults to None, which does nothing to axes.

Axes created corresponding to the image you added.

mne.viz.centers_to_edges

---

## mne.viz.Brain#

**URL:** https://mne.tools/stable/generated/mne.viz.Brain.html

**Contents:**
- mne.viz.Brain#
- Examples using mne.viz.Brain#

Class for visualizing a brain.

The API for this class is not currently complete. We suggest using mne.viz.plot_source_estimates() with the PyVista backend enabled to obtain a Brain instance.

Subject name in Freesurfer subjects dir.

Changed in version 1.2: This parameter was renamed from subject_id to subject.

Hemisphere id (ie ‘lh’, ‘rh’, ‘both’, or ‘split’). In the case of ‘both’, both hemispheres are shown in the same window. In the case of ‘split’ hemispheres are displayed side-by-side in different viewing panes.

FreeSurfer surface mesh name (ie ‘white’, ‘inflated’, etc.).

Title for the window.

Specifies how the cortical surface is rendered. Options:

'classic' (default), 'high_contrast', 'low_contrast', or 'bone'.

color, e.g. 'red' or (0.1, 0.4, 1.).

values for gyral (first) and sulcal (second). regions, e.g., ['red', 'blue'] or [(1, 0, 0), (0, 0, 1)].

values used to render the binarized curvature (where 0 is gyral, 1 is sulcal).

Changed in version 0.24: Add support for non-string arguments.

Alpha level to control opacity of the cortical surface.

The size of the window, in pixels. can be one number to specify a square window, or a length-2 sequence to specify (width, height).

The color definition of the background: (red, green, blue).

Color of the foreground (will be used for colorbars and text). None (default) will use black or white depending on the value of background.

If None (default), a new window will be created with the appropriate views.

If not None, this directory will be used as the subjects directory instead of the value set using the SUBJECTS_DIR environment variable.

View to use. Using multiple views (list) is not supported for mpl backend. See Brain.show_view for valid string options.

If True, shifts the right- or left-most x coordinate of the left and right surfaces, respectively, to be at zero. This is useful for viewing inflated surface where hemispheres typically overlap. Can be “auto” (default) use True with inflated surfaces and False otherwise (Default: ‘auto’). Only used when hemi='both'.

Changed in version 0.23: Default changed to “auto”.

Can be “trackball” (default) or “terrain”, i.e. a turntable-style camera.

Can be ‘m’ or ‘mm’ (default).

Can be “vertical” (default) or “horizontal”. When using “horizontal” mode, the PyVista backend must be used and hemi cannot be “split”.

As a dict, it contains the color, linewidth, alpha opacity and decimate (level of decimation between 0 and 1 or None) of the brain’s silhouette to display. If True, the default values are used and if False, no silhouette will be displayed. Defaults to False.

Can be “auto”, “light”, or “dark” or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_3D_OPTION_THEME will be used, defaulting to “auto” if it’s not found.

Display the window as soon as it is ready. Defaults to True.

A dictionary of PyVista surface objects for each hemisphere.

add_annotation(annot[, borders, alpha, ...])

Add an annotation file.

add_data(array[, fmin, fmid, fmax, thresh, ...])

Display data from a numpy array on the surface or volume.

add_dipole(dipole, trans[, colors, alpha, ...])

Add a quiver to render positions of dipoles.

add_foci(coords[, coords_as_verts, ...])

Add spherical foci, possibly mapping to displayed surf.

add_forward(fwd, trans[, alpha, scale])

Add a quiver to render positions of dipoles.

add_head([dense, color, alpha])

Add a mesh to render the outer head surface.

add_label(label[, color, alpha, ...])

Add an ROI label to the image.

add_sensors(info, trans[, meg, eeg, fnirs, ...])

Add mesh objects to represent sensor positions.

add_skull([outer, color, alpha])

Add a mesh to render the skull surface.

add_text(x, y, text[, name, color, opacity, ...])

Add a text to the visualization.

add_volume_labels([aseg, labels, colors, ...])

Add labels to the rendering from an anatomical segmentation.

Detect automatically fitting scaling parameters.

Clear the picking glyphs.

Close all figures and cleanup data structure.

Return the vertices of the picked points.

get_view([row, col, align])

Get the camera orientation for a given subplot display.

Display the help window.

plot_time_course(hemi, vertex_id, color[, ...])

Plot the vertex time course.

plot_time_line([update])

Add the time line to the MPL widget.

Remove all annotations from the image.

Remove rendered data from the mesh.

Remove dipole objects from the rendered scene.

Remove forward sources from the rendered scene.

Remove head objects from the rendered scene.

Remove all the ROI labels from the image.

remove_sensors([kind])

Remove sensors from the rendered scene.

Remove skull objects from the rendered scene.

Remove text from the rendered scene.

remove_volume_labels()

Remove the volume labels from the rendered scene.

Reset view, current time and time step.

restore_user_scaling()

Restore original scaling parameters.

save_image([filename, mode])

Save view from all panels to disk.

save_movie([filename, time_dilation, tmin, ...])

Save a movie (for data with a time axis).

screenshot([mode, time_viewer])

Generate a screenshot of current view.

set_data_smoothing(n_steps)

Set the number of smoothing steps.

set_playback_speed(speed)

Set the time playback speed.

Set the time to display (in seconds).

set_time_interpolation(interpolation)

Set the interpolation mode.

set_time_point(time_idx)

Set the time point to display (can be a float to interpolate).

setup_time_viewer([time_viewer, show_traces])

Configure the time viewer parameters.

show_view([view, roll, distance, row, col, ...])

Orient camera to display view.

toggle_interface([value])

Toggle the interface.

toggle_playback([value])

Toggle time playback.

update_lut([fmin, fmid, fmax, alpha])

Update the range of the color map.

The figure will publish and subscribe to the following UI events:

ColormapRange, kind="distributed_source_power"

This table shows the capabilities of each Brain backend (”✓” for full support, and “-” for partial support):

remove_volume_labels()

Add an annotation file.

Either path to annotation file or annotation name. Alternatively, the annotation can be specified as a (labels, ctab) tuple per hemisphere, i.e. annot=(labels, ctab) for a single hemisphere or annot=((lh_labels, lh_ctab), (rh_labels, rh_ctab)) for both hemispheres. labels and ctab should be arrays as returned by nibabel.freesurfer.io.read_annot().

Show only label borders. If int, specify the number of steps (away from the true border) along the cortical mesh to include as part of the border definition.

Alpha level to control opacity. Default is 1.

If None, it is assumed to belong to the hemisphere being shown. If two hemispheres are being shown, data must exist for both hemispheres.

If True (default), remove old annotations.

If used, show all annotations in the same (specified) color. Probably useful only when showing annotation borders.

Examples using add_annotation:

Plot a cortical parcellation

Working with sEEG data

FreeSurfer MRI reconstruction

Visualize source time courses (stcs)

Display data from a numpy array on the surface or volume.

This provides a similar interface to PySurfer, but it displays it with a single colormap. It offers more flexibility over the colormap, and provides a way to display four-dimensional data (i.e., a timecourse) or five-dimensional data (i.e., a vector-valued timecourse).

fmin sets the low end of the colormap, and is separate from thresh (this is a different convention from PySurfer).

Data array. For the data to be understood as vector-valued (3 values per vertex corresponding to X/Y/Z surface RAS), then array must be have all 3 dimensions. If vectors with no time dimension are desired, consider using a singleton (e.g., np.newaxis) to create a “time” dimension and pass time_label=None (vector values are not supported).

Minimum value in colormap (uses real fmin if None).

Intermediate value in colormap (fmid between fmin and fmax if None).

Maximum value in colormap (uses real max if None).

Not supported yet. If not None, values below thresh will not be visible.

If not None, center of a divergent colormap, changes the meaning of fmin, fmax and fmid.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Name of matplotlib colormap to use, a list of matplotlib colors, or a custom look up table (an n x 4 array coded with RBGA values between 0 and 255), the default “auto” chooses a default divergent colormap, if “center” is given (currently “icefire”), otherwise a default sequential colormap (currently “rocket”).

Alpha level to control opacity of the overlay.

Vertices for which the data is defined (needed if len(data) < nvtx).

Number of smoothing steps (smoothing is used if len(data) < nvtx) The value ‘nearest’ can be used too. None (default) will use as many as necessary to fill the surface.

Time points in the data array (if data is 2D or 3D).

Format of the time label (a format string, a function that maps floating point time values to strings, or None for no label). The default is 'auto', which will use time=%0.2f ms if there is more than one time point.

Whether to add a colorbar to the figure. Can also be a tuple to give the (row, col) index of where to put the colorbar.

If None, it is assumed to belong to the hemisphere being shown. If two hemispheres are being shown, an error will be thrown.

Not supported yet. Remove surface added by previous “add_data” call. Useful for conserving memory when displaying different data in a loop.

Font size of the time label (default 14).

Time initially shown in the plot. None to use the first time sample (default).

The scale factor to use when displaying glyphs for vector-valued data.

Alpha level to control opacity of the arrows. Only used for vector-valued data. If None (default), alpha is used.

Original clim arguments.

The source space corresponding to the source estimate. Only necessary if the STC is a volume or mixed source estimate.

Options for volumetric source estimate plotting, with key/value pairs:

Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks better at the cost of speed. None (default) uses the volume source space resolution, which is often something like 7 or 5 mm, without resampling.

Can be “mip” (default) for maximum intensity projection or “composite” for composite blending using alpha values.

Alpha for the volumetric rendering. Defaults are 0.4 for vector source estimates and 1.0 for scalar source estimates.

Alpha for the surface enclosing the volume(s). None (default) will use half the volume alpha. Set to zero to avoid plotting the surface.

Alpha for a silhouette along the outside of the volume. None (default) will use 0.25 * surface_alpha.

The line width to use for the silhouette. Default is 2.

A float input (default 1.) or None will be used for the 'resolution' entry.

Options to pass to pyvista.Plotter.add_scalar_bar (e.g., dict(title_font_size=10)).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

If the data is defined for a subset of vertices (specified by the “vertices” parameter), a smoothing method is used to interpolate the data onto the high resolution surface. If the data is defined for subsampled version of the surface, smoothing_steps can be set to None, in which case only as many smoothing steps are applied until the whole surface is filled with non-zeros.

Due to a VTK alpha rendering bug, vector_alpha is clamped to be strictly < 1.

Examples using add_data:

Plotting with mne.viz.Brain

Add a quiver to render positions of dipoles.

Dipole object containing position, orientation and amplitude of one or more dipoles or in the forward solution.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation.

A single color or list of anything matplotlib accepts: string, RGB, hex, etc. Default red.

Alpha level to control opacity. Default 1.

The size of the arrow representing the dipole in mne.viz.Brain units. Default 5mm.

The drawing mode for the dipole to render. Defaults to "arrow".

Examples using add_dipole:

Plotting with mne.viz.Brain

Add spherical foci, possibly mapping to displayed surf.

The foci spheres can be displayed at the coordinates given, or mapped through a surface geometry. In other words, coordinates from a volume-based analysis in MNI space can be displayed on an inflated average surface by finding the closest vertex on the white surface and mapping to that vertex on the inflated mesh.

Coordinates in stereotaxic space (default) or array of vertex ids (with coord_as_verts=True).

Whether the coords parameter should be interpreted as vertex ids.

Surface to project the coordinates to, or None to use raw coords. When set to a surface, each foci is positioned at the closest vertex in the mesh.

Controls the size of the foci spheres (relative to 1cm).

A list of anything matplotlib accepts: string, RGB, hex, etc.

Alpha level to control opacity. Default is 1.

Internal name to use.

If None, it is assumed to belong to the hemisphere being shown. If two hemispheres are being shown, an error will be thrown.

The resolution of the spheres.

Examples using add_foci:

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Plot point-spread functions (PSFs) for a volume

How MNE uses FreeSurfer’s outputs

The SourceEstimate data structure

Source localization with MNE, dSPM, sLORETA, and eLORETA

DICS for power mapping

Add a quiver to render positions of dipoles.

The forward solution. If present, the orientations of the dipoles present in the forward solution are displayed.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation.

Alpha level to control opacity. Default 1.

The size of the arrow representing the dipoles in mne.viz.Brain units. Default 1.5mm.

Add a mesh to render the outer head surface.

Whether to plot the dense head (seghead) or the less dense head (head).

A list of anything matplotlib accepts: string, RGB, hex, etc.

Alpha level to control opacity.

Examples using add_head:

Plotting with mne.viz.Brain

Working with sEEG data

Importing data from fNIRS devices

Add an ROI label to the image.

Label filepath or name. Can also be an instance of an object with attributes “hemi”, “vertices”, “name”, and optionally “color” and “values” (if scalar_thresh is not None).

Anything matplotlib accepts: string, RGB, hex, etc. (default “crimson”).

Alpha level to control opacity.

Threshold the label ids using this value in the label file’s scalar field (i.e. label only vertices with scalar >= thresh).

Show only label borders. If int, specify the number of steps (away from the true border) along the cortical mesh to include as part of the border definition.

If None, it is assumed to belong to the hemisphere being shown.

If a label is specified as name, subdir can be used to indicate that the label file is in a sub-directory of the subject’s label directory rather than in the label directory itself (e.g. for $SUBJECTS_DIR/$SUBJECT/label/aparc/lh.cuneus.label brain.add_label('cuneus', subdir='aparc')).

To remove previously added labels, run Brain.remove_labels().

Examples using add_label:

Generate a functional label from source estimates

Compute MxNE with time-frequency sparse prior

Compute Power Spectral Density of inverse solution from single epochs

Plotting with mne.viz.Brain

Plot a cortical parcellation

Add mesh objects to represent sensor positions.

The mne.Info object with information about the sensors and methods of measurement.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation.

Can be “helmet”, “sensors” or “ref” to show the MEG helmet, sensors or reference sensors respectively, or a combination like ('helmet', 'sensors') (same as None, default). True translates to ('helmet', 'sensors', 'ref'). Can also be a dict to specify alpha values, e.g. {"helmet": 0.1, "sensors": 0.8}.

Changed in version 1.6: Added support for specifying alpha values as a dict.

Shows EEG sensors using their digitized locations (after transformation to the chosen coord_frame)

The EEG locations projected onto the scalp, as is done in forward modeling

Can also be a list of these options, or a dict to specify the alpha values to use, e.g. dict(original=0.2, projected=0.8).

Changed in version 1.6: Added support for specifying alpha values as a dict.

Can be “channels”, “pairs”, “detectors”, and/or “sources” to show the fNIRS channel locations, optode locations, or line between source-detector pairs, or a combination like ('pairs', 'channels'). True translates to ('pairs',). A dict can also be used to specify alpha values (but only “channels” and “pairs” will be used), e.g. dict(channels=0.2, pairs=0.7).

Changed in version 1.6: Added support for specifying alpha values as a dict.

If True (default), show ECoG sensors.

If True (default), show sEEG electrodes.

If True (default), show DBS (deep brain stimulation) electrodes.

The maximum distance to project a sensor to the pial surface in meters. Sensors that are greater than this distance from the pial surface will not be assigned locations. Projections can be done to the inflated or flat brain.

Colors to use for the sensor glyphs. Can be None (default) to use default colors. A dict should provide the colors (values) for each channel type (keys), e.g.:

Where the value (eeg_colors above) can be broadcast to an array of colors with length that matches the number of channels of that type, i.e., is compatible with matplotlib.colors.to_rgba_array(). A few examples of this for the case above are the string "k", a list of n_eeg color strings, or an NumPy ndarray of shape (n_eeg, 3) or (n_eeg, 4).

Scale to use for the sensor glyphs. Can be None (default) to use default scale. A dict should provide the Scale (values) for each channel type (keys), e.g.:

Where the value (eeg_scales above) can be broadcast to an array of values with length that matches the number of channels of that type. A few examples of this for the case above are the value 10e-3, a list of n_eeg values, or an NumPy ndarray of shape (n_eeg,).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Examples using add_sensors:

Plotting with mne.viz.Brain

Working with sEEG data

Importing data from fNIRS devices

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Add a mesh to render the skull surface.

Adds the outer skull if True, otherwise adds the inner skull.

A list of anything matplotlib accepts: string, RGB, hex, etc.

Alpha level to control opacity.

Add a text to the visualization.

Name of the text (text label can be updated using update_text()).

Color of the text. Default is the foreground color set during initialization (default is black or white depending on the background color).

Opacity of the text (default 1.0).

Row index of which brain to use. Default is the top row.

Column index of which brain to use. Default is the left-most column.

The font size to use.

The text justification.

Examples using add_text:

Display sensitivity maps for EEG and MEG sensors

Morph surface source estimate

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Plot point-spread functions (PSFs) for a volume

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

The SourceEstimate data structure

Source localization with MNE, dSPM, sLORETA, and eLORETA

Computing various MNE solutions

Add labels to the rendering from an anatomical segmentation.

The anatomical segmentation file. Default auto uses aparc+aseg if available and wmparc if not. This may be any anatomical segmentation file in the mri subdirectory of the Freesurfer subject directory.

Changed in version 1.8: Added support for the new default 'auto'.

Labeled regions of interest to plot. See mne.get_montage_volume_labels() for one way to determine regions of interest. Regions can also be chosen from the FreeSurfer LUT.

A list of anything matplotlib accepts: string, RGB, hex, etc. (default FreeSurfer LUT colors).

Alpha level to control opacity.

The smoothing factor to be applied. Default 0 is no smoothing.

The size of holes to remove in the mesh in voxels. Default is None, no holes are removed. Warning, this dilates the boundaries of the surface by fill_hole_size number of voxels so use the minimal size.

Add a legend displaying the names of the labels. Default (None) is True if the number of labels is 10 or fewer. Can also be a dict of kwargs to pass to pyvista.Plotter.add_legend.

Examples using add_volume_labels:

Working with sEEG data

Visualize source time courses (stcs)

Detect automatically fitting scaling parameters.

Clear the picking glyphs.

Close all figures and cleanup data structure.

Examples using close:

Make figures more publication ready

Data used by time viewer and color bar widgets.

Return the vertices of the picked points.

The vertices picked by the time viewer, one key per hemisphere with a list of vertex indices.

Get the camera orientation for a given subplot display.

The row to use, default is the first one.

The column to check, the default is the first one.

If True, consider view arguments relative to canonical MRI directions (closest to MNI for the subject) rather than native MRI space. This helps when MRIs are not in standard orientation (e.g., have large rotations).

The roll of the camera rendering the view in degrees.

The distance from the camera rendering the view to the focalpoint in plot units (either m or mm). If “auto”, the bounds of visible objects will be used to set a reasonable distance.

Changed in version 1.6: None will no longer change the distance, use "auto" instead.

The azimuthal angle of the camera rendering the view in degrees.

The The zenith angle of the camera rendering the view in degrees.

The focal point of the camera rendering the view: (x, y, z) in plot units (either m or mm). When "auto", it is set to the center of mass of the visible bounds.

Display the help window.

The interaction style.

Plot the vertex time course.

The hemisphere id of the vertex.

The vertex identifier in the mesh.

The color of the time course.

Force an update of the plot. Defaults to True.

The time line object.

Add the time line to the MPL widget.

Force an update of the plot. Defaults to True.

Remove all annotations from the image.

Remove rendered data from the mesh.

Remove dipole objects from the rendered scene.

Remove forward sources from the rendered scene.

Remove head objects from the rendered scene.

Remove all the ROI labels from the image.

Remove sensors from the rendered scene.

If None, removes all sensor-related data including the helmet. Can be “meg”, “eeg”, “fnirs”, “ecog”, “seeg”, “dbs” or “helmet” to remove that item.

Remove skull objects from the rendered scene.

Remove text from the rendered scene.

Remove specific text by name. If None, all text will be removed.

Remove the volume labels from the rendered scene.

Reset view, current time and time step.

Restore original scaling parameters.

Save view from all panels to disk.

Path to new image file.

Either 'rgb' or 'rgba' for values to return.

Examples using save_image:

Repeated measures ANOVA on source data with spatio-temporal clustering

Save a movie (for data with a time axis).

The movie is created through the imageio module. The format is determined by the extension, and additional options can be specified through keyword arguments that depend on the format, see imageio’s format page.

This method assumes that time is specified in seconds when adding data. If time is specified in milliseconds this will result in movies 1000 times longer than expected.

Path at which to save the movie. The extension determines the format (e.g., '*.mov', '*.gif', …; see the imageio documentation for available formats).

Factor by which to stretch time (default 4). For example, an epoch from -100 to 600 ms lasts 700 ms. With time_dilation=4 this would result in a 2.8 s long movie.

First time point to include (default: all data).

Last time point to include (default: all data).

Framerate of the movie (frames per second, default 24).

Interpolation method (scipy.interpolate.interp1d parameter). Must be one of 'linear', 'nearest', 'zero', 'slinear', 'quadratic' or 'cubic'. If None, it uses the current brain.interpolation, which defaults to 'nearest'. Defaults to None.

A function to call on each iteration. Useful for status message updates. It will be passed keyword arguments frame and n_frames.

If True, include time viewer traces. Only used if time_viewer=True and separate_canvas=False.

Specify additional options for imageio.

Generate a screenshot of current view.

Either 'rgb' or 'rgba' for values to return.

If True, include time viewer traces. Only used if time_viewer=True and separate_canvas=False.

Examples using screenshot:

Plotting with mne.viz.Brain

Make figures more publication ready

Set the number of smoothing steps.

Number of smoothing steps.

Set the time playback speed.

The speed of the playback.

Set the time to display (in seconds).

The time to show, in seconds.

Examples using set_time:

Using the event system to link figures

Set the interpolation mode.

Interpolation method (scipy.interpolate.interp1d parameter). Must be one of 'linear', 'nearest', 'zero', 'slinear', 'quadratic' or 'cubic'.

Set the time point to display (can be a float to interpolate).

The time index to use. Can be a float to use interpolation between indices.

Configure the time viewer parameters.

If True, enable widgets interaction. Defaults to True.

If True, enable visualization of time traces. Defaults to True.

The keyboard shortcuts are the following:

‘?’: Display help window ‘i’: Toggle interface ‘s’: Apply auto-scaling ‘r’: Restore original clim ‘c’: Clear all traces ‘n’: Shift the time forward by the playback speed ‘b’: Shift the time backward by the playback speed ‘Space’: Start/Pause playback ‘Up’: Decrease camera elevation angle ‘Down’: Increase camera elevation angle ‘Left’: Decrease camera azimuth angle ‘Right’: Increase camera azimuth angle

Orient camera to display view.

The name of the view to show (e.g. “lateral”). Other arguments take precedence and modify the camera starting from the view. See Brain.show_view for valid string shortcut options.

The roll of the camera rendering the view in degrees.

The distance from the camera rendering the view to the focalpoint in plot units (either m or mm). If “auto”, the bounds of visible objects will be used to set a reasonable distance.

Changed in version 1.6: None will no longer change the distance, use "auto" instead.

The row to set. Default all rows.

The column to set. Default all columns.

Which hemi to use for view lookup (when in “both” mode).

If True, consider view arguments relative to canonical MRI directions (closest to MNI for the subject) rather than native MRI space. This helps when MRIs are not in standard orientation (e.g., have large rotations).

The azimuthal angle of the camera rendering the view in degrees.

The The zenith angle of the camera rendering the view in degrees.

The focal point of the camera rendering the view: (x, y, z) in plot units (either m or mm). When "auto", it is set to the center of mass of the visible bounds.

Force an update of the plot. Defaults to True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The builtin string views are the following perspectives, based on the RAS convention. If not otherwise noted, the view will have the top of the brain (superior, +Z) in 3D space shown upward in the 2D perspective:

From the left or right side such that the lateral (outside) surface of the given hemisphere is visible.

From the left or right side such that the medial (inside) surface of the given hemisphere is visible (at least when in split or single-hemi mode).

From above, with the front of the brain pointing up.

From below, with the front of the brain pointing up.

From the front and slightly lateral, with the brain slightly tilted forward (yielding a view from slightly above).

From the rear and slightly lateral, with the brain slightly tilted backward (yielding a view from slightly above).

From above with the brain pointing up (same as 'dorsal').

Three letter abbreviations (e.g., 'lat') of all of the above are also supported.

Examples using show_view:

Generate a functional label from source estimates

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Plotting with mne.viz.Brain

Working with sEEG data

How MNE uses FreeSurfer’s outputs

Visualize source time courses (stcs)

Importing data from fNIRS devices

Preprocessing functional near-infrared spectroscopy (fNIRS) data

DICS for power mapping

Repeated measures ANOVA on source data with spatio-temporal clustering

Using the event system to link figures

The interpolation mode.

Toggle the interface.

If True, the widgets are shown and if False, they are hidden. If None, the state of the widgets is toggled. Defaults to None.

Toggle time playback.

If True, automatic time playback is enabled and if False, it’s disabled. If None, the state of time playback is toggled. Defaults to None.

Update the range of the color map.

Minimum value in colormap (uses real fmin if None).

Intermediate value in colormap (fmid between fmin and fmax if None).

Maximum value in colormap (uses real max if None).

Alpha level to control opacity.

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Decoding source space data

Display sensitivity maps for EEG and MEG sensors

Use source space morphing

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Generate a functional label from source estimates

Compute MNE inverse solution on evoked data with a mixed source space

Compute source power estimate by projecting the covariance with MNE

Morph surface source estimate

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Plot point-spread functions (PSFs) for a volume

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Plotting the full vector-valued MNE solution

Simulate raw data using subject anatomy

Compute Power Spectral Density of inverse solution from single epochs

Compute source power spectral density (PSD) of VectorView and OPM data

Plotting with mne.viz.Brain

Plot a cortical parcellation

Working with sEEG data

FreeSurfer MRI reconstruction

How MNE uses FreeSurfer’s outputs

The SourceEstimate data structure

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Source reconstruction using an LCMV beamformer

Visualize source time courses (stcs)

EEG source localization given electrode locations on an MRI

Importing data from fNIRS devices

Working with CTF data: the Brainstorm auditory dataset

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Preprocessing optically pumped magnetometer (OPM) MEG data

Corrupt known signal with point spread

DICS for power mapping

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

Make figures more publication ready

Using the event system to link figures

mne.viz.ClickableImage

---

## mne.viz.centers_to_edges#

**URL:** https://mne.tools/stable/generated/mne.viz.centers_to_edges.html

**Contents:**
- mne.viz.centers_to_edges#

Convert center points to edges.

Each input array should be 1D monotonically increasing, and will be cast to float.

Given each input of shape (N,), the output will have shape (N+1,).

mne.viz.add_background_image

---

## mne.viz.circular_layout#

**URL:** https://mne.tools/stable/generated/mne.viz.circular_layout.html

**Contents:**
- mne.viz.circular_layout#
- Examples using mne.viz.circular_layout#

Create layout arranging nodes on a circle.

List with node names defining the order in which the nodes are arranged. Must have the elements as node_names but the order can be different. The nodes are arranged clockwise starting at “start_pos” degrees.

Angle in degrees that defines where the first node is plotted.

If True, the layout starts with the position between the nodes. This is the same as adding “180. / len(node_names)” to start_pos.

List of of boundaries between groups at which point a “group_sep” will be inserted. E.g. “[0, len(node_names) / 2]” will create two groups.

Group separation angle in degrees. See “group_boundaries”.

Node angles in degrees.

Visualize source leakage among labels using a circular graph

mne.viz.iter_topography

---

## mne.viz.ClickableImage#

**URL:** https://mne.tools/stable/generated/mne.viz.ClickableImage.html

**Contents:**
- mne.viz.ClickableImage#
- Examples using mne.viz.ClickableImage#

Display an image so you can click on it and store x/y positions.

Takes as input an image array (can be any array that works with imshow, but will work best with images. Displays the image and lets you click on it. Stores the xy coordinates of each click, so now you can superimpose something on top of it.

Upon clicking, the x/y coordinate of the cursor will be stored in self.coords, which is a list of (x, y) tuples.

The image that you wish to click on for 2-d points.

Keyword arguments. Passed to ax.imshow.

plot_clicks(**kwargs)

Plot the x/y positions stored in self.coords.

Turn coordinates into an MNE Layout object.

The matplotlib object that we use to get x/y position.

Plot the x/y positions stored in self.coords.

Arguments are passed to imshow in displaying the bg image.

Turn coordinates into an MNE Layout object.

Normalizes by the image you used to generate clicks

Arguments are passed to generate_2d_layout.

How to convert 3D electrode positions to a 2D image

---

## mne.viz.close_3d_figure#

**URL:** https://mne.tools/stable/generated/mne.viz.close_3d_figure.html

**Contents:**
- mne.viz.close_3d_figure#

Close the given scene.

The scene which needs to be closed.

mne.viz.create_3d_figure

mne.viz.close_all_3d_figures

---

## mne.viz.close_all_3d_figures#

**URL:** https://mne.tools/stable/generated/mne.viz.close_all_3d_figures.html

**Contents:**
- mne.viz.close_all_3d_figures#

Close all the scenes of the current 3d backend.

mne.viz.close_3d_figure

mne.viz.get_brain_class

---

## mne.viz.compare_fiff#

**URL:** https://mne.tools/stable/generated/mne.viz.compare_fiff.html

**Contents:**
- mne.viz.compare_fiff#

Compare the contents of two fiff files using diff and show_fiff.

First file to compare.

Second file to compare.

Filename to store the resulting diff. If None, a temporary file will be created.

If True, show the resulting diff in a new tab in a web browser.

How to indent the lines.

Max number of bytes of data to read from a tag. Can be np.inf to always read all data (helps test read completion).

Max number of characters of string representation to print for each tag’s data.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The filename used for storing the diff. Could be useful for when a temporary file is used.

mne.viz.centers_to_edges

mne.viz.circular_layout

---

## mne.viz.create_3d_figure#

**URL:** https://mne.tools/stable/generated/mne.viz.create_3d_figure.html

**Contents:**
- mne.viz.create_3d_figure#
- Examples using mne.viz.create_3d_figure#

Return an empty figure based on the current 3d backend.

Proceed with caution when the renderer object is returned (with scene=False) because the _Renderer API is not necessarily stable enough for production, it’s still actively in development.

The dimensions of the 3d figure (width, height).

The color of the background.

Whether to enable smooth shading. If None, uses the config value MNE_3D_OPTION_SMOOTH_SHADING. Defaults to None.

The figure identifier.

If True (default), the returned object is the Figure3D. If False, an advanced, undocumented Renderer object is returned (the API is not stable or documented, so this is not recommended).

If True, show the renderer immediately.

The window title to use (if applicable).

The requested empty figure or renderer, depending on scene.

Plot the MNE brain and helmet

The role of dipole orientations in distributed source localization

mne.viz.close_3d_figure

---

## mne.viz.eyetracking.plot_gaze#

**URL:** https://mne.tools/stable/generated/mne.viz.eyetracking.plot_gaze.html

**Contents:**
- mne.viz.eyetracking.plot_gaze#
- Examples using mne.viz.eyetracking.plot_gaze#

Plot a heatmap of eyetracking gaze data.

The Epochs object containing eyegaze channels.

An instance of Calibration with information about the screen size, distance, and resolution. If None, you must provide a width and height.

The width dimension of the plot canvas, only valid if eyegaze data are in pixels. For example, if the participant screen resolution was 1920x1080, then the width should be 1920.

The height dimension of the plot canvas, only valid if eyegaze data are in pixels. For example, if the participant screen resolution was 1920x1080, then the height should be 1080.

The amount of Gaussian smoothing applied to the heatmap data (standard deviation in pixels). If None, no smoothing is applied. Default is 25.

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is None, which will use the Matplotlib default colormap.

The opacity of the heatmap (default is 1).

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

The axes to plot into. If None, a new Figure will be created. Default is None.

Show the figure if True.

The resulting figure object for the heatmap plot.

Plotting eye-tracking heatmaps in MNE-Python

Working with eye tracker data in MNE-Python

mne.viz.use_browser_backend

mne.viz.ui_events.subscribe

---

## mne.viz.Figure3D#

**URL:** https://mne.tools/stable/generated/mne.viz.Figure3D.html

**Contents:**
- mne.viz.Figure3D#

Class that refers to a 3D figure.

This class should not be instantiated directly via mne.viz.Figure3D(...). Instead, use mne.viz.create_3d_figure().

The native 3D plotting widget.

The native 3D plotting widget.

The plotter. Useful for interacting with the native 3D library.

mne.viz.add_background_image

---

## mne.viz.get_3d_backend#

**URL:** https://mne.tools/stable/generated/mne.viz.get_3d_backend.html

**Contents:**
- mne.viz.get_3d_backend#

Return the 3D backend currently used.

The 3d backend currently in use. If no backend is found, returns None.

Changed in version 0.24: The 'pyvista' backend has been renamed 'pyvistaqt', so 'pyvista' is no longer returned by this function.

mne.viz.set_3d_backend

mne.viz.use_3d_backend

---

## mne.viz.get_brain_class#

**URL:** https://mne.tools/stable/generated/mne.viz.get_brain_class.html

**Contents:**
- mne.viz.get_brain_class#
- Examples using mne.viz.get_brain_class#

Return the proper Brain class based on the current 3d backend.

The Brain class corresponding to the current 3d backend.

Plot a cortical parcellation

FreeSurfer MRI reconstruction

mne.viz.close_all_3d_figures

mne.viz.set_browser_backend

---

## mne.viz.get_browser_backend#

**URL:** https://mne.tools/stable/generated/mne.viz.get_browser_backend.html

**Contents:**
- mne.viz.get_browser_backend#

Return the 2D backend currently used.

The 2D browser backend currently in use. If no backend is found, returns None.

mne.viz.set_browser_backend

mne.viz.use_browser_backend

---

## mne.viz.iter_topography#

**URL:** https://mne.tools/stable/generated/mne.viz.iter_topography.html

**Contents:**
- mne.viz.iter_topography#
- Examples using mne.viz.iter_topography#

Create iterator over channel positions.

This function returns a generator that unpacks into a series of matplotlib axis objects and data / channel indices, both corresponding to the sensor positions of the related layout passed or inferred from the channel info. Hence, this enables convenient topography plot customization.

The mne.Info object with information about the sensors and methods of measurement.

The layout to use. If None, layout will be guessed.

The callback function to be invoked on clicking one of the axes. Is supposed to instantiate the following API: function(axis, channel_index).

The figure object to be considered. If None, a new figure will be created.

The figure face color. Defaults to black.

The axis face color. Defaults to black.

The axis spine color. Defaults to black. In other words, the color of the axis’ edge lines.

Scaling factor for adjusting the relative size of the layout on the canvas. If None, nothing will be scaled.

If True, an additional axis is created in the bottom right corner that can be used to, e.g., construct a legend. The index of this axis will be -1.

Whether to enable the lasso-selection tool to enable the user to select channels. The selected channels will be available in fig.lasso.selection.

A generator that can be unpacked into:

The current axis of the topo plot.

The related channel index.

Plot custom topographies for MEG sensors

mne.viz.circular_layout

mne.viz.mne_analyze_colormap

---

## mne.viz.link_brains#

**URL:** https://mne.tools/stable/generated/mne.viz.link_brains.html

**Contents:**
- mne.viz.link_brains#

Plot multiple SourceEstimate objects with PyVista.

The collection of brains to plot.

If True, link the time controllers. Defaults to True.

If True, link the camera controls. Defaults to False.

If True, link the colorbar controllers. Defaults to True.

If True, link the vertices picked with the mouse. Defaults to False.

mne.viz.plot_source_estimates

mne.viz.plot_volume_source_estimates

---

## mne.viz.mne_analyze_colormap#

**URL:** https://mne.tools/stable/generated/mne.viz.mne_analyze_colormap.html

**Contents:**
- mne.viz.mne_analyze_colormap#

Return a colormap similar to that used by mne_analyze.

Bounds for the colormap, which will be mirrored across zero if length 3, or completely specified (and potentially asymmetric) if length 6.

Type of colormap to return. If ‘matplotlib’, will return a matplotlib.colors.LinearSegmentedColormap. If ‘vtk’, will return an RGBA array of shape (256, 4).

A teal->blue->gray->red->yellow colormap. See docstring of the ‘format’ argument for further details.

For this will return a colormap that will display correctly for data that are scaled by the plotting function to span [-fmax, fmax].

mne.viz.iter_topography

---

## mne.viz.plot_alignment#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_alignment.html

**Contents:**
- mne.viz.plot_alignment#
- Examples using mne.viz.plot_alignment#

Plot head, sensor, and source space alignment in 3D.

The mne.Info object with information about the sensors and methods of measurement. If None (default), no sensor information will be shown.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation. If trans is None, an identity matrix is assumed. “auto” will load trans from the FreeSurfer directory specified by subject and subjects_dir parameters.

Changed in version 0.19: Support for ‘fsaverage’ argument.

The FreeSurfer subject name. Can be omitted if src is provided.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Surfaces to plot. Supported values:

scalp: one of ‘head’, ‘outer_skin’ (alias for ‘head’), ‘head-dense’, or ‘seghead’ (alias for ‘head-dense’)

skull: ‘outer_skull’, ‘inner_skull’, ‘brain’ (alias for ‘inner_skull’)

brain: one of ‘pial’, ‘white’, ‘inflated’, or ‘brain’ (alias for ‘pial’).

Can be dict to specify alpha values for each surface. Use None to specify default value. Specified values must be between 0 and 1. for example:

Defaults to ‘auto’, which will look for a head surface and plot it if found.

For single layer BEMs it is recommended to use 'brain'.

The coordinate frame to use. If 'auto' (default), chooses 'mri' if trans was passed, and 'head' otherwise.

Changed in version 1.0: Defaults to 'auto'.

Can be “helmet”, “sensors” or “ref” to show the MEG helmet, sensors or reference sensors respectively, or a combination like ('helmet', 'sensors') (same as None, default). True translates to ('helmet', 'sensors', 'ref'). Can also be a dict to specify alpha values, e.g. {"helmet": 0.1, "sensors": 0.8}.

Changed in version 1.6: Added support for specifying alpha values as a dict.

Shows EEG sensors using their digitized locations (after transformation to the chosen coord_frame)

The EEG locations projected onto the scalp, as is done in forward modeling

Can also be a list of these options, or a dict to specify the alpha values to use, e.g. dict(original=0.2, projected=0.8).

Changed in version 1.6: Added support for specifying alpha values as a dict.

The forward solution. If present, the orientations of the dipoles present in the forward solution are displayed.

If True, plot the digitization points; ‘fiducials’ to plot fiducial points only.

If True (default), show ECoG sensors.

If not None, also plot the source space points.

Plot MRI fiducials (default False). If True, look for a file with the canonical name (bem/{subject}-fiducials.fif). If str, it can be 'estimated' to use mne.coreg.get_mni_fiducials(), otherwise it should provide the full path to the fiducials file.

New in v0.22: Support for 'estimated'.

Can be either the BEM surfaces (list of dict), a BEM solution or a sphere model. If None, we first try loading '$SUBJECTS_DIR/$SUBJECT/bem/$SUBJECT-$SOURCE.fif', and then look for '$SUBJECT*$SOURCE.fif' in the same directory. For 'outer_skin', the subjects bem and bem/flash folders are searched. Defaults to None.

If True (default), show sEEG electrodes.

Can be “channels”, “pairs”, “detectors”, and/or “sources” to show the fNIRS channel locations, optode locations, or line between source-detector pairs, or a combination like ('pairs', 'channels'). True translates to ('pairs',). A dict can also be used to specify alpha values (but only “channels” and “pairs” will be used), e.g. dict(channels=0.2, pairs=0.7).

Changed in version 1.6: Added support for specifying alpha values as a dict.

If True (default False), coordinate frame axis indicators will be shown:

MRI in gray (if trans is not None).

MEG in blue (if MEG sensors are present).

If True (default), show DBS (deep brain stimulation) electrodes.

PyVista scene in which to plot the alignment. If None, creates a new 600x600 pixel figure with black background.

How interactions with the scene via an input device (e.g., mouse or trackpad) modify the camera position. If 'terrain', one axis is fixed, enabling “turntable-style” rotations. If 'trackball', movement along all axes is possible, which provides more freedom of movement, but you may incidentally perform unintentional rotations along some axes.

Changed in version 1.0: Defaults to 'terrain'.

Colors to use for the sensor glyphs. Can be None (default) to use default colors. A dict should provide the colors (values) for each channel type (keys), e.g.:

Where the value (eeg_colors above) can be broadcast to an array of colors with length that matches the number of channels of that type, i.e., is compatible with matplotlib.colors.to_rgba_array(). A few examples of this for the case above are the string "k", a list of n_eeg color strings, or an NumPy ndarray of shape (n_eeg, 3) or (n_eeg, 4).

Changed in version 1.6: Support for passing a dict was added.

Scale to use for the sensor glyphs. Can be None (default) to use default scale. A dict should provide the Scale (values) for each channel type (keys), e.g.:

Where the value (eeg_scales above) can be broadcast to an array of values with length that matches the number of channels of that type. A few examples of this for the case above are the value 10e-3, a list of n_eeg values, or an NumPy ndarray of shape (n_eeg,).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

This function serves the purpose of checking the validity of the many different steps of source reconstruction:

Transform matrix (keywords trans, meg and mri_fiducials),

BEM surfaces (keywords bem and surfaces),

sphere conductor model (keywords bem and surfaces) and

source space (keywords surfaces and src).

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

Generate a left cerebellum volume source space

Reading an inverse operator

Annotate movement artifacts and reestimate dev_head_t

Compute source power spectral density (PSD) of VectorView and OPM data

How to convert 3D electrode positions to a 2D image

Plotting EEG sensors on the scalp

Plotting sensor layouts of MEG systems

Plot the MNE brain and helmet

Plotting sensor layouts of EEG systems

Working with sEEG data

Working with ECoG data

Source alignment and coordinate frames

Using an automated approach to coregistration

Head model and forward computation

EEG forward operator with a template MRI

Working with sensor locations

The role of dipole orientations in distributed source localization

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

Preprocessing optically pumped magnetometer (OPM) MEG data

mne.viz.snapshot_brain_montage

---

## mne.viz.plot_arrowmap#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_arrowmap.html

**Contents:**
- mne.viz.plot_arrowmap#
- Examples using mne.viz.plot_arrowmap#

Compute arrowmaps, based upon the Hosaka-Cohen transformation [1], these arrows represents an estimation of the current flow underneath the MEG sensors. They are a poor man’s MNE.

Since planar gradiometers takes gradients along latitude and longitude, they need to be projected to the flattened manifold span by magnetometer or radial gradiometers before taking the gradients in the 2D Cartesian coordinate system for visualization on the 2D topoplot. You can use the info_from and info_to parameters to interpolate from gradiometer data to magnetometer data.

The data values to plot.

The measurement info from data to interpolate from.

The measurement info to interpolate to. If None, it is assumed to be the same as info_from.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Colormap to use. If None, ‘Reds’ is used for all positive data, otherwise defaults to ‘RdBu_r’.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

The resolution of the topomap image (number of pixels along each side).

The axes to plot into. If None, a new Figure will be created. Default is None.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown. If True, a list of names must be provided (see names keyword).

Array indicating channel(s) to highlight with a distinct plotting style. Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Show the figure if True.

Handle for a function that is called when the user selects a set of channels by rectangle selection (matplotlib RectangleSelector). If None interactive selection is disabled. Defaults to None.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The Figure of the plot.

David Cohen and Hidehiro Hosaka. Part II magnetic field produced by a current dipole. Journal of Electrocardiology, 9(4):409–417, 1976. doi:10.1016/S0022-0736(76)80041-6.

Plotting topographic arrowmaps of evoked data

Visualizing Evoked data

mne.viz.snapshot_brain_montage

mne.viz.set_3d_backend

---

## mne.viz.plot_bem#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_bem.html

**Contents:**
- mne.viz.plot_bem#
- Examples using mne.viz.plot_bem#

Plot BEM contours on anatomical MRI slices.

The FreeSurfer subject name.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

‘coronal’ or ‘axial’ or ‘sagittal’.

The indices of the MRI slices to plot. If None, automatically pick 12 equally-spaced slices.

One or more brain surface to plot (optional). Entries should correspond to files in the subject’s surf directory (e.g. "white").

SourceSpaces instance or path to a source space to plot individual sources as scatter-plot. Sources will be shown on exactly one slice (whichever slice is closest to each source in the given orientation plane). Path can be absolute or relative to the subject’s bem folder.

Changed in version 0.20: All sources are shown on the nearest slice rather than some being omitted.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation. If trans is None, an identity matrix is assumed.

Show slice indices if True.

The name of the MRI to use. Can be a standard FreeSurfer MRI such as 'T1.mgz', or a full path to a custom MRI file.

Show the orientation (L/R, P/A, I/S) of the data slices. True (default) will only show it on the outside most edges of the figure, False will never show labels, and “always” will label each plot.

Changed in version 0.24: Added support for “always”.

Images are plotted in MRI voxel coordinates.

If src is not None, for a given slice index, all source points are shown that are halfway between the previous slice and the given slice, and halfway between the given slice and the next slice. For large slice decimations, this can make some source points appear outside the BEM contour, which is shown for the given slice index. For example, in the case where the single midpoint slice is used slices=[128], all source points will be shown on top of the midpoint MRI slice with the BEM boundary drawn for that slice.

Head model and forward computation

mne.viz.mne_analyze_colormap

mne.viz.plot_brain_colorbar

---

## mne.viz.plot_brain_colorbar#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_brain_colorbar.html

**Contents:**
- mne.viz.plot_brain_colorbar#
- Examples using mne.viz.plot_brain_colorbar#

Plot a colorbar that corresponds to a brain activation map.

The Axes to plot into.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bounds for colormap.

Lower, middle, and upper bound for colormap. Positive values will be mirrored directly across zero during colormap construction to obtain negative control points.

Only one of lims or pos_lims should be provided. Only sequential colormaps should be used with lims, and only divergent colormaps should be used with pos_lims.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Orientation of the colorbar, can be “vertical” or “horizontal”.

The color behind the colorbar (for alpha blending).

Make figures more publication ready

mne.viz.plot_bridged_electrodes

---

## mne.viz.plot_bridged_electrodes#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_bridged_electrodes.html

**Contents:**
- mne.viz.plot_bridged_electrodes#
- Examples using mne.viz.plot_bridged_electrodes#

Topoplot electrode distance matrix with bridged electrodes connected.

The mne.Info object with information about the sensors and methods of measurement.

The indices of channels marked as bridged with each bridged pair stored as a tuple. Can be generated via mne.preprocessing.compute_bridged_electrodes().

The electrical distance matrix for each pair of EEG electrodes. Can be generated via mne.preprocessing.compute_bridged_electrodes().

A title to add to the plot.

Arguments to pass to mne.viz.plot_topomap().

The topoplot figure handle.

Identify EEG Electrodes Bridged by too much Gel

mne.viz.plot_brain_colorbar

mne.viz.plot_chpi_snr

---

## mne.viz.plot_channel_labels_circle#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_channel_labels_circle.html

**Contents:**
- mne.viz.plot_channel_labels_circle#
- Examples using mne.viz.plot_channel_labels_circle#

Plot labels for each channel in a circle plot.

This primarily makes sense for sEEG channels where each channel can be assigned an anatomical label as the electrode passes through various brain areas.

Lists of labels (values) associated with each channel (keys).

The color (value) for each label (key).

The channels to consider.

Keyword arguments for mne_connectivity.viz.plot_connectivity_circle().

Working with sEEG data

mne.viz.plot_ch_adjacency

---

## mne.viz.plot_chpi_snr#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_chpi_snr.html

**Contents:**
- mne.viz.plot_chpi_snr#
- Examples using mne.viz.plot_chpi_snr#

Plot time-varying SNR estimates of the HPI coils.

The dictionary returned by compute_chpi_snr. Must have keys times, freqs, TYPE_snr, TYPE_power, and TYPE_resid (where TYPE can be mag or grad or both).

Figure axes in which to draw the SNR, power, and residual plots. The number of axes should be 3× the number of MEG sensor types present in snr_dict. If None (the default), a new Figure is created with the required number of axes.

A figure with subplots for SNR, power, and residual variance, separately for magnetometers and/or gradiometers (depending on what is present in snr_dict).

If you supply a list of existing Axes, then the figure legend will not be drawn automatically. If you still want it, running fig.legend(loc='right', title='cHPI frequencies') will recreate it.

Extracting and visualizing subject head movement

mne.viz.plot_bridged_electrodes

---

## mne.viz.plot_ch_adjacency#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_ch_adjacency.html

**Contents:**
- mne.viz.plot_ch_adjacency#
- Examples using mne.viz.plot_ch_adjacency#

Plot channel adjacency.

Info object with channel locations.

Array of channels x channels shape. Defines which channels are adjacent to each other. Note that if you edit adjacencies (via edit=True), this array will be modified in place.

Names of successive channels in the adjacency matrix.

How to plot the adjacency. Can be either '3d' or '2d'.

Whether to allow interactive editing of the adjacency matrix via clicking respective channel pairs. Once clicked, the channel is “activated” and turns green. Clicking on another channel adds or removes adjacency relation between the activated and newly clicked channel (depending on whether the channels are already adjacent or not); the newly clicked channel now becomes activated. Clicking on an activated channel deactivates it. Editing is currently only supported for kind='2d'.

The Figure instance where the channel adjacency is plotted.

Spatiotemporal permutation F-test on full sensor data

mne.viz.plot_channel_labels_circle

---

## mne.viz.plot_cov#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_cov.html

**Contents:**
- mne.viz.plot_cov#
- Examples using mne.viz.plot_cov#

Plot Covariance data.

The covariance matrix.

The mne.Info object with information about the sensors and methods of measurement.

List of channels to exclude. If empty do not exclude any channel. If ‘bads’, exclude info[‘bads’].

Show colorbar or not.

Apply projections or not.

Plot also singular values of the noise covariance for each sensor type. We show square roots ie. standard deviations.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The SVD plot of the covariance (i.e., the eigenvalues or “matrix spectrum”).

For each channel type, the rank is estimated using mne.compute_rank().

Changed in version 0.19: Approximate ranks for each channel type are shown with red dashed lines.

Kernel OPM phantom data

Compute source power estimate by projecting the covariance with MNE

Source localization with MNE, dSPM, sLORETA, and eLORETA

mne.viz.plot_chpi_snr

mne.viz.plot_channel_labels_circle

---

## mne.viz.plot_csd#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_csd.html

**Contents:**
- mne.viz.plot_csd#

A sub-plot is created for each frequency. If an info object is passed to the function, different channel types are plotted in different figures.

The CSD matrix to plot.

The mne.Info object with information about the sensors and methods of measurement. Used to split the figure by channel-type, if provided. By default, the CSD matrix is plotted as a whole.

Whether to plot the cross-spectral density (‘csd’, the default), or the coherence (‘coh’) between the channels.

Whether to show a colorbar. Defaults to True.

The matplotlib colormap to use. Defaults to None, which means the colormap will default to matplotlib’s default.

CSD matrices are plotted in a grid. This parameter controls how many matrix to plot side by side before starting a new row. By default, a number will be chosen to make the grid as square as possible.

Whether to show the figure. Defaults to True.

The figures created by this function.

mne.viz.plot_ch_adjacency

mne.viz.plot_dipole_amplitudes

---

## mne.viz.plot_dipole_amplitudes#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_dipole_amplitudes.html

**Contents:**
- mne.viz.plot_dipole_amplitudes#
- Examples using mne.viz.plot_dipole_amplitudes#

Plot the amplitude traces of a set of dipoles.

The dipoles whose amplitudes should be shown.

Color to plot with each dipole. If None default colors are used.

The figure object containing the plot.

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute Rap-Music on evoked data

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

mne.viz.plot_dipole_locations

---

## mne.viz.plot_dipole_locations#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_dipole_locations.html

**Contents:**
- mne.viz.plot_dipole_locations#
- Examples using mne.viz.plot_dipole_locations#

Plot dipole locations.

If mode is set to ‘arrow’ or ‘sphere’, only the location of the first time point of each dipole is shown else use the show_all parameter.

The mri to head trans. Can be None with mode set to ‘3d’.

The FreeSurfer subject name (will be used to set the FreeSurfer environment variable SUBJECT). Can be None with mode set to '3d'.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Plot in 3D mode using PyVista with the given glyph type.

Plot in matplotlib Axes3D using matplotlib with MRI slices shown on the sides of a cube, with the dipole(s) shown as arrows extending outward from a dot (i.e., the arrows pivot on the tail).

Plot in matplotlib Axes using a quiver of arrows for the dipoles in three axes (axial, coronal, and sagittal views), with the arrow pivoting in the middle of the arrow.

Changed in version 1.1: Added support for 'outlines'.

Coordinate frame to use: ‘head’ or ‘mri’. Can also be ‘mri_rotated’ when mode equals 'outlines'. Defaults to ‘mri’.

Changed in version 1.1: Added support for 'mri_rotated'.

Index of the initially plotted dipole. Can also be ‘gof’ to plot the dipole with highest goodness of fit value or ‘amplitude’ to plot the dipole with the highest amplitude. The dipoles can also be browsed through using up/down arrow keys or mouse scroll. Defaults to ‘gof’. Only used if mode equals ‘orthoview’.

Whether to always plot all the dipoles. If True (default), the active dipole is plotted as a red dot and its location determines the shown MRI slices. The non-active dipoles are plotted as small blue dots. If False, only the active dipole is plotted. Only used if mode='orthoview'.

Axes to plot into. If None (default), axes will be created. If mode equals 'orthoview', must be a single Axes3D. If mode equals 'outlines', must be a list of three Axes.

Whether to halt program execution until the figure is closed. Defaults to False. Only used if mode equals ‘orthoview’.

Show figure if True. Defaults to True. Only used if mode equals ‘orthoview’.

The scale (size in meters) of the dipoles if mode is not 'orthoview'. The default is 0.03 when mode is 'outlines' and 0.005 otherwise.

The color of the dipoles. The default (None) will use 'y' if mode is 'orthoview' and show_all is True, else ‘r’. Can also be a list of colors to use when mode is 'outlines'.

Changed in version 0.19.0: Color is now passed in orthoview mode.

The highlight color. Only used in orthoview mode with show_all=True.

3D figure in which to plot the alignment. If None, creates a new 600x600 pixel figure with black background. Only used when mode is 'arrow' or 'sphere'.

The title of the figure if mode='orthoview' (ignored for all other modes). If None, dipole number and its properties (amplitude, orientation etc.) will be shown. Defaults to None.

Head source(s) to use. See the source option of mne.get_head_surf() for more information. Only used when mode equals 'outlines'.

Brain surface to show outlines for, can be 'white', 'pial', or None. Only used when mode is 'outlines'.

Width of the matplotlib quiver arrow, see matplotlib.axes.Axes.quiver(). If None (default), when mode is 'outlines' 0.015 will be used, and when mode is 'orthoview' the matplotlib default is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The PyVista figure or matplotlib Figure.

Kernel OPM phantom data

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute Rap-Music on evoked data

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

The role of dipole orientations in distributed source localization

Brainstorm Elekta phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

mne.viz.plot_dipole_amplitudes

mne.viz.plot_drop_log

---

## mne.viz.plot_drop_log#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_drop_log.html

**Contents:**
- mne.viz.plot_drop_log#

Show the channel stats based on a drop_log from Epochs.

Epoch drop log from Epochs.drop_log.

The percentage threshold to use to decide whether or not to plot. Default is zero (always plot).

Maximum number of channels to show stats for.

The subject name to use in the title of the plot. If None, do not display a subject name.

Changed in version 0.23: Added support for None.

Changed in version 1.0: Defaults to None.

Color to use for the bars.

The drop reasons to ignore.

mne.viz.plot_dipole_locations

---

## mne.viz.plot_events#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_events.html

**Contents:**
- mne.viz.plot_events#
- Examples using mne.viz.plot_events#

Plot events to get a visual display of the paradigm.

The identity and timing of experimental events, around which the epochs were created. See events for more information.

The sample frequency. If None, data will be displayed in samples (not seconds).

The index of the first sample. Recordings made on Neuromag systems number samples relative to the system start (not relative to the beginning of the recording). In such cases the raw.first_samp attribute can be passed here. Default is 0.

Dictionary of event_id integers as keys and colors as values. If None, colors are automatically drawn from a default list (cycled through if number of events longer than list of default colors). Color can be any valid matplotlib color.

Dictionary of event labels (e.g. ‘aud_l’) as keys and their associated event_id values. Labels are used to plot a legend. If None, no legend is drawn.

Use equal spacing between events in y-axis.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when event numbers from event_id are missing from events. When numbers from events are missing from event_id they will be ignored and a warning emitted; consider using verbose='error' in this case.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure object containing the plot.

Single trial linear regression analysis with the LIMO dataset

Automated epochs metadata generation with variable time windows

Sleep stage classification from polysomnography (PSG) data

Overview of MEG/EEG analysis with MNE-Python

Preprocessing functional near-infrared spectroscopy (fNIRS) data

mne.viz.plot_epochs_psd_topomap

---

## mne.viz.plot_filter#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_filter.html

**Contents:**
- mne.viz.plot_filter#
- Examples using mne.viz.plot_filter#

Plot properties of a filter.

An IIR dict or 1D ndarray of coefficients (for FIR filter).

Sample rate of the data (Hz).

The ideal response frequencies to plot (must be in ascending order). If None (default), do not plot the ideal response.

The ideal response gains to plot. If None (default), do not plot the ideal response.

The title to use. If None (default), determine the title based on the type of the system.

The color to use (default ‘#1f77b4’).

If not None, the x-axis frequency limits (Hz) to use. If None, freq will be used. If None (default) and freq is None, (0.1, sfreq / 2.) will be used.

Frequency scaling to use, can be “log” (default) or “linear”.

The y-axis amplitude limits (dB) to use (default: (-60, 10)).

Show figure if True (default).

If True, compensate for the filter delay (phase will not be shown).

For linear-phase FIR filters, this visualizes the filter coefficients assuming that the output will be shifted by N // 2.

For IIR filters, this changes the filter coefficient display by filtering backward and forward, and the frequency response by squaring it.

A list of the requested plots from time, magnitude and delay. Default is to plot all three filter properties (‘time’, ‘magnitude’, ‘delay’).

The axes to plot to. If list, the list must be a list of Axes of the same length as the number of requested plot types. If instance of Axes, there must be only one filter property plotted. Defaults to None.

The y-axis delay limits (s) to use (default: (-tmax / 2., tmax / 2.)).

The figure containing the plots.

Background information on filtering

Filtering and resampling data

mne.viz.plot_evoked_white

mne.viz.plot_head_positions

---

## mne.viz.plot_head_positions#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_head_positions.html

**Contents:**
- mne.viz.plot_head_positions#
- Examples using mne.viz.plot_head_positions#

The head position data. Can also be a list to treat as a concatenation of runs.

Can be ‘traces’ (default) to show position and quaternion traces, or ‘field’ to show the position as a vector field over time.

Colormap to use for the trace plot, default is “viridis”.

Can be any combination of “x”, “y”, or “z” (default: “z”) to show directional axes in “field” mode.

Show figure if True. Defaults to True.

The destination location for the head. See mne.preprocessing.maxwell_filter() for details.

The mne.Info object with information about the sensors and methods of measurement. If provided, will be used to show the destination position when destination is None, and for showing the MEG sensors.

The color to use for lines in mode == 'traces' and quiver arrows in mode == 'field'.

The matplotlib axes to use.

Changed in version 1.8: Added support for making use of this argument when mode="field".

If True and in traces mode, show the total distance and angle in a fourth row.

Maxwell filter data with movement compensation

Annotate movement artifacts and reestimate dev_head_t

Extracting and visualizing subject head movement

Signal-space separation (SSS) and Maxwell filtering

mne.viz.plot_ideal_filter

---

## mne.viz.plot_ica_components#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_ica_components.html

**Contents:**
- mne.viz.plot_ica_components#

Project mixing matrix on interpolated sensor topography.

Indices of the independent components (ICs) to visualize. If an integer, represents the index of the IC to pick. Multiple ICs can be selected using a list of int or a slice. The indices are 0-indexed, so picks=1 will pick the second IC: ICA001. None will pick all independent components in the order fitted.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

To be able to see component properties after clicking on component topomap you need to pass relevant data - instances of Raw or Epochs (for example the data that ICA was trained on). This takes effect only when running matplotlib in interactive mode.

Whether to plot standard deviation in ERP/ERF and spectrum plots. Defaults to True, which plots one standard deviation above/below. If set to float allows to control how many standard deviations are plotted. For example 2.5 will plot 2.5 standard deviation above/below.

Allows to specify rejection parameters used to drop epochs (or segments if continuous signal is passed as inst). If None, no rejection is applied. The default is ‘auto’, which applies the rejection parameters used when fitting the ICA object.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The subplot(s) to plot to. Either a single Axes or an iterable of Axes if more than one subplot is needed. The number of subplots must match the number of selected components. If None, new figures will be created with the number of subplots per figure controlled by nrows and ncols.

The title of the generated figure. If None (default) and axes=None, a default title of “ICA Components” will be used.

The number of rows and columns of topographies to plot. If both nrows and ncols are 'auto', will plot up to 20 components in a 5×4 grid, and return multiple figures if more than 20 components are requested. If one is 'auto' and the other a scalar, a single figure is generated. If scalars are provided for both arguments, will plot up to nrows*ncols components in a grid and return multiple figures as needed. Default is nrows='auto', ncols='auto'.

Show the figure if True.

Dictionary of arguments to pass to plot_epochs_image() in interactive mode. Ignored if inst is not supplied. If None, nothing is passed. Defaults to None.

Dictionary of arguments to pass to compute_psd() in interactive mode. Ignored if inst is not supplied. If None, nothing is passed. Defaults to None.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure object(s).

When run in interactive mode, plot_ica_components allows to reject components by clicking on their title label. The state of each component is indicated by its label color (gray: rejected; black: retained). It is also possible to open component properties by clicking on the component topomap (this option is only available when the inst argument is supplied).

mne.viz.plot_ica_sources

mne.viz.plot_ica_properties

---

## mne.viz.plot_ica_overlay#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_ica_overlay.html

**Contents:**
- mne.viz.plot_ica_overlay#

Overlay of raw and cleaned signals given the unmixing matrix.

This method helps visualizing signal quality and artifact rejection.

The signal to plot. If Raw, the raw data per channel type is displayed before and after cleaning. A second panel with the RMS for MEG sensors and the GFP for EEG sensors is displayed. If Evoked, butterfly traces for signals before and after cleaning will be superimposed.

The components marked for exclusion. If None (default), the components listed in ICA.exclude will be used.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels that were included during fitting.

The first and last time point (in seconds) of the data to plot. If inst is a Raw object, start=None and stop=None will be translated into start=0. and stop=3., respectively. For Evoked, None refers to the beginning and end of the evoked signal.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

The number of PCA components to be kept, either absolute (int) or fraction of the explained variance (float). If None (default), the ica.n_pca_components from initialization will be used in 0.22; in 0.23 all components will be used.

How to handle baseline-corrected epochs or evoked data. Can be 'raise' to raise an error, 'warn' (default) to emit a warning, 'ignore' to ignore, or “reapply” to reapply the baseline after applying ICA.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.viz.plot_ica_scores

mne.viz.plot_epochs_image

---

## mne.viz.plot_ica_properties#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_ica_properties.html

**Contents:**
- mne.viz.plot_ica_properties#

Display component properties.

Properties include the topography, epochs image, ERP/ERF, power spectrum, and epoch variance.

The data to use in plotting properties.

You can interactively cycle through topographic maps for different channel types by pressing T.

Indices of the independent components (ICs) to visualize. If an integer, represents the index of the IC to pick. Multiple ICs can be selected using a list of int or a slice. The indices are 0-indexed, so picks=1 will pick the second IC: ICA001. None will pick the first 5 components.

List of five matplotlib axes to use in plotting: [topomap_axis, image_axis, erp_axis, spectrum_axis, variance_axis]. If None a new figure with relevant axes is created. Defaults to None.

Whether to plot spectrum in dB. Defaults to True.

Whether to plot standard deviation/confidence intervals in ERP/ERF and spectrum plots. Defaults to True, which plots one standard deviation above/below for the spectrum. If set to float allows to control how many standard deviations are plotted for the spectrum. For example 2.5 will plot 2.5 standard deviation above/below. For the ERP/ERF, by default, plot the 95 percent parametric confidence interval is calculated. To change this, use ci in ts_args in image_args (see below).

Whether to use a logarithmic frequency axis to plot the spectrum. Defaults to False.

You can interactively toggle this setting by pressing L.

Dictionary of arguments to plot_topomap. If None, doesn’t pass any additional arguments. Defaults to None.

Dictionary of arguments to plot_epochs_image. If None, doesn’t pass any additional arguments. Defaults to None.

Dictionary of arguments to compute_psd(). If None, doesn’t pass any additional arguments. Defaults to None.

Allows to control size of the figure. If None, the figure size defaults to [7., 6.].

Allows to specify rejection parameters used to drop epochs (or segments if continuous signal is passed as inst). If None, no rejection is applied. The default is ‘auto’, which applies the rejection parameters used when fitting the ICA object.

Whether to omit bad segments from the data before fitting. If True (default), annotated segments whose description begins with 'bad' are omitted. If False, no rejection based on annotations is performed.

Has no effect if inst is not a mne.io.Raw object.

Can be “power” for power spectral density (PSD; default), “amplitude” for amplitude spectrum density (ASD).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of matplotlib figures.

mne.viz.plot_ica_components

mne.viz.plot_ica_scores

---

## mne.viz.plot_ica_scores#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_ica_scores.html

**Contents:**
- mne.viz.plot_ica_scores#

Plot scores related to detected components.

Use this function to asses how well your score describes outlier sources and how well you were detecting them.

Scores based on arbitrary metric to characterize ICA components.

The components marked for exclusion. If None (default), ICA.exclude will be used.

The labels to consider for the axes tests. Defaults to None. If list, should match the outer shape of scores. If ‘ecg’ or ‘eog’, the labels_ attributes will be looked up. Note that ‘/’ is used internally for sublabels specifying ECG and EOG channels.

Draw horizontal line to e.g. visualize rejection threshold.

The figure size. If None it gets set automatically.

Scores are plotted in a grid. This parameter controls how many to plot side by side before starting a new row. By default, a number will be chosen to make the grid as square as possible.

mne.viz.plot_ica_properties

mne.viz.plot_ica_overlay

---

## mne.viz.plot_ideal_filter#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_ideal_filter.html

**Contents:**
- mne.viz.plot_ideal_filter#
- Examples using mne.viz.plot_ideal_filter#

Plot an ideal filter response.

The ideal response frequencies to plot (must be in ascending order).

The ideal response gains to plot.

The subplot handle. With None (default), axes are created.

The title to use, (default: ‘’).

If not None, the x-axis frequency limits (Hz) to use. If None (default), freq used.

Frequency scaling to use, can be “log” (default) or “linear”.

If not None (default), the y-axis limits (dB) to use.

The color to use (default: ‘r’).

The alpha to use (default: 0.5).

The line style to use (default: ‘–‘).

Show figure if True (default).

Plot a simple ideal band-pass filter:

Background information on filtering

mne.viz.plot_head_positions

mne.viz.plot_compare_evokeds

---

## mne.viz.plot_layout#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_layout.html

**Contents:**
- mne.viz.plot_layout#

Plot the sensor positions.

Layout instance specifying sensor positions.

Channels to include in the layout. Slices and lists of integers will be interpreted as channel indices. Can also be the string value 'all' to pick all channels. None (default) will pick all channels.

Show layout axes if True. Defaults to False.

Show figure if True. Defaults to True.

Figure containing the sensor topography.

mne.viz.plot_epochs_image

---

## mne.viz.plot_montage#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_montage.html

**Contents:**
- mne.viz.plot_montage#

The montage to visualize.

Determines the scale of the channel points and labels; values < 1 will scale down, whereas values > 1 will scale up.

Whether to display all channel names. If a list, only the channel names in the list are shown. Defaults to True.

Whether to plot the montage as ‘3d’ or ‘topomap’ (default).

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.viz.plot_projs_topomap

---

## mne.viz.plot_projs_topomap#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_projs_topomap.html

**Contents:**
- mne.viz.plot_projs_topomap#
- Examples using mne.viz.plot_projs_topomap#

Plot topographic maps of SSP projections.

The mne.Info object with information about the sensors and methods of measurement. Must be associated with the channels in the projectors.

Changed in version 0.20: The positional argument layout was replaced by info.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all projectors of the same channel type (instead of separately for each projector), using the min/max of the data for that channel type. If vlim is "joint", info must not be None. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of projectors. Default is None.

Show the figure if True.

Figure with a topomap subplot for each projector.

Repairing artifacts with SSP

mne.viz.plot_projs_joint

---

## mne.viz.plot_raw#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_raw.html

**Contents:**
- mne.viz.plot_raw#

The raw data to plot.

Events to show with vertical bars.

Time window (s) to plot. The lesser of this value and the duration of the raw file will be used.

Initial time to show (can be changed dynamically once plotted). If show_first_samp is True, then it is taken relative to raw.first_samp.

Number of channels to plot at once. Defaults to 20. The lesser of n_channels and len(raw.ch_names) will be shown. Has no effect if order is ‘position’, ‘selection’ or ‘butterfly’.

Color of the background.

Color for the data traces. If None, defaults to:

Color to make bad channels.

Color(s) to use for events. To show all events in the same color, pass any matplotlib-compatible color. To color events differently, pass a dict that maps event names or integer event numbers to colors (must include entries for all events, or include a “fallback” entry with key -1). If None, colors are chosen from the current Matplotlib color cycle. Defaults to 'cyan'.

A regex pattern applied to each annotation’s label. Matching labels remain visible, non-matching labels are hidden.

Scaling factors for the traces. If a dictionary where any value is 'auto', the scaling factor is set to match the 99.5th percentile of the respective data. If 'auto', all scalings (for all channel types) are set to 'auto'. If any values are 'auto' and the data is not preloaded, a subset up to 100 MB will be loaded. If None, defaults to:

A particular scaling value s corresponds to half of the visualized signal range around zero (i.e. from 0 to +s or from 0 to -s). For example, the default scaling of 20e-6 (20µV) for EEG signals means that the visualized range will be 40 µV (20 µV in the positive direction and 20 µV in the negative direction).

If True remove DC component when plotting data.

Order in which to plot data. If the array is shorter than the number of channels, only the given channels are plotted. If None (default), all channels are plotted. If group_by is 'position' or 'selection', the order parameter is used only for selecting the channels to be plotted.

If True, a dialog for options related to projection is shown.

The title of the window. If None, and either the filename of the raw object or ‘<unknown>’ will be displayed as title.

Whether to halt program execution until the figure is closed. Useful for setting bad channels on the fly by clicking on a line. May not work on all systems / platforms. (Only Qt) If you run from a script, this needs to be True or a Qt-eventloop needs to be started somewhere else in the script (e.g. if you want to implement the browser inside another Qt-Application).

Highpass to apply when displaying data.

Lowpass to apply when displaying data. If highpass > lowpass, a bandstop rather than bandpass filter will be applied.

Filtering order. 0 will use FIR filtering with MNE defaults. Other values will construct an IIR filter of the given order and apply it with filtfilt() (making the effective order twice filtorder). Filtering may produce some edge artifacts (at the left and right edges) of the signals during display.

Changed in version 0.18: Support for filtorder=0 to use FIR filtering.

If None, channels are allowed to exceed their designated bounds in the plot. If “clamp”, then values are clamped to the appropriate range for display, creating step-like artifacts. If “transparent”, then excessive values are not shown, creating gaps in the traces. If float, clipping occurs for values beyond the clipping multiple of their dedicated range, so clipping=1. is an alias for clipping='transparent'.

Changed in version 0.21: Support for float, and default changed from None to 1.5.

If True, show time axis relative to the raw.first_samp.

Whether to apply projectors prior to plotting (default is True). Individual projectors can be enabled/disabled interactively (see Notes). This argument only affects the plot; use raw.apply_proj() to modify the data stored in the Raw object.

How to group channels. 'type' groups by channel type, 'original' plots in the order of ch_names, 'selection' uses Elekta’s channel groupings (only works for Neuromag data), 'position' groups the channels by the positions of the sensors. 'selection' and 'position' modes allow custom selections by using a lasso selector on the topomap. In butterfly mode, 'type' and 'original' group the channels by type, whereas 'selection' and 'position' use regional grouping. 'type' and 'original' modes are ignored when order is not None. Defaults to 'type'.

Whether to start in butterfly mode. Defaults to False.

Amount to decimate the data during display for speed purposes. You should only decimate if the data are sufficiently low-passed, otherwise aliasing can occur. The ‘auto’ mode (default) uses the decimation that results in a sampling rate least three times larger than min(info['lowpass'], lowpass) (e.g., a 40 Hz lowpass will result in at least a 120 Hz displayed sample rate).

Noise covariance used to whiten the data while plotting. Whitened data channels are scaled by scalings['whitened'], and their channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().

Event IDs used to show at event markers (default None shows the event numbers).

Whether to show scrollbars when the plot is initialized. Can be toggled after initialization by pressing z (“zen mode”) while the plot window is focused. Default is True.

Whether to show scale bars when the plot is initialized. Can be toggled after initialization by pressing s while the plot window is focused. Default is True.

Style of time labels on the horizontal axis. If 'float', labels will be number of seconds from the start of the recording. If 'clock', labels will show “clock time” (hours/minutes/seconds) inferred from raw.info['meas_date']. Default is 'float'.

Whether to load all data (not just the visible portion) into RAM and apply preprocessing (e.g., projectors) to the full data array in a separate processor thread, instead of window-by-window during scrolling. The default None uses the MNE_BROWSER_PRECOMPUTE variable, which defaults to 'auto'. 'auto' compares available RAM space to the expected size of the precomputed data, and precomputes only if enough RAM is available. This is only used with the Qt backend.

Changed in version 1.0: Support for the MNE_BROWSER_PRECOMPUTE config variable.

Whether to use OpenGL when rendering the plot (requires pyopengl). May increase performance, but effect is dependent on system CPU and graphics hardware. Only works if using the Qt backend. Default is None, which will use False unless the user configuration variable MNE_BROWSER_USE_OPENGL is set to 'true', see mne.set_config().

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Can be “auto”, “light”, or “dark” or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_BROWSER_THEME will be used, defaulting to “auto” if it’s not found. Only supported by the 'qt' backend.

Can be “channels”, “empty”, or “hidden” to set the overview bar mode for the 'qt' backend. If None (default), the config option MNE_BROWSER_OVERVIEW_MODE will be used, defaulting to “channels” if it’s not found.

If True (default), a splash screen is shown during the application startup. Only applicable to the qt backend.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The arrow keys (up/down/left/right) can typically be used to navigate between channels and time ranges, but this depends on the backend matplotlib is configured to use (e.g., mpl.use(‘TkAgg’) should work). The left/right arrows will scroll by 25% of duration, whereas shift+left/shift+right will scroll by 100% of duration. The scaling can be adjusted with - and + (or =) keys. The viewport dimensions can be adjusted with page up/page down and home/end keys. Full screen mode can be toggled with the F11 key, and scrollbars can be hidden/shown by pressing ‘z’. Right-click a channel label to view its location. To mark or un-mark a channel as bad, click on a channel label or a channel trace. The changes will be reflected immediately in the raw object’s raw.info['bads'] entry.

If projectors are present, a button labelled “Prj” in the lower right corner of the plot window opens a secondary control window, which allows enabling/disabling specific projectors individually. This provides a means of interactively observing how each projector would affect the raw data if it were applied.

Annotation mode is toggled by pressing ‘a’, butterfly mode by pressing ‘b’, and whitening mode (when noise_cov is not None) by pressing ‘w’. By default, the channel means are removed when remove_dc is set to True. This flag can be toggled by pressing ‘d’.

MNE-Python provides two different backends for browsing plots (i.e., raw.plot(), epochs.plot(), and ica.plot_sources()). One is based on matplotlib, and the other is based on PyQtGraph. You can set the backend temporarily with the context manager mne.viz.use_browser_backend(), you can set it for the duration of a Python session using mne.viz.set_browser_backend(), and you can set the default for your computer via mne.set_config('MNE_BROWSER_BACKEND', 'matplotlib') (or 'qt').

For the PyQtGraph backend to run in IPython with block=False you must run the magic command %gui qt5 first.

To report issues with the PyQtGraph backend, please use the issues of mne-qt-browser.

mne.viz.plot_projs_joint

---

## mne.viz.plot_raw_psd#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_raw_psd.html

**Contents:**
- mne.viz.plot_raw_psd#

LEGACY: New code should use Raw.compute_psd().plot().

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (╎) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (⋮). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Number of points to use in Welch FFT calculations. Default is None, which uses the minimum of 2048 and the number of time points.

The number of points of overlap between blocks. The default value is 0 (no overlap).

Whether to omit bad spans of data before spectral estimation. If True, spans with annotations whose description begins with bad will be omitted.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of channel types present in the object.. Default is None.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Scale of the frequency axis. Default is 'linear'.

Mode for plotting area. If ‘std’, the mean +/- 1 STD (across channels) will be plotted. If ‘range’, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted.

Plot power spectral density (PSD) in units (dB/Hz) if dB=True and estimate='power'. Plot PSD in units (amplitude**2/Hz) if dB=False and estimate='power'. Plot amplitude spectral density (ASD) in units (amplitude/sqrt(Hz)) if dB=False and estimate='amplitude'. Plot ASD in units (dB/sqrt(Hz)) if dB=True and estimate='amplitude'.

Can be “power” for power spectral density (PSD; default), “amplitude” for amplitude spectrum density (ASD).

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

If False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap.

Alpha for the PSD line. Can be None (default) to use 1.0 when average=True and 0.1 when average=False.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Windowing function to use. See scipy.signal.get_window().

Channels names to exclude from being shown. If ‘bads’, the bad channels are excluded. Pass an empty list to plot all channels (including channels marked “bad”, if any).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure with frequency spectra of the data channels.

This function exists to support legacy code; for new code the preferred idiom is inst.compute_psd().plot() (where inst is an instance of Raw, Epochs, or Evoked).

mne.viz.plot_regression_weights

---

## mne.viz.plot_regression_weights#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_regression_weights.html

**Contents:**
- mne.viz.plot_regression_weights#

Plot the regression weights of a fitted EOGRegression model.

The fitted EOGRegression model whose weights will be plotted.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel(s) to highlight with a distinct plotting style. Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of times provided (unless times is None). Default is None.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

Figure with a topomap subplot for each channel type.

---

## mne.viz.plot_sensors#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_sensors.html

**Contents:**
- mne.viz.plot_sensors#

Plot sensors positions.

The mne.Info object with information about the sensors and methods of measurement.

Whether to plot the sensors as 3d, topomap or as an interactive sensor selection dialog. Available options 'topomap', '3d', 'select'. If 'select', a set of channels can be selected interactively by using lasso selector or clicking while holding the control key. The selected channels are returned along with the figure instance. Defaults to 'topomap'.

The channel type to plot. Available options 'mag', 'grad', 'eeg', 'seeg', 'dbs', 'ecog', 'all'. If 'all', all the available mag, grad, eeg, seeg, dbs and ecog channels are plotted. If None (default), then channels are chosen in the order given above.

Title for the figure. If None (default), equals to 'Sensor positions (%s)' % ch_type.

Whether to display all channel names. If an array, only the channel names in the array are shown. Defaults to False.

Channel groups for coloring the sensors. If None (default), default coloring scheme is used. If ‘position’, the sensors are divided into 8 regions. See order kwarg of mne.viz.plot_raw(). If array, the channels are divided by picks given in the array. Also accepts a list of lists to allow channel groups of the same or different sizes.

Whether to project the 3d locations to a sphere. When False, the sensor array appears similar as to looking downwards straight above the subject’s head. Has no effect when kind='3d'. Defaults to True.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Whether to halt program execution until the figure is closed. Defaults to False.

Show figure if True. Defaults to True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The size of the points. If None (default), will bet set to 75 if kind='3d', or 25 otherwise.

The width of the outline. If 0, the outline will not be drawn.

Colormap for coloring ch_groups. Has effect only when ch_groups is list of list. If None, set to matplotlib.rcParams["image.cmap"]. Defaults to None.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the sensor topography.

A list of selected channels. Only returned if kind=='select'.

This function plots the sensor locations from the info structure using matplotlib. For drawing the sensors using PyVista see mne.viz.plot_alignment().

mne.viz.plot_regression_weights

mne.viz.plot_snr_estimate

---

## mne.viz.plot_snr_estimate#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_snr_estimate.html

**Contents:**
- mne.viz.plot_snr_estimate#
- Examples using mne.viz.plot_snr_estimate#

Plot a data SNR estimate.

The evoked instance. This should probably be baseline-corrected.

The minimum-norm inverse operator.

The axes to plot into.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure object containing the plot.

The bluish green line is the SNR determined by the GFP of the whitened evoked data. The orange line is the SNR estimated based on the mismatch between the data and the data re-estimated from the regularized inverse.

Estimate data SNR using an inverse

mne.viz.plot_source_estimates

---

## mne.viz.plot_source_estimates#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_source_estimates.html

**Contents:**
- mne.viz.plot_source_estimates#
- Examples using mne.viz.plot_source_estimates#

The source estimates to plot.

The FreeSurfer subject name. If None, stc.subject will be used.

The type of surface (inflated, white etc.).

Hemisphere id (ie 'lh', 'rh', 'both', or 'split'). In the case of 'both', both hemispheres are shown in the same window. In the case of 'split' hemispheres are displayed side-by-side in different viewing panes.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255. The default (‘auto’) uses 'hot' for one-sided data and ‘mne’ for two-sided data.

Format of the time label (a format string, a function that maps floating point time values to strings, or None for no label). The default is 'auto', which will use time=%0.2f ms if there is more than one time point.

The amount of smoothing.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Alpha value to apply globally to the overlay. Has no effect with mpl backend.

Display time viewer GUI. Can also be ‘auto’, which will mean True for the PyVista backend and False otherwise.

Changed in version 0.20.0: “auto” mode added.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

If None, a new figure will be created. If multiple views or a split view is requested, this must be a list of the appropriate length. If int is provided it will be used to identify the PyVista figure by it’s id or create a new figure with the given id. If an instance of matplotlib figure, mpl backend is used for plotting.

View to use. Using multiple views (list) is not supported for mpl backend. See Brain.show_view for valid string options.

When plotting a standard SourceEstimate (not volume, mixed, or vector) and using the PyVista backend, views='flat' is also supported to plot cortex as a flatmap.

Using multiple views (list) is not supported by the matplotlib backend.

Changed in version 0.21.0: Support for flatmaps.

If True, display colorbar on scene.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bounds for colormap.

Lower, middle, and upper bound for colormap. Positive values will be mirrored directly across zero during colormap construction to obtain negative control points.

Only one of lims or pos_lims should be provided. Only sequential colormaps should be used with lims, and only divergent colormaps should be used with pos_lims.

Specifies how binarized curvature values are rendered. Either the name of a preset Brain cortex colorscheme (one of 'classic', 'bone', 'low_contrast', or 'high_contrast'), or the name of a colormap, or a tuple with values (colormap, min, max, reverse) to fully specify the curvature colors. Has no effect with the matplotlib backend.

The size of the window, in pixels. can be one number to specify a square window, or the (width, height) of a rectangular window. Has no effect with mpl backend.

Color of the background of the display window.

Color of the foreground of the display window. Has no effect with mpl backend. None will choose white or black based on the background color.

The time to display on the plot initially. None to display the first time sample (default).

Whether time is represented in seconds (“s”, default) or milliseconds (“ms”).

Which backend to use. If 'auto' (default), tries to plot with pyvistaqt, but resorts to matplotlib if no 3d backend is available.

Only affects the matplotlib backend. The spacing to use for the source space. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, or 'all' for all points. In general, you can speed up the plotting by selecting a sparser source space. Defaults to ‘oct6’.

Title for the figure window. If None, the subject name will be used.

If True, enable interactive picking of a point on the surface of the brain and plot its time course. This feature is only available with the PyVista 3d backend, and requires time_viewer=True. Defaults to ‘auto’, which will use True if and only if time_viewer=True, the backend is PyVista, and there is more than one time point. If float (between zero and one), it specifies what proportion of the total window should be devoted to traces (True is equivalent to 0.25, i.e., it will occupy the bottom 1/4 of the figure).

The source space corresponding to the source estimate. Only necessary if the STC is a volume or mixed source estimate.

Options for volumetric source estimate plotting, with key/value pairs:

Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks better at the cost of speed. None (default) uses the volume source space resolution, which is often something like 7 or 5 mm, without resampling.

Can be “mip” (default) for maximum intensity projection or “composite” for composite blending using alpha values.

Alpha for the volumetric rendering. Defaults are 0.4 for vector source estimates and 1.0 for scalar source estimates.

Alpha for the surface enclosing the volume(s). None (default) will use half the volume alpha. Set to zero to avoid plotting the surface.

Alpha for a silhouette along the outside of the volume. None (default) will use 0.25 * surface_alpha.

The line width to use for the silhouette. Default is 2.

A float input (default 1.) or None will be used for the 'resolution' entry.

Can be “vertical” (default) or “horizontal”. When using “horizontal” mode, the PyVista backend must be used and hemi cannot be “split”.

Additional arguments to brain.add_data (e.g., dict(time_label_size=10)).

Additional arguments to the mne.viz.Brain constructor (e.g., dict(silhouette=True)).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

An instance of mne.viz.Brain or matplotlib figure.

Flatmaps are available by default for fsaverage but not for other subjects reconstructed by FreeSurfer. We recommend using mne.compute_source_morph() to morph source estimates to fsaverage for flatmap plotting. If you want to construct your own flatmap for a given subject, these links might help:

https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferOccipitalFlattenedPatch

https://openwetware.org/wiki/Beauchamp:FreeSurfer

Plotting the full vector-valued MNE solution

mne.viz.plot_snr_estimate

---

## mne.viz.plot_sparse_source_estimates#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_sparse_source_estimates.html

**Contents:**
- mne.viz.plot_sparse_source_estimates#
- Examples using mne.viz.plot_sparse_source_estimates#

Plot source estimates obtained with sparse solver.

Active dipoles are represented in a “Glass” brain. If the same source is active in multiple source estimates it is displayed with a sphere otherwise with a cone in 3D.

The source estimates.

Line width in 2D plot.

Background color in 3D.

Opacity of brain mesh.

Show figures if True.

If True, plot on the original (non-downsampled) cortical mesh.

Matplotlib figure number.

Labels to show sources in clusters. Sources with the same label and the waveforms within each cluster are presented in the same color. labels should be a list of ndarrays when stcs is a list ie. one label for each stc.

Should be a list, with each entry being 'cone' or 'sphere' to specify how the dipoles should be shown. The pivot for the glyphs in 'cone' mode is always the tail whereas the pivot in 'sphere' mode is the center.

List of floating point scale factors for the markers.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Keyword arguments to pass to renderer.mesh.

The 3D figure containing the triangular mesh surface.

Source localization with a custom inverse solver

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Compute MxNE with time-frequency sparse prior

Generate simulated evoked data

mne.viz.plot_vector_source_estimates

mne.viz.plot_tfr_topomap

---

## mne.viz.plot_tfr_topomap#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_tfr_topomap.html

**Contents:**
- mne.viz.plot_tfr_topomap#

Plot topographic maps of specific time-frequency intervals of TFR data.

The AverageTFR object.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The time interval to apply rescaling / baseline correction. If None do not apply it. If baseline is (a, b) the interval is between “a (s)” and “b (s)”. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) the whole time interval is used.

Perform baseline correction by

subtracting the mean baseline power (‘mean’)

dividing by the mean baseline power (‘ratio’)

dividing by the mean baseline power and taking the log (‘logratio’)

subtracting the mean baseline power followed by dividing by the mean baseline power (‘percent’)

subtracting the mean baseline power and dividing by the standard deviation of the baseline power (‘zscore’)

dividing by the mean baseline power, taking the log, and dividing by the standard deviation of the baseline power (‘zlogratio’)

If None no baseline correction is applied.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created. Default is None.

Show the figure if True.

The figure containing the topography.

mne.viz.plot_sparse_source_estimates

mne.viz.plot_topo_image_epochs

---

## mne.viz.plot_topomap#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_topomap.html

**Contents:**
- mne.viz.plot_topomap#
- Examples using mne.viz.plot_topomap#

Plot a topographic map as image.

The data values to plot.

Location information for the channels. If an array, should provide the x and y coordinates for plotting the channels in 2D. If an Info object it must contain only one channel type and exactly len(data) channels; the x/y coordinates will be inferred from the montage in the Info object.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

Labels for the sensors. If a list, labels should correspond to the order of channels in data. If None (default), no channel names are plotted.

Array indicating channel(s) to highlight with a distinct plotting style. Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The axes to plot into. If None, a new Figure will be created. Default is None.

Changed in version 1.2: If axes=None, a new Figure is created instead of plotting into the current axes.

Show the figure if True.

A function to be called when the user selects a set of channels by click-dragging (uses a matplotlib RectangleSelector). If None interactive channel selection is disabled. Defaults to None.

The interpolated data.

Receptive Field Estimation and Prediction

Getting impedances from raw files

Identify EEG Electrodes Bridged by too much Gel

Plotting topographic maps of evoked data

Working with sensor locations

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

mne.viz.plot_topo_image_epochs

mne.viz.plot_alignment

---

## mne.viz.plot_vector_source_estimates#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_vector_source_estimates.html

**Contents:**
- mne.viz.plot_vector_source_estimates#
- Examples using mne.viz.plot_vector_source_estimates#

Plot VectorSourceEstimate with PyVista.

A “glass brain” is drawn and all dipoles defined in the source estimate are shown using arrows, depicting the direction and magnitude of the current moment at the dipole. Additionally, an overlay is plotted on top of the cortex with the magnitude of the current.

The vector source estimate to plot.

The FreeSurfer subject name. If None, stc.subject will be used.

The hemisphere to display.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255. This should be a sequential colormap.

Format of the time label (a format string, a function that maps floating point time values to strings, or None for no label). The default is 'auto', which will use time=%0.2f ms if there is more than one time point.

The amount of smoothing.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Alpha value to apply globally to the surface meshes. Defaults to 0.4.

Alpha value to apply globally to the overlay. Defaults to brain_alpha.

Alpha value to apply globally to the vector glyphs. Defaults to 1.

Scaling factor for the vector glyphs. By default, an attempt is made to automatically determine a sane value.

Display time viewer GUI. Can be “auto”, which is True for the PyVista backend and False otherwise.

Changed in version 0.20: Added “auto” option and default.

The path to the freesurfer subjects reconstructions. It corresponds to Freesurfer environment variable SUBJECTS_DIR.

If None, a new figure will be created. If multiple views or a split view is requested, this must be a list of the appropriate length. If int is provided it will be used to identify the PyVista figure by it’s id or create a new figure with the given id.

View to use. Using multiple views (list) is not supported for mpl backend. See Brain.show_view for valid string options.

If True, display colorbar on scene.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bound for colormap.

Unlike stc.plot, it cannot use pos_lims, as the surface plot must show the magnitude.

Specifies how binarized curvature values are rendered. either the name of a preset Brain cortex colorscheme (one of ‘classic’, ‘bone’, ‘low_contrast’, or ‘high_contrast’), or the name of a colormap, or a tuple with values (colormap, min, max, reverse) to fully specify the curvature colors.

The size of the window, in pixels. can be one number to specify a square window, or the (width, height) of a rectangular window.

Color of the background of the display window.

Color of the foreground of the display window. None will choose black or white based on the background color.

The time to display on the plot initially. None to display the first time sample (default).

Whether time is represented in seconds (“s”, default) or milliseconds (“ms”).

Title for the figure window. If None, the subject name will be used.

If True, enable interactive picking of a point on the surface of the brain and plot its time course. This feature is only available with the PyVista 3d backend, and requires time_viewer=True. Defaults to ‘auto’, which will use True if and only if time_viewer=True, the backend is PyVista, and there is more than one time point. If float (between zero and one), it specifies what proportion of the total window should be devoted to traces (True is equivalent to 0.25, i.e., it will occupy the bottom 1/4 of the figure).

The source space corresponding to the source estimate. Only necessary if the STC is a volume or mixed source estimate.

Options for volumetric source estimate plotting, with key/value pairs:

Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks better at the cost of speed. None (default) uses the volume source space resolution, which is often something like 7 or 5 mm, without resampling.

Can be “mip” (default) for maximum intensity projection or “composite” for composite blending using alpha values.

Alpha for the volumetric rendering. Defaults are 0.4 for vector source estimates and 1.0 for scalar source estimates.

Alpha for the surface enclosing the volume(s). None (default) will use half the volume alpha. Set to zero to avoid plotting the surface.

Alpha for a silhouette along the outside of the volume. None (default) will use 0.25 * surface_alpha.

The line width to use for the silhouette. Default is 2.

A float input (default 1.) or None will be used for the 'resolution' entry.

Can be “vertical” (default) or “horizontal”. When using “horizontal” mode, the PyVista backend must be used and hemi cannot be “split”.

Additional arguments to brain.add_data (e.g., dict(time_label_size=10)).

Additional arguments to the mne.viz.Brain constructor (e.g., dict(silhouette=True)).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A instance of mne.viz.Brain.

If the current magnitude overlay is not desired, set overlay_alpha=0 and smoothing_steps=1.

Plotting the full vector-valued MNE solution

mne.viz.plot_volume_source_estimates

mne.viz.plot_sparse_source_estimates

---

## mne.viz.plot_volume_source_estimates#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_volume_source_estimates.html

**Contents:**
- mne.viz.plot_volume_source_estimates#

Plot Nutmeg style volumetric source estimates using nilearn.

The vector source estimate to plot.

The source space. Can also be a SourceMorph to morph the STC to a new subject (see Examples).

Changed in version 0.18: Support for SpatialImage.

The FreeSurfer subject name. If None, stc.subject will be used.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The plotting mode to use. For 'glass_brain', activation absolute values are displayed after being transformed to a standard MNI brain.

The background image used in the nilearn plotting function. Can also be a string to use the bg_img file in the subject’s MRI directory (default is 'T1.mgz'). Not used in “glass brain” plotting.

If True, display a colorbar on the right of the plots.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bounds for colormap.

Lower, middle, and upper bound for colormap. Positive values will be mirrored directly across zero during colormap construction to obtain negative control points.

Only one of lims or pos_lims should be provided. Only sequential colormaps should be used with lims, and only divergent colormaps should be used with pos_lims.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Show figures if True. Defaults to True.

The initial time to plot. Can be None (default) to use the time point with the maximal absolute value activation across all voxels or the initial_pos voxel (if initial_pos is None or not, respectively).

The initial position to use (in m). Can be None (default) to use the voxel with the maximum absolute value activation across all time points or at initial_time (if initial_time is None or not, respectively).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Click on any of the anatomical slices to explore the time series. Clicking on any time point will bring up the corresponding anatomical map.

The left and right arrow keys can be used to navigate in time. To move in time by larger steps, use shift+left and shift+right.

In 'glass_brain' mode, values are transformed to the standard MNI brain using the FreeSurfer Talairach transformation $SUBJECTS_DIR/$SUBJECT/mri/transforms/talairach.xfm.

Changed in version 0.19: MRI volumes are automatically transformed to MNI space in 'glass_brain' mode.

Passing a mne.SourceMorph as the src parameter can be useful for plotting in a different subject’s space (here, a 'sample' STC in 'fsaverage'’s space):

mne.viz.plot_vector_source_estimates

---

## mne.viz.set_3d_backend#

**URL:** https://mne.tools/stable/generated/mne.viz.set_3d_backend.html

**Contents:**
- mne.viz.set_3d_backend#

Set the 3D backend for MNE.

The backend will be set as specified and operations will use that backend.

The 3d backend to select. See Notes for the capabilities of each backend ('pyvistaqt' and 'notebook').

Changed in version 0.24: The 'pyvista' backend was renamed 'pyvistaqt'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The old backend that was in use.

To use PyVista, set backend_name to pyvistaqt but the value pyvista is still supported for backward compatibility.

This table shows the capabilities of each backend (”✓” for full support, and “-” for partial support):

plot_vector_source_estimates()

plot_source_estimates()

plot_sparse_source_estimates()

snapshot_brain_montage()

Support geometric glyph

Inline plot in Jupyter Notebook

Inline plot in JupyterLab

Inline plot in Google Colab

mne.viz.plot_arrowmap

mne.viz.get_3d_backend

---

## mne.viz.set_3d_options#

**URL:** https://mne.tools/stable/generated/mne.viz.set_3d_options.html

**Contents:**
- mne.viz.set_3d_options#

Set 3D rendering options.

If bool, whether to enable or disable full-screen anti-aliasing. False is useful when renderers have problems (such as software MESA renderers). If None, use the default setting. This option can also be controlled using an environment variable, e.g., MNE_3D_OPTION_ANTIALIAS=false.

If bool, whether to enable or disable accurate transparency. False is useful when renderers have problems (for instance while X forwarding on remote servers). If None, use the default setting. This option can also be controlled using an environment variable, e.g., MNE_3D_OPTION_DEPTH_PEELING=false.

If bool, whether to enable or disable smooth color transitions between polygons. False is useful on certain configurations where this type of shading is not supported or for performance reasons. This option can also be controlled using an environment variable, e.g., MNE_3D_OPTION_SMOOTH_SHADING=false.

Number of multi-samples. Should be 1 for MESA for volumetric rendering to work properly.

mne.viz.use_3d_backend

---

## mne.viz.set_3d_title#

**URL:** https://mne.tools/stable/generated/mne.viz.set_3d_title.html

**Contents:**
- mne.viz.set_3d_title#
- Examples using mne.viz.set_3d_title#

Configure the title of the given scene.

The scene which is modified.

The title of the scene.

The size of the title.

The color of the title.

The position to use, e.g., “upper_left”. See pyvista.Plotter.add_text() for details.

The text object returned by the given backend.

Plotting sensor layouts of MEG systems

Plotting sensor layouts of EEG systems

Visualizing Evoked data

mne.viz.create_3d_figure

---

## mne.viz.set_3d_view#

**URL:** https://mne.tools/stable/generated/mne.viz.set_3d_view.html

**Contents:**
- mne.viz.set_3d_view#
- Examples using mne.viz.set_3d_view#

Configure the view of the given scene.

The scene which is modified.

The azimuthal angle of the camera rendering the view in degrees.

The The zenith angle of the camera rendering the view in degrees.

The focal point of the camera rendering the view: (x, y, z) in plot units (either m or mm). When "auto", it is set to the center of mass of the visible bounds.

The distance from the camera rendering the view to the focalpoint in plot units (either m or mm). If “auto”, the bounds of visible objects will be used to set a reasonable distance.

Changed in version 1.6: None will no longer change the distance, use "auto" instead.

The roll of the camera rendering the view in degrees.

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

Generate a left cerebellum volume source space

Reading an inverse operator

Annotate movement artifacts and reestimate dev_head_t

Compute source power spectral density (PSD) of VectorView and OPM data

How to convert 3D electrode positions to a 2D image

Plotting EEG sensors on the scalp

Plot the MNE brain and helmet

Plotting sensor layouts of EEG systems

Working with ECoG data

Source alignment and coordinate frames

Using an automated approach to coregistration

Head model and forward computation

EEG forward operator with a template MRI

How MNE uses FreeSurfer’s outputs

Working with sensor locations

The role of dipole orientations in distributed source localization

Brainstorm Elekta phantom dataset tutorial

KIT phantom dataset tutorial

mne.viz.set_3d_options

---

## mne.viz.set_browser_backend#

**URL:** https://mne.tools/stable/generated/mne.viz.set_browser_backend.html

**Contents:**
- mne.viz.set_browser_backend#

Set the 2D browser backend for MNE.

The backend will be set as specified and operations will use that backend.

The 2D browser backend to select. See Notes for the capabilities of each backend ('qt', 'matplotlib'). The 'qt' browser requires mne-qt-browser.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The old backend that was in use.

This table shows the capabilities of each backend (”✓” for full support, and “-” for partial support):

Add/Edit/Remove Annotations

Overview-Bar (with Z-Score-Mode)

mne.viz.get_brain_class

mne.viz.get_browser_backend

---

## mne.viz.snapshot_brain_montage#

**URL:** https://mne.tools/stable/generated/mne.viz.snapshot_brain_montage.html

**Contents:**
- mne.viz.snapshot_brain_montage#
- Examples using mne.viz.snapshot_brain_montage#

Take a snapshot of a PyVista Scene and project channels onto 2d coords.

Note that this will take the raw values for 3d coordinates of each channel, without applying any transforms. If brain images are flipped up/dn upon using imshow, check your matplotlib backend as this behavior changes.

The figure on which you’ve plotted electrodes using mne.viz.plot_alignment().

The digital montage for the electrodes plotted in the scene. If Info, channel positions will be pulled from the loc field of chs. dict should have ch:xyz mappings.

Whether to remove the spheres in the scene before taking a snapshot. The sensors will always be shown in the final figure. If you want an image of just the brain, use mne.viz.Brain instead.

The 2d location of each channel on the image of the current scene view.

The screenshot of the current scene view.

How to convert 3D electrode positions to a 2D image

Working with ECoG data

mne.viz.plot_alignment

mne.viz.plot_arrowmap

---

## mne.viz.ui_events.ColormapRange#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.ColormapRange.html

**Contents:**
- mne.viz.ui_events.ColormapRange#

Indicates that the user has updated the bounds of the colormap.

Kind of colormap being updated. The Notes section of the drawing routine publishing this event should mention the possible kinds.

Type of sensor the data originates from.

Minimum value in colormap (uses real fmin if None).

Intermediate value in colormap (fmid between fmin and fmax if None).

Maximum value in colormap (uses real max if None).

Alpha level to control opacity.

The colormap to use. Either string or matplotlib.colors.Colormap instance.

Kind of colormap being updated. The Notes section of the drawing routine publishing this event should mention the possible kinds.

Type of sensor the data originates from.

The unit of the values.

The name of the event, which is the class name in snake case.

The figure that published the event.

Minimum value in colormap (uses real fmin if None).

Intermediate value in colormap (fmid between fmin and fmax if None).

Maximum value in colormap (uses real max if None).

Alpha level to control opacity.

The colormap to use. Either string or matplotlib.colors.Colormap instance.

The name of the event, which is the class name in snake case.

mne.viz.ui_events.UIEvent

mne.viz.ui_events.Contours

---

## mne.viz.ui_events.Contours#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.Contours.html

**Contents:**
- mne.viz.ui_events.Contours#

Indicates that the user has changed the contour lines.

The kind of contours lines being changed. The Notes section of the drawing routine publishing this event should mention the possible kinds.

The new values at which contour lines need to be drawn.

The name of the event, which is the class name in snake case.

The figure that published the event.

The kind of contours lines being changed. The Notes section of the drawing routine publishing this event should mention the possible kinds.

The new values at which contour lines need to be drawn.

The name of the event, which is the class name in snake case.

mne.viz.ui_events.ColormapRange

mne.viz.ui_events.FigureClosing

---

## mne.viz.ui_events.disable_ui_events#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.disable_ui_events.html

**Contents:**
- mne.viz.ui_events.disable_ui_events#

Temporarily disable generation of UI events. Use as context manager.

The figure whose UI event generation should be temporarily disabled.

mne.viz.ui_events.unlink

mne.viz.ui_events.UIEvent

---

## mne.viz.ui_events.FigureClosing#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.FigureClosing.html

**Contents:**
- mne.viz.ui_events.FigureClosing#

Indicates that the user has requested to close a figure.

The name of the event, which is the class name in snake case.

The figure that published the event.

The name of the event, which is the class name in snake case.

mne.viz.ui_events.Contours

mne.viz.ui_events.PlaybackSpeed

---

## mne.viz.ui_events.link#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.link.html

**Contents:**
- mne.viz.ui_events.link#
- Examples using mne.viz.ui_events.link#

Link the event channels of two figures together.

When event channels are linked, any events that are published on one channel are simultaneously published on the other channel. Links are bi-directional.

The figures whose event channel will be linked.

Select which events to publish across figures. By default (None), both figures will receive all of each other’s events. Passing a list of event names will restrict the events being shared across the figures to only the given ones.

Select which events not to publish across figures. By default (None), no events are excluded.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Using the event system to link figures

mne.viz.ui_events.publish

mne.viz.ui_events.unlink

---

## mne.viz.ui_events.PlaybackSpeed#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.PlaybackSpeed.html

**Contents:**
- mne.viz.ui_events.PlaybackSpeed#

Indicates that the user has selected a different playback speed for videos.

The new speed in seconds per frame.

The name of the event, which is the class name in snake case.

The figure that published the event.

The new speed in seconds per frame.

The name of the event, which is the class name in snake case.

mne.viz.ui_events.FigureClosing

mne.viz.ui_events.TimeChange

---

## mne.viz.ui_events.publish#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.publish.html

**Contents:**
- mne.viz.ui_events.publish#
- Examples using mne.viz.ui_events.publish#

Publish an event to all subscribers of the figure’s channel.

The figure’s event channel and all linked event channels are searched for subscribers to the given event. Each subscriber had provided a callback function when subscribing, so we call that.

The figure that publishes the event.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Using the event system to link figures

mne.viz.ui_events.unsubscribe

mne.viz.ui_events.link

---

## mne.viz.ui_events.subscribe#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.subscribe.html

**Contents:**
- mne.viz.ui_events.subscribe#
- Examples using mne.viz.ui_events.subscribe#

Subscribe to an event on a figure’s event channel.

The figure of which event channel to subscribe.

The name of the event to listen for.

The function that should be called whenever the event is published.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Using the event system to link figures

mne.viz.eyetracking.plot_gaze

mne.viz.ui_events.unsubscribe

---

## mne.viz.ui_events.TimeChange#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.TimeChange.html

**Contents:**
- mne.viz.ui_events.TimeChange#
- Examples using mne.viz.ui_events.TimeChange#

Indicates that the user has selected a time.

The new time in seconds.

The name of the event, which is the class name in snake case.

The figure that published the event.

The new time in seconds.

The name of the event, which is the class name in snake case.

Using the event system to link figures

mne.viz.ui_events.PlaybackSpeed

mne.viz.ui_events.VertexSelect

---

## mne.viz.ui_events.UIEvent#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.UIEvent.html

**Contents:**
- mne.viz.ui_events.UIEvent#
- Examples using mne.viz.ui_events.UIEvent#

Abstract base class for all events.

The name of the event, which is the class name in snake case.

The figure that published the event.

The name of the event, which is the class name in snake case.

Using the event system to link figures

mne.viz.ui_events.disable_ui_events

mne.viz.ui_events.ColormapRange

---

## mne.viz.ui_events.unlink#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.unlink.html

**Contents:**
- mne.viz.ui_events.unlink#

Remove all links involving the event channel of the given figure.

The figure whose event channel should be unlinked from all other event channels.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.viz.ui_events.link

mne.viz.ui_events.disable_ui_events

---

## mne.viz.ui_events.unsubscribe#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.unsubscribe.html

**Contents:**
- mne.viz.ui_events.unsubscribe#

Unsubscribe from an event on a figure’s event channel.

The figure of which event channel to unsubscribe from.

Select which events to stop subscribing to. Can be a single string event name, a list of event names or "all" which will unsubscribe from all events.

The callback function that should be unsubscribed, leaving all other callback functions that may be subscribed untouched. By default (None) all callback functions are unsubscribed from the event.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.viz.ui_events.subscribe

mne.viz.ui_events.publish

---

## mne.viz.ui_events.VertexSelect#

**URL:** https://mne.tools/stable/generated/mne.viz.ui_events.VertexSelect.html

**Contents:**
- mne.viz.ui_events.VertexSelect#

Indicates that the user has selected a vertex.

The hemisphere the vertex was selected on. Can be "lh", "rh", or "vol".

The vertex number (in the high resolution mesh) that was selected.

The name of the event, which is the class name in snake case.

The figure that published the event.

The hemisphere the vertex was selected on. Can be "lh", "rh", or "vol".

The vertex number (in the high resolution mesh) that was selected.

The name of the event, which is the class name in snake case.

mne.viz.ui_events.TimeChange

---

## mne.viz.use_3d_backend#

**URL:** https://mne.tools/stable/generated/mne.viz.use_3d_backend.html

**Contents:**
- mne.viz.use_3d_backend#

Create a 3d visualization context using the designated backend.

See mne.viz.set_3d_backend() for more details on the available 3d backends and their capabilities.

The 3d backend to use in the context.

mne.viz.get_3d_backend

mne.viz.set_3d_options

---

## mne.viz.use_browser_backend#

**URL:** https://mne.tools/stable/generated/mne.viz.use_browser_backend.html

**Contents:**
- mne.viz.use_browser_backend#
- Examples using mne.viz.use_browser_backend#

Create a 2D browser visualization context using the designated backend.

See mne.viz.set_browser_backend() for more details on the available 2D browser backends and their capabilities.

The 2D browser backend to use in the context.

EEG analysis - Event-Related Potentials (ERPs)

Handling bad channels

Filtering and resampling data

Repairing artifacts with ICA

Background on projectors and projections

Repairing artifacts with SSP

Setting the EEG reference

mne.viz.get_browser_backend

mne.viz.eyetracking.plot_gaze

---

## mne.VolSourceEstimate#

**URL:** https://mne.tools/stable/generated/mne.VolSourceEstimate.html

**Contents:**
- mne.VolSourceEstimate#
- Examples using mne.VolSourceEstimate#

Container for volume source estimates.

The data in source space. The data can either be a single array or a tuple with two arrays: “kernel” shape (n_vertices, n_sensors) and “sens_data” shape (n_sensors, n_times). In this case, the source space data corresponds to np.dot(kernel, sens_data).

The indices of the dipoles in the source space. Should be a single array of shape (n_dipoles,) unless there are subvolumes.

Time point of the first sample in data.

Time step between successive samples in data.

The FreeSurfer subject name. While not necessary, it is safer to set the subject parameter to avoid analysis errors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A timestamp for each sample.

The indices of the dipoles in the source space. Should be a single array of shape (n_dipoles,) unless there are subvolumes.

Numpy array of source estimate data.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

apply_baseline([baseline, verbose])

Baseline correct source estimate data.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of vertices.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

as_volume(src[, dest, mri_resolution, format])

Export volume source estimate as a nifti object.

bin(width[, tstart, tstop, func])

Return a source estimate object with data summarized over time bins.

Return copy of source estimate instance.

crop([tmin, tmax, include_tmax])

Restrict SourceEstimate to a time interval.

extract_label_time_course(labels, src[, ...])

Extract label time courses for lists of labels.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_peak([tmin, tmax, mode, vert_as_index, ...])

Get location and latency of peak amplitude.

in_label(label, mri, src, *[, verbose])

Get a source estimate object restricted to a label.

Make a summary stc file with mean over time points.

plot(src[, subject, subjects_dir, mode, ...])

Plot Nutmeg style volumetric source estimates using nilearn.

plot_3d([subject, surface, hemi, colormap, ...])

resample(sfreq, *[, npad, method, window, ...])

save(fname[, ftype, overwrite, verbose])

Save the source estimates to a file.

save_as_volume(fname, src[, dest, ...])

Save a volume source estimate in a NIfTI file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

Take the square root.

Make a summary stc file with sum over time points.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

transform(func[, idx, tmin, tmax, copy])

Apply linear transform.

transform_data(func[, idx, tmin_idx, tmax_idx])

Get data after a linear (time) transform has been applied.

A container for surface source estimates.

A container for vector surface source estimates.

A container for volume vector source estimates.

A container for mixed surface + volume source estimates.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

Baseline correct source estimate data.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each source individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire source estimate data.

Baseline correction is appropriate when signal and noise are approximately additive, and the noise level can be estimated from the baseline interval. This can be the case for non-normalized source activities (e.g. signed and unsigned MNE), but it is not the case for normalized estimates (e.g. signal-to-noise ratios, dSPM, sLORETA).

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected source estimate object.

Baseline correction can be done multiple times.

Apply a function to a subset of vertices.

The function fun is applied to the vertices defined in picks. The source estimate object’s data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to vertices in picks).

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) because it will apply vertex-wise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if vertice_wise=False as the workload is split across vertices.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The SourceEstimate object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‘auto’, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal “x_a(t)” of “x(t)” is:

where “F” is the Fourier transform, “U” the unit step function, and “y” the Hilbert transform of “x”. One usage of the analytic signal is the computation of the envelope signal, which is given by “e(t) = abs(x_a(t))”. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Export volume source estimate as a nifti object.

The source spaces (should all be of type volume, or part of a mixed source space).

If 'mri' the volume is defined in the coordinate system of the original T1 image. If ‘surf’ the coordinate system of the FreeSurfer surface is used (Surface RAS).

It True the image is saved in MRI resolution.

Either ‘nifti1’ (default) or ‘nifti2’.

Examples using as_volume:

Compute MNE-dSPM inverse solution on evoked data in volume source space

Return a source estimate object with data summarized over time bins.

Time bins of width seconds. This method is intended for visualization only. No filter is applied to the data before binning, making the method inappropriate as a tool for downsampling data.

Width of the individual bins in seconds.

Time point where the first bin starts. The default is the first time point of the stc.

Last possible time point contained in a bin (if the last bin would be shorter than width it is dropped). The default is the last time point of the stc.

Function that is applied to summarize the data. Needs to accept a numpy.array as first input and an axis keyword argument.

The binned source estimate.

Return copy of source estimate instance.

A copy of the source estimate.

Restrict SourceEstimate to a time interval.

The first time point in seconds. If None the first present is used.

The last time point in seconds. If None the last present is used.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The cropped source estimate.

Compute MNE-dSPM inverse solution on evoked data in volume source space

Morph volumetric source estimate

Computing source timecourses with an XFit-like multi-dipole model

Numpy array of source estimate data.

Extract label time courses for lists of labels.

This function will extract one time course for each label. The way the time courses are extracted depends on the mode parameter.

If using a surface or mixed source space, this should be the Label’s for which to extract the time course. If working with whole-brain volume source estimates, this must be one of:

a string path to a FreeSurfer atlas for the subject (e.g., their ‘aparc.a2009s+aseg.mgz’) to extract time courses for all volumes in the atlas

a two-element list or tuple, the first element being a path to an atlas, and the second being a list or dict of volume_labels to extract (see mne.setup_volume_source_space() for details).

Changed in version 0.21.0: Support for volume source estimates.

The source spaces for the source time courses.

Extraction mode, see Notes.

False (default) will emit an error if there are labels that have no vertices in the source estimate. True and 'ignore' will return all-zero time courses for labels that do not have any vertices in the source estimate, and True will emit a warning while and “ignore” will just log a message.

Changed in version 0.21.0: Support for “ignore”.

If True (default), the volume source space will be upsampled to the original MRI resolution via trilinear interpolation before the atlas values are extracted. This ensnures that each atlas label will contain source activations. When False, only the original source space points are used, and some atlas labels thus may not contain any source space vertices.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Extracted time course for each label and source estimate.

Extract time courses for multiple STCs.

Valid values for mode are:

Maximum absolute value across vertices at each time point within each label.

Average across vertices at each time point within each label. Ignores orientation of sources for standard source estimates, which varies across the cortical surface, which can lead to cancellation. Vector source estimates are always in XYZ / RAS orientation, and are thus already geometrically aligned.

Finds the dominant direction of source space normal vector orientations within each label, applies a sign-flip to time series at vertices whose orientation is more than 90° different from the dominant direction, and then averages across vertices at each time point within each label.

Applies singular value decomposition to the time courses within each label, and uses the first right-singular vector as the representative label time course. This signal is scaled so that its power matches the average (per-vertex) power within the label, and sign-flipped by multiplying by np.sign(u @ flip), where u is the first left-singular vector and flip is the same sign-flip vector used when mode='mean_flip'. This sign-flip ensures that extracting time courses from the same label in similar STCs does not result in 180° direction/phase changes.

Uses 'mean_flip' when a standard source estimate is applied, and 'mean' when a vector source estimate is supplied.

No aggregation is performed, and an array of shape (n_vertices, n_times) is returned.

New in v0.21: Support for 'auto', vector, and volume source estimates.

The only modes that work for vector and volume source estimates are 'mean', 'max', and 'auto'.

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Get location and latency of peak amplitude.

The minimum point in time to be considered for peak getting.

The maximum point in time to be considered for peak getting.

How to deal with the sign of the data. If ‘pos’ only positive values will be considered. If ‘neg’ only negative values will be considered. If ‘abs’ absolute values will be considered. Defaults to ‘abs’.

Whether to return the vertex index (True) instead of of its ID (False, default).

Whether to return the time index (True) instead of the latency (False, default).

The vertex exhibiting the maximum response, either ID or index.

The latency in seconds.

Get a source estimate object restricted to a label.

SourceEstimate contains the time course of activation of all sources inside the label.

The label to use. Can be the name of a label if using a standard FreeSurfer atlas, or an integer value to extract from the mri.

Path to the atlas to use.

The volumetric source space. It must be a single, whole-brain volume.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimate restricted to the given label.

Make a summary stc file with mean over time points.

Plot Nutmeg style volumetric source estimates using nilearn.

The source space. Can also be a SourceMorph to morph the STC to a new subject (see Examples).

Changed in version 0.18: Support for SpatialImage.

The FreeSurfer subject name. If None, stc.subject will be used.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The plotting mode to use. For 'glass_brain', activation absolute values are displayed after being transformed to a standard MNI brain.

The background image used in the nilearn plotting function. Can also be a string to use the bg_img file in the subject’s MRI directory (default is 'T1.mgz'). Not used in “glass brain” plotting.

If True, display a colorbar on the right of the plots.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bounds for colormap.

Lower, middle, and upper bound for colormap. Positive values will be mirrored directly across zero during colormap construction to obtain negative control points.

Only one of lims or pos_lims should be provided. Only sequential colormaps should be used with lims, and only divergent colormaps should be used with pos_lims.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Show figures if True. Defaults to True.

The initial time to plot. Can be None (default) to use the time point with the maximal absolute value activation across all voxels or the initial_pos voxel (if initial_pos is None or not, respectively).

The initial position to use (in m). Can be None (default) to use the voxel with the maximum absolute value activation across all time points or at initial_time (if initial_time is None or not, respectively).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Click on any of the anatomical slices to explore the time series. Clicking on any time point will bring up the corresponding anatomical map.

The left and right arrow keys can be used to navigate in time. To move in time by larger steps, use shift+left and shift+right.

In 'glass_brain' mode, values are transformed to the standard MNI brain using the FreeSurfer Talairach transformation $SUBJECTS_DIR/$SUBJECT/mri/transforms/talairach.xfm.

Changed in version 0.19: MRI volumes are automatically transformed to MNI space in 'glass_brain' mode.

Passing a mne.SourceMorph as the src parameter can be useful for plotting in a different subject’s space (here, a 'sample' STC in 'fsaverage'’s space):

Source reconstruction using an LCMV beamformer

Visualize source time courses (stcs)

The FreeSurfer subject name. If None, stc.subject will be used.

The type of surface (inflated, white etc.).

Hemisphere id (ie 'lh', 'rh', 'both', or 'split'). In the case of 'both', both hemispheres are shown in the same window. In the case of 'split' hemispheres are displayed side-by-side in different viewing panes.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255. The default (‘auto’) uses 'hot' for one-sided data and ‘mne’ for two-sided data.

Format of the time label (a format string, a function that maps floating point time values to strings, or None for no label). The default is 'auto', which will use time=%0.2f ms if there is more than one time point.

The amount of smoothing.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Alpha value to apply globally to the overlay. Has no effect with mpl backend.

Display time viewer GUI. Can also be ‘auto’, which will mean True for the PyVista backend and False otherwise.

Changed in version 0.20.0: “auto” mode added.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

If None, a new figure will be created. If multiple views or a split view is requested, this must be a list of the appropriate length. If int is provided it will be used to identify the PyVista figure by it’s id or create a new figure with the given id. If an instance of matplotlib figure, mpl backend is used for plotting.

View to use. Using multiple views (list) is not supported for mpl backend. See Brain.show_view for valid string options.

When plotting a standard SourceEstimate (not volume, mixed, or vector) and using the PyVista backend, views='flat' is also supported to plot cortex as a flatmap.

Using multiple views (list) is not supported by the matplotlib backend.

Changed in version 0.21.0: Support for flatmaps.

If True, display colorbar on scene.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bounds for colormap.

Lower, middle, and upper bound for colormap. Positive values will be mirrored directly across zero during colormap construction to obtain negative control points.

Only one of lims or pos_lims should be provided. Only sequential colormaps should be used with lims, and only divergent colormaps should be used with pos_lims.

Specifies how binarized curvature values are rendered. Either the name of a preset Brain cortex colorscheme (one of 'classic', 'bone', 'low_contrast', or 'high_contrast'), or the name of a colormap, or a tuple with values (colormap, min, max, reverse) to fully specify the curvature colors. Has no effect with the matplotlib backend.

The size of the window, in pixels. can be one number to specify a square window, or the (width, height) of a rectangular window. Has no effect with mpl backend.

Color of the background of the display window.

Color of the foreground of the display window. Has no effect with mpl backend. None will choose white or black based on the background color.

The time to display on the plot initially. None to display the first time sample (default).

Whether time is represented in seconds (“s”, default) or milliseconds (“ms”).

Which backend to use. If 'auto' (default), tries to plot with pyvistaqt, but resorts to matplotlib if no 3d backend is available.

Only affects the matplotlib backend. The spacing to use for the source space. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, or 'all' for all points. In general, you can speed up the plotting by selecting a sparser source space. Defaults to ‘oct6’.

Title for the figure window. If None, the subject name will be used.

If True, enable interactive picking of a point on the surface of the brain and plot its time course. This feature is only available with the PyVista 3d backend, and requires time_viewer=True. Defaults to ‘auto’, which will use True if and only if time_viewer=True, the backend is PyVista, and there is more than one time point. If float (between zero and one), it specifies what proportion of the total window should be devoted to traces (True is equivalent to 0.25, i.e., it will occupy the bottom 1/4 of the figure).

The source space corresponding to the source estimate. Only necessary if the STC is a volume or mixed source estimate.

Options for volumetric source estimate plotting, with key/value pairs:

Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks better at the cost of speed. None (default) uses the volume source space resolution, which is often something like 7 or 5 mm, without resampling.

Can be “mip” (default) for maximum intensity projection or “composite” for composite blending using alpha values.

Alpha for the volumetric rendering. Defaults are 0.4 for vector source estimates and 1.0 for scalar source estimates.

Alpha for the surface enclosing the volume(s). None (default) will use half the volume alpha. Set to zero to avoid plotting the surface.

Alpha for a silhouette along the outside of the volume. None (default) will use 0.25 * surface_alpha.

The line width to use for the silhouette. Default is 2.

A float input (default 1.) or None will be used for the 'resolution' entry.

Can be “vertical” (default) or “horizontal”. When using “horizontal” mode, the PyVista backend must be used and hemi cannot be “split”.

Additional arguments to brain.add_data (e.g., dict(time_label_size=10)).

Additional arguments to the mne.viz.Brain constructor (e.g., dict(silhouette=True)).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

An instance of mne.viz.Brain or matplotlib figure.

Flatmaps are available by default for fsaverage but not for other subjects reconstructed by FreeSurfer. We recommend using mne.compute_source_morph() to morph source estimates to fsaverage for flatmap plotting. If you want to construct your own flatmap for a given subject, these links might help:

https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferOccipitalFlattenedPatch

https://openwetware.org/wiki/Beauchamp:FreeSurfer

Examples using plot_3d:

Plot point-spread functions (PSFs) for a volume

Working with sEEG data

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be “auto” to use a padding that will result in a power-of-two size (can be much faster).

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn(). The default (“auto”) means 'reflect_limited' for method='fft' and 'reflect' for method='polyphase'.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled source estimate.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent – check your data!

Note that the sample rate of the original data is inferred from tstep.

Save the source estimates to a file.

The stem of the file name. The stem is extended with "-vl.stc" or "-vl.w".

File format to use. Allowed values are "stc" (default), "w", and "h5". The "w" format only supports a single time point.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Save a volume source estimate in a NIfTI file.

The name of the generated nifti file.

The list of source spaces (should all be of type volume).

If 'mri' the volume is defined in the coordinate system of the original T1 image. If 'surf' the coordinate system of the FreeSurfer surface is used (Surface RAS).

It True the image is saved in MRI resolution.

Either 'nifti1' (default) or 'nifti2'.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [1] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627–1639, 1964. doi:10.1021/ac60214a047.

Sample rate of the data.

Take the square root.

A copy of the SourceEstimate with sqrt(data).

Make a summary stc file with sum over time points.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

A timestamp for each sample.

Export data in tabular structure as a pandas DataFrame.

Vertices are converted to columns in the DataFrame. By default, an additional column “time” is added, unless index='time' (in which case time values form the DataFrame’s index).

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) — i.e., converts EEG to µV, magnetometers to fT, and gradiometers to fT/cm.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and vertex. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Apply linear transform.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first two dimensions of the transformed data should be (i) vertices and (ii) time. See Notes for details.

Indices of source time courses for which to compute transform. If None, all time courses are used.

First time point to include (ms). If None, self.tmin is used.

Last time point to include (ms). If None, self.tmax is used.

If True, return a new instance of SourceEstimate instead of modifying the input inplace.

The transformed stc or, in the case of transforms which yield N-dimensional output (where N > 2), a list of stcs. For a list, copy must be True.

Transforms which yield 3D output (e.g. time-frequency transforms) are valid, so long as the first two dimensions are vertices and time. In this case, the copy parameter must be True and a list of SourceEstimates, rather than a single instance of SourceEstimate, will be returned, one for each index of the 3rd dimension of the transformed data. In the case of transforms yielding 2D output (e.g. filtering), the user has the option of modifying the input inplace (copy = False) or returning a new instance of SourceEstimate (copy = True) with the transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

Get data after a linear (time) transform has been applied.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first return value is the transformed data, remaining outputs are ignored. The first dimension of the transformed data has to be the same as the first dimension of the input data.

Indicices of source time courses for which to compute transform. If None, all time courses are used.

Index of first time point to include. If None, the index of the first time point is used.

Index of the first time point not to include. If None, time points up to (and including) the last time point are included.

The transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

The change in time between two consecutive samples (1 / sfreq).

Compute MNE-dSPM inverse solution on evoked data in volume source space

Morph volumetric source estimate

Computing source timecourses with an XFit-like multi-dipole model

Plot point-spread functions (PSFs) for a volume

Working with sEEG data

Source localization with equivalent current dipole (ECD) fit

Source reconstruction using an LCMV beamformer

Visualize source time courses (stcs)

mne.VectorSourceEstimate

mne.VolVectorSourceEstimate

---

## mne.VolVectorSourceEstimate#

**URL:** https://mne.tools/stable/generated/mne.VolVectorSourceEstimate.html

**Contents:**
- mne.VolVectorSourceEstimate#

Container for volume source estimates.

The data in source space. Each dipole contains three vectors that denote the dipole strength in X, Y and Z directions over time.

The indices of the dipoles in the source space. Should be a single array of shape (n_dipoles,) unless there are subvolumes.

Time point of the first sample in data.

Time step between successive samples in data.

The FreeSurfer subject name. While not necessary, it is safer to set the subject parameter to avoid analysis errors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A timestamp for each sample.

The indices of the dipoles in the source space. Should be a single array of shape (n_dipoles,) unless there are subvolumes.

Numpy array of source estimate data.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

apply_baseline([baseline, verbose])

Baseline correct source estimate data.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of vertices.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

as_volume(src[, dest, mri_resolution, format])

Export volume source estimate as a nifti object.

bin(width[, tstart, tstop, func])

Return a source estimate object with data summarized over time bins.

Return copy of source estimate instance.

crop([tmin, tmax, include_tmax])

Restrict SourceEstimate to a time interval.

extract_label_time_course(labels, src[, ...])

Extract label time courses for lists of labels.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_peak([tmin, tmax, mode, vert_as_index, ...])

Get location and latency of peak amplitude.

in_label(label, mri, src, *[, verbose])

Get a source estimate object restricted to a label.

Compute magnitude of activity without directionality.

Make a summary stc file with mean over time points.

plot(src[, subject, subjects_dir, mode, ...])

Plot Nutmeg style volumetric source estimates using nilearn.

plot_3d([subject, hemi, colormap, ...])

Plot VectorSourceEstimate with PyVista.

project(directions[, src, use_cps])

Project the data for each vertex in a given direction.

resample(sfreq, *[, npad, method, window, ...])

save(fname[, ftype, overwrite, verbose])

Save the full source estimate to an HDF5 file.

save_as_volume(fname, src[, dest, ...])

Save a volume source estimate in a NIfTI file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

Take the square root.

Make a summary stc file with sum over time points.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

transform(func[, idx, tmin, tmax, copy])

Apply linear transform.

transform_data(func[, idx, tmin_idx, tmax_idx])

Get data after a linear (time) transform has been applied.

A container for surface source estimates.

A container for vector surface source estimates.

A container for volume source estimates.

A container for mixed surface + volume source estimates.

Add source estimates.

Divide source estimates.

Multiply source estimates.

Negate the source estimate.

Subtract source estimates.

Baseline correct source estimate data.

The time interval to consider as “baseline” when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each source individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire source estimate data.

Baseline correction is appropriate when signal and noise are approximately additive, and the noise level can be estimated from the baseline interval. This can be the case for non-normalized source activities (e.g. signed and unsigned MNE), but it is not the case for normalized estimates (e.g. signal-to-noise ratios, dSPM, sLORETA).

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected source estimate object.

Baseline correction can be done multiple times.

Apply a function to a subset of vertices.

The function fun is applied to the vertices defined in picks. The source estimate object’s data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to vertices in picks).

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) because it will apply vertex-wise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if vertice_wise=False as the workload is split across vertices.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The SourceEstimate object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‘auto’, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal “x_a(t)” of “x(t)” is:

where “F” is the Fourier transform, “U” the unit step function, and “y” the Hilbert transform of “x”. One usage of the analytic signal is the computation of the envelope signal, which is given by “e(t) = abs(x_a(t))”. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Export volume source estimate as a nifti object.

The source spaces (should all be of type volume, or part of a mixed source space).

If 'mri' the volume is defined in the coordinate system of the original T1 image. If ‘surf’ the coordinate system of the FreeSurfer surface is used (Surface RAS).

It True the image is saved in MRI resolution.

Either ‘nifti1’ (default) or ‘nifti2’.

Return a source estimate object with data summarized over time bins.

Time bins of width seconds. This method is intended for visualization only. No filter is applied to the data before binning, making the method inappropriate as a tool for downsampling data.

Width of the individual bins in seconds.

Time point where the first bin starts. The default is the first time point of the stc.

Last possible time point contained in a bin (if the last bin would be shorter than width it is dropped). The default is the last time point of the stc.

Function that is applied to summarize the data. Needs to accept a numpy.array as first input and an axis keyword argument.

The binned source estimate.

Return copy of source estimate instance.

A copy of the source estimate.

Restrict SourceEstimate to a time interval.

The first time point in seconds. If None the first present is used.

The last time point in seconds. If None the last present is used.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The cropped source estimate.

Numpy array of source estimate data.

Extract label time courses for lists of labels.

This function will extract one time course for each label. The way the time courses are extracted depends on the mode parameter.

If using a surface or mixed source space, this should be the Label’s for which to extract the time course. If working with whole-brain volume source estimates, this must be one of:

a string path to a FreeSurfer atlas for the subject (e.g., their ‘aparc.a2009s+aseg.mgz’) to extract time courses for all volumes in the atlas

a two-element list or tuple, the first element being a path to an atlas, and the second being a list or dict of volume_labels to extract (see mne.setup_volume_source_space() for details).

Changed in version 0.21.0: Support for volume source estimates.

The source spaces for the source time courses.

Extraction mode, see Notes.

False (default) will emit an error if there are labels that have no vertices in the source estimate. True and 'ignore' will return all-zero time courses for labels that do not have any vertices in the source estimate, and True will emit a warning while and “ignore” will just log a message.

Changed in version 0.21.0: Support for “ignore”.

If True (default), the volume source space will be upsampled to the original MRI resolution via trilinear interpolation before the atlas values are extracted. This ensnures that each atlas label will contain source activations. When False, only the original source space points are used, and some atlas labels thus may not contain any source space vertices.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Extracted time course for each label and source estimate.

Extract time courses for multiple STCs.

Valid values for mode are:

Maximum absolute value across vertices at each time point within each label.

Average across vertices at each time point within each label. Ignores orientation of sources for standard source estimates, which varies across the cortical surface, which can lead to cancellation. Vector source estimates are always in XYZ / RAS orientation, and are thus already geometrically aligned.

Finds the dominant direction of source space normal vector orientations within each label, applies a sign-flip to time series at vertices whose orientation is more than 90° different from the dominant direction, and then averages across vertices at each time point within each label.

Applies singular value decomposition to the time courses within each label, and uses the first right-singular vector as the representative label time course. This signal is scaled so that its power matches the average (per-vertex) power within the label, and sign-flipped by multiplying by np.sign(u @ flip), where u is the first left-singular vector and flip is the same sign-flip vector used when mode='mean_flip'. This sign-flip ensures that extracting time courses from the same label in similar STCs does not result in 180° direction/phase changes.

Uses 'mean_flip' when a standard source estimate is applied, and 'mean' when a vector source estimate is supplied.

No aggregation is performed, and an array of shape (n_vertices, n_times) is returned.

New in v0.21: Support for 'auto', vector, and volume source estimates.

The only modes that work for vector and volume source estimates are 'mean', 'max', and 'auto'.

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).

str: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=”firwin”, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.

Can be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Get location and latency of peak amplitude.

The minimum point in time to be considered for peak getting.

The maximum point in time to be considered for peak getting.

How to deal with the sign of the data. If ‘pos’ only positive values will be considered. If ‘neg’ only negative values will be considered. If ‘abs’ absolute values will be considered. Defaults to ‘abs’.

Whether to return the vertex index (True) instead of of its ID (False, default).

Whether to return the time index (True) instead of the latency (False, default).

The vertex exhibiting the maximum response, either ID or index.

The latency in seconds.

Get a source estimate object restricted to a label.

SourceEstimate contains the time course of activation of all sources inside the label.

The label to use. Can be the name of a label if using a standard FreeSurfer atlas, or an integer value to extract from the mri.

Path to the atlas to use.

The volumetric source space. It must be a single, whole-brain volume.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimate restricted to the given label.

Compute magnitude of activity without directionality.

The source estimate without directionality information.

Make a summary stc file with mean over time points.

Plot Nutmeg style volumetric source estimates using nilearn.

The source space. Can also be a SourceMorph to morph the STC to a new subject (see Examples).

Changed in version 0.18: Support for SpatialImage.

The FreeSurfer subject name. If None, stc.subject will be used.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

The plotting mode to use. For 'glass_brain', activation absolute values are displayed after being transformed to a standard MNI brain.

The background image used in the nilearn plotting function. Can also be a string to use the bg_img file in the subject’s MRI directory (default is 'T1.mgz'). Not used in “glass brain” plotting.

If True, display a colorbar on the right of the plots.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bounds for colormap.

Lower, middle, and upper bound for colormap. Positive values will be mirrored directly across zero during colormap construction to obtain negative control points.

Only one of lims or pos_lims should be provided. Only sequential colormaps should be used with lims, and only divergent colormaps should be used with pos_lims.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Show figures if True. Defaults to True.

The initial time to plot. Can be None (default) to use the time point with the maximal absolute value activation across all voxels or the initial_pos voxel (if initial_pos is None or not, respectively).

The initial position to use (in m). Can be None (default) to use the voxel with the maximum absolute value activation across all time points or at initial_time (if initial_time is None or not, respectively).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Click on any of the anatomical slices to explore the time series. Clicking on any time point will bring up the corresponding anatomical map.

The left and right arrow keys can be used to navigate in time. To move in time by larger steps, use shift+left and shift+right.

In 'glass_brain' mode, values are transformed to the standard MNI brain using the FreeSurfer Talairach transformation $SUBJECTS_DIR/$SUBJECT/mri/transforms/talairach.xfm.

Changed in version 0.19: MRI volumes are automatically transformed to MNI space in 'glass_brain' mode.

Passing a mne.SourceMorph as the src parameter can be useful for plotting in a different subject’s space (here, a 'sample' STC in 'fsaverage'’s space):

Plot VectorSourceEstimate with PyVista.

A “glass brain” is drawn and all dipoles defined in the source estimate are shown using arrows, depicting the direction and magnitude of the current moment at the dipole. Additionally, an overlay is plotted on top of the cortex with the magnitude of the current.

The FreeSurfer subject name. If None, stc.subject will be used.

The hemisphere to display.

Name of colormap to use or a custom look up table. If array, must be (n x 3) or (n x 4) array for with RGB or RGBA values between 0 and 255. This should be a sequential colormap.

Format of the time label (a format string, a function that maps floating point time values to strings, or None for no label). The default is 'auto', which will use time=%0.2f ms if there is more than one time point.

The amount of smoothing.

If True: use a linear transparency between fmin and fmid and make values below fmin fully transparent (symmetrically for divergent colormaps). None will choose automatically based on colormap type.

Alpha value to apply globally to the surface meshes. Defaults to 0.4.

Alpha value to apply globally to the overlay. Defaults to brain_alpha.

Alpha value to apply globally to the vector glyphs. Defaults to 1.

Scaling factor for the vector glyphs. By default, an attempt is made to automatically determine a sane value.

Display time viewer GUI. Can be “auto”, which is True for the PyVista backend and False otherwise.

Changed in version 0.20: Added “auto” option and default.

The path to the freesurfer subjects reconstructions. It corresponds to Freesurfer environment variable SUBJECTS_DIR.

If None, a new figure will be created. If multiple views or a split view is requested, this must be a list of the appropriate length. If int is provided it will be used to identify the PyVista figure by it’s id or create a new figure with the given id.

View to use. Using multiple views (list) is not supported for mpl backend. See Brain.show_view for valid string options.

If True, display colorbar on scene.

Colorbar properties specification. If ‘auto’, set clim automatically based on data percentiles. If dict, should contain:

Flag to specify type of limits.

Lower, middle, and upper bound for colormap.

Unlike stc.plot, it cannot use pos_lims, as the surface plot must show the magnitude.

Specifies how binarized curvature values are rendered. either the name of a preset Brain cortex colorscheme (one of ‘classic’, ‘bone’, ‘low_contrast’, or ‘high_contrast’), or the name of a colormap, or a tuple with values (colormap, min, max, reverse) to fully specify the curvature colors.

The size of the window, in pixels. can be one number to specify a square window, or the (width, height) of a rectangular window.

Color of the background of the display window.

Color of the foreground of the display window. None will choose black or white based on the background color.

The time to display on the plot initially. None to display the first time sample (default).

Whether time is represented in seconds (“s”, default) or milliseconds (“ms”).

Title for the figure window. If None, the subject name will be used.

If True, enable interactive picking of a point on the surface of the brain and plot its time course. This feature is only available with the PyVista 3d backend, and requires time_viewer=True. Defaults to ‘auto’, which will use True if and only if time_viewer=True, the backend is PyVista, and there is more than one time point. If float (between zero and one), it specifies what proportion of the total window should be devoted to traces (True is equivalent to 0.25, i.e., it will occupy the bottom 1/4 of the figure).

The source space corresponding to the source estimate. Only necessary if the STC is a volume or mixed source estimate.

Options for volumetric source estimate plotting, with key/value pairs:

Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks better at the cost of speed. None (default) uses the volume source space resolution, which is often something like 7 or 5 mm, without resampling.

Can be “mip” (default) for maximum intensity projection or “composite” for composite blending using alpha values.

Alpha for the volumetric rendering. Defaults are 0.4 for vector source estimates and 1.0 for scalar source estimates.

Alpha for the surface enclosing the volume(s). None (default) will use half the volume alpha. Set to zero to avoid plotting the surface.

Alpha for a silhouette along the outside of the volume. None (default) will use 0.25 * surface_alpha.

The line width to use for the silhouette. Default is 2.

A float input (default 1.) or None will be used for the 'resolution' entry.

Can be “vertical” (default) or “horizontal”. When using “horizontal” mode, the PyVista backend must be used and hemi cannot be “split”.

Additional arguments to brain.add_data (e.g., dict(time_label_size=10)).

Additional arguments to the mne.viz.Brain constructor (e.g., dict(silhouette=True)).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A instance of mne.viz.Brain.

If the current magnitude overlay is not desired, set overlay_alpha=0 and smoothing_steps=1.

Project the data for each vertex in a given direction.

Project onto the source space normals.

SVD will be used to project onto the direction of maximal power for each source.

Projection directions for each source.

The source spaces corresponding to the source estimate. Not used when directions is an array, optional when directions='pca'.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True). Should be the same value that was used when the forward model was computed (typically True).

The projected source estimate.

The directions that were computed (or just used).

When using SVD, there is a sign ambiguity for the direction of maximal power. When src is None, the direction is chosen that makes the resulting time waveform sum positive (i.e., have positive amplitudes). When src is provided, the directions are flipped in the direction of the source normals, i.e., outward from cortex for surface source spaces and in the +Z / superior direction for volume source spaces.

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be “auto” to use a padding that will result in a power-of-two size (can be much faster).

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn(). The default (“auto”) means 'reflect_limited' for method='fft' and 'reflect' for method='polyphase'.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled source estimate.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent – check your data!

Note that the sample rate of the original data is inferred from tstep.

Save the full source estimate to an HDF5 file.

The file name to write the source estimate to, should end in '-stc.h5'.

File format to use. Currently, the only allowed values is "h5".

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Save a volume source estimate in a NIfTI file.

The name of the generated nifti file.

The list of source spaces (should all be of type volume).

If 'mri' the volume is defined in the coordinate system of the original T1 image. If 'surf' the coordinate system of the FreeSurfer surface is used (Surface RAS).

It True the image is saved in MRI resolution.

Either 'nifti1' (default) or 'nifti2'.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [1] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627–1639, 1964. doi:10.1021/ac60214a047.

Sample rate of the data.

Take the square root.

A copy of the SourceEstimate with sqrt(data).

Make a summary stc file with sum over time points.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

A timestamp for each sample.

Export data in tabular structure as a pandas DataFrame.

Vertices are converted to columns in the DataFrame. By default, an additional column “time” is added, unless index='time' (in which case time values form the DataFrame’s index).

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) — i.e., converts EEG to µV, magnetometers to fT, and gradiometers to fT/cm.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and vertex. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Apply linear transform.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first two dimensions of the transformed data should be (i) vertices and (ii) time. See Notes for details.

Indices of source time courses for which to compute transform. If None, all time courses are used.

First time point to include (ms). If None, self.tmin is used.

Last time point to include (ms). If None, self.tmax is used.

If True, return a new instance of SourceEstimate instead of modifying the input inplace.

The transformed stc or, in the case of transforms which yield N-dimensional output (where N > 2), a list of stcs. For a list, copy must be True.

Transforms which yield 3D output (e.g. time-frequency transforms) are valid, so long as the first two dimensions are vertices and time. In this case, the copy parameter must be True and a list of SourceEstimates, rather than a single instance of SourceEstimate, will be returned, one for each index of the 3rd dimension of the transformed data. In the case of transforms yielding 2D output (e.g. filtering), the user has the option of modifying the input inplace (copy = False) or returning a new instance of SourceEstimate (copy = True) with the transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

Get data after a linear (time) transform has been applied.

The transform is applied to each source time course independently.

The transform to be applied, including parameters (see, e.g., functools.partial()). The first parameter of the function is the input data. The first return value is the transformed data, remaining outputs are ignored. The first dimension of the transformed data has to be the same as the first dimension of the input data.

Indicices of source time courses for which to compute transform. If None, all time courses are used.

Index of first time point to include. If None, the index of the first time point is used.

Index of the first time point not to include. If None, time points up to (and including) the last time point are included.

The transformed data.

Applying transforms can be significantly faster if the SourceEstimate object was created using “(kernel, sens_data)”, for the “data” parameter as the transform is applied in sensor space. Inverse methods, e.g., “apply_inverse_epochs”, or “apply_lcmv_epochs” do this automatically (if possible).

The change in time between two consecutive samples (1 / sfreq).

mne.VolSourceEstimate

---

## mne.what#

**URL:** https://mne.tools/stable/generated/mne.what.html

**Contents:**
- mne.what#

Try to determine the type of the FIF file.

The filename. Should end in .fif or .fif.gz.

The type of the file. Will be ‘unknown’ if it could not be determined.

---

## mne.write_bem_solution#

**URL:** https://mne.tools/stable/generated/mne.write_bem_solution.html

**Contents:**
- mne.write_bem_solution#

Write a BEM model with solution.

The filename to use. Can end with .h5 to write using HDF5.

The BEM model with solution to save.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.write_labels_to_annot

mne.write_bem_surfaces

---

## mne.write_bem_surfaces#

**URL:** https://mne.tools/stable/generated/mne.write_bem_surfaces.html

**Contents:**
- mne.write_bem_surfaces#

Write BEM surfaces to a FIF file.

Filename to write. Can end with .h5 to write using HDF5.

The surfaces, or a single surface.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.write_bem_solution

---

## mne.write_cov#

**URL:** https://mne.tools/stable/generated/mne.write_cov.html

**Contents:**
- mne.write_cov#

Write a noise covariance matrix.

The name of the file. It should end with -cov.fif or -cov.fif.gz.

The noise covariance matrix.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

---

## mne.write_events#

**URL:** https://mne.tools/stable/generated/mne.write_events.html

**Contents:**
- mne.write_events#

Write events to file.

Name of the output file. If the extension is .fif, events are written in binary FIF format, otherwise (e.g., .eve, .lst, .txt) events are written as plain text. Note that new format event files do not contain the "time" column (used to be the second column).

The identity and timing of experimental events, around which the epochs were created. See events for more information.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

---

## mne.write_forward_solution#

**URL:** https://mne.tools/stable/generated/mne.write_forward_solution.html

**Contents:**
- mne.write_forward_solution#

Write forward solution to a file.

File name to save the forward solution to. It should end with -fwd.fif or -fwd.fif.gz to save to FIF, or -fwd.h5 to save to HDF5.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Forward solutions, which are derived from an original forward solution with free orientation, are always stored on disk as forward solution with free orientation in X/Y/Z RAS coordinates. Transformations (surface orientation, fixed orientation) will be reverted. To reapply any transformation to the forward operator please apply convert_forward_solution() after reading the forward solution with read_forward_solution().

Forward solutions, which are derived from an original forward solution with fixed orientation, are stored on disk as forward solution with fixed surface-based orientations. Please note that the transformation to surface-based, fixed orientation cannot be reverted after loading the forward solution with read_forward_solution().

---

## mne.write_head_bem#

**URL:** https://mne.tools/stable/generated/mne.write_head_bem.html

**Contents:**
- mne.write_head_bem#
- Examples using mne.write_head_bem#

Write a head surface to a FIF file.

Coordinate points in the MRI coordinate system.

Triangulation (each line contains indices for three points which together form a face).

What to do if the surface is found to have topological defects. Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when one or more defects are found. Note that a lot of computations in MNE-Python assume the surfaces to be topologically correct, topological defects may still make other computations (e.g., mne.make_bem_model and mne.make_bem_solution) fail irrespective of this parameter.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Fixing BEM and head surfaces

mne.write_bem_surfaces

---

## mne.write_labels_to_annot#

**URL:** https://mne.tools/stable/generated/mne.write_labels_to_annot.html

**Contents:**
- mne.write_labels_to_annot#

Create a FreeSurfer annotation from a list of labels.

The labels to create a parcellation from.

The FreeSurfer subject name.

The parcellation name to use.

Overwrite files if they already exist.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Filename of the .annot file. If not None, only this file is written and the arguments parc and subject are ignored.

Colormap to use to generate label colors for labels that do not have a color specified.

The hemisphere(s) for which to write *.annot files (only applies if annot_fname is not specified; default is ‘both’).

If True (default), labels will be sorted by name before writing.

The table name to use for the colortable.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Vertices that are not covered by any of the labels are assigned to a label named "unknown".

mne.write_bem_solution

---

## mne.write_label#

**URL:** https://mne.tools/stable/generated/mne.write_label.html

**Contents:**
- mne.write_label#

Write a FreeSurfer label.

Path to label file to produce.

The label object to save.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Note that due to file specification limitations, the Label’s subject and color attributes are not saved to disk.

mne.write_forward_solution

---

## mne.write_proj#

**URL:** https://mne.tools/stable/generated/mne.write_proj.html

**Contents:**
- mne.write_proj#

Write projections to a FIF file.

The name of file containing the projections vectors. It should end with -proj.fif or -proj.fif.gz.

The list of projection vectors.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.write_source_spaces

---

## mne.write_source_spaces#

**URL:** https://mne.tools/stable/generated/mne.write_source_spaces.html

**Contents:**
- mne.write_source_spaces#

Write source spaces to a file.

The name of the file, which should end with -src.fif or -src.fif.gz.

The source spaces (as returned by read_source_spaces).

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

---

## mne.write_surface#

**URL:** https://mne.tools/stable/generated/mne.write_surface.html

**Contents:**
- mne.write_surface#
- Examples using mne.write_surface#

Write a triangular Freesurfer surface mesh.

Accepts the same data format as is returned by read_surface().

Triangulation (each line contains indices for three points which together form a face).

Comment that is written to the beginning of the file. Can not contain line breaks.

Key-value pairs to encode at the end of the file. Valid keys:

‘head’ : array of int

‘volume’ : array of int, shape (3,)

‘voxelsize’ : array of float, shape (3,)

‘xras’ : array of float, shape (3,)

‘yras’ : array of float, shape (3,)

‘zras’ : array of float, shape (3,)

‘cras’ : array of float, shape (3,)

File format to use. Can be ‘freesurfer’ to write a FreeSurfer surface file, or ‘obj’ to write a Wavefront .obj file (common format for importing in other software), or ‘auto’ to attempt to infer from the file name. Defaults to ‘auto’.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Fixing BEM and head surfaces

mne.write_source_spaces

---

## mne.write_trans#

**URL:** https://mne.tools/stable/generated/mne.write_trans.html

**Contents:**
- mne.write_trans#

Write a transformation FIF file.

The name of the file, which should end in -trans.fif.

Trans file data, as returned by read_trans.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

---

## MNE-Python Homepage#

**URL:** https://mne.tools/stable/

**Contents:**
- MNE-Python Homepage#

Open-source Python package for exploring, visualizing, and analyzing human neurophysiological data: MEG, EEG, sEEG, ECoG, NIRS, and more.

Distributed, sparse, mixed-norm, beam­formers, dipole fitting, and more.

Advanced decoding models including time general­iza­tion.

Receptive field estima­tion with optional smooth­ness priors.

Parametric and non-parametric, permutation tests and clustering.

All-to-all spectral and effective connec­tivity measures.

Explore your data from multiple perspectives.

Supporting institutions

Installing MNE-Python

---

## MNE-Report#

**URL:** https://mne.tools/stable/api/report.html

**Contents:**
- MNE-Report#

Report([info_fname, subjects_dir, subject, ...])

Object for rendering HTML.

open_report(fname, **params)

Read a saved report or, if it doesn't exist yet, create a new one.

---

## MRI Processing#

**URL:** https://mne.tools/stable/api/mri.html

**Contents:**
- MRI Processing#

Step by step instructions for using gui.coregistration():

Coregistration for subjects with structural MRI

Scaling a template MRI for subjects for which no MRI is available

mne_gui_addons.locate_ieeg().

coreg.get_mni_fiducials(subject[, ...])

Estimate fiducials for a subject.

coreg.estimate_head_mri_t(subject[, ...])

Estimate the head->mri transform from fsaverage fiducials.

io.read_fiducials(fname, *[, verbose])

Read fiducials from a fiff file.

io.write_fiducials(fname, pts[, ...])

Write fiducials to a fiff file.

get_montage_volume_labels(montage, subject)

Get regions of interest near channels from a Freesurfer parcellation.

gui.coregistration(*[, width, height, inst, ...])

Coregister an MRI with a subject's head shape.

create_default_subject([fs_home, update, ...])

Create an average brain subject for subjects without structural MRI.

head_to_mni(pos, subject, mri_head_t[, ...])

Convert pos from head coordinate system to MNI ones.

head_to_mri(pos, subject, mri_head_t[, ...])

Convert pos from head coordinate system to MRI ones.

read_freesurfer_lut([fname])

Read a Freesurfer-formatted LUT.

read_lta(fname[, verbose])

Read a Freesurfer linear transform array file.

read_talxfm(subject[, subjects_dir, verbose])

Compute MRI-to-MNI transform from FreeSurfer talairach.xfm file.

scale_mri(subject_from, subject_to, scale[, ...])

Create a scaled copy of an MRI subject.

scale_bem(subject_to, bem_name[, ...])

scale_labels(subject_to[, pattern, ...])

Scale labels to match a brain that was previously created by scaling.

scale_source_space(subject_to, src_name[, ...])

Scale a source space for an mri created with scale_mri().

transforms.apply_volume_registration(moving, ...)

Apply volume registration.

transforms.apply_volume_registration_points(...)

Apply volume registration.

transforms.compute_volume_registration(...)

Align two volumes using an affine and, optionally, SDR.

vertex_to_mni(vertices, hemis, subject[, ...])

Convert the array of vertices for a hemisphere to MNI coordinates.

coreg.Coregistration(info, subject[, ...])

Class for MRI<->head coregistration.

mne.coreg.get_mni_fiducials

---

## Python API Reference#

**URL:** https://mne.tools/stable/api/python_reference.html

**Contents:**
- Python API Reference#

This is the reference for classes (CamelCase names) and functions (underscore_case names) of MNE-Python, grouped thematically by analysis stage. Functions and classes that are not below a module heading are found in the mne namespace.

MNE-Python also provides multiple command-line scripts that can be called directly from a terminal, see Command line tools using Python.

MNE software for MEG and EEG data analysis.

Papers citing MNE-Python

---

## Reading raw data#

**URL:** https://mne.tools/stable/api/reading_raw_data.html

**Contents:**
- Reading raw data#

IO module for reading raw data.

anonymize_info(info[, daysback, keep_his, ...])

Anonymize measurement information in place.

read_raw(fname, *[, preload, verbose])

read_raw_ant(fname[, eog, misc, bipolars, ...])

Reader for Raw ANT files in .cnt format.

read_raw_artemis123(input_fname[, preload, ...])

Read Artemis123 data as raw object.

read_raw_bdf(input_fname[, eog, misc, ...])

Reader function for BDF files.

read_raw_boxy(fname[, preload, verbose])

Reader for an optical imaging recording.

read_raw_brainvision(vhdr_fname[, eog, ...])

Reader for Brain Vision EEG file.

read_raw_bti(pdf_fname[, config_fname, ...])

Raw object from 4D Neuroimaging MagnesWH3600 data.

read_raw_cnt(input_fname[, eog, misc, ecg, ...])

Read CNT data as raw object.

read_raw_ctf(directory[, system_clock, ...])

Raw object from CTF directory.

read_raw_curry(fname[, preload, ...])

Read raw data from Curry files.

read_raw_edf(input_fname[, eog, misc, ...])

Reader function for EDF and EDF+ files.

read_raw_eeglab(input_fname[, eog, preload, ...])

Read an EEGLAB .set file.

read_raw_egi(input_fname[, eog, misc, ...])

Read EGI simple binary as raw object.

read_raw_eximia(fname[, preload, verbose])

Reader for an eXimia EEG file.

read_raw_eyelink(fname, *[, ...])

Reader for an Eyelink .asc file.

read_raw_fieldtrip(fname, info[, data_name])

Load continuous (raw) data from a FieldTrip preprocessing structure.

read_raw_fif(fname[, allow_maxshield, ...])

Reader function for Raw FIF data.

read_raw_fil(binfile[, precision, preload, ...])

Raw object from FIL-OPMEG formatted data.

read_raw_gdf(input_fname[, eog, misc, ...])

Reader function for GDF files.

read_raw_hitachi(fname[, preload, verbose])

Reader for a Hitachi fNIRS recording.

read_raw_kit(input_fname[, mrk, elp, hsp, ...])

Reader function for Ricoh/KIT conversion to FIF.

read_raw_nedf(filename[, preload, verbose])

Read NeuroElectrics .nedf files.

read_raw_nicolet(input_fname, ch_type[, ...])

Read Nicolet data as raw object.

read_raw_nihon(fname[, preload, encoding, ...])

Reader for an Nihon Kohden EEG file.

read_raw_nirx(fname[, saturated, preload, ...])

Reader for a NIRX fNIRS recording.

read_raw_nsx(input_fname[, stim_channel, ...])

Reader function for NSx (Blackrock Microsystems) files.

read_raw_neuralynx(fname, *[, preload, ...])

Reader for Neuralynx files.

read_raw_persyst(fname[, preload, verbose])

Reader for a Persyst (.lay/.dat) recording.

read_raw_snirf(fname[, optode_frame, sfreq, ...])

Reader for a continuous wave SNIRF data.

BaseRaw(info[, preload, first_samps, ...])

Base class for Raw data.

KIT module for reading raw data.

Marker Point Extraction in MEG space directly from sqd.

mne.io.anonymize_info

---

## Realtime#

**URL:** https://mne.tools/stable/api/realtime.html

**Contents:**
- Realtime#

Realtime functionality has moved to the standalone module MNE-LSL.

mne.decoding.get_spatial_filter_from_estimator

---

## Sensor Space Data#

**URL:** https://mne.tools/stable/api/sensor_space.html

**Contents:**
- Sensor Space Data#

combine_evoked(all_evoked, weights)

Merge evoked data by weighted addition or subtraction.

concatenate_raws(raws[, preload, ...])

Concatenate Raw instances as if they were continuous.

equalize_channels(instances[, copy, verbose])

Equalize channel picks and ordering across multiple MNE-Python objects.

grand_average(all_inst[, interpolate_bads, ...])

Make grand average of a list of Evoked, AverageTFR, or Spectrum data.

match_channel_orders(insts[, copy])

Ensure consistent channel order across instances (Raw, Epochs, or Evoked).

pick_channels(ch_names, include[, exclude, ...])

Pick channels by names.

pick_channels_cov(orig[, include, exclude, ...])

Pick channels from covariance matrix.

pick_channels_forward(orig[, include, ...])

Pick channels from forward operator.

pick_channels_regexp(ch_names, regexp)

Pick channels using regular expression.

pick_types(info[, meg, eeg, stim, eog, ecg, ...])

Pick channels by type and names.

pick_types_forward(orig[, meg, eeg, ...])

Pick by channel type and names from a forward operator.

pick_info(info[, sel, copy, verbose])

Restrict an info structure to a selection of channels.

read_epochs(fname[, proj, preload, verbose])

Read epochs from a fif file.

read_reject_parameters(fname)

Read rejection parameters from .cov or .ave config file.

read_vectorview_selection(name[, fname, ...])

Read Neuromag Vector View channel selection from a file.

rename_channels(info, mapping[, ...])

Utility functions to baseline-correct data.

rescale(data, times, baseline[, mode, copy, ...])

Rescale (baseline correct) data.

mne.epochs.make_metadata

---

## Simulation#

**URL:** https://mne.tools/stable/api/simulation.html

**Contents:**
- Simulation#

Data simulation code.

add_chpi(raw[, head_pos, interp, n_jobs, ...])

Add cHPI activations to raw data.

add_ecg(raw[, head_pos, interp, n_jobs, ...])

Add ECG noise to raw data.

add_eog(raw[, head_pos, interp, n_jobs, ...])

Add blink noise to raw data.

add_noise(inst, cov[, iir_filter, ...])

Create noise as a multivariate Gaussian.

simulate_evoked(fwd, stc, info[, cov, nave, ...])

Generate noisy evoked data.

simulate_raw(info[, stc, trans, src, bem, ...])

simulate_stc(src, labels, stc_data, tmin, tstep)

Simulate sources time courses from waveforms and labels.

simulate_sparse_stc(src, n_dipoles, times[, ...])

Generate sparse (n_dipoles) sources time courses from data_fun.

select_source_in_label(src, label[, ...])

Select source positions using a label.

SourceSimulator(src[, tstep, duration, ...])

Class to generate simulated Source Estimates.

mne.simulation.metrics:

Metrics module for compute stc-based metrics.

cosine_score(stc_true, stc_est[, per_sample])

Compute cosine similarity between 2 source estimates.

region_localization_error(stc_true, stc_est, src)

Compute region localization error (RLE) between 2 source estimates.

f1_score(stc_true, stc_est[, threshold, ...])

Compute the F1 score, also known as balanced F-score or F-measure.

precision_score(stc_true, stc_est[, ...])

Compute the precision.

recall_score(stc_true, stc_est[, threshold, ...])

roc_auc_score(stc_true, stc_est[, per_sample])

Compute ROC AUC between 2 source estimates.

spatial_deviation_error(stc_true, stc_est, src)

Compute the spatial deviation.

peak_position_error(stc_true, stc_est, src)

Compute the peak position error.

mne.spatio_temporal_dist_adjacency

mne.simulation.add_chpi

---

## Source Space Data#

**URL:** https://mne.tools/stable/api/source_space.html

**Contents:**
- Source Space Data#

BiHemiLabel(lh, rh[, name, color])

A freesurfer/MNE label with vertices in both hemispheres.

Label([vertices, pos, values, hemi, ...])

A FreeSurfer/MNE label with vertices restricted to one hemisphere.

MixedSourceEstimate(data[, vertices, tmin, ...])

Container for mixed surface and volume source estimates.

MixedVectorSourceEstimate(data[, vertices, ...])

Container for volume source estimates.

SourceEstimate(data, vertices, tmin, tstep)

Container for surface source estimates.

VectorSourceEstimate(data[, vertices, tmin, ...])

Container for vector surface source estimates.

VolSourceEstimate(data, vertices, tmin, tstep)

Container for volume source estimates.

VolVectorSourceEstimate(data[, vertices, ...])

Container for volume source estimates.

SourceMorph(subject_from, subject_to, kind, ...)

Morph source space data from one subject to another.

compute_source_morph(src[, subject_from, ...])

Create a SourceMorph from one subject to another.

extract_label_time_course(stcs, labels, src)

Extract label time course for lists of labels and source estimates.

grade_to_tris(grade[, verbose])

Get tris defined for a certain grade.

grade_to_vertices(subject, grade[, ...])

Convert a grade to source space vertices for a given subject.

label.select_sources(subject, label[, ...])

Select sources from a label.

grow_labels(subject, seeds, extents, hemis)

Generate circular labels in source space with region growing.

label_sign_flip(label, src)

Compute sign for label averaging.

labels_to_stc(labels, values[, tmin, tstep, ...])

Convert a set of labels and values to a STC.

morph_labels(labels, subject_to[, ...])

Morph a set of labels.

random_parcellation(subject, n_parcel, hemi)

Generate random cortex parcellation by growing labels.

read_labels_from_annot(subject[, parc, ...])

Read labels from a FreeSurfer annotation file.

read_dipole(fname[, verbose])

Read a dipole object from a file.

read_label(filename[, subject, color, verbose])

Read FreeSurfer Label file.

read_source_estimate(fname[, subject])

Read a source estimate object.

read_source_morph(fname)

Load the morph for source estimates from a file.

split_label(label[, parts, subject, ...])

Split a Label into two or more parts.

stc_to_label(stc[, src, smooth, connected, ...])

Compute a label from the non-zero sources in an stc object.

stc_near_sensors(evoked, trans, subject[, ...])

Create a STC from ECoG, sEEG and DBS sensor data.

transform_surface_to(surf, dest, trans[, copy])

Transform surface to the desired coordinate system.

write_labels_to_annot(labels[, subject, ...])

Create a FreeSurfer annotation from a list of labels.

write_label(filename, label[, verbose])

Write a FreeSurfer label.

source_space.compute_distance_to_sensors(...)

Compute distances between vertices and sensors.

source_space.get_decimated_surfaces(src)

Get the decimated surfaces from a source space.

mne.dipole.get_phantom_dipoles

---

## Statistics#

**URL:** https://mne.tools/stable/api/statistics.html

**Contents:**
- Statistics#

Functions for statistical analysis.

Parametric statistics (see scipy.stats and statsmodels for more options):

ttest_1samp_no_p(X[, sigma, method])

Perform one-sample t-test.

ttest_ind_no_p(a, b[, equal_var, sigma])

Independent samples t-test without p calculation.

Perform a 1-way ANOVA.

f_mway_rm(data, factor_levels[, effects, ...])

Compute M-way repeated measures ANOVA for fully balanced designs.

f_threshold_mway_rm(n_subjects, factor_levels)

Compute F-value thresholds for a two-way ANOVA.

linear_regression(inst, design_matrix[, names])

Fit Ordinary Least Squares (OLS) regression.

linear_regression_raw(raw, events[, ...])

Estimate regression-based evoked potentials/fields by linear modeling.

Mass-univariate multiple comparison correction:

bonferroni_correction(pval[, alpha])

P-value correction with Bonferroni method.

fdr_correction(pvals[, alpha, method])

P-value correction with False Discovery Rate (FDR).

Non-parametric (clustering) resampling methods:

combine_adjacency(*structure)

Create a sparse binary adjacency/neighbors matrix.

permutation_cluster_test(X[, threshold, ...])

Cluster-level statistical permutation test.

permutation_cluster_1samp_test(X[, ...])

Non-parametric cluster-level paired t-test.

permutation_t_test(X[, n_permutations, ...])

One sample/paired sample permutation test based on a t-statistic.

spatio_temporal_cluster_test(X[, threshold, ...])

Non-parametric cluster-level test for spatio-temporal data.

spatio_temporal_cluster_1samp_test(X[, ...])

Non-parametric cluster-level paired t-test for spatio-temporal data.

summarize_clusters_stc(clu[, p_thresh, ...])

Assemble summary SourceEstimate from spatiotemporal cluster results.

bootstrap_confidence_interval(arr[, ci, ...])

Get confidence intervals from non-parametric bootstrap.

ERP-related statistics:

erp.compute_sme(epochs[, start, stop])

Compute standardized measurement error (SME).

Compute adjacency matrices for cluster-level statistics:

channels.find_ch_adjacency(info, ch_type)

Find the adjacency matrix for the given channels.

channels.read_ch_adjacency(fname[, picks])

Read a channel adjacency ("neighbors") file that ships with MNE.

spatial_dist_adjacency(src, dist[, verbose])

Compute adjacency from distances in a source space.

spatial_src_adjacency(src[, dist, verbose])

Compute adjacency for a source space activation.

spatial_tris_adjacency(tris[, ...])

Compute adjacency from triangles.

spatial_inter_hemi_adjacency(src, dist[, ...])

Get vertices on each hemisphere that are close to the other hemisphere.

spatio_temporal_src_adjacency(src, n_times)

Compute adjacency for a source space activation over time.

spatio_temporal_tris_adjacency(tris, n_times)

Compute adjacency from triangles and time instants.

spatio_temporal_dist_adjacency(src, n_times, ...)

Compute adjacency from distances in a source space and time instants.

Connectivity Estimation

mne.stats.ttest_1samp_no_p

---

## The typical M/EEG workflow#

**URL:** https://mne.tools/stable/documentation/cookbook.html

**Contents:**
- The typical M/EEG workflow#
- Overview#
- Preprocessing#
  - Marking bad channels#
  - Artifact suppression#
    - SSP#
    - ICA#
- Epoching and evoked data#
  - Rejection using annotations#
- Source localization#

This section describes a typical MEG/EEG workflow, eventually up to source reconstruction. The workflow is summarized in Workflow of the MNE software. References below refer to Python functions and objects.

Workflow of the MNE software#

The following MEG and EEG data preprocessing steps are recommended:

Bad channels in the MEG and EEG data must be identified, see Marking bad channels.

The data has to be filtered to the desired passband.

Artifacts should be suppressed (e.g., using ICA or SSP).

Sometimes some MEG or EEG channels are not functioning properly for various reasons. These channels should be excluded from analysis by marking them bad as:

Especially if a channel does not show a signal at all (flat) it is important to exclude it from the analysis, since its noise estimate will be unrealistically low and thus the current estimate calculations will give a strong weight to the zero signal on the flat channels and will essentially vanish. It is also important to exclude noisy channels because they can possibly affect others when signal-space projections or EEG average electrode reference is employed. Noisy bad channels can also adversely affect averaging and noise-covariance matrix estimation by causing unnecessary rejections of epochs.

Recommended ways to identify bad channels are:

Observe the quality of data during data acquisition and make notes of observed malfunctioning channels to your measurement protocol sheet.

View the on-line averages and check the condition of the channels.

Compute preliminary off-line averages with artifact rejection, SSP/ICA, and EEG average electrode reference computation off and check the condition of the channels.

View raw data with mne.io.Raw.plot() without SSP/ICA enabled and identify bad channels.

It is strongly recommended that bad channels are identified and marked in the original raw data files. If present in the raw data files, the bad channel selections will be automatically transferred to averaged files, noise-covariance matrices, forward solution files, and inverse operator decompositions.

The Signal-Space Projection (SSP) is one approach to rejection of external disturbances in software. Unlike many other noise-cancellation approaches, SSP does not require additional reference sensors to record the disturbance fields. Instead, SSP relies on the fact that the magnetic field distributions generated by the sources in the brain have spatial distributions sufficiently different from those generated by external noise sources. Furthermore, it is implicitly assumed that the linear space spanned by the significant external noise patterns has a low dimension.

SSP-based rejection is often done using the mne.preprocessing.compute_proj_ecg() and mne.preprocessing.compute_proj_eog() methods, see Background on projectors and projections and Repairing artifacts with SSP for more information.

Many M/EEG signals including biological artifacts reflect non-Gaussian processes. Therefore PCA-based artifact rejection will likely perform worse at separating the signal from noise sources.

ICA-based artifact rejection is done using the mne.preprocessing.ICA class, see the Independent component analysis (ICA) section for more information.

Epoching of raw data is done using events, which define a t=0 for your data chunks. Event times stamped to the acquisition software can be extracted using mne.find_events():

The events array can then be modified, extended, or changed if necessary. If the original trigger codes and trigger times are correct for the analysis of interest, mne.Epochs for the first event type (1) can be constructed using:

The rejection thresholds (set with argument reject) are defined in T / m for gradiometers, T for magnetometers and V for EEG and EOG channels.

The reject keyword of mne.Epochs is used for rejecting bad epochs based on peak-to-peak thresholds. Bad segments of data can also be rejected by marking segments of raw data with annotations. See Rejecting bad data spans and breaks and mne.Annotations for more .

Once the mne.Epochs are constructed, they can be averaged to obtain mne.Evoked data as:

MNE makes extensive use of the FreeSurfer file structure for analysis. Before starting data analysis, we recommend setting up the environment variable SUBJECTS_DIR (or set it permanently using mne.set_config()) to select the directory under which the anatomical MRI data are stored. This makes it so that the subjects_dir argument does not need to be passed to many functions.

The first processing stage is the creation of various surface reconstructions with FreeSurfer. The recommended FreeSurfer workflow is summarized on the FreeSurfer wiki pages. See also this information FreeSurfer MRI reconstruction.

This stage consists of the following:

Creating a suitable decimated dipole grid on the white matter surface.

Creating the source space file in fif format.

This is accomplished with using mne.setup_source_space() and mne.write_source_spaces(). These assume that the anatomical MRI processing has been completed as described in Cortical surface reconstruction with FreeSurfer.

Sources per hemisphere

Surface area per source / mm2

For example, to create the reconstruction geometry for subject='sample' with a ~5-mm spacing between the grid points, say:

This creates the source spaces and writes them to disk.

Compute Source Space illustrates how the source space is used to compute the forward model.

Calculation of the forward solution using the boundary-element model (BEM) requires that the surfaces separating regions of different electrical conductivities are tessellated with suitable surface elements. Our BEM software employs triangular tessellations. Therefore, prerequisites for BEM calculations are the segmentation of the MRI data and the triangulation of the relevant surfaces.

For MEG computations, a reasonably accurate solution can be obtained by using a single-compartment BEM assuming the shape of the intracranial volume. For EEG, the standard model contains the intracranial space, the skull, and the scalp.

At present, no bulletproof method exists for creating the triangulations. Feasible approaches are described in The Boundary Element Model (BEM).

The segmentation algorithms described in The Boundary Element Model (BEM) produce either FreeSurfer surfaces or triangulation data in text. Before proceeding to the creation of the boundary element model, standard files for FreeSurfer surfaces must be present:

inner_skull.surf contains the inner skull triangulation.

outer_skull.surf contains the outer skull triangulation.

outer_skin.surf contains the head surface triangulation.

This stage sets up the subject-dependent data for computing the forward solutions:”

Where surfaces is a list of BEM surfaces that have each been read using mne.read_surface(). This step also checks that the input surfaces are complete and that they are topologically correct, i.e., that the surfaces do not intersect and that the surfaces are correctly ordered (outer skull surface inside the scalp and inner skull surface inside the outer skull).

This step assigns the conductivity values to the BEM compartments. For the scalp and the brain compartments, the default is 0.3 S/m. The default skull conductivity is 50 times smaller, i.e., 0.006 S/m. Recent publications report a range of skull conductivity ratios ranging from 1:15 [1] to 1:25 - 1:50 [2][3]. The MNE default ratio 1:50 is based on the typical values reported in [2], since their approach is based on comparison of SEF/SEP measurements in a BEM model. The variability across publications may depend on individual variations but, more importantly, on the precision of the skull compartment segmentation.

To produce single layer BEM models (–homog flag in the C command line tools) pass a list with one single conductivity value, e.g. conductivities=[0.3].

Using this model, the BEM solution can be computed using mne.make_bem_solution() as:

After the BEM is set up it is advisable to check that the BEM model meshes are correctly positioned using e.g. mne.viz.plot_alignment() or mne.Report.

Up to this point all processing stages depend on the anatomical (geometrical) information only and thus remain identical across different MEG studies.

If you use custom head models you might need to set the ico=None parameter to None and skip subsampling of the surface.

The calculation of the forward solution requires knowledge of the relative location and orientation of the MEG/EEG and MRI coordinate systems (see The head and device coordinate systems). The head coordinate frame is defined by identifying the fiducial landmark locations, making the origin and orientation of the head coordinate system slightly user dependent. As a result, it is safest to reestablish the definition of the coordinate transformation computation for each experimental session, i.e., each time when new head digitization data are employed.

The corregistration is stored in -trans.fif file. If is present, you can follow Source alignment and coordinate frames to validate its correctness. If the -trans.fif is not present or the alignment is not correct you need to use mne.gui.coregistration() (or its convenient command line equivalent mne coreg) to generate it.

This step is important. If the alignment of the coordinate frames is inaccurate all subsequent processing steps suffer from the error. Therefore, this step should be performed by the person in charge of the study or by a trained technician. Written or photographic documentation of the alignment points employed during the MEG/EEG acquisition can also be helpful.

After the MRI-MEG/EEG alignment has been set, the forward solution, i.e., the magnetic fields and electric potentials at the measurement sensors and electrodes due to dipole sources located on the cortex, can be calculated with help of mne.make_forward_solution() as:

The MNE software employs an estimate of the noise-covariance matrix to weight the channels correctly in the calculations. The noise-covariance matrix provides information about field and potential patterns representing uninteresting noise sources of either human or environmental origin.

The noise covariance matrix can be calculated in several ways:

Employ the individual epochs during off-line averaging to calculate the full noise covariance matrix. This is the recommended approach for evoked responses, e.g. using mne.compute_covariance():

Employ empty room data (collected without the subject) to calculate the full noise covariance matrix. This is recommended for analyzing ongoing spontaneous activity. This can be done using mne.compute_raw_covariance() as:

Employ a section of continuous raw data collected in the presence of the subject to calculate the full noise covariance matrix. This is the recommended approach for analyzing epileptic activity. The data used for this purpose should be free of technical artifacts and epileptic activity of interest. The length of the data segment employed should be at least 20 seconds. One can also use a long (*> 200 s) segment of data with epileptic spikes present provided that the spikes occur infrequently and that the segment is apparently stationary with respect to background brain activity. This can also use mne.compute_raw_covariance().

The MNE software doesn’t calculate the inverse operator explicitly but rather computes an SVD of a matrix composed of the noise-covariance matrix, the result of the forward calculation, and the source covariance matrix. This approach has the benefit that the regularization parameter (‘SNR’) can be adjusted easily when the final source estimates or dSPMs are computed. For mathematical details of this approach, please consult The minimum-norm current estimates.

This computation stage can be done by using mne.minimum_norm.make_inverse_operator() as:

Once all the preprocessing steps described above have been completed, the inverse operator computed can be applied to the MEG and EEG data as:

And the results can be viewed as:

Group analysis is facilitated by morphing source estimates, which can be done e.g., to subject='fsaverage' as:

See Morphing and averaging source estimates for more information.

Thom F. Oostendorp, Jean Delbeke, and Dick F. Stegeman. The conductivity of the human skull: results of in vivo and in vitro measurements. IEEE Transactions on Biomedical Engineering, 47(11):1487–1492, 2000. doi:10.1109/TBME.2000.880100.

Sónia I. Gonçalves, Jan Casper de Munck, Jeroen P. A. Verbunt, Fetsje Bijma, Rob M. Heethaar, and Fernando Lopes da Silva. In vivo measurement of the brain and skull resistivities using an EIT-based method and realistic models for the head. IEEE Transactions on Biomedical Engineering, 50(6):754–767, 2003. doi:10.1109/TBME.2003.812164.

Seok Lew, Carsten H. Wolters, Alfred Anwander, Scott Makeig, and Rob S. MacLeod. Improved EEG source analysis using low-resolution conductivity estimation in a four-compartment finite element head model. Human Brain Mapping, 30(9):2862–2878, 2009. doi:10.1002/hbm.20714.

Migrating from other analysis software

How to cite MNE-Python

---

## Time-Frequency#

**URL:** https://mne.tools/stable/api/time_frequency.html

**Contents:**
- Time-Frequency#

Time frequency analysis tools.

AverageTFR(*[, inst, freqs, method, tmin, ...])

Data object for spectrotemporal representations of averaged data.

AverageTFRArray(info, data, times, freqs, *)

Data object for precomputed spectrotemporal representations of averaged data.

BaseTFR(inst, method, freqs, tmin, tmax, ...)

Base class for RawTFR, EpochsTFR, and AverageTFR (for type checking only).

EpochsTFR(*[, inst, freqs, method, tmin, ...])

Data object for spectrotemporal representations of epoched data.

EpochsTFRArray(info, data, times, freqs, *)

Data object for precomputed spectrotemporal representations of epoched data.

RawTFR(inst[, method, freqs, tmin, tmax, ...])

Data object for spectrotemporal representations of continuous data.

RawTFRArray(info, data, times, freqs, *[, ...])

Data object for precomputed spectrotemporal representations of continuous data.

CrossSpectralDensity(data, ch_names, ...[, ...])

Cross-spectral density.

Spectrum(inst, method, fmin, fmax, tmin, ...)

Data object for spectral representations of continuous data.

SpectrumArray(data, info, freqs[, ...])

Data object for precomputed spectral data (in NumPy array format).

EpochsSpectrum(inst, method, fmin, fmax, ...)

Data object for spectral representations of epoched data.

EpochsSpectrumArray(data, info, freqs[, ...])

Data object for precomputed epoched spectral data (in NumPy array format).

Functions that operate on mne-python objects:

combine_spectrum(all_spectrum[, weights])

Merge spectral data by weighted addition.

combine_tfr(all_tfr[, weights])

Merge AverageTFR data by weighted addition.

csd_tfr(epochs_tfr[, tmin, tmax, picks, ...])

Compute covariance matrices across frequencies for TFR epochs.

csd_fourier(epochs[, fmin, fmax, tmin, ...])

Estimate cross-spectral density from an array using short-time fourier.

csd_multitaper(epochs[, fmin, fmax, tmin, ...])

Estimate cross-spectral density from epochs using a multitaper method.

csd_morlet(epochs, frequencies[, tmin, ...])

Estimate cross-spectral density from epochs using Morlet wavelets.

pick_channels_csd(csd[, include, exclude, ...])

Pick channels from cross-spectral density matrix.

Read a CrossSpectralDensity object from an HDF5 file.

fit_iir_model_raw(raw[, order, picks, tmin, ...])

Fit an AR model to raw data and creates the corresponding IIR filter.

tfr_morlet(inst, freqs, n_cycles[, use_fft, ...])

tfr_multitaper(inst, freqs, n_cycles[, ...])

tfr_stockwell(inst[, fmin, fmax, n_fft, ...])

read_tfrs(fname[, condition, verbose])

Load a TFR object from disk.

write_tfrs(fname, tfr[, overwrite, verbose])

Write a TFR dataset to hdf5.

Load a mne.time_frequency.Spectrum object from disk.

Functions that operate on np.ndarray objects:

csd_array_fourier(X, sfreq[, t0, fmin, ...])

Estimate cross-spectral density from an array using short-time fourier.

csd_array_multitaper(X, sfreq[, t0, fmin, ...])

Estimate cross-spectral density from an array using a multitaper method.

csd_array_morlet(X, sfreq, frequencies[, ...])

Estimate cross-spectral density from an array using Morlet wavelets.

dpss_windows(N, half_nbw, Kmax, *[, sym, ...])

Compute Discrete Prolate Spheroidal Sequences.

Compute the full-width half maximum of a Morlet wavelet.

morlet(sfreq, freqs[, n_cycles, sigma, ...])

Compute Morlet wavelets for the given frequency range.

stft(x, wsize[, tstep, verbose])

STFT Short-Term Fourier Transform using a sine window.

istft(X[, tstep, Tx])

ISTFT Inverse Short-Term Fourier Transform using a sine window.

stftfreq(wsize[, sfreq])

Compute frequencies of stft transformation.

psd_array_multitaper(x, sfreq[, fmin, fmax, ...])

Compute power spectral density (PSD) using a multi-taper method.

psd_array_welch(x, sfreq[, fmin, fmax, ...])

Compute power spectral density (PSD) using Welch's method.

tfr_array_morlet(data, sfreq, freqs[, ...])

Compute Time-Frequency Representation (TFR) using Morlet wavelets.

tfr_array_multitaper(data, sfreq, freqs[, ...])

Compute Time-Frequency Representation (TFR) using DPSS tapers.

tfr_array_stockwell(data, sfreq[, fmin, ...])

Compute power and intertrial coherence using Stockwell (S) transform.

mne.time_frequency.tfr:

A module which implements the time-frequency estimation.

Morlet code inspired by Matlab code from Sheraz Khan & Brainstorm & SPM

cwt(X, Ws[, use_fft, mode, decim])

Compute time-frequency decomposition with continuous wavelet transform.

morlet(sfreq, freqs[, n_cycles, sigma, ...])

Compute Morlet wavelets for the given frequency range.

mne.source_space.get_decimated_surfaces

mne.time_frequency.AverageTFR

---
