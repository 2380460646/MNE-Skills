# Mne-Core - Tutorials

**Pages:** 295

---

## 2 samples permutation test on source data with spatio-temporal clustering#

**URL:** https://mne.tools/stable/auto_tutorials/stats-source-space/30_cluster_ftest_spatiotemporal.html

**Contents:**
- 2 samples permutation test on source data with spatio-temporal clustering#
- Set parameters#
- Compute statistic#
- Visualize the clusters#

Go to the end to download the full example code.

Tests if the source space data are significantly different between 2 groups of subjects (simulated here using one subject‚Äôs data). The multiple comparisons problem is addressed with a cluster-level permutation test across space and time.

To use an algorithm optimized for spatio-temporal clustering, we just pass the spatial adjacency matrix (instead of spatio-temporal)

Total running time of the script: (0 minutes 11.437 seconds)

Download Jupyter notebook: 30_cluster_ftest_spatiotemporal.ipynb

Download Python source code: 30_cluster_ftest_spatiotemporal.py

Download zipped: 30_cluster_ftest_spatiotemporal.zip

Gallery generated by Sphinx-Gallery

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

---

## 4D Neuroimaging/BTi phantom dataset tutorial#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/90_phantom_4DBTi.html

**Contents:**
- 4D Neuroimaging/BTi phantom dataset tutorial#

Go to the end to download the full example code.

Here we read 4DBTi epochs data obtained with a spherical phantom using four different dipole locations. For each condition we compute evoked data and compute dipole fits.

Data are provided by Jean-Michel Badier from MEG center in Marseille, France.

Read data and compute a dipole fit at the peak of the evoked response

Compute localisation errors

Plot the dipoles in 3D

Total running time of the script: (0 minutes 29.599 seconds)

Download Jupyter notebook: 90_phantom_4DBTi.ipynb

Download Python source code: 90_phantom_4DBTi.py

Download zipped: 90_phantom_4DBTi.zip

Gallery generated by Sphinx-Gallery

Brainstorm CTF phantom dataset tutorial

KIT phantom dataset tutorial

---

## Analysis of evoked response using ICA and PCA reduction techniques#

**URL:** https://mne.tools/stable/auto_examples/decoding/decoding_unsupervised_spatial_filter.html

**Contents:**
- Analysis of evoked response using ICA and PCA reduction techniques#

Go to the end to download the full example code.

This example computes PCA and ICA of evoked or epochs data. Then the PCA / ICA components, a.k.a. spatial filters, are used to transform the channel data to new sources / virtual channels. The output is visualized on the average of all the epochs.

Transform data with PCA computed on the average ie evoked response

Transform data with ICA computed on the raw epochs (no averaging)

Total running time of the script: (0 minutes 2.272 seconds)

Download Jupyter notebook: decoding_unsupervised_spatial_filter.ipynb

Download Python source code: decoding_unsupervised_spatial_filter.py

Download zipped: decoding_unsupervised_spatial_filter.zip

Gallery generated by Sphinx-Gallery

Decoding sensor space data with generalization across time and conditions

XDAWN Decoding From EEG data

---

## Annotate movement artifacts and reestimate dev_head_t#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/movement_detection.html

**Contents:**
- Annotate movement artifacts and reestimate dev_head_t#
- Plot continuous head position with respect to the mean recording position#
- Plot raw data with annotated movement#

Go to the end to download the full example code.

Periods, where the participant moved considerably, are contaminated by low amplitude artifacts. When averaging the magnetic fields, the more spread the head position, the bigger the cancellation due to different locations. Similarly, the covariance will also be affected by severe head movement, and source estimation will suffer low/smeared coregistration accuracy.

This example uses the continuous head position indicators (cHPI) times series to annotate periods of head movement, then the device to head transformation matrix is estimated from the artifact-free segments. The new head position will be more representative of the actual head position during the recording.

After checking the annotated movement artifacts, calculate the new transform and plot it:

Total running time of the script: (0 minutes 11.434 seconds)

Download Jupyter notebook: movement_detection.ipynb

Download Python source code: movement_detection.py

Download zipped: movement_detection.zip

Gallery generated by Sphinx-Gallery

Maxwell filter data with movement compensation

Annotate muscle artifacts

---

## Annotate muscle artifacts#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/muscle_detection.html

**Contents:**
- Annotate muscle artifacts#
- Plot muscle z-scores across recording#
- View the annotations#

Go to the end to download the full example code.

Muscle contractions produce high frequency activity that can mask brain signal of interest. Muscle artifacts can be produced when clenching the jaw, swallowing, or twitching a cranial muscle. Muscle artifacts are most noticeable in the range of 110-140 Hz.

This example uses annotate_muscle_zscore() to annotate segments where muscle activity is likely present. This is done by band-pass filtering the data in the 110-140 Hz range. Then, the envelope is taken using the hilbert analytical signal to only consider the absolute amplitude and not the phase of the high frequency signal. The envelope is z-scored and summed across channels and divided by the square root of the number of channels. Because muscle artifacts last several hundred milliseconds, a low-pass filter is applied on the averaged z-scores at 4 Hz, to remove transient peaks. Segments above a set threshold are annotated as BAD_muscle. In addition, the min_length_good parameter determines the cutoff for whether short spans of ‚Äúgood data‚Äù in between muscle artifacts are included in the surrounding ‚ÄúBAD‚Äù annotation.

Notch filter the data:

If line noise is present, you should perform notch-filtering before detecting muscle artifacts. See Power line noise for an example.

Total running time of the script: (0 minutes 4.114 seconds)

Download Jupyter notebook: muscle_detection.ipynb

Download Python source code: muscle_detection.py

Download zipped: muscle_detection.zip

Gallery generated by Sphinx-Gallery

Annotate movement artifacts and reestimate dev_head_t

Removing muscle ICA components

---

## Annotating continuous data#

**URL:** https://mne.tools/stable/auto_tutorials/raw/30_annotate_raw.html

**Contents:**
- Annotating continuous data#
- Creating annotations programmatically#
- Annotating Raw objects interactively#
- How annotations affect preprocessing and analysis#
- Operations on Annotations objects#
- Reading and writing Annotations to/from a file#

Go to the end to download the full example code.

This tutorial describes adding annotations to a Raw object, and how annotations are used in later stages of data processing.

As usual we‚Äôll start by importing the modules we need, loading some example data, and (since we won‚Äôt actually analyze the raw data in this tutorial) cropping the Raw object to just 60 seconds before loading it into RAM to save memory:

Annotations in MNE-Python are a way of storing short strings of information about temporal spans of a Raw object. Below the surface, Annotations are list-like objects, where each element comprises three pieces of information: an onset time (in seconds), a duration (also in seconds), and a description (a text string). Additionally, the Annotations object itself also keeps track of orig_time, which is a POSIX timestamp denoting a real-world time relative to which the annotation onsets should be interpreted.

If you know in advance what spans of the Raw object you want to annotate, Annotations can be created programmatically, and you can even pass lists or arrays to the Annotations constructor to annotate multiple spans at once:

Notice that orig_time is None, because we haven‚Äôt specified it. In those cases, when you add the annotations to a Raw object, it is assumed that the orig_time matches the time of the first sample of the recording, so orig_time will be set to match the recording measurement date (raw.info['meas_date']).

Since the example data comes from a Neuromag system that starts counting sample numbers before the recording begins, adding my_annot to the Raw object also involved another automatic change: an offset equalling the time of the first recorded sample (raw.first_samp / raw.info['sfreq']) was added to the onset values of each annotation (see Time, sample number, and sample index for more info on raw.first_samp):

If you know that your annotation onsets are relative to some other time, you can set orig_time before you call set_annotations(), and the onset times will get adjusted based on the time difference between your specified orig_time and raw.info['meas_date'], but without the additional adjustment for raw.first_samp. orig_time can be specified in various ways (see the documentation of Annotations for the options); here we‚Äôll use an ISO 8601 formatted string, and set it to be 50 seconds later than raw.info['meas_date'].

If your annotations fall outside the range of data times in the Raw object, the annotations outside the data range will not be added to raw.annotations, and a warning will be issued.

Now that your annotations have been added to a Raw object, you can see them when you visualize the Raw object:

The three annotations appear as differently colored rectangles because they have different description values (which are printed along the top edge of the plot area). Notice also that colored spans appear in the small scroll bar at the bottom of the plot window, making it easy to quickly view where in a Raw object the annotations are so you can easily browse through the data to find and examine them.

Annotations can also be added to a Raw object interactively by clicking-and-dragging the mouse in the plot window. To do this, you must first enter ‚Äúannotation mode‚Äù by pressing a while the plot window is focused; this will bring up the annotation controls:

The drop-down-menu on the left determines which existing label will be created by the next click-and-drag operation in the main plot window. New annotation descriptions can be added by clicking the Add description button; the new description will be added to the list of descriptions and automatically selected. The following functions relate to which description is currently selected in the drop-down-menu: With Remove description you can remove description including the annotations. With Edit description you can edit the description of either only one annotation (the one currently selected) or all annotations of a description. With Set Visible you can show or hide descriptions.

During interactive annotation it is also possible to adjust the start and end times of existing annotations, by clicking-and-dragging on the left or right edges of the highlighting rectangle corresponding to that annotation. When an annotation is selected (the background of the label at the bottom changes to darker) the values for start and stop are visible in two spinboxes and can also be edited there.

Calling set_annotations() replaces any annotations currently stored in the Raw object, so be careful when working with annotations that were created interactively (you could lose a lot of work if you accidentally overwrite your interactive annotations). A good safeguard is to run interactive_annot = raw.annotations after you finish an interactive annotation session, so that the annotations are stored in a separate variable outside the Raw object.

You may have noticed that the description for new labels in the annotation controls window defaults to BAD_. The reason for this is that annotation is often used to mark bad temporal spans of data (such as movement artifacts or environmental interference that cannot be removed in other ways such as projection or filtering). Several MNE-Python operations are ‚Äúannotation aware‚Äù and will avoid using data that is annotated with a description that begins with ‚Äúbad‚Äù or ‚ÄúBAD‚Äù; such operations typically have a boolean reject_by_annotation parameter. Examples of such operations are independent components analysis (mne.preprocessing.ICA), functions for finding heartbeat and blink artifacts (find_ecg_events(), find_eog_events()), and creation of epoched data from continuous data (mne.Epochs). See Rejecting bad data spans and breaks for details.

Annotations objects can be combined by simply adding them with the + operator, as long as they share the same orig_time:

Notice that it is possible to create overlapping annotations, even when they share the same description. This is not possible when annotating interactively; click-and-dragging to create a new annotation that overlaps with an existing annotation with the same description will cause the old and new annotations to be merged.

Individual annotations can be accessed by indexing an Annotations object, and subsets of the annotations can be achieved by either slicing or indexing with a list, tuple, or array of indices:

You can also iterate over the annotations within an Annotations object:

Note that iterating, indexing and slicing Annotations all return a copy, so changes to an indexed, sliced, or iterated element will not modify the original Annotations object.

Annotations objects have a save() method which can write .fif, .csv, and .txt formats (the format to write is inferred from the file extension in the filename you provide). Be aware that the format of the onset information that is written to the file depends on the file extension. While .csv files store the onset as timestamps, .txt files write floats (in seconds). There is a corresponding read_annotations() function to load them from disk:

Total running time of the script: (0 minutes 4.594 seconds)

Download Jupyter notebook: 30_annotate_raw.ipynb

Download Python source code: 30_annotate_raw.py

Download zipped: 30_annotate_raw.zip

Gallery generated by Sphinx-Gallery

Built-in plotting methods for Raw objects

---

## Automated epochs metadata generation with variable time windows#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/epochs_metadata.html

**Contents:**
- Automated epochs metadata generation with variable time windows#
- Visualizing the events#
- Declaring ‚Äúrow events‚Äù#
- Specifying metadata time windows#
  - Fixed time window#
  - Fixed time window with keep_first#
  - Variable time window#
  - Variable time window (simplified)#

Go to the end to download the full example code.

When working with Epochs, metadata can be invaluable. There is an extensive tutorial on how it can be generated automatically. In the brief examples below, we will demonstrate different ways to bound the time windows used to generate the metadata.

We will use data from an EEG recording during an Eriksen flanker task. For the purpose of demonstration, we‚Äôll only load the first 60 seconds of data.

All experimental events are stored in the Raw instance as Annotations. We first need to convert these to events and the corresponding mapping from event codes to event names (event_id). We then visualize the events.

As you can see, there are four types of stimulus and two types of response events.

For the sake of this example, we will assume that during analysis our epochs will be time-locked to the stimulus onset events. Hence, we would like to create metadata with one row per stimulus. We can achieve this by specifying all stimulus event names as row_events.

Now, we will explore different ways of specifying the time windows around the row_events when generating metadata. Any events falling within the same time window will be added to the same row in the metadata table.

A simple way to specify the time window extent is by specifying the time in seconds relative to the row event. In the following example, the time window spans from the row event (time point zero) up until three seconds later.

This looks good at the first glance. However, for example in the 2nd and 3rd row, we have two responses listed (left and right). This is because the 3-second time window is obviously a bit too wide and captures more than one trial. While we could make it narrower, this could lead to a loss of events ‚Äì if the window might become too narrow. Ultimately, this problem arises because the response time varies from trial to trial, so it‚Äôs difficult for us to set a fixed upper bound for the time window.

One workaround is using the keep_first parameter, which will create a new column containing the first event of the specified type.

As you can see, a new column response was created with the time of the first response event falling inside the time window. The first_response column specifies which response occurred first (left or right).

Another way to address the challenge of variable time windows without the need to create new columns is by specifying tmin and tmax as event names. In this example, we use tmin=row_events, because we want the time window to start with the time-locked event. tmax, on the other hand, are the response events: The first response event following tmin will be used to determine the duration of the time window.

We can slightly simplify the above code: Since tmin shall be set to the row_events, we can paass tmin=None, which is a more convenient way to express tmin=row_events. The resulting metadata looks the same as in the previous example.

Total running time of the script: (0 minutes 1.350 seconds)

Download Jupyter notebook: epochs_metadata.ipynb

Download Python source code: epochs_metadata.py

Download zipped: epochs_metadata.zip

Gallery generated by Sphinx-Gallery

Reduce EOG artifacts through regression

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

---

## Auto-generating Epochs metadata#

**URL:** https://mne.tools/stable/auto_tutorials/epochs/40_autogenerate_metadata.html

**Contents:**
- Auto-generating Epochs metadata#
- Preparation#
- Creating metadata from events#
  - The basics of make_metadata#
  - Specifying time-locked events#
  - Keeping only the first events of a group#
- Adding new columns to describe stimulation side and response correctness#
- Creating Epochs with metadata, and visualizing ERPs#
- Applying the knowledge: visualizing the ERN component#
- References#

Go to the end to download the full example code.

This tutorial shows how to auto-generate metadata for Epochs, based on events via mne.epochs.make_metadata.

We are going to use data from the ERP CORE Dataset (derived from [1]). This is EEG data from a single participant performing an active visual task (Eriksen flanker task).

If you wish to skip the introductory parts of this tutorial, you may jump straight to Applying the knowledge: visualizing the ERN component after completing the data import and event creation in the Preparation section.

This tutorial is loosely divided into two parts:

We will first focus on producing ERPs time-locked to the visual stimulation, conditional on response correctness and response time in order to familiarize ourselves with the make_metadata function.

After that, we will calculate ERPs time-locked to the responses ‚Äì again, conditional on response correctness ‚Äì to visualize the error-related negativity (ERN), i.e. the ERP component associated with incorrect behavioral responses.

Let‚Äôs start by reading, filtering, and producing a simple visualization of the raw data. The data is pretty clean and contains very few blinks, so there‚Äôs no need to apply sophisticated preprocessing and data cleaning procedures. We will also convert the Annotations contained in this dataset to events by calling mne.events_from_annotations.

Now it‚Äôs time to think about the time windows to use for epoching and metadata generation. It is important to understand that these time windows need not be the same! That is, the automatically generated metadata might include information about events from only a fraction of the epochs duration; or it might include events that occurred well outside a given epoch.

Let us look at a concrete example. In the Flankers task of the ERP CORE dataset, participants were required to respond to visual stimuli by pressing a button. We‚Äôre interested in looking at the visual evoked responses (ERPs) of trials with correct responses. Assume that based on literature studies, we decide that responses later than 1500 ms after stimulus onset are to be considered invalid, because they don‚Äôt capture the neuronal processes of interest here. We can approach this in the following way with the help of mne.epochs.make_metadata:

We can see that the generated table has 802 rows, each one corresponding to an individual event in all_events. The first column, event_name, contains the name of the respective event around which the metadata of that specific column was generated ‚Äì we‚Äôll call that the ‚Äútime-locked event‚Äù, because we‚Äôll assign it time point zero.

The names of the remaining columns correspond to the event names specified in the all_event_id dictionary. These columns contain floats; the values represent the latency of that specific event in seconds, relative to the time-locked event (the one mentioned in the event_name column). For events that didn‚Äôt occur within the given time window, you‚Äôll see a value of NaN, simply indicating that no event latency could be extracted.

Now, there‚Äôs a problem here. We want to investigate the visual ERPs conditional on responses. But the metadata that was just created contains one row for every event, including responses. While we could create epochs for all events, allowing us to pass those metadata, and later subset the created events, there‚Äôs a more elegant way to handle this: make_metadata has a row_events parameter that allows us to specify for which events to create metadata rows, while still creating columns for all events in the event_id dictionary.

Because the metadata, then, only pertains to a subset of our original events, it‚Äôs important to keep the returned events and event_id around for later use when we actually create our epochs, to ensure that metadata, events, and event descriptions stay in sync.

The metadata now contains 400 rows ‚Äì one per stimulation ‚Äì and the same number of columns as before. Great!

We have two types of responses in our data: response/left and response/right. We would like to map those to ‚Äúcorrect‚Äù and ‚Äúincorrect‚Äù. To make this easier, we can ask make_metadata to generate an entirely new column that refers to the first response observed during the given time interval. This works by passing a subset of the hierarchical event descriptors (HEDs, inspired by [2]) used to name events via the keep_first parameter. For example, in the case of the HEDs response/left and response/right, we could pass keep_first='response' to generate a new column, response, containing the latency of the respective event. This value represents the first (or, in this specific example: the only) response, regardless of side (left or right). To indicate which event type (here: response side) was matched, a second column named first_response is added. The values in this column are the event types without the string used for matching, as it is already encoded as the column name, i.e. in our example, we expect it to only contain 'left' and 'right'.

The first_response column contains only "left" and "right" entries, derived from the respective initial events "response/left" and "response/right":

For stimulus events, there are not only two, but four different types: stimulus/compatible/target_left, stimulus/compatible/target_right, stimulus/incompatible/target_left, and stimulus/incompatible/target_right. What‚Äôs more, because in the present paradigm stimuli were presented in rapid succession, sometimes multiple stimulus events occurred within the 1.5 second time window we used to generate our metadata. See for example:

Looking at the stimulus/compatible/target_left and stimulus/compatible/target_right columns, you will see that both always contain a numerical value (one is always zero, the other is not). This is because both events occurred within the time window of 1.5 seconds.

This can easily lead to confusion during later stages of processing, so let‚Äôs create a column for the first stimulus ‚Äì which will always be the time-locked stimulus, as our time interval starts at 0 seconds. We can pass a list of strings to keep_first.

Perfect! Now it‚Äôs time to define which responses were correct and incorrect. We first add a column encoding the side of stimulation, and then simply check whether the response matches the stimulation side, and add this result to another column.

400 rows √ó 13 columns

Count the number of correct and incorrect responses:

The metadata is ready. Now it‚Äôs finally time to create our epochs! We will assign the metadata directly on epochs creation via the metadata parameter. Also, it is important to remember to pass the events and event_id that were returned from make_metadata, as we only created metadata for a subset of our original events by passing row_events. If we were to pass to ‚Äúoriginal‚Äù values instead, the length of the metadata and the number of epochs would mismatch, which would raise an error.

You probably also noticed that 9 epochs were dropped because they exceeded our rejection limits. This is another reason why it is important to assign the metadata on epochs creation: the metadata will be updated automatically to reflect the actual epochs that were kept.

Lastly, let‚Äôs visualize the ERPs associated with the visual stimulation. We will only consider trials with correct responses and produce three plots: one for all correct responses, one for correct slow responses (response time slower than 0.5 s), and one for correct fast responses (response time up to 0.5 s).

Aside from the fact that the data for the (much fewer) slow responses looks noisier ‚Äì which is entirely to be expected ‚Äì not much of an ERP difference can be seen.

In the following analysis, we will use the same dataset as above, but we‚Äôll time-lock our epochs to the response events, not to the stimulus onset. Comparing ERPs associated with correct and incorrect behavioral responses, we should be able to see the error-related negativity (ERN) in the difference wave.

Since we want to time-lock our analysis to responses, for the automated metadata generation we‚Äôll consider events occurring up to 1500 ms before the response trigger so we can be sure to capture the stimulation event as well.

We only wish to consider the last stimulus and response in each time window: Remember that we‚Äôre dealing with rapid stimulus presentations in this paradigm; taking the last response (time point zero) and the last stimulus (the one closest to the response) ensures that we actually create the right stimulus-response pairings. We can achieve this by passing the keep_last parameter, which works exactly like keep_first we used previously, only that it keeps the last occurrences of the specified events and stores them in columns whose names start with last_.

402 rows √ó 11 columns

Exactly like in the previous example, we create new columns stimulus_side and response_correct.

402 rows √ó 13 columns

Now it‚Äôs already time to epoch the data! When deciding upon the epochs duration for this specific analysis, we need to ensure to include quite a bit of signal from before and after the motor response. We also must be aware of the fact that motor-/muscle-related signals will most likely be present before the response button trigger pulse appears in our data, so the time period close to the response event should not be used for baseline correction. But at the same time, we don‚Äôt want to use a baseline period that extends too far away from the button event. The following values seem to work quite well. Remember: time point zero is the response event.

Let‚Äôs do a final sanity check: we want to make sure that in every row, we actually have a stimulus. We use epochs.metadata (and not metadata) because when creating the epochs, we passed the reject parameter, and MNE-Python always ensures that epochs.metadata stays in sync with the available epochs. During epochs creation, several epochs were dropped as they exceeded the rejection limits.

Bummer! It seems the very first two responses were recorded before the first stimulus appeared: the values in the stimulus column are None. There is a very simple way to select only those epochs that do have a stimulus (i.e., are not None):

Now it‚Äôs time to calculate the ERPs for correct and incorrect responses.

For visualization, we‚Äôll only look at sensor FCz, which is known to show the ERN nicely in the given paradigm.

We‚Äôll also create a topoplot to get an impression of the average scalp potentials measured in the first 100 ms after an incorrect response.

We can see a strong negative deflection immediately after incorrect responses, compared to correct responses. The topoplot, too, leaves no doubt: what we‚Äôre looking at is, in fact, the ERN.

Some researchers suggest to construct the difference wave between ERPs for correct and incorrect responses, as it more clearly reveals signal differences, while ideally also improving the signal-to-noise ratio (under the assumption that the noise level in ‚Äúcorrect‚Äù and ‚Äúincorrect‚Äù trials is similar). Let‚Äôs do just that and put it into a publication-ready visualization.

Emily S. Kappenman, Jaclyn L. Farrens, Wendy Zhang, Andrew X. Stewart, and Steven J. Luck. ERP CORE: an open resource for human event-related potential research. NeuroImage, 225:117465, 2021. doi:10.1016/j.neuroimage.2020.117465.

Nima Bigdely-Shamlo, Kenneth Kreutz-Delgado, Kay Robbins, Makoto Miyakoshi, Marissa Westerfield, Tarik Bel-Bahar, Christian Kothe, Jessica Hsi, and Scott Makeig. Hierarchical event descriptor (HED) tags for analysis of event-related EEG studies. In 2013 IEEE Global Conference on Signal and Information Processing, 1‚Äì4. IEEE, 2013. doi:10.1109/GlobalSIP.2013.6736796.

Total running time of the script: (0 minutes 21.367 seconds)

Download Jupyter notebook: 40_autogenerate_metadata.ipynb

Download Python source code: 40_autogenerate_metadata.py

Download zipped: 40_autogenerate_metadata.zip

Gallery generated by Sphinx-Gallery

Working with Epoch metadata

Exporting Epochs to Pandas DataFrames

---

## Background information on filtering#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/25_background_filtering.html

**Contents:**
- Background information on filtering#
- Problem statement#
- Filtering basics#
- FIR Filters#
  - Designing FIR filters#
  - Applying FIR filters#
- IIR filters#
  - Designing IIR filters#
  - Applying IIR filters#
- Some pitfalls of filtering#

Go to the end to download the full example code.

Here we give some background information on filtering in general, and how it is done in MNE-Python in particular. Recommended reading for practical applications of digital filter design can be found in Parks & Burrus (1987) [1] and Ifeachor & Jervis (2002) [2], and for filtering in an M/EEG context we recommend reading Widmann et al. (2015) [3].

This tutorial goes pretty deep into the mathematics of filtering and the design decisions that go into choosing a filter. If you just want to know how to apply the default filters in MNE-Python to your data, skip this tutorial and read Filtering and resampling data instead (but someday, you should come back and read this one too üôÇ).

Practical issues with filtering electrophysiological data are covered in Widmann et al. (2012) [4], where they conclude with this statement:

Filtering can result in considerable distortions of the time course (and amplitude) of a signal as demonstrated by VanRullen (2011) [5]. Thus, filtering should not be used lightly. However, if effects of filtering are cautiously considered and filter artifacts are minimized, a valid interpretation of the temporal dynamics of filtered electrophysiological data is possible and signals missed otherwise can be detected with filtering.

In other words, filtering can increase signal-to-noise ratio (SNR), but if it is not used carefully, it can distort data. Here we hope to cover some filtering basics so users can better understand filtering trade-offs and why MNE-Python has chosen particular defaults.

Let‚Äôs get some of the basic math down. In the frequency domain, digital filters have a transfer function that is given by:

In the time domain, the numerator coefficients \(b_k\) and denominator coefficients \(a_k\) can be used to obtain our output data \(y(n)\) in terms of our input data \(x(n)\) as:

In other words, the output at time \(n\) is determined by a sum over

the numerator coefficients \(b_k\), which get multiplied by the previous input values \(x(n-k)\), and

the denominator coefficients \(a_k\), which get multiplied by the previous output values \(y(n-k)\).

Note that these summations correspond to (1) a weighted moving average and (2) an autoregression.

Filters are broken into two classes based on these coefficients: FIR (finite impulse response) and IIR (infinite impulse response) filters. FIR filters use a finite number of numerator coefficients \(b_k\) (where \(a_k=0\qquad \forall k\)), and thus each output value \(y(n)\) depends only on the \(M\) previous input values. IIR filters depend on the previous input and output values, and thus can have effectively infinitely long impulse responses.

As outlined in Parks & Burrus (1987) [1], FIR and IIR filters have different pros and cons:

A causal FIR filter can be linear-phase ‚Äì i.e., the same time delay across all frequencies ‚Äì whereas a causal IIR filter cannot. The phase and group delay characteristics are also usually better for FIR filters.

IIR filters can generally have a steeper cutoff than an FIR filter of equivalent order.

IIR filters are generally less numerically stable, in part due to accumulating error (due to recursive calculations).

In MNE-Python we default to using FIR filtering. As noted in Widmann et al. (2015) [3]:

Despite IIR filters often being considered as computationally more efficient, they are recommended only when high throughput and sharp cutoffs are required (Ifeachor and Jervis, 2002 [2], p. 321). FIR filters are easier to control, are always stable, have a well-defined passband, can be corrected to zero-phase without additional computations, and can be converted to minimum-phase. We therefore recommend FIR filters for most purposes in electrophysiological data analysis.

When designing a filter (FIR or IIR), there are always trade-offs that need to be considered, including but not limited to:

Ripple in the pass-band

Attenuation of the stop-band

Steepness of roll-off

Filter order (i.e., length for FIR filters)

In general, the sharper something is in frequency, the broader it is in time, and vice-versa. This is a fundamental time-frequency trade-off, and it will show up below.

First, we will focus on FIR filters, which are the default filters used by MNE-Python.

Here we‚Äôll try to design a low-pass filter and look at trade-offs in terms of time- and frequency-domain filter characteristics. Later, in Applying FIR filters, we‚Äôll look at how such filters can affect signals when they are used.

First let‚Äôs import some useful tools for filtering, and set some default values for our data that are reasonable for M/EEG.

Take for example an ideal low-pass filter, which would give a magnitude response of 1 in the pass-band (up to frequency \(f_p\)) and a magnitude response of 0 in the stop-band (down to frequency \(f_s\)) such that \(f_p=f_s=40\) Hz here (shown to a lower limit of -60 dB for simplicity):

This filter hypothetically achieves zero ripple in the frequency domain, perfect attenuation, and perfect steepness. However, due to the discontinuity in the frequency response, the filter would require infinite ringing in the time domain (i.e., infinite order) to be realized. Another way to think of this is that a rectangular window in the frequency domain is actually a sinc function in the time domain, which requires an infinite number of samples (and thus infinite time) to represent. So although this filter has ideal frequency suppression, it has poor time-domain characteristics.

Let‚Äôs try to na√Øvely make a brick-wall (sinc) filter of length 0.1 s, and look at the filter itself in the time domain and the frequency domain:

This is not so good! Making the filter 10 times longer (1 s) gets us a slightly better stop-band suppression, but still has a lot of ringing in the time domain. Note the x-axis is an order of magnitude longer here, and the filter has a correspondingly much longer group delay (again equal to half the filter length, or 0.5 seconds):

Let‚Äôs make the stop-band tighter still with a longer filter (10 s), with a resulting larger x-axis:

Now we have very sharp frequency suppression, but our filter rings for the entire 10 seconds. So this na√Øve method is probably not a good way to build our low-pass filter.

Fortunately, there are multiple established methods to design FIR filters based on desired response characteristics. These include:

The Remez algorithm (scipy.signal.remez())

Windowed FIR design (scipy.signal.firwin2(), scipy.signal.firwin())

Least squares design (scipy.signal.firls())

Frequency-domain design (construct filter in Fourier domain and use an IFFT to invert it)

Remez and least squares designs have advantages when there are ‚Äúdo not care‚Äù regions in our frequency response. However, we want well controlled responses in all frequency regions. Frequency-domain construction is good when an arbitrary response is desired, but generally less clean (due to sampling issues) than a windowed approach for more straightforward filter applications. Since our filters (low-pass, high-pass, band-pass, band-stop) are fairly simple and we require precise control of all frequency regions, we will primarily use and explore windowed FIR design.

If we relax our frequency-domain filter requirements a little bit, we can use these functions to construct a lowpass filter that instead has a transition band, a region between the pass frequency \(f_p\) and stop frequency \(f_s\):

Accepting a shallower roll-off of the filter in the frequency domain makes our time-domain response potentially much better. We end up with a more gradual slope through the transition region, but a much cleaner time domain signal. Here again for the 1 s filter:

Since our lowpass is around 40 Hz with a 10 Hz transition, we can actually use a shorter filter (5 cycles at 10 Hz = 0.5 s) and still get acceptable stop-band attenuation:

But if we shorten the filter too much (2 cycles of 10 Hz = 0.2 s), our effective stop frequency gets pushed out past 60 Hz:

If we want a filter that is only 0.1 seconds long, we should probably use something more like a 25 Hz transition band (0.2 s = 5 cycles @ 25 Hz):

So far, we have only discussed non-causal filtering, which means that each sample at each time point \(t\) is filtered using samples that come after (\(t + \Delta t\)) and before (\(t - \Delta t\)) the current time point \(t\). In this sense, each sample is influenced by samples that come both before and after it. This is useful in many cases, especially because it does not delay the timing of events.

However, sometimes it can be beneficial to use causal filtering, whereby each sample \(t\) is filtered only using time points that came after it.

Note that the delay is variable (whereas for linear/zero-phase filters it is constant) but small in the pass-band. Unlike zero-phase filters, which require time-shifting backward the output of a linear-phase filtering stage (and thus becoming non-causal), minimum-phase filters do not require any compensation to achieve small delays in the pass-band.

We can construct a minimum-phase filter from our existing linear-phase filter, and note that the falloff is not as steep. Here we do this with function mne.fixes.minimum_phase() to avoid a SciPy bug; once SciPy 1.14.0 is released you could directly use scipy.signal.minimum_phase(..., half=False).

Note that this minimum-phase filter has a much smaller delay compared to an uncompensated, causal linear-phase filter, as shown below. This is why in MNE-Python we currently only offer zero-phase, non-causal filters (i.e., delay-compensated filters) or minimum-phase causal filters. The linear phase filter has a constant, large delay:

Now lets look at some practical effects of these filters by applying them to some data.

Let‚Äôs construct a Gaussian-windowed sinusoid (i.e., Morlet imaginary part) plus noise (random and line). Note that the original clean signal contains frequency content in both the pass band and transition bands of our low-pass filter.

Let‚Äôs filter it with a shallow cutoff, linear-phase FIR (which allows us to compensate for the constant filter delay):

Now let‚Äôs filter it with a different design method fir_design="firwin2", and also compensate for the constant filter delay. This method does not produce quite as sharp a transition compared to fir_design="firwin", despite being twice as long:

Let‚Äôs also filter with the MNE-Python 0.13 default, which is a long-duration, steep cutoff FIR that gets applied twice:

Let‚Äôs also filter it with the MNE-C default, which is a long-duration steep-slope FIR filter designed using frequency-domain techniques:

And now an example of a minimum-phase filter:

Both the MNE-Python 0.13 and MNE-C filters have excellent frequency attenuation, but it comes at a cost of potential ringing (long-lasting ripples) in the time domain. Ringing can occur with steep filters, especially in signals with frequency content around the transition band. Our Morlet wavelet signal has power in our transition band, and the time-domain ringing is thus more pronounced for the steep-slope, long-duration filter than the shorter, shallower-slope filter:

MNE-Python also offers IIR filtering functionality that is based on the methods from scipy.signal. Specifically, we use the general-purpose functions scipy.signal.iirfilter() and scipy.signal.iirdesign(), which provide unified interfaces to IIR filter design.

Let‚Äôs continue with our design of a 40 Hz low-pass filter and look at some trade-offs of different IIR filters.

Often the default IIR filter is a Butterworth filter, which is designed to have a maximally flat pass-band. Let‚Äôs look at a few filter orders, i.e., a few different numbers of coefficients used and therefore steepness of the filter:

Notice that the group delay (which is related to the phase) of the IIR filters below are not constant. In the FIR case, we can design so-called linear-phase filters that have a constant group delay, and thus compensate for the delay (making the filter non-causal) if necessary. This cannot be done with IIR filters, as they have a non-linear phase (non-constant group delay). As the filter order increases, the phase distortion near and in the transition band worsens. However, if non-causal (forward-backward) filtering can be used, e.g. with scipy.signal.filtfilt(), these phase issues can theoretically be mitigated.

The falloff of this filter is not very steep.

Here we have made use of second-order sections (SOS) by using scipy.signal.sosfilt() and, under the hood, scipy.signal.zpk2sos() when passing the output='sos' keyword argument to scipy.signal.iirfilter(). The filter definitions given above use the polynomial numerator/denominator (sometimes called ‚Äútf‚Äù) form (b, a), which are theoretically equivalent to the SOS form used here. In practice, however, the SOS form can give much better results due to issues with numerical precision (see scipy.signal.sosfilt() for an example), so SOS should be used whenever possible.

Let‚Äôs increase the order, and note that now we have better attenuation, with a longer impulse response. Let‚Äôs also switch to using the MNE filter design function, which simplifies a few things and gives us some information about the resulting filter:

There are other types of IIR filters that we can use. For a complete list, check out the documentation for scipy.signal.iirdesign(). Let‚Äôs try a Chebychev (type I) filter, which trades off ripple in the pass-band to get better attenuation in the stop-band:

If we can live with even more ripple, we can get it slightly steeper, but the impulse response begins to ring substantially longer (note the different x-axis scale):

Similarly to FIR filters, we can define causal IIR filters.

Now let‚Äôs look at how our shallow and steep Butterworth IIR filters perform on our Morlet signal from before:

Multiple recent papers have noted potential risks of drawing errant inferences due to misapplication of filters.

Filters in general, especially those that are non-causal (zero-phase), can make activity appear to occur earlier or later than it truly did. As mentioned in VanRullen (2011) [5], investigations of commonly (at the time) used low-pass filters created artifacts when they were applied to simulated data. However, such deleterious effects were minimal in many real-world examples in Rousselet (2012) [6].

Perhaps more revealing, it was noted in Widmann & Schr√∂ger (2012) [4] that the problematic low-pass filters from VanRullen (2011) [5]:

Used a least-squares design (like scipy.signal.firls()) that included ‚Äúdo-not-care‚Äù transition regions, which can lead to uncontrolled behavior.

Had a filter length that was independent of the transition bandwidth, which can cause excessive ringing and signal distortion.

When it comes to high-pass filtering, using corner frequencies above 0.1 Hz were found in Acunzo et al. (2012) [7] to:

‚Äú‚Ä¶ generate a systematic bias easily leading to misinterpretations of neural activity.‚Äù

In a related paper, Widmann et al. (2015) [3] also came to suggest a 0.1 Hz highpass. More evidence followed in Tanner et al. (2015) [8] of such distortions. Using data from language ERP studies of semantic and syntactic processing (i.e., N400 and P600), using a high-pass above 0.3 Hz caused significant effects to be introduced implausibly early when compared to the unfiltered data. From this, the authors suggested the optimal high-pass value for language processing to be 0.1 Hz.

We can recreate a problematic simulation from Tanner et al. (2015) [8]:

‚ÄúThe simulated component is a single-cycle cosine wave with an amplitude of 5¬µV [sic], onset of 500 ms poststimulus, and duration of 800 ms. The simulated component was embedded in 20 s of zero values to avoid filtering edge effects. [‚Ä¶] Distortions [were] caused by 2 Hz low-pass and high-pass filters. [‚Ä¶] No visible distortion to the original waveform [occurred] with 30 Hz low-pass and 0.01 Hz high-pass filters. [‚Ä¶] Filter frequencies correspond to the half-amplitude (-6 dB) cutoff (12 dB/octave roll-off).‚Äù

This simulated signal contains energy not just within the pass-band, but also within the transition and stop-bands ‚Äì perhaps most easily understood because the signal has a non-zero DC value, but also because it is a shifted cosine that has been windowed (here multiplied by a rectangular window), which makes the cosine and DC frequencies spread to other frequencies (multiplication in time is convolution in frequency, so multiplying by a rectangular window in the time domain means convolving a sinc function with the impulses at DC and the cosine frequency in the frequency domain).

Similarly, in a P300 paradigm reported by Kappenman & Luck (2010) [9], of they found that applying a 1 Hz high-pass decreased the probability finding a significant difference in the N100 response, likely because the P300 response was smeared (and inverted) in time by the high-pass filter such that it tended to cancel out the increased N100. However, they nonetheless noted that some high-passing can still be useful to deal with drifts in the data.

Even though these papers generally advise a 0.1 Hz or lower frequency for a high-pass, it is important to keep in mind (as most authors note) that filtering choices should depend on the frequency content of both the signal(s) of interest and the noise to be suppressed. For example, in some of the MNE-Python examples involving the Sample dataset, high-pass values of around 1 Hz are used when looking at auditory or visual N100 responses, because we analyze standard (not deviant) trials and thus expect that contamination by later or slower components will be limited.

In an evolving discussion, Tanner et al. (2015) [8] suggest using baseline correction to remove slow drifts in data. However, Maess et al. (2016) [10] suggest that baseline correction, which is a form of high-passing, does not offer substantial advantages over standard high-pass filtering. Tanner et al. (2016) [11] rebutted that baseline correction can correct for problems with filtering.

To see what they mean, consider again our old simulated signal x from before:

In response, Maess et al. (2016) [12] note that these simulations do not address cases of pre-stimulus activity that is shared across conditions, as applying baseline correction will effectively copy the topology outside the baseline period. We can see this if we give our signal x with some consistent pre-stimulus activity, which makes everything look bad.

An important thing to keep in mind with these plots is that they are for a single simulated sensor. In multi-electrode recordings the topology (i.e., spatial pattern) of the pre-stimulus activity will leak into the post-stimulus period. This will likely create a spatially varying distortion of the time-domain signals, as the averaged pre-stimulus spatial pattern gets subtracted from the sensor time courses.

Putting some activity in the baseline period:

Both groups seem to acknowledge that the choices of filtering cutoffs, and perhaps even the application of baseline correction, depend on the characteristics of the data being investigated, especially when it comes to:

The frequency content of the underlying evoked activity relative to the filtering parameters.

The validity of the assumption of no consistent evoked activity in the baseline period.

We thus recommend carefully applying baseline correction and/or high-pass values based on the characteristics of the data to be analyzed.

Most often, filtering in MNE-Python is done at the mne.io.Raw level, and thus mne.io.Raw.filter() is used. This function under the hood (among other things) calls mne.filter.filter_data() to actually filter the data, which by default applies a zero-phase FIR filter designed using scipy.signal.firwin(). In Widmann et al. (2015) [3], they suggest a specific set of parameters to use for high-pass filtering, including:

‚Äú‚Ä¶ providing a transition bandwidth of 25% of the lower passband edge but, where possible, not lower than 2 Hz and otherwise the distance from the passband edge to the critical frequency.‚Äù

In practice, this means that for each high-pass value l_freq or low-pass value h_freq below, you would get this corresponding l_trans_bandwidth or h_trans_bandwidth, respectively, if the sample rate were 100 Hz (i.e., Nyquist frequency of 50 Hz):

MNE-Python has adopted this definition for its high-pass (and low-pass) transition bandwidth choices when using l_trans_bandwidth='auto' and h_trans_bandwidth='auto'.

To choose the filter length automatically with filter_length='auto', the reciprocal of the shortest transition bandwidth is used to ensure decent attenuation at the stop frequency. Specifically, the reciprocal (in samples) is multiplied by 3.1, 3.3, or 5.0 for the Hann, Hamming, or Blackman windows, respectively, as selected by the fir_window argument for fir_design='firwin', and double these for fir_design='firwin2' mode.

For fir_design='firwin2', the multiplicative factors are doubled compared to what is given in Ifeachor & Jervis (2002) [2] (p. 357), as scipy.signal.firwin2() has a smearing effect on the frequency response, which we compensate for by increasing the filter length. This is why fir_desgin='firwin' is preferred to fir_design='firwin2'.

In 0.14, we default to using a Hamming window in filter design, as it provides up to 53 dB of stop-band attenuation with small pass-band ripple.

In band-pass applications, often a low-pass filter can operate effectively with fewer samples than the high-pass filter, so it is advisable to apply the high-pass and low-pass separately when using fir_design='firwin2'. For design mode fir_design='firwin', there is no need to separate the operations, as the lowpass and highpass elements are constructed separately to meet the transition band requirements.

For more information on how to use the MNE-Python filtering functions with real data, consult the preprocessing tutorial on Filtering and resampling data.

MNE-C by default uses:

5 Hz transition band for low-pass filters.

3-sample transition band for high-pass filters.

Filter length of 8197 samples.

The filter is designed in the frequency domain, creating a linear-phase filter such that the delay is compensated for as is done with the MNE-Python phase='zero' filtering option.

Squared-cosine ramps are used in the transition regions. Because these are used in place of more gradual (e.g., linear) transitions, a given transition width will result in more temporal ringing but also more rapid attenuation than the same transition width in windowed FIR designs.

The default filter length will generally have excellent attenuation but long ringing for the sample rates typically encountered in M/EEG data (e.g. 500-2000 Hz).

A good but possibly outdated comparison of filtering in various software packages is available in Widmann et al. (2015) [3]. Briefly:

MNE-Python 0.14 defaults to behavior very similar to that of EEGLAB (see the EEGLAB filtering FAQ for more information).

By default FieldTrip applies a forward-backward Butterworth IIR filter of order 4 (band-pass and band-stop filters) or 2 (for low-pass and high-pass filters). Similar filters can be achieved in MNE-Python when filtering with raw.filter(..., method='iir') (see also mne.filter.construct_iir_filter() for options). For more information, see e.g. the FieldTrip band-pass documentation.

On page 45 in Widmann et al. (2015) [3], there is a convenient list of important filter parameters that should be reported with each publication:

Filter type (high-pass, low-pass, band-pass, band-stop, FIR, IIR)

Cutoff frequency (including definition)

Filter order (or length)

Roll-off or transition bandwidth

Passband ripple and stopband attenuation

Filter delay (zero-phase, linear-phase, non-linear phase) and causality

Direction of computation (one-pass forward/reverse, or two-pass forward and reverse)

In the following, we will address how to deal with these parameters in MNE.

Depending on the function or method used, the filter type can be specified. To name an example, in mne.filter.create_filter(), the relevant arguments would be l_freq, h_freq, method, and if the method is FIR fir_window and fir_design.

The cutoff of FIR filters in MNE is defined as half-amplitude cutoff in the middle of the transition band. That is, if you construct a lowpass FIR filter with h_freq = 40, the filter function will provide a transition bandwidth that depends on the h_trans_bandwidth argument. The desired half-amplitude cutoff of the lowpass FIR filter is then at h_freq + transition_bandwidth/2.

In the Defaults in MNE-Python section, we have already talked about the default filter lengths and transition bandwidths that are used when no custom values are specified using the respective filter function arguments.

If you want to find out about the filter length and transition bandwidth that were used through the ‚Äòauto‚Äô setting, you can use mne.filter.create_filter() to print out the settings once more:

If you are using an IIR filter, mne.filter.create_filter() will not print a filter length and transition bandwidth to the log. Instead, you can specify the roll-off with the iir_params argument or stay with the default, which is a fourth order (Butterworth) filter.

When using the standard scipy.signal.firwin() design (as for FIR filters in MNE), the passband ripple and stopband attenuation depend on the window used in design. For standard windows the values are listed in this table (see Ifeachor & Jervis (2002) [2], p. 357):

Name of window function

For reporting this information, it might be sufficient to read the docstring of the filter function or method that you apply. For example in the docstring of mne.filter.create_filter, for the phase parameter it says:

Phase of the filter, only used if method='fir'. By default, a symmetric linear-phase FIR filter is constructed. If phase='zero' (default), the delay of this filter is compensated for. If phase=='zero-double', then this filter is applied twice, once forward, and once backward. If 'minimum', then a minimum-phase, causal filter will be used.

When filtering, there are always trade-offs that should be considered. One important trade-off is balancing time-domain characteristics (like ringing) and frequency-domain attenuation characteristics (like effective transition bandwidth). Filters with sharp frequency cutoffs can produce outputs that ring for a long time when they operate on signals with frequency content in the transition band. In general, therefore, the wider a transition band that can be tolerated, the better behaved the filter will be in the time domain.

Thomas W. Parks and C. Sidney S. Burrus. Digital Filter Design. Topics in Digital Signal Processing. Wiley, New York, 1987. ISBN 978-0-471-82896-9.

Emmanuel C. Ifeachor and Barrie W. Jervis. Digital Signal Processing: A Practical Approach. Pearson, 2 edition, 2002.

Andreas Widmann, Erich Schr√∂ger, and Burkhard Maess. Digital filter design for electrophysiological data ‚Äì a practical approach. Journal of Neuroscience Methods, 250:34‚Äì46, 2015. doi:10.1016/j.jneumeth.2014.08.002.

Andreas Widmann and Erich Schr√∂ger. Filter effects and filter artifacts in the analysis of electrophysiological data. Frontiers in Psychology, 2012. doi:10.3389/fpsyg.2012.00233.

Rufin VanRullen. Four common conceptual fallacies in mapping the time course of recognition. Frontiers in Psychology, 2011. doi:10.3389/fpsyg.2011.00365.

Guillaume A. Rousselet. Does filtering preclude us from studying ERP time-courses? Frontiers in Psychology, 2012. doi:10.3389/fpsyg.2012.00131.

David J. Acunzo, Graham MacKenzie, and Mark C.W. van Rossum. Systematic biases in early ERP and ERF components as a result of high-pass filtering. Journal of Neuroscience Methods, 209(1):212‚Äì218, 2012. doi:10.1016/j.jneumeth.2012.06.011.

Darren Tanner, Kara Morgan-Short, and Steven J. Luck. How inappropriate high-pass filters can produce artifactual effects and incorrect conclusions in ERP studies of language and cognition: high-pass filtering and artifactual ERP effects. Psychophysiology, 52(8):997‚Äì1009, 2015. doi:10.1111/psyp.12437.

Emily S. Kappenman and Steven J. Luck. The effects of electrode impedance on data quality and statistical significance in ERP recordings. Psychophysiology, 2010. doi:10.1111/j.1469-8986.2010.01009.x.

Burkhard Maess, Erich Schr√∂ger, and Andreas Widmann. High-pass filters and baseline correction in M/EEG analysis. Commentary on: ‚ÄúHow inappropriate high-pass filters can produce artefacts and incorrect conclusions in ERP studies of language and cognition‚Äù. Journal of Neuroscience Methods, 266:164‚Äì165, 2016. doi:10.1016/j.jneumeth.2015.12.003.

Darren Tanner, James J.S. Norton, Kara Morgan-Short, and Steven J. Luck. On high-pass filter artifacts (they‚Äôre real) and baseline correction (it‚Äôs a good idea) in ERP/ERMF analysis. Journal of Neuroscience Methods, 266:166‚Äì170, 2016. doi:10.1016/j.jneumeth.2016.01.002.

Burkhard Maess, Erich Schr√∂ger, and Andreas Widmann. High-pass filters and baseline correction in M/EEG analysis-continued discussion. Journal of Neuroscience Methods, 266:171‚Äì172, 2016. doi:10.1016/j.jneumeth.2016.01.016.

Total running time of the script: (0 minutes 20.202 seconds)

Download Jupyter notebook: 25_background_filtering.ipynb

Download Python source code: 25_background_filtering.py

Download zipped: 25_background_filtering.zip

Gallery generated by Sphinx-Gallery

Rejecting bad data spans and breaks

Filtering and resampling data

---

## Background on projectors and projections#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/45_projectors_background.html

**Contents:**
- Background on projectors and projections#
- What is a projection?#
  - Example: projection as noise reduction#
- Signal-space projection (SSP)#
- Projectors in MNE-Python#
  - Computing projectors#
  - Visualizing the effect of projectors#
  - Loading and saving projectors#
  - Adding and removing projectors#
  - When are projectors ‚Äúapplied‚Äù?#

Go to the end to download the full example code.

This tutorial provides background information on projectors and Signal Space Projection (SSP), and covers loading and saving projectors, adding and removing projectors from Raw objects, the difference between ‚Äúapplied‚Äù and ‚Äúunapplied‚Äù projectors, and at what stages MNE-Python applies projectors automatically.

We‚Äôll start by importing the Python modules we need; we‚Äôll also define a short function to make it easier to make several plots that look similar:

In the most basic terms, a projection is an operation that converts one set of points into another set of points, where repeating the projection operation on the resulting points has no effect. To give a simple geometric example, imagine the point \((3, 2, 5)\) in 3-dimensional space. A projection of that point onto the \(x, y\) plane looks a lot like a shadow cast by that point if the sun were directly above it:

The @ symbol indicates matrix multiplication on NumPy arrays, and was introduced in Python 3.5 / NumPy 1.10. The notation plot(*point) uses Python argument expansion to ‚Äúunpack‚Äù the elements of point into separate positional arguments to the function. In other words, plot(*point) expands to plot(3, 2, 5).

Notice that we used matrix multiplication to compute the projection of our point \((3, 2, 5)\) onto the \(x, y\) plane:

‚Ä¶and that applying the projection again to the result just gives back the result again:

From an information perspective, this projection has taken the point \(x, y, z\) and removed the information about how far in the \(z\) direction our point was located; all we know now is its position in the \(x, y\) plane. Moreover, applying our projection matrix to any point in \(x, y, z\) space will reduce it to a corresponding point on the \(x, y\) plane. The term for this is a subspace: the projection matrix projects points in the original space into a subspace of lower dimension than the original. The reason our subspace is the \(x,y\) plane (instead of, say, the \(y,z\) plane) is a direct result of the particular values in our projection matrix.

Another way to describe this ‚Äúloss of information‚Äù or ‚Äúprojection into a subspace‚Äù is to say that projection reduces the rank (or ‚Äúdegrees of freedom‚Äù) of the measurement ‚Äî here, from 3 dimensions down to 2. On the other hand, if you know that measurement component in the \(z\) direction is just noise due to your measurement method, and all you care about are the \(x\) and \(y\) components, then projecting your 3-dimensional measurement into the \(x, y\) plane could be seen as a form of noise reduction.

Of course, it would be very lucky indeed if all the measurement noise were concentrated in the \(z\) direction; you could just discard the \(z\) component without bothering to construct a projection matrix or do the matrix multiplication. Suppose instead that in order to take that measurement you had to pull a trigger on a measurement device, and the act of pulling the trigger causes the device to move a little. If you measure how trigger-pulling affects measurement device position, you could then ‚Äúcorrect‚Äù your real measurements to ‚Äúproject out‚Äù the effect of the trigger pulling. Here we‚Äôll suppose that the average effect of the trigger is to move the measurement device by \((3, -1, 1)\):

Knowing that, we can compute a plane that is orthogonal to the effect of the trigger (using the fact that a plane through the origin has equation \(Ax + By + Cz = 0\) given a normal vector \((A, B, C)\)), and project our real measurements onto that plane.

Computing the projection matrix from the trigger_effect vector is done using singular value decomposition (SVD); interested readers may consult the internet or a linear algebra textbook for details on this method. With the projection matrix in place, we can project our original vector \((3, 2, 5)\) to remove the effect of the trigger, and then plot it:

Just as before, the projection matrix will map any point in \(x, y, z\) space onto that plane, and once a point has been projected onto that plane, applying the projection again will have no effect. For that reason, it should be clear that although the projected points vary in all three \(x\), \(y\), and \(z\) directions, the set of projected points have only two effective dimensions (i.e., they are constrained to a plane).

In MNE-Python, the matrix used to project a raw signal into a subspace is usually called a projector or a projection operator ‚Äî these terms are interchangeable with the term projection matrix used above.

Projections of EEG or MEG signals work in very much the same way: the point \(x, y, z\) corresponds to the value of each sensor at a single time point, and the projection matrix varies depending on what aspects of the signal (i.e., what kind of noise) you are trying to project out. The only real difference is that instead of a single 3-dimensional point \((x, y, z)\) you‚Äôre dealing with a time series of \(N\)-dimensional ‚Äúpoints‚Äù (one at each sampling time), where \(N\) is usually in the tens or hundreds (depending on how many sensors your EEG/MEG system has). Fortunately, because projection is a matrix operation, it can be done very quickly even on signals with hundreds of dimensions and tens of thousands of time points.

We mentioned above that the projection matrix will vary depending on what kind of noise you are trying to project away. Signal-space projection (SSP) [1] is a way of estimating what that projection matrix should be, by comparing measurements with and without the signal of interest. For example, you can take additional ‚Äúempty room‚Äù measurements that record activity at the sensors when no subject is present. By looking at the spatial pattern of activity across MEG sensors in an empty room measurement, you can create one or more \(N\)-dimensional vector(s) giving the ‚Äúdirection(s)‚Äù of environmental noise in sensor space (analogous to the vector for ‚Äúeffect of the trigger‚Äù in our example above). SSP is also often used for removing heartbeat and eye movement artifacts ‚Äî in those cases, instead of empty room recordings the direction of the noise is estimated by detecting the artifacts, extracting epochs around them, and averaging. See Repairing artifacts with SSP for examples.

Once you know the noise vectors, you can create a hyperplane that is orthogonal to them, and construct a projection matrix to project your experimental recordings onto that hyperplane. In that way, the component of your measurements associated with environmental noise can be removed. Again, it should be clear that the projection reduces the dimensionality of your data ‚Äî you‚Äôll still have the same number of sensor signals, but they won‚Äôt all be linearly independent ‚Äî but typically there are tens or hundreds of sensors and the noise subspace that you are eliminating has only 3-5 dimensions, so the loss of degrees of freedom is usually not problematic.

In our example data, SSP has already been performed using empty room recordings, but the projectors are stored alongside the raw data and have not been applied yet (or, synonymously, the projectors are not active yet). Here we‚Äôll load the sample data and crop it to 60 seconds; you can see the projectors in the output of read_raw_fif() below:

In MNE-Python, the environmental noise vectors are computed using principal component analysis, usually abbreviated ‚ÄúPCA‚Äù, which is why the SSP projectors usually have names like ‚ÄúPCA-v1‚Äù. (Incidentally, since the process of performing PCA uses singular value decomposition under the hood, it is also common to see phrases like ‚Äúprojectors were computed using SVD‚Äù in published papers.) The projectors are stored in the projs field of raw.info:

raw.info['projs'] is an ordinary Python list of Projection objects, so you can access individual projectors by indexing into it. The Projection object itself is similar to a Python dict, so you can use its .keys() method to see what fields it contains (normally you don‚Äôt need to access its properties directly, but you can if necessary):

The Raw, Epochs, and Evoked objects all have a boolean proj attribute that indicates whether there are any unapplied / inactive projectors stored in the object. In other words, the proj attribute is True if at least one projector is present and all of them are active. In addition, each individual projector also has a boolean active field:

In MNE-Python, SSP vectors can be computed using general purpose functions mne.compute_proj_raw(), mne.compute_proj_epochs(), and mne.compute_proj_evoked(). The general assumption these functions make is that the data passed contains raw data, epochs or averages of the artifact you want to repair via projection. In practice this typically involves continuous raw data of empty room recordings or averaged ECG or EOG artifacts. A second set of high-level convenience functions is provided to compute projection vectors for typical use cases. This includes mne.preprocessing.compute_proj_ecg() and mne.preprocessing.compute_proj_eog() for computing the ECG and EOG related artifact components, respectively; see Repairing artifacts with SSP for examples of these uses. For computing the EEG reference signal as a projector, the function mne.set_eeg_reference() can be used; see Setting the EEG reference for more information.

It is best to compute projectors only on channels that will be used (e.g., excluding bad channels). This ensures that projection vectors will remain ortho-normalized and that they properly capture the activity of interest.

You can see the effect the projectors are having on the measured signal by comparing plots with and without the projectors applied. By default, raw.plot() will apply the projectors in the background before plotting (without modifying the Raw object); you can control this with the boolean proj parameter as shown below, or you can turn them on and off interactively with the projectors interface, accessed via the Proj button in the lower right corner of the plot window. Here we‚Äôll look at just the magnetometers, and a 2-second sample from the beginning of the file.

Additional ways of visualizing projectors are covered in the tutorial Repairing artifacts with SSP.

SSP can be used for other types of signal cleaning besides just reduction of environmental noise. You probably noticed two large deflections in the magnetometer signals in the previous plot that were not removed by the empty-room projectors ‚Äî those are artifacts of the subject‚Äôs heartbeat. SSP can be used to remove those artifacts as well. The sample data includes projectors for heartbeat noise reduction that were saved in a separate file from the raw data, which can be loaded with the mne.read_proj() function:

There is a corresponding mne.write_proj() function that can be used to save projectors to disk in .fif format:

By convention, MNE-Python expects projectors to be saved with a filename ending in -proj.fif (or -proj.fif.gz), and will issue a warning if you forgo this recommendation.

Above, when we printed the ecg_projs list that we loaded from a file, it showed two projectors for gradiometers (the first two, marked ‚Äúplanar‚Äù), two for magnetometers (the middle two, marked ‚Äúaxial‚Äù), and two for EEG sensors (the last two, marked ‚Äúeeg‚Äù). We can add them to the Raw object using the add_proj() method:

To remove projectors, there is a corresponding method del_proj() that will remove projectors based on their index within the raw.info['projs'] list. For the special case of replacing the existing projectors with new ones, use raw.add_proj(ecg_projs, remove_existing=True).

To see how the ECG projectors affect the measured signal, we can once again plot the data with and without the projectors applied (though remember that the plot() method only temporarily applies the projectors for visualization, and does not permanently change the underlying data). We‚Äôll compare the mags variable we created above, which had only the empty room SSP projectors, to the data with both empty room and ECG projectors:

By default, projectors are applied when creating epoched data from Raw data, though application of the projectors can be delayed by passing proj=False to the Epochs constructor. However, even when projectors have not been applied, the mne.Epochs.get_data() method will return data as if the projectors had been applied (though the Epochs object will be unchanged). Additionally, projectors cannot be applied if the data are not preloaded. If the data are memory-mapped (i.e., not preloaded), you can check the _projector attribute to see whether any projectors will be applied once the data is loaded in memory.

Finally, when performing inverse imaging (i.e., with mne.minimum_norm.apply_inverse()), the projectors will be automatically applied. It is also possible to apply projectors manually when working with Raw, Epochs or Evoked objects via the object‚Äôs apply_proj() method. For all instance types, you can always copy the contents of <instance>.info['projs'] into a separate list variable, use <instance>.del_proj(<index of proj(s) to remove>) to remove one or more projectors, and then add them back later with <instance>.add_proj(<list containing projs>) if desired.

Remember that once a projector is applied, it can‚Äôt be un-applied, so during interactive / exploratory analysis it‚Äôs a good idea to use the object‚Äôs copy() method before applying projectors.

In general, it is recommended to apply projectors when creating Epochs from Raw data. There are two reasons for this recommendation:

It is computationally cheaper to apply projectors to data after the data have been reduced to just the segments of interest (the epochs)

If you are applying amplitude-based rejection criteria to epochs, it is preferable to reject based on the signal after projectors have been applied, because the projectors may reduce noise in some epochs to tolerable levels (thereby increasing the number of acceptable epochs and consequenty increasing statistical power in any later analyses).

Mikko A. Uusitalo and Risto J. Ilmoniemi. Signal-space projection method for separating MEG or EEG into components. Medical & Biological Engineering & Computing, 35(2):135‚Äì140, 1997. doi:10.1007/BF02534144.

Total running time of the script: (0 minutes 9.460 seconds)

Download Jupyter notebook: 45_projectors_background.ipynb

Download Python source code: 45_projectors_background.py

Download zipped: 45_projectors_background.zip

Gallery generated by Sphinx-Gallery

Repairing artifacts with ICA

Repairing artifacts with SSP

---

## Brainstorm CTF phantom dataset tutorial#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/85_brainstorm_phantom_ctf.html

**Contents:**
- Brainstorm CTF phantom dataset tutorial#
- References#

Go to the end to download the full example code.

Here we compute the evoked from raw for the Brainstorm CTF phantom tutorial dataset. For comparison, see [1] and:

https://neuroimage.usc.edu/brainstorm/Tutorials/PhantomCtf

Fran√ßois Tadel, Sylvain Baillet, John C. Mosher, Dimitrios Pantazis, and Richard M. Leahy. Brainstorm: a user-friendly application for MEG/EEG analysis. Computational Intelligence and Neuroscience, 2011:1‚Äì13, 2011. doi:10.1155/2011/879716.

The data were collected with a CTF system at 2400 Hz.

The sinusoidal signal is generated on channel HDAC006, so we can use that to obtain precise timing.

Let‚Äôs create some events using this signal by thresholding the sinusoid.

The CTF software compensation works reasonably well:

But here we can get slightly better noise suppression, lower localization bias, and a better dipole goodness of fit with spatio-temporal (tSSS) Maxwell filtering:

Our choice of tmin and tmax should capture exactly one cycle, so we can make the unusual choice of baselining using the entire epoch when creating our evoked data. We also then crop to a single time point (@t=0) because this is a peak in our signal.

Let‚Äôs use a sphere head geometry model and let‚Äôs see the coordinate alignment and the sphere location.

To do a dipole fit, let‚Äôs use the covariance provided by the empty room recording.

Compare the actual position with the estimated one.

Total running time of the script: (0 minutes 31.661 seconds)

Download Jupyter notebook: 85_brainstorm_phantom_ctf.ipynb

Download Python source code: 85_brainstorm_phantom_ctf.py

Download zipped: 85_brainstorm_phantom_ctf.zip

Gallery generated by Sphinx-Gallery

Brainstorm Elekta phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

---

## Brainstorm Elekta phantom dataset tutorial#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/80_brainstorm_phantom_elekta.html

**Contents:**
- Brainstorm Elekta phantom dataset tutorial#
- References#

Go to the end to download the full example code.

Here we compute the evoked from raw for the Brainstorm Elekta phantom tutorial dataset. For comparison, see [1] and the original Brainstorm tutorial.

The data were collected with an Elekta Neuromag VectorView system at 1000 Hz and low-pass filtered at 330 Hz. Here the medium-amplitude (200 nAm) data are read to construct instances of mne.io.Raw.

Data channel array consisted of 204 MEG planor gradiometers, 102 axial magnetometers, and 3 stimulus channels. Let‚Äôs get the events for the phantom, where each dipole (1-32) gets its own event:

The data has strong line frequency (60 Hz and harmonics) and cHPI coil noise (five peaks around 300 Hz). Here, we use only the first 30 seconds to save memory:

Our phantom produces sinusoidal bursts at 20 Hz:

Now we epoch our data, average it, and look at the first dipole response. The first peak appears around 3 ms. Because we low-passed at 40 Hz, we can also decimate our data to save memory.

Let‚Äôs use a sphere head geometry model and let‚Äôs see the coordinate alignment and the sphere location. The phantom is properly modeled by a single-shell sphere with origin (0., 0., 0.).

Even though this is a VectorView/TRIUX phantom, we can use the Otaniemi phantom subject as a surrogate because the ‚Äúhead‚Äù surface (hemisphere outer shell) has the same geometry for both phantoms, even though the internal dipole locations differ. The phantom_otaniemi scan was aligned to the phantom‚Äôs head coordinate frame, so an identity trans is appropriate here.

Let‚Äôs do some dipole fits. We first compute the noise covariance, then do the fits for each event_id taking the time instant that maximizes the global field power.

Do a quick visualization of how much variance we explained, putting the data and residuals on the same scale (here the ‚Äútime points‚Äù are the 32 dipole peak values that we fit):

Now we can compare to the actual locations, taking the difference in mm:

Let‚Äôs plot the positions and the orientations of the actual and the estimated dipoles

Fran√ßois Tadel, Sylvain Baillet, John C. Mosher, Dimitrios Pantazis, and Richard M. Leahy. Brainstorm: a user-friendly application for MEG/EEG analysis. Computational Intelligence and Neuroscience, 2011:1‚Äì13, 2011. doi:10.1155/2011/879716.

Total running time of the script: (1 minutes 3.906 seconds)

Download Jupyter notebook: 80_brainstorm_phantom_elekta.ipynb

Download Python source code: 80_brainstorm_phantom_elekta.py

Download zipped: 80_brainstorm_phantom_elekta.zip

Gallery generated by Sphinx-Gallery

EEG source localization given electrode locations on an MRI

Brainstorm CTF phantom dataset tutorial

---

## Built-in plotting methods for Raw objects#

**URL:** https://mne.tools/stable/auto_tutorials/raw/40_visualize_raw.html

**Contents:**
- Built-in plotting methods for Raw objects#
- Interactive data browsing with Raw.plot()#
- Plotting spectral density of continuous data#
- Plotting sensor locations from Raw objects#
- Plotting projectors from Raw objects#

Go to the end to download the full example code.

This tutorial shows how to plot continuous data as a time series, how to plot the spectral density of continuous data, and how to plot the sensor locations and projectors stored in Raw objects.

As usual we‚Äôll start by importing the modules we need, loading some example data, and cropping the Raw object to just 60 seconds before loading it into RAM to save memory:

We‚Äôve seen in a previous tutorial how to plot data from a Raw object using matplotlib, but Raw objects also have several built-in plotting methods:

The first one is discussed here in detail; the last two are shown briefly and covered in-depth in other tutorials. This tutorial also covers a few ways of plotting the spectral content of Raw data.

The plot method of Raw objects provides a versatile interface for exploring continuous data. For interactive viewing and data quality checking, it can be called with no additional parameters:

It may not be obvious when viewing this tutorial online, but by default, the plot method generates an interactive plot window with several useful features:

It spaces the channels equally along the y-axis.

20 channels are shown by default; you can scroll through the channels using the ‚Üë and ‚Üì arrow keys, or by clicking on the colored scroll bar on the right edge of the plot.

The number of visible channels can be adjusted by the n_channels parameter, or changed interactively using page up and page down keys.

You can toggle the display to ‚Äúbutterfly‚Äù mode (superimposing all channels of the same type on top of one another) by pressing b, or start in butterfly mode by passing the butterfly=True parameter.

It shows the first 10 seconds of the Raw object.

You can shorten or lengthen the window length using home and end keys, or start with a specific window duration by passing the duration parameter.

You can scroll in the time domain using the ‚Üê and ‚Üí arrow keys, or start at a specific point by passing the start parameter. Scrolling using shift‚Üí or shift‚Üê scrolls a full window width at a time.

It allows clicking on channels to mark/unmark as ‚Äúbad‚Äù.

When the plot window is closed, the Raw object‚Äôs info attribute will be updated, adding or removing the newly (un)marked channels to/from the Info object‚Äôs bads field (A.K.A. raw.info['bads']).

It allows interactive annotation of the raw data.

This allows you to mark time spans that should be excluded from future computations due to large movement artifacts, line noise, or other distortions of the signal. Annotation mode is entered by pressing a. See Basic annotation for details.

It automatically applies any projectors before plotting the data.

These can be enabled/disabled interactively by clicking the Proj button at the lower right corner of the plot window, or disabled by default by passing the proj=False parameter. See Background on projectors and projections for more info on projectors.

These and other keyboard shortcuts are listed in the Help window, accessed through the Help button at the lower left corner of the plot window. Other plot properties (such as color of the channel traces, channel order and grouping, simultaneous plotting of events, scaling, clipping, filtering, etc.) can also be adjusted through parameters passed to the plot method; see the docstring for details.

To visualize the frequency content of continuous data, the Raw object provides a compute_psd() method to compute spectral density and the resulting Spectrum object has a plot() method:

If the data have been filtered, vertical dashed lines will automatically indicate filter boundaries. The spectrum for each channel type is drawn in its own subplot; here we‚Äôve passed the average=True parameter to get a summary for each channel type, but it is also possible to plot each channel individually, with options for how the spectrum should be computed, color-coding the channels by location, and more. For example, here is a plot of just a few sensors (specified with the picks parameter), color-coded by spatial location (via the spatial_colors parameter, see the documentation of plot for full details):

It is also possible to plot spectral power estimates across sensors as a scalp topography, using the Spectrum‚Äôs plot_topomap() method. The default parameters will plot five frequency bands (Œ¥, Œ∏, Œ±, Œ≤, Œ≥), will compute power based on magnetometer channels (if present), and will plot the power estimates on a dB-like log-scale:

Alternatively, you can plot the PSD for every sensor on its own axes, with the axes arranged spatially to correspond to sensor locations in space, using plot_topo:

This plot is also interactive; hovering over each ‚Äúthumbnail‚Äù plot will display the channel name in the bottom left of the plot window, and clicking on a thumbnail plot will create a second figure showing a larger version of the selected channel‚Äôs spectral density (as if you had called plot with that channel passed as picks).

By default, plot_topo will show only the MEG channels if MEG channels are present; if only EEG channels are found, they will be plotted instead:

Prior to the addition of the Spectrum class, the above plots were possible via:

(there was no plot_topomap method for Raw). The plot_psd() and plot_psd_topo() methods of Raw objects are still provided to support legacy analysis scripts, but new code should instead use the Spectrum object API.

The channel locations in a Raw object can be easily plotted with the plot_sensors method. A brief example is shown here; notice that channels in raw.info['bads'] are plotted in red. More details and additional examples are given in the tutorial Working with sensor locations.

As seen in the output of mne.io.read_raw_fif above, there are projectors included in the example Raw file (representing environmental noise in the signal, so it can later be ‚Äúprojected out‚Äù during preprocessing). You can visualize these projectors using the plot_projs_topomap method. By default it will show one figure per channel type for which projectors are present, and each figure will have one subplot per projector. The three projectors in this file were only computed for magnetometers, so one figure with three subplots is generated. More details on working with and plotting projectors are given in Background on projectors and projections and Repairing artifacts with SSP.

Total running time of the script: (0 minutes 7.042 seconds)

Download Jupyter notebook: 40_visualize_raw.ipynb

Download Python source code: 40_visualize_raw.py

Download zipped: 40_visualize_raw.zip

Gallery generated by Sphinx-Gallery

Annotating continuous data

---

## Clinical applications#

**URL:** https://mne.tools/stable/auto_tutorials/clinical/index.html

**Contents:**
- Clinical applications#
- MNE-GUI-addons examples#
- MNE-Python examples#

These tutorials illustrate some clinical use cases.

The mne_gui_addons package supports some clinical use cases:

Locating intracranial electrode contacts

MNE-Python also supports some clinical use cases directly:

Working with sEEG data

Working with ECoG data

Sleep stage classification from polysomnography (PSG) data

Working with sEEG data

---

## Compare evoked responses for different conditions#

**URL:** https://mne.tools/stable/auto_examples/visualization/topo_compare_conditions.html

**Contents:**
- Compare evoked responses for different conditions#

Go to the end to download the full example code.

In this example, an Epochs object for visual and auditory responses is created. Both conditions are then accessed by their respective names to create a sensor layout plot of the related evoked responses.

Show topography for two different conditions.

Total running time of the script: (0 minutes 2.661 seconds)

Download Jupyter notebook: topo_compare_conditions.ipynb

Download Python source code: topo_compare_conditions.py

Download zipped: topo_compare_conditions.zip

Gallery generated by Sphinx-Gallery

Sensitivity map of SSP projections

Plot custom topographies for MEG sensors

---

## Compare the different ICA algorithms in MNE#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/ica_comparison.html

**Contents:**
- Compare the different ICA algorithms in MNE#

Go to the end to download the full example code.

Different ICA algorithms are fit to raw MEG data, and the corresponding maps are displayed.

Read and preprocess the data. Preprocessing consists of:

MEG channel selection

1-30 Hz band-pass filter

Define a function that runs ICA on the raw MEG data and plots the components

Total running time of the script: (0 minutes 25.763 seconds)

Download Jupyter notebook: ica_comparison.ipynb

Download Python source code: ica_comparison.py

Download zipped: ica_comparison.zip

Gallery generated by Sphinx-Gallery

Visualise NIRS artifact correction methods

Interpolate bad channels for MEG/EEG channels

---

## Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM#

**URL:** https://mne.tools/stable/auto_examples/inverse/evoked_ers_source_power.html

**Contents:**
- Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM#
- Compute covariances#
- Compute some source estimates#
- Plot source estimates#

Go to the end to download the full example code.

Here we examine 3 ways of localizing event-related synchronization (ERS) of beta band activity in this dataset: Somatosensory using DICS, LCMV beamformer, and dSPM applied to active and baseline covariance matrices.

Reading the raw data and creating epochs:

ERS activity starts at 0.5 seconds after stimulus onset. Because these data have been processed by MaxFilter directly (rather than MNE-Python‚Äôs version), we have to be careful to compute the rank with a more conservative threshold in order to get the correct data rank (64). Once this is used in combination with an advanced covariance estimator like ‚Äúshrunk‚Äù, the rank will be correctly preserved.

Here we will use DICS, LCMV beamformer, and dSPM.

See Compute source power using DICS beamformer for more information about DICS.

For more advanced usage, see Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM.

Total running time of the script: (0 minutes 31.447 seconds)

Download Jupyter notebook: evoked_ers_source_power.ipynb

Download Python source code: evoked_ers_source_power.py

Download zipped: evoked_ers_source_power.zip

Gallery generated by Sphinx-Gallery

Compute source power using DICS beamformer

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

---

## Compute MNE-dSPM inverse solution on evoked data in volume source space#

**URL:** https://mne.tools/stable/auto_examples/inverse/compute_mne_inverse_volume.html

**Contents:**
- Compute MNE-dSPM inverse solution on evoked data in volume source space#

Go to the end to download the full example code.

Compute dSPM inverse solution on MNE evoked dataset in a volume source space and stores the solution in a nifti file for visualisation.

Total running time of the script: (0 minutes 4.688 seconds)

Download Jupyter notebook: compute_mne_inverse_volume.ipynb

Download Python source code: compute_mne_inverse_volume.py

Download zipped: compute_mne_inverse_volume.zip

Gallery generated by Sphinx-Gallery

Compute sLORETA inverse solution on raw data

Source localization with a custom inverse solver

---

## Compute MNE-dSPM inverse solution on single epochs#

**URL:** https://mne.tools/stable/auto_examples/inverse/compute_mne_inverse_epochs_in_label.html

**Contents:**
- Compute MNE-dSPM inverse solution on single epochs#

Go to the end to download the full example code.

Compute dSPM inverse solution on single trial epochs restricted to a brain label.

View activation time-series to illustrate the benefit of aligning/flipping

Viewing single trial dSPM and average dSPM for unflipped pooling over label Compare to (1) Inverse (dSPM) then average, (2) Evoked then dSPM

Total running time of the script: (0 minutes 2.584 seconds)

Download Jupyter notebook: compute_mne_inverse_epochs_in_label.ipynb

Download Python source code: compute_mne_inverse_epochs_in_label.py

Download zipped: compute_mne_inverse_epochs_in_label.zip

Gallery generated by Sphinx-Gallery

Inverse problem and source analysis

Compute sLORETA inverse solution on raw data

---

## Compute MNE inverse solution on evoked data with a mixed source space#

**URL:** https://mne.tools/stable/auto_examples/inverse/mixed_source_space_inverse.html

**Contents:**
- Compute MNE inverse solution on evoked data with a mixed source space#
- Set up our source space#
- View the source space#
- Compute the fwd matrix#
- Compute inverse solution#
- Plot the mixed source estimate#
- Plot the surface#
- Plot the volume#
- Process labels#

Go to the end to download the full example code.

Create a mixed source space and compute an MNE inverse solution on an evoked dataset.

List substructures we are interested in. We select only the sub structures we want to include in the source space:

Get a surface-based source space, here with few source points for speed in this demonstration, in general you should use oct6 spacing!

Now we create a mixed src space by adding the volume regions specified in the list labels_vol. First, read the aseg file and the source space bounds using the inner skull surface (here using 10mm spacing to save time, we recommend something smaller like 5.0 in actual analyses):

We could write the mixed source space with:

We can also export source positions to NIfTI file and visualize it again:

Average the source estimates within each label of the cortical parcellation and each sub structure contained in the src space

Total running time of the script: (0 minutes 48.135 seconds)

Download Jupyter notebook: mixed_source_space_inverse.ipynb

Download Python source code: mixed_source_space_inverse.py

Download zipped: mixed_source_space_inverse.zip

Gallery generated by Sphinx-Gallery

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute source power estimate by projecting the covariance with MNE

---

## Compute Power Spectral Density of inverse solution from single epochs#

**URL:** https://mne.tools/stable/auto_examples/time_frequency/compute_source_psd_epochs.html

**Contents:**
- Compute Power Spectral Density of inverse solution from single epochs#
- Compute source space PSD in label#

Go to the end to download the full example code.

Compute PSD of dSPM inverse solution on single trial epochs restricted to a brain label. The PSD is computed using a multi-taper method with Discrete Prolate Spheroidal Sequence (DPSS) windows.

By using ‚Äúreturn_generator=True‚Äù stcs will be a generator object instead of a list. This allows us so to iterate without having to keep everything in memory.

Visualize the 10 Hz PSD:

Visualize the entire spectrum:

Total running time of the script: (0 minutes 5.161 seconds)

Download Jupyter notebook: compute_source_psd_epochs.ipynb

Download Python source code: compute_source_psd_epochs.py

Download zipped: compute_source_psd_epochs.zip

Gallery generated by Sphinx-Gallery

Compute a cross-spectral density (CSD) matrix

Compute power and phase lock in label of the source space

---

## Compute Rap-Music on evoked data#

**URL:** https://mne.tools/stable/auto_examples/inverse/rap_music.html

**Contents:**
- Compute Rap-Music on evoked data#
- References#

Go to the end to download the full example code.

Compute a Recursively Applied and Projected MUltiple Signal Classification (RAP-MUSIC) [1] on evoked data.

John C. Mosher and Richard M. Leahy. Source localization using recursively applied and projected (RAP) MUSIC. IEEE Transactions on Signal Processing, 47(2):332‚Äì340, 1999. doi:10.1109/78.740118.

Total running time of the script: (0 minutes 12.737 seconds)

Download Jupyter notebook: rap_music.ipynb

Download Python source code: rap_music.py

Download zipped: rap_music.zip

Gallery generated by Sphinx-Gallery

Plot point-spread functions (PSFs) for a volume

Reading an inverse operator

---

## Compute source level time-frequency timecourses using a DICS beamformer#

**URL:** https://mne.tools/stable/auto_examples/inverse/dics_epochs.html

**Contents:**
- Compute source level time-frequency timecourses using a DICS beamformer#

Go to the end to download the full example code.

In this example, a Dynamic Imaging of Coherent Sources (DICS) [1] beamformer is used to transform sensor-level time-frequency objects to the source level. We will look at the event-related synchronization (ERS) of beta band activity in the somato dataset.

Organize the data that we will use for this example.

First, we load the data and compute for each epoch the time-frequency decomposition in sensor space.

Now, we build a DICS beamformer and project the sensor-level TFR to the source level.

Let‚Äôs visualize the source time course estimate. We can see the expected activation of the two gyri bordering the central sulcus, the primary somatosensory and motor cortices (S1 and M1).

Total running time of the script: (0 minutes 52.143 seconds)

Download Jupyter notebook: dics_epochs.ipynb

Download Python source code: dics_epochs.py

Download zipped: dics_epochs.zip

Gallery generated by Sphinx-Gallery

Source localization with a custom inverse solver

Compute source power using DICS beamformer

---

## Compute Trap-Music on evoked data#

**URL:** https://mne.tools/stable/auto_examples/inverse/trap_music.html

**Contents:**
- Compute Trap-Music on evoked data#
- References#

Go to the end to download the full example code.

Compute a Truncated Recursively Applied and Projected MUltiple Signal Classification (TRAP-MUSIC) [1] on evoked data.

Niko M√§kel√§, Matti Stenroos, Jukka Sarvas, and Risto J. Ilmoniemi. Truncated rap-music (trap-music) for meg and eeg source localization. Neuroimage, 167():73‚Äì83, 2018. doi:10.1016/j.neuroimage.2017.11.013.

Total running time of the script: (0 minutes 9.448 seconds)

Download Jupyter notebook: trap_music.ipynb

Download Python source code: trap_music.py

Download zipped: trap_music.zip

Gallery generated by Sphinx-Gallery

Compute MxNE with time-frequency sparse prior

Plotting the full vector-valued MNE solution

---

## Computing a covariance matrix#

**URL:** https://mne.tools/stable/auto_tutorials/forward/90_compute_covariance.html

**Contents:**
- Computing a covariance matrix#
- Plot the covariance matrices#
- How should I regularize the covariance matrix?#
- References#

Go to the end to download the full example code.

Many methods in MNE, including source estimation and some classification algorithms, require covariance estimations from the recordings. In this tutorial we cover the basics of sensor covariance computations and construct a noise covariance matrix that can be used when computing the minimum-norm inverse solution. For more information, see The minimum-norm current estimates.

Source estimation methods such as MNE require noise estimates from the recordings. In this tutorial we cover the basics of noise covariance and construct a noise covariance matrix that can be used when computing the inverse solution. For more information, see The minimum-norm current estimates.

The definition of noise depends on the paradigm. In MEG it is quite common to use empty room measurements for the estimation of sensor noise. However if you are dealing with evoked responses, you might want to also consider resting state brain activity as noise. First we compute the noise using empty room recording. Note that you can also use only a part of the recording with tmin and tmax arguments. That can be useful if you use resting state as a noise baseline. Here we use the whole empty room recording to compute the noise covariance (tmax=None is the same as the end of the recording, see mne.compute_raw_covariance()).

Keep in mind that you want to match your empty room dataset to your actual MEG data, processing-wise. Ensure that filters are all the same and if you use ICA, apply it to your empty-room and subject data equivalently. In this case we did not filter the data and we don‚Äôt use ICA. However, we do have bad channels and projections in the MEG data, and, hence, we want to make sure they get stored in the covariance object.

Now that you have the covariance matrix in an MNE-Python object you can save it to a file with mne.write_cov(). Later you can read it back using mne.read_cov().

You can also use the pre-stimulus baseline to estimate the noise covariance. First we have to construct the epochs. When computing the covariance, you should use baseline correction when constructing the epochs. Otherwise the covariance matrix will be inaccurate. In MNE this is done by default, but just to be sure, we define it here manually.

Note that this method also attenuates any activity in your source estimates that resemble the baseline, if you like it or not.

Try setting proj to False to see the effect. Notice that the projectors in epochs are already applied, so proj parameter has no effect.

The estimated covariance can be numerically unstable and tends to induce correlations between estimated source amplitudes and the number of samples available. The MNE manual therefore suggests to regularize the noise covariance matrix (see Regularization of the noise-covariance matrix), especially if only few samples are available. Unfortunately it is not easy to tell the effective number of samples, hence, to choose the appropriate regularization. In MNE-Python, regularization is done using advanced regularization methods described in Engemann and Gramfort[1]. For this the 'auto' option can be used. With this option, cross-validation will be used to learn the optimal regularization:

This procedure evaluates the noise covariance quantitatively by how well it whitens the data using the negative log-likelihood of unseen data. The final result can also be visually inspected. Under the assumption that the baseline does not contain a systematic signal (time-locked to the event of interest), the whitened baseline signal should be follow a multivariate Gaussian distribution, i.e., whitened baseline signals should be between -1.96 and 1.96 at a given time sample. Based on the same reasoning, the expected value for the global field power (GFP) is 1 (calculation of the GFP should take into account the true degrees of freedom, e.g. ddof=3 with 2 active SSP vectors):

This plot displays both, the whitened evoked signals for each channels and the whitened GFP. The numbers in the GFP panel represent the estimated rank of the data, which amounts to the effective degrees of freedom by which the squared sum across sensors is divided when computing the whitened GFP. The whitened GFP also helps detecting spurious late evoked components which can be the consequence of over- or under-regularization.

Note that if data have been processed using signal space separation (SSS) [2], gradiometers and magnetometers will be displayed jointly because both are reconstructed from the same SSS basis vectors with the same numerical rank. This also implies that both sensor types are not any longer statistically independent. These methods for evaluation can be used to assess model violations. Additional introductory materials can be found here.

For expert use cases or debugging the alternative estimators can also be compared (see Whitening evoked data with a noise covariance):

This will plot the whitened evoked for the optimal estimator and display the GFP for all estimators as separate lines in the related panel.

Finally, let‚Äôs have a look at the difference between empty room and event related covariance, hacking the "method" option so that their types are shown in the legend of the plot.

Based on the negative log-likelihood, the baseline covariance seems more appropriate. Improper regularization can lead to overestimation of source amplitudes, see [1] for more information and examples.

Denis A. Engemann and Alexandre Gramfort. Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals. NeuroImage, 108:328‚Äì342, 2015. doi:10.1016/j.neuroimage.2014.12.040.

Samu Taulu, Juha Simola, and Matti J. Kajola. Applications of the signal space separation method. IEEE Transactions on Signal Processing, 53(9):3359‚Äì3372, 2005. doi:10.1109/TSP.2005.853302.

Total running time of the script: (0 minutes 21.844 seconds)

Download Jupyter notebook: 90_compute_covariance.ipynb

Download Python source code: 90_compute_covariance.py

Download zipped: 90_compute_covariance.zip

Gallery generated by Sphinx-Gallery

Fixing BEM and head surfaces

Source localization and inverses

---

## Computing various MNE solutions#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/40_mne_fixed_free.html

**Contents:**
- Computing various MNE solutions#
- Fixed orientation#
- Free orientation#

Go to the end to download the full example code.

This example shows example fixed- and free-orientation source localizations produced by the minimum-norm variants implemented in MNE-Python: MNE, dSPM, sLORETA, and eLORETA.

First let‚Äôs create a fixed-orientation inverse, with the default weighting.

Let‚Äôs look at the current estimates using MNE. We‚Äôll take the absolute value of the source estimates to simplify the visualization.

Next let‚Äôs use the default noise normalization, dSPM:

Now let‚Äôs not constrain the orientation of the dipoles at all by creating a free-orientation inverse.

Let‚Äôs look at the current estimates using MNE. We‚Äôll take the absolute value of the source estimates to simplify the visualization.

Next let‚Äôs use the default noise normalization, dSPM:

And one interesting property to note is the noise normalization of dSPM can be easily seen by visualizing the source reconstruction of the noise covariance used to compute the inverse operator ‚Äì it‚Äôs takes on the value of 1. (orange in the colormap here) across the entire brain:

Total running time of the script: (0 minutes 42.158 seconds)

Download Jupyter notebook: 40_mne_fixed_free.ipynb

Download Python source code: 40_mne_fixed_free.py

Download zipped: 40_mne_fixed_free.zip

Gallery generated by Sphinx-Gallery

The role of dipole orientations in distributed source localization

Source reconstruction using an LCMV beamformer

---

## Configuring MNE-Python#

**URL:** https://mne.tools/stable/auto_tutorials/intro/50_configure_mne.html

**Contents:**
- Configuring MNE-Python#
- Getting and setting configuration variables#
- Where configurations are stored#
- Using environment variables#
- Logging#
- Getting information about your system#

Go to the end to download the full example code.

This tutorial covers how to configure MNE-Python to suit your local system and your analysis preferences.

We begin by importing the necessary Python modules:

Configuration variables are read and written using the functions mne.get_config() and mne.set_config(). To read a specific configuration variable, pass its name to get_config() as the key parameter (key is the first parameter so you can pass it unnamed if you want):

Note that the string values read from the JSON file are not parsed in any way, so get_config() returns a string even for true/false config values, rather than a Python boolean. Similarly, set_config() will only set string values (or None values, to unset a variable):

If you‚Äôre unsure whether a config variable has been set, there is a convenient way to check it and provide a fallback in case it doesn‚Äôt exist: get_config() has a default parameter.

There are also two convenience modes of get_config(). The first will return a dict containing all config variables (and their values) that have been set on your system; this is done by passing key=None (which is the default, so it can be omitted):

The second convenience mode will return a tuple of all the keys that MNE-Python recognizes and uses, regardless of whether they‚Äôve been set on your system. This is done by passing an empty string '' as the key:

It is possible to add config variables that are not part of the recognized list, by passing any arbitrary key to set_config(). This will yield a warning, however, which is a nice check in cases where you meant to set a valid key but simply misspelled it:

Let‚Äôs delete that config variable we just created. To unset a config variable, use set_config() with value=None. Since we‚Äôre still dealing with an unrecognized key (as far as MNE-Python is concerned) we‚Äôll still get a warning, but the key will be unset:

MNE-Python stores configuration variables in a JSON file. By default, this file is located in %USERPROFILE%\.mne\mne-python.json on Windows and $HOME/.mne/mne-python.json on Linux or macOS. You can get the full path to the config file with mne.get_config_path().

However it is not a good idea to directly edit files in the .mne directory; use the getting and setting functions described in the previous section.

If for some reason you want to load the configuration from a different location, you can pass the home_dir parameter to get_config_path(), specifying the parent directory of the .mne directory where the configuration file you wish to load is stored.

For compatibility with MNE-C, MNE-Python also reads and writes environment variables to specify configuration. This is done with the same functions that read and write the JSON configuration, and is controlled with the parameters use_env and set_env. By default, get_config() will check os.environ before checking the MNE-Python JSON file; to check only the JSON file use use_env=False. To demonstrate, here‚Äôs an environment variable that is not specific to MNE-Python (and thus is not in the JSON config file):

Also by default, set_config() will set values in both the JSON file and in os.environ; to set a config variable only in the JSON file use set_env=False. Here we‚Äôll use print() statement to confirm that an environment variable is being created and deleted (we could have used the Python assert statement instead, but it doesn‚Äôt print any output when it succeeds so it‚Äôs a little less obvious):

One important configuration variable is MNE_LOGGING_LEVEL. Throughout the module, messages are generated describing the actions MNE-Python is taking behind-the-scenes. How you set MNE_LOGGING_LEVEL determines how many of those messages you see. The default logging level on a fresh install of MNE-Python is info:

The logging levels that can be set as config variables are debug, info, warning, error, and critical. Around 90% of the log messages in MNE-Python are info messages, so for most users the choice is between info (tell me what is happening) and warning (tell me only if something worrisome happens). The debug logging level is intended for MNE-Python developers.

In an earlier section we saw how mne.set_config() is used to change the logging level for the current Python session and all future sessions. To change the logging level only for the current Python session, you can use mne.set_log_level() instead. The set_log_level() function takes the same five string options that are used for the MNE_LOGGING_LEVEL config variable; additionally, it can accept int or bool values that are equivalent to those strings. The equivalencies are given in this table:

With many MNE-Python functions it is possible to change the logging level temporarily for just that function call, by using the verbose parameter. To illustrate this, we‚Äôll load some sample data with different logging levels set. First, with log level warning:

No messages were generated, because none of the messages were of severity ‚Äúwarning‚Äù or worse. Next, we‚Äôll load the same file with log level info (the default level):

This time, we got a few messages about extracting information from the file, converting that information into the MNE-Python Info format, etc. Finally, if we request debug-level information, we get even more detail ‚Äì and we do so this time using the mne.use_log_level() context manager, which is another way to accomplish the same thing as passing verbose='debug':

We‚Äôve been passing string values to the verbose parameter, but we can see from the table above that verbose=True will give us the info messages and verbose=False will suppress them; this is a useful shorthand to use in scripts, so you don‚Äôt have to remember the specific names of the different logging levels. One final note: verbose=None (which is the default for functions that have a verbose parameter) will fall back on whatever logging level was most recently set by mne.set_log_level(), or if that hasn‚Äôt been called during the current Python session, it will fall back to the value of mne.get_config('MNE_LOGGING_LEVEL').

You can also get information about what mne imports as dependencies from your system. This can be done via the command line with:

Or you can use mne.sys_info() directly, which prints to stdout by default:

Total running time of the script: (0 minutes 12.360 seconds)

Download Jupyter notebook: 50_configure_mne.ipynb

Download Python source code: 50_configure_mne.py

Download zipped: 50_configure_mne.zip

Gallery generated by Sphinx-Gallery

Working with sensor locations

Getting started with mne.Report

---

## Corrupt known signal with point spread#

**URL:** https://mne.tools/stable/auto_tutorials/simulation/70_point_spread.html

**Contents:**
- Corrupt known signal with point spread#
- Load the MEG data#
- Estimate the background noise covariance from the baseline period#
- Generate sinusoids in two spatially distant labels#
- Find the center vertices in source space of each label#
- Create source-space data with known signals#
- Plot original signals#
- Simulate sensor-space signals#
- Plot the point-spread of corrupted signal#
- Exercises#

Go to the end to download the full example code.

The aim of this tutorial is to demonstrate how to put a known signal at a desired location(s) in a mne.SourceEstimate and then corrupt the signal with point-spread by applying a forward and inverse solution.

First, we set some parameters.

We want the known signal in each label to only be active at the center. We create a mask for each label that is 1 at the center vertex and 0 at all other vertices in the label. This mask is then used when simulating source-space data.

Put known signals onto surface vertices using the array of signals and the label masks (stored in labels[i].values).

Note that the original signals are highly concentrated (point) sources.

Use the forward solution and add Gaussian noise to simulate sensor-space (evoked) data from the known source-space signals. The amount of noise is controlled by nave (higher values imply less noise).

Notice that after applying the forward- and inverse-operators to the known point sources that the point sources have spread across the source-space. This spread is due to the minimum norm solution so that the signal leaks to nearby vertices with similar orientations so that signal ends up crossing the sulci and gyri.

Change the method parameter to either 'dSPM' or 'MNE' to explore the effect of the inverse method.

Try setting evoked_snr to a small, finite value, e.g. 3., to see the effect of noise.

Total running time of the script: (0 minutes 15.348 seconds)

Download Jupyter notebook: 70_point_spread.ipynb

Download Python source code: 70_point_spread.py

Download zipped: 70_point_spread.zip

Gallery generated by Sphinx-Gallery

Creating MNE-Python data structures from scratch

DICS for power mapping

---

## Cortical Signal Suppression (CSS) for removal of cortical signals#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/css.html

**Contents:**
- Cortical Signal Suppression (CSS) for removal of cortical signals#
- References#

Go to the end to download the full example code.

This script shows an example of how to use CSS [1] . CSS suppresses the cortical contribution to the signal subspace in EEG data using MEG data, facilitating detection of subcortical signals. We will illustrate how it works by simulating one cortical and one subcortical oscillation at different frequencies; 40 Hz and 239 Hz for cortical and subcortical activity, respectively, then process it with CSS and look at the power spectral density of the raw and processed data.

Load sample subject data

Find patches (labels) to activate

Simulate one cortical dipole (40 Hz) and one subcortical (239 Hz)

Process with CSS and plot PSD of EEG data before and after processing

John Samuelsson, Sheraz Khan, Padma Sundaram, Noam Peled, and Matti H√§m√§l√§inen. Cortical signal suppression (css) for detection of subcortical activity using meg and eeg. Brain Topography, 32:215‚Äì228, 2019. doi:10.1007/s10548-018-00694-5.

Total running time of the script: (0 minutes 1.444 seconds)

Download Jupyter notebook: css.ipynb

Download Python source code: css.py

Download zipped: css.zip

Gallery generated by Sphinx-Gallery

Using contralateral referencing for EEG

Define target events based on time lag, plot evoked response

---

## Creating data objects from arrays#

**URL:** https://mne.tools/stable/api/creating_from_arrays.html

**Contents:**
- Creating data objects from arrays#

EvokedArray(data, info[, tmin, comment, ...])

Evoked object from numpy array.

EpochsArray(data, info[, events, tmin, ...])

Epochs object from numpy array.

io.RawArray(data, info[, first_samp, copy, ...])

Raw object from numpy array.

create_info(ch_names, sfreq[, ch_types, verbose])

Create a basic Info instance suitable for use with create_raw.

---

## Creating MNE-Python data structures from scratch#

**URL:** https://mne.tools/stable/auto_tutorials/simulation/10_array_objs.html

**Contents:**
- Creating MNE-Python data structures from scratch#
- Creating Info objects#
- Creating Raw objects#
- Creating Epochs objects#
- Creating Evoked Objects#

Go to the end to download the full example code.

This tutorial shows how to create MNE-Python‚Äôs core data structures using an existing NumPy array of (real or synthetic) data.

We begin by importing the necessary Python modules:

For full documentation on the Info object, see The Info data structure.

The core data structures for continuous (Raw), discontinuous (Epochs), and averaged (Evoked) data all have an info attribute comprising an mne.Info object. When reading recorded data using one of the functions in the mne.io submodule, Info objects are created and populated automatically. But if we want to create a Raw, Epochs, or Evoked object from scratch, we need to create an appropriate Info object as well. The easiest way to do this is with the mne.create_info function to initialize the required info fields. Additional fields can be assigned later as one would with a regular dictionary.

To initialize a minimal Info object requires a list of channel names, and the sampling frequency. As a convenience for simulated data, channel names can be provided as a single integer, and the names will be automatically created as sequential integers (starting with 0):

You can see in the output above that, by default, the channels are assigned as type ‚Äúmisc‚Äù (where it says chs: 32 MISC). You can assign the channel type when initializing the Info object if you want:

If the channel names follow one of the standard montage naming schemes, their spatial locations can be automatically added using the set_montage method:

When assigning new values to the fields of an Info object, it is important that the fields stay consistent. if there are N channels:

The length of the channel information field chs must be N.

The length of the ch_names field must be N.

The ch_names field should be consistent with the name field of the channel information contained in chs.

Note the new field dig that includes our seven channel locations as well as theoretical values for the three cardinal scalp landmarks.

Additional fields can be added in the same way that Python dictionaries are modified, using square-bracket key assignment:

The expected units for the different channel types are:

Volts: eeg, eog, seeg, dbs, emg, ecg, bio, ecog

Arbitrary units: misc

To create a Raw object from scratch, you can use the mne.io.RawArray class constructor, which takes an Info object and a NumPy array of shape (n_channels, n_samples). Here, we‚Äôll create some sinusoidal data and plot it:

To create an Epochs object from scratch, you can use the mne.EpochsArray class constructor, which takes an Info object and a NumPy array of shape (n_epochs, n_channels, n_samples). Here we‚Äôll create 5 epochs of our 2-channel data, and plot it. Notice that we have to pass picks='misc' to the plot method, because by default it only plots data channels.

Since we did not supply an events array, the EpochsArray constructor automatically created one for us, with all epochs having the same event number:

If we want to simulate having different experimental conditions, we can pass an event array (and an event ID dictionary) to the constructor. Since our epochs are 1 second long and have 200 samples/second, we‚Äôll put our events spaced 200 samples apart, and pass tmin=-0.5, so that the events land in the middle of each epoch (the events are always placed at time=0 in each epoch).

You could also create simulated epochs by using the normal Epochs (not EpochsArray) constructor on the simulated RawArray object, by creating an events array (e.g., using mne.make_fixed_length_events) and extracting epochs around those events.

If you already have data that was averaged across trials, you can use it to create an Evoked object using the EvokedArray class constructor. It requires an Info object and a data array of shape (n_channels, n_times), and has an optional tmin parameter like EpochsArray does. It also has a parameter nave indicating how many trials were averaged together, and a comment parameter useful for keeping track of experimental conditions, etc. Here we‚Äôll do the averaging on our NumPy array and use the resulting averaged data to make our Evoked.

In certain situations you may wish to use a custom time-frequency decomposition for estimation of power spectra. Or you may wish to process pre-computed power spectra in MNE. Following the same logic, it is possible to instantiate averaged power spectrum using the SpectrumArray or EpochsSpectrumArray classes.

Total running time of the script: (0 minutes 4.972 seconds)

Download Jupyter notebook: 10_array_objs.ipynb

Download Python source code: 10_array_objs.py

Download zipped: 10_array_objs.zip

Gallery generated by Sphinx-Gallery

Corrupt known signal with point spread

---

## Decoding (MVPA)#

**URL:** https://mne.tools/stable/auto_tutorials/machine-learning/50_decoding.html

**Contents:**
- Decoding (MVPA)#
- Design philosophy#
- Transformation classes#
  - Scaler#
  - Vectorizer#
  - PSDEstimator#
  - FilterEstimator#
- Spatial filters#
  - Common spatial pattern#
  - Source power comodulation (SPoC)#

Go to the end to download the full example code.

Decoding (a.k.a. MVPA) in MNE largely follows the machine learning API of the scikit-learn package. Each estimator implements fit, transform, fit_transform, and (optionally) inverse_transform methods. For more details on this design, visit scikit-learn. For additional theoretical insights into the decoding framework in MNE [1].

For ease of comprehension, we will denote instantiations of the class using the same name as the class but in small caps instead of camel cases.

Let‚Äôs start by loading data for a simple two-class problem:

The mne.decoding.Scaler will standardize the data based on channel scales. In the simplest modes scalings=None or scalings=dict(...), each data channel type (e.g., mag, grad, eeg) is treated separately and scaled by a constant. This is the approach used by e.g., mne.compute_covariance() to standardize channel scales.

If scalings='mean' or scalings='median', each channel is scaled using empirical measures. Each channel is scaled independently by the mean and standand deviation, or median and interquartile range, respectively, across all epochs and time points during fit (during training). The transform() method is called to transform data (training or test set) by scaling all time points and epochs on a channel-by-channel basis. To perform both the fit and transform operations in a single call, the fit_transform() method may be used. To invert the transform, inverse_transform() can be used. For scalings='median', scikit-learn version 0.17+ is required.

Using this class is different from directly applying sklearn.preprocessing.StandardScaler or sklearn.preprocessing.RobustScaler offered by scikit-learn. These scale each classification feature, e.g. each time point for each channel, with mean and standard deviation computed across epochs, whereas mne.decoding.Scaler scales each channel using mean and standard deviation computed across all of its time points and epochs.

Scikit-learn API provides functionality to chain transformers and estimators by using sklearn.pipeline.Pipeline. We can construct decoding pipelines and perform cross-validation and grid-search. However scikit-learn transformers and estimators generally expect 2D data (n_samples * n_features), whereas MNE transformers typically output data with a higher dimensionality (e.g. n_samples * n_channels * n_frequencies * n_times). A Vectorizer therefore needs to be applied between the MNE and the scikit-learn steps like:

The mne.decoding.PSDEstimator computes the power spectral density (PSD) using the multitaper method. It takes a 3D array as input, converts it into 2D and computes the PSD.

The mne.decoding.FilterEstimator filters the 3D epochs data.

Just like temporal filters, spatial filters provide weights to modify the data along the sensor dimension. They are popular in the BCI community because of their simplicity and ability to distinguish spatially-separated neural activity.

mne.decoding.CSP is a technique to analyze multichannel data based on recordings from two classes [2] (see also https://en.wikipedia.org/wiki/Common_spatial_pattern).

Let \(X \in R^{C\times T}\) be a segment of data with \(C\) channels and \(T\) time points. The data at a single time point is denoted by \(x(t)\) such that \(X=[x(t), x(t+1), ..., x(t+T-1)]\). Common spatial pattern (CSP) finds a decomposition that projects the signal in the original sensor space to CSP space using the following transformation:

where each column of \(W \in R^{C\times C}\) is a spatial filter and each row of \(x_{CSP}\) is a CSP component. The matrix \(W\) is also called the de-mixing matrix in other contexts. Let \(\Sigma^{+} \in R^{C\times C}\) and \(\Sigma^{-} \in R^{C\times C}\) be the estimates of the covariance matrices of the two conditions. CSP analysis is given by the simultaneous diagonalization of the two covariance matrices

where \(\lambda^{C}\) is a diagonal matrix whose entries are the eigenvalues of the following generalized eigenvalue problem

Large entries in the diagonal matrix corresponds to a spatial filter which gives high variance in one class but low variance in the other. Thus, the filter facilitates discrimination between the two classes.

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Decoding in time-frequency space using Common Spatial Patterns (CSP)

The winning entry of the Grasp-and-lift EEG competition in Kaggle used the CSP implementation in MNE and was featured as a script of the week.

We can use CSP with these data with:

Source Power Comodulation (mne.decoding.SPoC) [3] identifies the composition of orthogonal spatial filters that maximally correlate with a continuous target.

SPoC can be seen as an extension of the CSP where the target is driven by a continuous variable rather than a discrete variable. Typical applications include extraction of motor patterns using EMG power or audio patterns using sound envelope.

Continuous Target Decoding with SPoC

mne.preprocessing.Xdawn is a spatial filtering method designed to improve the signal to signal + noise ratio (SSNR) of the ERP responses [4]. Xdawn was originally designed for P300 evoked potential by enhancing the target response with respect to the non-target response. The implementation in MNE-Python is a generalization to any type of ERP.

XDAWN Decoding From EEG data

The result of mne.decoding.EMS is a spatial filter at each time point and a corresponding time course [5]. Intuitively, the result gives the similarity between the filter at each time point and the data vector (sensors) at that time point.

Compute effect-matched-spatial filtering (EMS)

When interpreting the components of the CSP (or spatial filters in general), it is often more intuitive to think about how \(x(t)\) is composed of the different CSP components \(x_{CSP}(t)\). In other words, we can rewrite Equation (1) as follows:

The columns of the matrix \((W^{-1})^T\) are called spatial patterns. This is also called the mixing matrix. The example Linear classifier on sensor data with plot patterns and filters discusses the difference between patterns and filters.

These can be plotted for every spatial filter including CSP, XdawnTransformer, SSD and SPoC:

This strategy consists in fitting a multivariate predictive model on each time instant and evaluating its performance at the same instant on new epochs. The mne.decoding.SlidingEstimator will take as input a pair of features \(X\) and targets \(y\), where \(X\) has more than 2 dimensions. For decoding over time the data \(X\) is the epochs data of shape n_epochs √ó n_channels √ó n_times. As the last dimension of \(X\) is the time, an estimator will be fit on every time instant.

This approach is analogous to SlidingEstimator-based approaches in fMRI, where here we are interested in when one can discriminate experimental conditions and therefore figure out when the effect of interest happens.

When working with linear models as estimators, this approach boils down to estimating a discriminative spatial filter for each time instant.

We‚Äôll use a Logistic Regression for a binary classification as machine learning model.

You can retrieve the spatial filters and spatial patterns if you explicitly use a LinearModel

Temporal generalization is an extension of the decoding over time approach. It consists in evaluating whether the model estimated at a particular time instant accurately predicts any other time instant. It is analogous to transferring a trained model to a distinct learning problem, where the problems correspond to decoding the patterns of brain activity recorded at distinct time instants.

The object to for Temporal generalization is mne.decoding.GeneralizingEstimator. It expects as input \(X\) and \(y\) (similarly to SlidingEstimator) but generates predictions from each model for all time instants. The class GeneralizingEstimator is generic and will treat the last dimension as the one to be used for generalization testing. For convenience, here, we refer to it as different tasks. If \(X\) corresponds to epochs data then the last dimension is time.

This runs the analysis used in [6] and further detailed in [7]:

Plot the full (generalization) matrix:

If you use a linear classifier (or regressor) for your data, you can also project these to source space. For example, using our evoked_time_gen from before:

And this can be visualized using stc.plot:

Source space decoding is also possible, but because the number of features can be much larger than in the sensor space, univariate feature selection using ANOVA f-test (or some other metric) can be done to reduce the feature dimension. Interpreting decoding results might be easier in source space as compared to sensor space.

Decoding source space data

Explore other datasets from MNE (e.g. Face dataset from SPM to predict Face vs. Scrambled)

Jean-R√©mi King, Laura Gwilliams, Chris Holdgraf, Jona Sassenhagen, Alexandre Barachant, Denis Engemann, Eric Larson, and Alexandre Gramfort. Encoding and decoding neuronal dynamics: methodological framework to uncover the algorithms of cognition. hal-01848442, 2018. URL: https://hal.archives-ouvertes.fr/hal-01848442.

Zoltan J. Koles. The quantitative extraction and topographic mapping of the abnormal components in the clinical EEG. Electroencephalography and Clinical Neurophysiology, 79(6):440‚Äì447, 1991. doi:10.1016/0013-4694(91)90163-X.

Sven D√§hne, Frank C. Meinecke, Stefan Haufe, Johannes H√∂hne, Michael Tangermann, Klaus-Robert M√ºller, and Vadim V. Nikulin. SPoC: a novel framework for relating the amplitude of neuronal oscillations to behaviorally relevant parameters. NeuroImage, 86:111‚Äì122, 2014. doi:10.1016/j.neuroimage.2013.07.079.

Bertrand Rivet, Antoine Souloumiac, Virginie Attina, and Guillaume Gibert. xDAWN algorithm to enhance evoked potentials: application to brain‚Äìcomputer interface. IEEE Transactions on Biomedical Engineering, 56(8):2035‚Äì2043, 2009. doi:10.1109/TBME.2009.2012869.

Aaron Schurger, Sebastien Marti, and Stanislas Dehaene. Reducing multi-sensor data to a single time course that reveals experimental effects. BMC Neuroscience, 2013. doi:10.1186/1471-2202-14-122.

Jean-R√©mi King, Alexandre Gramfort, Aaron Schurger, Lionel Naccache, and Stanislas Dehaene. Two distinct dynamic modes subtend the detection of unexpected sounds. PLoS ONE, 9(1):e85791, 2014. doi:10.1371/journal.pone.0085791.

Jean-R√©mi King and Stanislas Dehaene. Characterizing the dynamics of mental representations: the temporal generalization method. Trends in Cognitive Sciences, 18(4):203‚Äì210, 2014. doi:10.1016/j.tics.2014.01.002.

Total running time of the script: (0 minutes 17.950 seconds)

Download Jupyter notebook: 50_decoding.ipynb

Download Python source code: 50_decoding.py

Download zipped: 50_decoding.zip

Gallery generated by Sphinx-Gallery

Spectro-temporal receptive field (STRF) estimation on continuous data

Clinical applications

---

## Define target events based on time lag, plot evoked response#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/define_target_events.html

**Contents:**
- Define target events based on time lag, plot evoked response#

Go to the end to download the full example code.

This script shows how to define higher order events based on time lag between reference and target events. For illustration, we will put face stimuli presented into two classes, that is 1) followed by an early button press (within 590 milliseconds) and followed by a late button press (later than 590 milliseconds). Finally, we will visualize the evoked responses to both ‚Äòquickly-processed‚Äô and ‚Äòslowly-processed‚Äô face stimuli.

Find stimulus event followed by quick button presses

Total running time of the script: (0 minutes 1.140 seconds)

Download Jupyter notebook: define_target_events.ipynb

Download Python source code: define_target_events.py

Download zipped: define_target_events.zip

Gallery generated by Sphinx-Gallery

Cortical Signal Suppression (CSS) for removal of cortical signals

Identify EEG Electrodes Bridged by too much Gel

---

## DICS for power mapping#

**URL:** https://mne.tools/stable/auto_tutorials/simulation/80_dics.html

**Contents:**
- DICS for power mapping#
- Setup#
- Data simulation#
- Power mapping#
- References#

Go to the end to download the full example code.

In this tutorial, we‚Äôll simulate two signals originating from two locations on the cortex. These signals will be sinusoids, so we‚Äôll be looking at oscillatory activity (as opposed to evoked activity).

We‚Äôll use dynamic imaging of coherent sources (DICS) [1] to map out spectral power along the cortex. Let‚Äôs see if we can find our two simulated sources.

We first import the required packages to run this tutorial and define a list of filenames for various things we‚Äôll be using.

The following function generates a timeseries that contains an oscillator, whose frequency fluctuates a little over time, but stays close to 10 Hz. We‚Äôll use this function to generate our two signals.

Let‚Äôs simulate two timeseries and plot some basic information about them.

Now we put the signals at two locations on the cortex. We construct a mne.SourceEstimate object to store them in.

The timeseries will have a part where the signal is active and a part where it is not. The techniques we‚Äôll be using in this tutorial depend on being able to contrast data that contains the signal of interest versus data that does not (i.e. it contains only noise).

Before we simulate the sensor-level data, let‚Äôs define a signal-to-noise ratio. You are encouraged to play with this parameter and see the effect of noise on our results.

Now we run the signal through the forward model to obtain simulated sensor data. To save computation time, we‚Äôll only simulate gradiometer data. You can try simulating other types of sensors as well.

Some noise is added based on the baseline noise covariance matrix from the sample dataset, scaled to implement the desired SNR.

We create an mne.Epochs object containing two trials: one with both noise and signal and one with just noise

With our simulated dataset ready, we can now pretend to be researchers that have just recorded this from a real subject and are going to study what parts of the brain communicate with each other.

First, we‚Äôll create a source estimate of the MEG data. We‚Äôll use both a straightforward MNE-dSPM inverse solution for this, and the DICS beamformer which is specifically designed to work with oscillatory data.

Computing the inverse using MNE-dSPM:

We will now compute the cortical power map at 10 Hz. using a DICS beamformer. A beamformer will construct for each vertex a spatial filter that aims to pass activity originating from the vertex, while dampening activity from other sources as much as possible.

The mne.beamformer.make_dics() function has many switches that offer precise control over the way the filter weights are computed. Currently, there is no clear consensus regarding the best approach. This is why we will demonstrate two approaches here:

The approach as described in [2], which first normalizes the forward solution and computes a vector beamformer.

The scalar beamforming approach based on [3], which uses weight normalization instead of normalizing the forward solution.

Plot the DICS power maps for both approaches, starting with the first:

Excellent! All methods found our two simulated sources. Of course, with a signal-to-noise ratio (SNR) of 1, is isn‚Äôt very hard to find them. You can try playing with the SNR and see how the MNE-dSPM and DICS approaches hold up in the presence of increasing noise. In the presence of more noise, you may need to increase the regularization parameter of the DICS beamformer.

Joachim Gro√ü, Jan Kujala, Matti S. H√§m√§l√§inen, Lars Timmermann, Alfons Schnitzler, and Riitta Salmelin. Dynamic imaging of coherent sources: studying neural interactions in the human brain. Proceedings of the National Academy of Sciences, 98(2):694‚Äì699, 2001. doi:10.1073/pnas.98.2.694.

Marijn van Vliet, Mia Liljestr√∂m, Susanna Aro, Riitta Salmelin, and Jan Kujala. Analysis of functional connectivity and oscillatory power using DICS: from raw MEG data to group-level statistics in Python. bioRxiv, 2018. doi:10.1101/245530.

Kensuke Sekihara and Srikantan S. Nagarajan. Adaptive Spatial Filters for Electromagnetic Brain Imaging. Series in Biomedical Engineering. Springer, Berlin; Heidelberg, 2008. ISBN 978-3-540-79369-4 978-3-540-79370-0. doi:10.1007/978-3-540-79370-0.

Total running time of the script: (0 minutes 14.575 seconds)

Download Jupyter notebook: 80_dics.ipynb

Download Python source code: 80_dics.py

Download zipped: 80_dics.zip

Gallery generated by Sphinx-Gallery

Corrupt known signal with point spread

Visualization tutorials

---

## Divide continuous data into equally-spaced epochs#

**URL:** https://mne.tools/stable/auto_tutorials/epochs/60_make_fixed_length_epochs.html

**Contents:**
- Divide continuous data into equally-spaced epochs#
- Characteristics of Fixed Length Epochs#
- Example Use Case for Fixed Length Epochs: Connectivity Analysis#

Go to the end to download the full example code.

This tutorial shows how to segment continuous data into a set of epochs spaced equidistantly in time. The epochs will not be created based on experimental events; instead, the continuous data will be ‚Äúchunked‚Äù into consecutive epochs (which may be temporally overlapping, adjacent, or separated). We will also briefly demonstrate how to use these epochs in connectivity analysis.

First, we import the necessary modules and read in a sample raw data set. This data set contains brain activity that is event-related, i.e., synchronized to the onset of auditory stimuli. However, rather than creating epochs by segmenting the data around the onset of each stimulus, we will create 30 second epochs that allow us to perform non-event-related analyses of the signal.

Starting in version 1.0, all functions in the mne.connectivity sub-module are housed in a separate package called mne-connectivity. Download it by running:

For this tutorial we‚Äôll crop and resample the raw data to a manageable size for our web server to handle, ignore EEG channels, and remove the heartbeat artifact so we don‚Äôt get spurious correlations just because of that.

To create fixed length epochs, we simply call the function and provide it with the appropriate parameters indicating the desired duration of epochs in seconds, whether or not to preload data, whether or not to reject epochs that overlap with raw data segments annotated as bad, whether or not to include projectors, and finally whether or not to be verbose. Here, we choose a long epoch duration (30 seconds). To conserve memory, we set preload to False.

Fixed length epochs are generally unsuitable for event-related analyses. This can be seen in an image map of our fixed length epochs. When the epochs are averaged, as seen at the bottom of the plot, misalignment between onsets of event-related activity results in noise.

For information about creating epochs for event-related analyses, please see The Epochs data structure: discontinuous data.

Fixed lengths epochs are suitable for many types of analysis, including frequency or time-frequency analyses, connectivity analyses, or classification analyses. Here we briefly illustrate their utility in a sensor space connectivity analysis.

The data from our epochs object has shape (n_epochs, n_sensors, n_times) and is therefore an appropriate basis for using MNE-Python‚Äôs envelope correlation function to compute power-based connectivity in sensor space. The long duration of our fixed length epochs, 30 seconds, helps us reduce edge artifacts and achieve better frequency resolution when filtering must be applied after epoching.

Let‚Äôs examine the alpha band. We allow default values for filter parameters (for more information on filtering, please see Filtering and resampling data).

If desired, separate correlation matrices for each epoch can be obtained. For envelope correlations, this is the default return if you use mne_connectivity.EpochConnectivity.get_data():

Now we can plot correlation matrices. We‚Äôll compare the first and last 30-second epochs of the recording:

Total running time of the script: (0 minutes 32.643 seconds)

Download Jupyter notebook: 60_make_fixed_length_epochs.ipynb

Download Python source code: 60_make_fixed_length_epochs.py

Download zipped: 60_make_fixed_length_epochs.zip

Gallery generated by Sphinx-Gallery

Exporting Epochs to Pandas DataFrames

Estimating evoked responses

---

## EEG analysis - Event-Related Potentials (ERPs)#

**URL:** https://mne.tools/stable/auto_tutorials/evoked/30_eeg_erp.html

**Contents:**
- EEG analysis - Event-Related Potentials (ERPs)#
- Channel names and types#
- Channel locations#
- Setting the EEG reference#
- Filtering#
- Evoked responses: epoching and averaging#
- Global field power (GFP)#
- Averaging across channels with regions of interest#
- Comparing conditions#
- Grand averages#

Go to the end to download the full example code.

This tutorial shows how to perform standard ERP analyses in MNE-Python. Most of the material here is covered in other tutorials too, but for convenience the functions and methods most useful for ERP analyses are collected here, with links to other tutorials where more detailed information is given.

As usual we‚Äôll start by importing the modules we need and loading some example data. Instead of parsing the events from the raw data‚Äôs stim channel (like we do in this tutorial), we‚Äôll load the events from an external events file. Finally, to speed up computations we‚Äôll crop the raw data from ~4.5 minutes down to 90 seconds.

The file that we loaded has already been partially processed: 3D sensor locations have been saved as part of the .fif file, the data have been low-pass filtered at 40 Hz, and a common average reference is set for the EEG channels, stored as a projector (see Creating the average reference as a projector in the Setting the EEG reference tutorial for more info about when you may want to do this). We‚Äôll discuss how to do each of these below.

Since this is a combined EEG/MEG dataset, let‚Äôs start by restricting the data to just the EEG and EOG channels. This will cause the other projectors saved in the file (which apply only to magnetometer channels) to be removed. By looking at the measurement info we can see that we now have 59 EEG channels and 1 EOG channel.

In practice it is quite common to have some channels labeled as EEG that are actually EOG channels. Raw objects have a set_channel_types() method that can be used to change a channel that is mislabeled as eeg to eog.

You can also rename channels using rename_channels(). Detailed examples of both of these methods can be found in the tutorial The Raw data structure: continuous data.

In our data set, all channel types are already correct. Therefore, we‚Äôll only remove a space and a leading zero in the channel names and convert to lowercase:

The assignment to a temporary name _ (the _ = part) is included here to suppress automatic printing of the raw object. You do not have to do this in your interactive analysis.

The tutorial Working with sensor locations describes how sensor locations are handled in great detail. To briefly summarize: MNE-Python distinguishes montages (which contain 3D sensor locations x, y, and z, in meters) from layouts (which define 2D sensor arrangements for plotting schematic sensor location diagrams). Additionally, montages may specify idealized sensor locations (based on, e.g., an idealized spherical head model), or they may contain realistic sensor locations obtained by digitizing the 3D locations of the sensors when placed on a real person‚Äôs head.

This dataset has realistic digitized 3D sensor locations saved as part of the .fif file, so we can view the sensor locations in 2D or 3D using the plot_sensors() method:

If you‚Äôre working with a standard montage like the 10‚Äì20 system, you can add sensor locations to the data with raw.set_montage('standard_1020') (see Working with sensor locations for information on other standard montages included with MNE-Python).

If you have digitized realistic sensor locations, there are dedicated functions for loading those digitization files into MNE-Python (see Reading sensor digitization files for discussion and Supported formats for digitized 3D locations for a list of supported formats). Once loaded, the digitized sensor locations can be added to the data by passing the loaded montage object to set_montage().

As mentioned, this data already has an EEG common average reference added as a projector. We can view the effect of this projector on the raw data by plotting it with and without the projector applied:

The referencing scheme can be changed with the function mne.set_eeg_reference() (which by default operates on a copy of the data) or the raw.set_eeg_reference() method (which always modifies the data in-place). The tutorial Setting the EEG reference shows several examples.

MNE-Python has extensive support for different ways of filtering data. For a general discussion of filter characteristics and MNE-Python defaults, see Background information on filtering. For practical examples of how to apply filters to your data, see Filtering and resampling data. Here, we‚Äôll apply a simple high-pass filter for illustration:

The general process for extracting evoked responses from continuous data is to use the Epochs constructor, and then average the resulting epochs to create an Evoked object. In MNE-Python, events are represented as a NumPy array containing event latencies (in samples) and integer event codes. The event codes are stored in the last column of the events array:

The Working with events tutorial discusses event arrays in more detail. Integer event codes are mapped to more descriptive text using a Python dictionary usually called event_id. This mapping is determined by your experiment (i.e., it reflects which event codes you chose to represent different experimental events or conditions). The Sample data uses the following mapping:

Now we can proceed to epoch the continuous data. An interactive plot allows us to click on epochs to mark them as ‚Äúbad‚Äù and drop them from the analysis (it is not interactive on this documentation website, but will be when you run epochs.plot() in a Python console).

It is also possible to automatically drop epochs (either when first creating them or later on) by providing maximum peak-to-peak signal value thresholds (passed to Epochs as the reject parameter; see Rejecting Epochs based on peak-to-peak channel amplitude for details). You can also do this after the epochs are already created using drop_bad():

Next, we generate a barplot of which channels contributed most to epochs getting rejected. If one channel is responsible for many epoch rejections, it may be worthwhile to mark that channel as ‚Äúbad‚Äù in the Raw object and then re-run epoching (fewer channels with more good epochs may be preferable to keeping all channels but losing many epochs). See Handling bad channels for more information.

Epochs can also be dropped automatically if the event around which the epoch is created is too close to the start or end of the Raw object (e.g., if the epoch would extend past the end of the recording; this is the cause for the ‚ÄúTOO_SHORT‚Äù entry in the plot_drop_log() plot).

Epochs may also be dropped automatically if the Raw object contains annotations that begin with either bad or edge (‚Äúedge‚Äù annotations are automatically inserted when concatenating two or more Raw objects). See Rejecting bad data spans and breaks for more information on annotation-based epoch rejection.

Now that we‚Äôve dropped all bad epochs, let‚Äôs look at our evoked responses for some conditions we care about. Here, the average() method will create an Evoked object, which we can then plot. Notice that we select which condition we want to average using square-bracket indexing (like for a dictionary). This returns a subset with only the desired epochs, which we then average:

These Evoked objects have their own interactive plotting method (though again, it won‚Äôt be interactive on the documentation website). Clicking and dragging a span of time will generate a topography of scalp potentials for the selected time segment. Here, we also demonstrate built-in color-coding the channel traces by location:

Scalp topographies can also be obtained non-interactively with the plot_topomap() method. Here, we display topomaps of the average evoked potential in 50 ms time windows centered at -200 ms, 100 ms, and 400 ms.

Considerable customization of these plots is possible, see the docstring of plot_topomap() for details.

There is also a built-in method for combining butterfly plots of the signals with scalp topographies called plot_joint(). Like in plot_topomap(), you can specify times for the scalp topographies or you can let the method choose times automatically as shown here:

Global field power [1][2][3] is, generally speaking, a measure of agreement of the signals picked up by all sensors across the entire scalp: if all sensors have the same value at a given time point, the GFP will be zero at that time point. If the signals differ, the GFP will be non-zero at that time point. GFP peaks may reflect ‚Äúinteresting‚Äù brain activity, warranting further investigation. Mathematically, the GFP is the population standard deviation across all sensors, calculated separately for every time point.

You can plot the GFP using evoked.plot(gfp=True). The GFP trace will be black if spatial_colors=True and green otherwise. The EEG reference does not affect the GFP:

To plot the GFP by itself, you can pass gfp='only' (this makes it easier to read off the GFP data values, because the scale is aligned):

The GFP is the population standard deviation of the signal across channels. To compute it manually, we can leverage the fact that evoked.data is a NumPy array, and verify by plotting it using plain Matplotlib commands:

Since our sample data contains responses to left and right auditory and visual stimuli, we may want to compare left versus right regions of interest (ROIs). To average across channels in a given ROI, we first find the relevant channel indices. Revisiting the 2D sensor plot above, we might choose the following channels for left and right ROIs, respectively:

Now we can create a new Evoked object with two virtual channels (one for each ROI):

If we wanted to contrast auditory to visual stimuli, a useful function is mne.viz.plot_compare_evokeds(). By default, this function will combine all channels in each evoked object using GFP (or RMS for MEG channels); here instead we specify to combine by averaging, and restrict it to a subset of channels by passing picks:

We can also generate confidence intervals by treating each epoch as a separate observation using iter_evoked(). A confidence interval across subjects could also be obtained by passing a list of Evoked objects (one per subject) to the plot_compare_evokeds() function.

We can also compare conditions by subtracting one Evoked object from another using the mne.combine_evoked() function (this function also supports pooling of epochs without subtraction).

The code above yields an equal-weighted difference. If you have different numbers of epochs per condition, you might want to equalize the number of events per condition first by using epochs.equalize_event_counts() before averaging.

To compute grand averages across conditions (or subjects), you can pass a list of Evoked objects to mne.grand_average(). The result is another Evoked object.

For combining conditions it is also possible to make use of HED tags in the condition names when selecting which epochs to average. For example, we have the condition names:

We can select the auditory conditions (left and right together) by passing:

See Subselecting epochs for more details on that.

The tutorials The Epochs data structure: discontinuous data and The Evoked data structure: evoked/averaged data have many more details about working with the Epochs and Evoked classes.

It is common in ERP research to extract measures of amplitude or latency to compare across different conditions. There are many measures that can be extracted from ERPs, and many of these are detailed (including the respective strengths and weaknesses) in chapter 9 of Luck [4] (also see the Measurement Tool in the ERPLAB Toolbox [5]).

This part of the tutorial will demonstrate how to extract three common measures:

The most common measures of amplitude and latency are peak measures. Peak measures are basically the maximum amplitude of the signal in a specified time window and the time point (or latency) at which the peak amplitude occurred.

Peak measures can be obtained using the get_peak() method. There are two important things to point out about get_peak(). First, it finds the strongest peak looking across all channels of the selected type that are available in the Evoked object. As a consequence, if you want to restrict the search to a group of channels or a single channel, you should first use the pick() or pick_channels() methods. Second, the get_peak() method can find different types of peaks using the mode argument. There are three options:

mode='pos': finds the peak with a positive voltage (ignores negative voltages)

mode='neg': finds the peak with a negative voltage (ignores positive voltages)

mode='abs': finds the peak with the largest absolute voltage regardless of sign (positive or negative)

The following example demonstrates how to find the first positive peak in the ERP (i.e., the P100) for the left visual condition (i.e., the l_vis Evoked object). The time window used to search for the peak ranges from 0.08 to 0.12 s. This time window was selected because it is when P100 typically occurs. Note that all 'eeg' channels are submitted to the get_peak() method.

The output shows that channel eeg55 had the maximum positive peak in the chosen time window from all of the 'eeg' channels searched. In practice, one might want to pull out the peak for an a priori region of interest or a single channel depending on the study. This can be done by combining the pick() or pick_channels() methods with the get_peak() method.

Here, let‚Äôs assume we believe the effects of interest will occur at eeg59.

While the peak latencies are the same in channels eeg55 and eeg59, the peak amplitudes differ. This approach can also be applied to virtual channels created with the combine_channels() function and difference waves created with the mne.combine_evoked() function (see aud_minus_vis in section Comparing conditions above).

Peak measures are very susceptible to high frequency noise in the signal (for discussion, see [4]). Specifically, high frequency noise positively biases peak amplitude measures. This bias can confound comparisons across conditions where ERPs differ in the level of high frequency noise, such as when the conditions differ in the number of trials contributing to the ERP. One way to avoid this is to apply a non-causal low-pass filter to the ERP. Low-pass filters reduce the contribution of high frequency noise by smoothing out fast (i.e., high frequency) fluctuations in the signal (see Background information on filtering). While this can reduce the positive bias in peak amplitude measures caused by high frequency noise, low-pass filtering the ERP can introduce challenges in interpreting peak latency measures for effects of interest [6][7].

If using peak measures, it is critical to visually inspect the data to make sure the selected time window actually contains a peak. The meth:get_peak method detects the maximum or minimum voltage in the specified time range and returns the latency and amplitude of this peak. There is no guarantee that this method will return an actual peak. Instead, it may return a value on the rising or falling edge of a peak we are trying to find.

The following example demonstrates why visual inspection is crucial. Below, we use a known bad time window (0.095 to 0.135 s) to search for a peak in channel eeg59.

If all we had were the above values, it would be unclear if they are truly identifying a peak in the ERP. In fact, the 0.095 to 0.135 s time window actually does not contain the true peak, which is shown in the top panel below. The bad time window (highlighted in orange) does not contain the true peak (the pink star). In contrast, the time window defined initially (0.08 to 0.12 s; highlighted in blue) returns an actual peak instead of a just a maximum or minimum in the searched time window. Visual inspection will always help you to convince yourself that the returned values are actual peaks.

Another common practice in ERP studies is to define a component (or effect) as the mean amplitude within a specified time window. One advantage of this approach is that it is less sensitive to high frequency noise (compared to peak amplitude measures), because averaging over a time window acts as a low-pass filter (see discussion in the previous section Peak latency and amplitude).

When using mean amplitude measures, selecting the time window based on the effect of interest (e.g., the difference between two conditions) can inflate the likelihood of finding false positives in your results [8]. There are other, and better, ways to identify a time window to use for extracting mean amplitude measures. First, you can use an a priori time window based on prior research. A second option is to define a time window from an independent condition or set of trials not used in the analysis (e.g., a ‚Äúlocalizer‚Äù). A third approach is to define a time window using the across-condition grand average. This latter approach is not circular because the across-condition mean and condition difference are independent of one another. The issues discussed above also apply to selecting channels used for analysis.

The following example demonstrates how to pull out the mean amplitude from the left visual condition (i.e., the l_vis Evoked object) from selected channels and time windows. Stimulating the left visual field increases neural activity of visual cortex in the contralateral (i.e., right) hemisphere. We can test this by examining the amplitude of the ERP for left visual field stimulation over right (contralateral) and left (ipsilateral) channels. The channels used for this analysis are eeg54 and eeg57 (left hemisphere), and eeg59 and eeg55 (right hemisphere). The time window used is 0.08 (good_tmin) to 0.12 s (good_tmax) as it corresponds to when the P100 typically occurs. The P100 is sensitive to left and right visual field stimulation. The mean amplitude is extracted from the above four channels and stored in a pandas.DataFrame.

As demonstrated in this example, the mean amplitude was higher and positive in right compared to left hemisphere channels. It should be reiterated that both spatial and temporal windows used in the analysis should be determined in an independent manner (e.g., defined a priori from prior research, a ‚Äúlocalizer‚Äù or another independent condition) and not based on the data you will use to test your hypotheses.

The example can be modified to extract the mean amplitude from all channels and store the resulting output in a pandas.DataFrame. This can be useful for statistical analyses conducted in other programming languages.

Dietrich Lehmann and Wolfgang Skrandies. Reference-free identification of components of checkerboard-evoked multichannel potential fields. Electroencephalography and Clinical Neurophysiology, 48(6):609‚Äì621, 1980. doi:10.1016/0013-4694(80)90419-8.

Dietrich Lehmann and Wolfgang Skrandies. Spatial analysis of evoked potentials in man‚Äîa review. Progress in Neurobiology, 23(3):227‚Äì250, 1984. doi:10.1016/0301-0082(84)90003-0.

Micah M. Murray, Denis Brunet, and Christoph M. Michel. Topographic ERP analyses: A step-by-step tutorial review. Brain Topography, 20(4):249‚Äì264, 2008. doi:10.1007/s10548-008-0054-5.

Steven J Luck. An Introduction to the Event-Related Potential Technique. The MIT Press, Cambridge, MA, 2nd edition, 2014. ISBN 978-0-262-52585-5. URL: https://mitpress.mit.edu/books/introduction-event-related-potential-technique-second-edition.

Javier Lopez-Calderon and Steven J. Luck. Erplab: an open-source toolbox for the analysis of event-related potentials. Frontiers in Human Neuroscience, 2014. doi:10.3389/fnhum.2014.00213.

Guillaume A. Rousselet. Does filtering preclude us from studying ERP time-courses? Frontiers in Psychology, 2012. doi:10.3389/fpsyg.2012.00131.

Rufin VanRullen. Four common conceptual fallacies in mapping the time course of recognition. Frontiers in Psychology, 2011. doi:10.3389/fpsyg.2011.00365.

Steven J. Luck and Nicholas Gaspelin. How to get statistically significant effects in any ERP experiment (and why you shouldn‚Äôt). Psychophysiology, 54(1):146‚Äì157, 2017. doi:10.1111/psyp.12639.

Total running time of the script: (0 minutes 16.090 seconds)

Download Jupyter notebook: 30_eeg_erp.ipynb

Download Python source code: 30_eeg_erp.py

Download zipped: 30_eeg_erp.zip

Gallery generated by Sphinx-Gallery

Visualizing Evoked data

Plotting whitened data

---

## EEG forward operator with a template MRI#

**URL:** https://mne.tools/stable/auto_tutorials/forward/35_eeg_no_mri.html

**Contents:**
- EEG forward operator with a template MRI#
- Adult template MRI (fsaverage)#
  - Load the data#
  - Setup source space and compute forward#
- Infant MRI surrogates#
  - Get an infant MRI template#

Go to the end to download the full example code.

This tutorial explains how to compute the forward operator from EEG data using the standard template MRI subject fsaverage.

Source reconstruction without an individual T1 MRI from the subject will be less accurate. Do not over interpret activity locations which can be off by multiple centimeters.

First we show how fsaverage can be used as a surrogate subject.

We use here EEG data from the BCI dataset.

See Plotting sensor layouts of EEG systems to view all the standard EEG montages available in MNE-Python.

From here on, standard inverse imaging methods can be used!

We don‚Äôt have a sample infant dataset for MNE, so let‚Äôs fake a 10-20 one:

To use an infant head model for M/EEG data, you can use mne.datasets.fetch_infant_template() to download an infant template:

It comes with several helpful built-in files, including a 10-20 montage in the MRI coordinate frame, which can be used to compute the MRI<->head transform trans:

There are also BEM and source spaces:

You can ensure everything is as expected by plotting the result:

From here, standard forward and inverse operators can be computed

If you have digitized head positions or MEG data, consider using mne coreg to warp a suitable infant template MRI to your digitization information.

Total running time of the script: (0 minutes 56.274 seconds)

Download Jupyter notebook: 35_eeg_no_mri.ipynb

Download Python source code: 35_eeg_no_mri.py

Download zipped: 35_eeg_no_mri.zip

Gallery generated by Sphinx-Gallery

Head model and forward computation

How MNE uses FreeSurfer‚Äôs outputs

---

## EEG source localization given electrode locations on an MRI#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/70_eeg_mri_coords.html

**Contents:**
- EEG source localization given electrode locations on an MRI#
- Prerequisites#
- Visualizing the MRI#
- Getting our MRI voxel EEG locations to head (and MRI surface RAS) coords#
- Getting a source estimate#

Go to the end to download the full example code.

This tutorial explains how to compute the forward operator from EEG data when the electrodes are in MRI voxel coordinates.

For this we will assume that you have:

your subject‚Äôs MRI reconstrcted using FreeSurfer

an appropriate boundary element model (BEM)

an appropriate source space (src)

your EEG electrodes in Freesurfer surface RAS coordinates, stored in one of the formats mne.channels.read_custom_montage() supports

Let‚Äôs set the paths to these files for the sample dataset, including a modified sample MRI showing the electrode locations plus a .elc file corresponding to the points in MRI coords (these were synthesized, and thus are stored as part of the misc dataset).

Let‚Äôs take our MRI-with-eeg-locations and adjust the affine to put the data in MNI space, and plot using nilearn.plotting.plot_glass_brain(), which does a maximum intensity projection (easy to see the fake electrodes). This plotting function requires data to be in MNI space. Because img.affine gives the voxel-to-world (RAS) mapping, if we apply a RAS-to-MNI transform to it, it becomes the voxel-to-MNI transformation we need. Thus we create a ‚Äúnew‚Äù MRI image in MNI coordinates and plot it as:

Let‚Äôs load our DigMontage using mne.channels.read_custom_montage(), making note of the fact that we stored our locations in Freesurfer surface RAS (MRI) coordinates.

If you have voxel coordinates in MRI voxels, you can transform these to FreeSurfer surface RAS (called ‚Äúmri‚Äù in MNE) coordinates using the transformations that FreeSurfer computes during reconstruction. nibabel calls this transformation the vox2ras_tkr transform and operates in millimeters, so we can load it, convert it to meters, and then apply it:

You can also verify that these are correct (or manually convert voxels to MRI coords) by looking at the points in Freeview or tkmedit.

We can then get our transformation from the MRI coordinate frame (where our points are defined) to the head coordinate frame from the object.

Let‚Äôs apply this digitization to our dataset, and in the process automatically convert our locations to the head coordinate frame, as shown by plot_sensors().

Now we can do standard sensor-space operations like make joint plots of evoked data.

New we have all of the components we need to compute a forward solution, but first we should sanity check that everything is well aligned:

Now we can actually compute the forward:

Finally let‚Äôs compute the inverse and apply it:

Total running time of the script: (0 minutes 32.247 seconds)

Download Jupyter notebook: 70_eeg_mri_coords.ipynb

Download Python source code: 70_eeg_mri_coords.py

Download zipped: 70_eeg_mri_coords.zip

Gallery generated by Sphinx-Gallery

Visualize source time courses (stcs)

Brainstorm Elekta phantom dataset tutorial

---

## Estimating evoked responses#

**URL:** https://mne.tools/stable/auto_tutorials/evoked/index.html

**Contents:**
- Estimating evoked responses#

These tutorials cover estimates of evoked responses (i.e., averages across several repetitions of an experimental condition).

The Evoked data structure: evoked/averaged data

Visualizing Evoked data

EEG analysis - Event-Related Potentials (ERPs)

Plotting whitened data

Divide continuous data into equally-spaced epochs

The Evoked data structure: evoked/averaged data

---

## Exporting#

**URL:** https://mne.tools/stable/api/export.html

**Contents:**
- Exporting#

Functions for exporting data to non-FIF formats.

export_epochs(fname, epochs[, fmt, ...])

Export Epochs to external formats.

export_evokeds(fname, evoked[, fmt, ...])

Export evoked dataset to external formats.

export_evokeds_mff(fname, evoked[, history, ...])

Export evoked dataset to MFF.

export_raw(fname, raw[, fmt, ...])

Export Raw to external formats.

mne.export.export_epochs

---

## Exporting Epochs to Pandas DataFrames#

**URL:** https://mne.tools/stable/auto_tutorials/epochs/50_epochs_to_data_frame.html

**Contents:**
- Exporting Epochs to Pandas DataFrames#
- Converting an Epochs object to a DataFrame#
  - Scaling time and channel values#
  - Setting the index#
  - Wide- versus long-format DataFrames#

Go to the end to download the full example code.

This tutorial shows how to export the data in Epochs objects to a Pandas DataFrame, and applies a typical Pandas split-apply-combine workflow to examine the latencies of the response maxima across epochs and conditions.

We‚Äôll use the Sample dataset, but load a version of the raw file that has already been filtered and downsampled, and has an average reference applied to its EEG channels. As usual we‚Äôll start by importing the modules we need and loading the data:

Next we‚Äôll load a list of events from file, map them to condition names with an event dictionary, set some signal rejection thresholds (cf. Rejecting Epochs based on peak-to-peak channel amplitude), and segment the continuous data into epochs:

Once we have our Epochs object, converting it to a DataFrame is simple: just call epochs.to_data_frame(). Each channel‚Äôs data will be a column of the new DataFrame, alongside three additional columns of event name, epoch number, and sample time. Here we‚Äôll just show the first few rows and columns:

By default, time values are converted from seconds to milliseconds and then rounded to the nearest integer; if you don‚Äôt want this, you can pass time_format=None to keep time as a float value in seconds, or convert it to a Timedelta value via time_format='timedelta'.

Note also that, by default, channel measurement values are scaled so that EEG data are converted to ¬µV, magnetometer data are converted to fT, and gradiometer data are converted to fT/cm. These scalings can be customized through the scalings parameter, or suppressed by passing scalings=dict(eeg=1, mag=1, grad=1).

Notice that the time values are no longer integers, and the channel values have changed by several orders of magnitude compared to the earlier DataFrame.

It is also possible to move one or more of the indicator columns (event name, epoch number, and sample time) into the index, by passing a string or list of strings as the index parameter. We‚Äôll also demonstrate here the effect of time_format='timedelta', yielding Timedelta values in the ‚Äútime‚Äù column.

Another parameter, long_format, determines whether each channel‚Äôs data is in a separate column of the DataFrame (long_format=False), or whether the measured values are pivoted into a single 'value' column with an extra indicator column for the channel name (long_format=True). Passing long_format=True will also create an extra column ch_type indicating the channel type.

Generating the DataFrame in long format can be helpful when using other Python modules for subsequent analysis or plotting. For example, here we‚Äôll take data from the ‚Äúauditory/left‚Äù condition, pick a couple MEG channels, and use seaborn.lineplot() to automatically plot the mean and confidence band for each channel, with confidence computed across the epochs in the chosen condition:

We can also now use all the power of Pandas for grouping and transforming our data. Here, we find the latency of peak activation of 2 gradiometers (one near auditory cortex and one near visual cortex), and plot the distribution of the timing of the peak in each channel as a violinplot():

Total running time of the script: (0 minutes 13.221 seconds)

Download Jupyter notebook: 50_epochs_to_data_frame.ipynb

Download Python source code: 50_epochs_to_data_frame.py

Download zipped: 50_epochs_to_data_frame.zip

Gallery generated by Sphinx-Gallery

Auto-generating Epochs metadata

Divide continuous data into equally-spaced epochs

---

## Extracting and visualizing subject head movement#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/59_head_positions.html

**Contents:**
- Extracting and visualizing subject head movement#
- HPI frequencies#
- Estimating continuous head position#
- Visualizing continuous head position#
- Computing SNR of the HPI signal#

Go to the end to download the full example code.

Continuous head movement can be encoded during MEG recordings by use of HPI coils that continuously emit sinusoidal signals. These signals can then be extracted from the recording and used to estimate head position as a function of time. Here we show an example of how to do this, and how to visualize the result.

First let‚Äôs load a short bit of raw data where the subject intentionally moved their head during the recording. Its power spectral density shows five peaks (most clearly visible in the gradiometers) corresponding to the HPI coil frequencies, plus other peaks related to power line interference (60 Hz and harmonics).

We can use mne.chpi.get_chpi_info to retrieve the coil frequencies, the index of the channel indicating when which coil was switched on, and the respective ‚Äúevent codes‚Äù associated with each coil‚Äôs activity.

First, let‚Äôs extract the HPI coil amplitudes as a function of time:

Second, let‚Äôs compute time-varying HPI coil locations from these:

Lastly, compute head positions from the coil locations:

Note that these can then be written to disk or read from disk with mne.chpi.write_head_pos() and mne.chpi.read_head_pos(), respectively.

We can plot as traces, which is especially useful for long recordings:

Or we can visualize them as a continuous field (with the vectors pointing in the head-upward direction):

These head positions can then be used with mne.preprocessing.maxwell_filter() to compensate for movement, or with mne.preprocessing.annotate_movement() to mark segments as bad that deviate too much from the average head position.

It is also possible to compute the SNR of the continuous HPI measurements. This can be a useful proxy for head position along the vertical dimension, i.e., it can indicate the distance between the HPI coils and the MEG sensors. Using compute_chpi_snr, the HPI power and SNR are computed separately for each MEG sensor type and each HPI coil (frequency), along with the residual power for each sensor type. The results can then be visualized with plot_chpi_snr. Here we‚Äôll just show a few seconds, for speed:

Total running time of the script: (0 minutes 58.193 seconds)

Download Jupyter notebook: 59_head_positions.ipynb

Download Python source code: 59_head_positions.py

Download zipped: 59_head_positions.zip

Gallery generated by Sphinx-Gallery

Setting the EEG reference

Signal-space separation (SSS) and Maxwell filtering

---

## FDR correction on T-test on sensor data#

**URL:** https://mne.tools/stable/auto_examples/stats/fdr_stats_evoked.html

**Contents:**
- FDR correction on T-test on sensor data#

Go to the end to download the full example code.

One tests if the evoked response significantly deviates from 0. Multiple comparison problem is addressed with False Discovery Rate (FDR) correction.

Read epochs for the channel of interest

Download Jupyter notebook: fdr_stats_evoked.ipynb

Download Python source code: fdr_stats_evoked.py

Download zipped: fdr_stats_evoked.zip

Gallery generated by Sphinx-Gallery

Permutation F-test on sensor data with 1D cluster level

Regression on continuous data (rER[P/F])

---

## Filtering and resampling data#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/30_filtering_resampling.html

**Contents:**
- Filtering and resampling data#
- Background on filtering#
- Repairing artifacts by filtering#
  - Slow drifts#
  - Power line noise#
- Resampling#
  - Best practices#

Go to the end to download the full example code.

This tutorial covers filtering and resampling, and gives examples of how filtering can be used for artifact repair.

We begin as always by importing the necessary Python modules and loading some example data. We‚Äôll also crop the data to 60 seconds (to save memory on the documentation server):

A filter removes or attenuates parts of a signal. Usually, filters act on specific frequency ranges of a signal ‚Äî for example, suppressing all frequency components above or below a certain cutoff value. There are many ways of designing digital filters; see Background information on filtering for a longer discussion of the various approaches to filtering physiological signals in MNE-Python.

Artifacts that are restricted to a narrow frequency range can sometimes be repaired by filtering the data. Two examples of frequency-restricted artifacts are slow drifts and power line noise. Here we illustrate how each of these can be repaired by filtering.

Low-frequency drifts in raw data can usually be spotted by plotting a fairly long span of data with the plot() method, though it is helpful to disable channel-wise DC shift correction to make slow drifts more readily visible. Here we plot 60 seconds, showing all the magnetometer channels:

A half-period of this slow drift appears to last around 10 seconds, so a full period would be 20 seconds, i.e., \(\frac{1}{20} \mathrm{Hz}\). To be sure those components are excluded, we want our highpass to be higher than that, so let‚Äôs try \(\frac{1}{10} \mathrm{Hz}\) and \(\frac{1}{5} \mathrm{Hz}\) filters to see which works best:

Looks like 0.1 Hz was not quite high enough to fully remove the slow drifts. Notice that the text output summarizes the relevant characteristics of the filter that was created. If you want to visualize the filter, you can pass the same arguments used in the call to raw.filter() above to the function mne.filter.create_filter() to get the filter parameters, and then pass the filter parameters to mne.viz.plot_filter(). create_filter() also requires parameters data (a NumPy array) and sfreq (the sampling frequency of the data), so we‚Äôll extract those from our Raw object:

Notice that the output is the same as when we applied this filter to the data using raw.filter(). You can now pass the filter parameters (and the sampling frequency) to plot_filter() to plot the filter:

Power line noise is an environmental artifact that manifests as persistent oscillations centered around the AC power line frequency. Power line artifacts are easiest to see on plots of the spectrum, so we‚Äôll use compute_psd() to get a Spectrum object, and use its plot() method to illustrate. We‚Äôll also write a little function that adds arrows to the spectrum plot to highlight the artifacts:

It should be evident that MEG channels are more susceptible to this kind of interference than EEG that is recorded in the magnetically shielded room. Removing power-line noise can be done with a notch filter, applied directly to the Raw object, specifying an array of frequencies to be attenuated. Since the EEG channels are relatively unaffected by the power line noise, we‚Äôll also specify a picks argument so that only the magnetometers and gradiometers get filtered:

notch_filter() also has parameters to control the notch width, transition bandwidth and other aspects of the filter. See the docstring for details.

It‚Äôs also possible to try to use a spectrum fitting routine to notch filter. In principle it can automatically detect the frequencies to notch, but our implementation generally does not do so reliably, so we specify the frequencies to remove instead, and it does a good job of removing the line noise at those frequencies:

EEG and MEG recordings are notable for their high temporal precision, and are often recorded with sampling rates around 1000 Hz or higher. This is good when precise timing of events is important to the experimental design or analysis plan, but also consumes more memory and computational resources when processing the data. In cases where high-frequency components of the signal are not of interest and precise timing is not needed (e.g., computing EOG or ECG projectors on a long recording), downsampling the signal can be a useful time-saver.

In MNE-Python, the resampling methods (raw.resample(), epochs.resample() and evoked.resample()) apply a low-pass filter to the signal to avoid aliasing, so you don‚Äôt need to explicitly filter it yourself first. This built-in filtering that happens when using raw.resample(), epochs.resample(), or evoked.resample() is a brick-wall filter applied in the frequency domain at the Nyquist frequency of the desired new sampling rate. This can be clearly seen in the PSD plot, where a dashed vertical line indicates the filter cutoff; the original data had an existing lowpass at around 172 Hz (see raw.info['lowpass']), and the data resampled from ~600 Hz to 200 Hz gets automatically lowpass filtered at 100 Hz (the Nyquist frequency for a target rate of 200 Hz):

By default, MNE-Python resamples using method="fft", which performs FFT-based resampling via scipy.signal.resample(). While efficient and good for most biological signals, it has two main potential drawbacks:

It assumes periodicity of the signal. We try to overcome this with appropriate signal padding, but some signal leakage may still occur.

It treats the entire signal as a single block. This means that in general effects are not guaranteed to be localized in time, though in practice they often are.

Alternatively, resampling can be performed using method="polyphase" instead. This uses scipy.signal.resample_poly() under the hood, which in turn utilizes a three-step process to resample signals (see scipy.signal.upfirdn() for details). This process guarantees that each resampled output value is only affected by input values within a limited range. In other words, output values are guaranteed to be a result of a specific set of input values.

In general, using method="polyphase" can also be faster than method="fft" in cases where the desired sampling rate is an integer factor different from the input sampling rate. For example:

Because resampling involves filtering, there are some pitfalls to resampling at different points in the analysis stream:

Performing resampling on Raw data (before epoching) will negatively affect the temporal precision of Event arrays, by causing jitter in the event timing. This reduced temporal precision will propagate to subsequent epoching operations.

Performing resampling after epoching can introduce edge artifacts on every epoch, whereas filtering the Raw object will only introduce artifacts at the start and end of the recording (which is often far enough from the first and last epochs to have no affect on the analysis).

The following section suggests best practices to mitigate both of these issues.

To avoid the reduction in temporal precision of events that comes with resampling a Raw object, and also avoid the edge artifacts that come with filtering an Epochs or Evoked object, the best practice is to:

low-pass filter the Raw data at or below \(\frac{1}{3}\) of the desired sample rate, then

decimate the data after epoching, by either passing the decim parameter to the Epochs constructor, or using the decimate() method after the Epochs have been created.

The recommendation for setting the low-pass corner frequency at \(\frac{1}{3}\) of the desired sample rate is a fairly safe rule of thumb based on the default settings in raw.filter() (which are different from the filter settings used inside the raw.resample() method). If you use a customized lowpass filter (specifically, if your transition bandwidth is wider than 0.5√ó the lowpass cutoff), downsampling to 3√ó the lowpass cutoff may still not be enough to avoid aliasing, and MNE-Python will not warn you about it (because the raw.info object only keeps track of the lowpass cutoff, not the transition bandwidth). Conversely, if you use a steeper filter, the warning may be too sensitive. If you are unsure, plot the PSD of your filtered data before decimating and ensure that there is no content in the frequencies above the Nyquist frequency of the sample rate you‚Äôll end up with after decimation.

Note that this method of manually filtering and decimating is exact only when the original sampling frequency is an integer multiple of the desired new sampling frequency. Since the sampling frequency of our example data is 600.614990234375 Hz, ending up with a specific sampling frequency like (say) 90 Hz will not be possible:

If for some reason you cannot follow the above-recommended best practices, you should at the very least either:

resample the data after epoching, and make your epochs long enough that edge effects from the filtering do not affect the temporal span of the epoch that you hope to analyze / interpret; or

perform resampling on the Raw object and its corresponding Events array simultaneously so that they stay more or less in synch. This can be done by passing the Events array as the events parameter to raw.resample().

Total running time of the script: (0 minutes 31.764 seconds)

Download Jupyter notebook: 30_filtering_resampling.ipynb

Download Python source code: 30_filtering_resampling.py

Download zipped: 30_filtering_resampling.zip

Gallery generated by Sphinx-Gallery

Background information on filtering

Repairing artifacts with regression

---

## Find MEG reference channel artifacts#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/find_ref_artifacts.html

**Contents:**
- Find MEG reference channel artifacts#
- References#

Go to the end to download the full example code.

Use ICA decompositions of MEG reference channels to remove intermittent noise.

Many MEG systems have an array of reference channels which are used to detect external magnetic noise. However, standard techniques that use reference channels to remove noise from standard channels often fail when noise is intermittent. The technique described here (using ICA on the reference channels) often succeeds where the standard techniques do not.

There are two algorithms to choose from: separate and together (default). In the ‚Äúseparate‚Äù algorithm, two ICA decompositions are made: one on the reference channels, and one on reference + standard channels. The reference + standard channel components which correlate with the reference channel components are removed.

In the ‚Äútogether‚Äù algorithm, a single ICA decomposition is made on reference + standard channels, and those components whose weights are particularly heavy on the reference channels are removed.

This technique is fully described and validated in [1]

Read raw data, cropping to 5 minutes to save memory

Note that even though standard noise removal has already been applied to these data, much of the noise in the reference channels (bottom of the plot) can still be seen in the standard channels.

The PSD of these data show the noise as clear peaks.

Run the ‚Äútogether‚Äù algorithm.

Now try the ‚Äúseparate‚Äù algorithm.

Cleaned raw data traces:

Cleaned raw data PSD:

Jeff Hanna, Cora Kim, and Nadia M√ºller-Voggel. External noise removed from magnetoencephalographic signal using independent component analysis of reference channels. Journal of Neuroscience Methods, 2020. doi:10.1016/j.jneumeth.2020.108592.

Total running time of the script: (0 minutes 17.117 seconds)

Download Jupyter notebook: find_ref_artifacts.ipynb

Download Python source code: find_ref_artifacts.py

Download zipped: find_ref_artifacts.zip

Gallery generated by Sphinx-Gallery

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Visualise NIRS artifact correction methods

---

## Fixing BEM and head surfaces#

**URL:** https://mne.tools/stable/auto_tutorials/forward/80_fix_bem_in_blender.html

**Contents:**
- Fixing BEM and head surfaces#
- Exporting surfaces to Blender#
- Editing in Blender#
- Using the fixed surfaces in MNE-Python#
- Editing the head surfaces#
  - Low-resolution head#
  - High-resolution head#
  - Blender editing tips#
- What if you still get an error?#
  - Blender operations#

Go to the end to download the full example code.

Sometimes when creating a BEM model the surfaces need manual correction because of a series of problems that can arise (e.g. intersection between surfaces). Here, we will see how this can be achieved by exporting the surfaces to the 3D modeling program Blender, editing them, and re-importing them. We will also give a simple example of how to use pymeshfix to fix topological problems.

Much of this tutorial is based on ezemikulan/blender_freesurfer by Ezequiel Mikulan.

In this tutorial, we are working with the MNE-Sample set, for which the surfaces have no issues. To demonstrate how to fix problematic surfaces, we are going to manually place one of the inner-skull vertices outside the outer-skill mesh.

We then convert the surfaces to .obj files and create a new folder called conv inside the FreeSurfer subject folder to keep them in.

See the following video tutorial for how to import, edit and export surfaces in Blender (step-by-step instructions are also below):

We can now open Blender and import the surfaces. Go to File > Import > Wavefront (.obj). Navigate to the conv folder and select the file you want to import. Make sure to select the Keep Vert Order option. You can also select the Y Forward option to load the axes in the correct direction (RAS):

For convenience, you can save these settings by pressing the + button next to Operator Presets.

Repeat the procedure for all surfaces you want to import (e.g. inner_skull and outer_skull).

You can now edit the surfaces any way you like. See the Beginner Blender Tutorial Series to learn how to use Blender. Specifically, part 2 will teach you how to use the basic editing tools you need to fix the surface.

In Blender, you can export a surface as an .obj file by selecting it and go to File > Export > Wavefront (.obj). You need to again select the Y Forward option and check the Keep Vertex Order box.

Each surface needs to be exported as a separate file. We recommend saving them in the conv folder and ending the file name with _fixed.obj, although this is not strictly necessary.

In order to be able to run this tutorial script top to bottom, we here simulate the edits you did manually in Blender using Python code:

Back in Python, you can read the fixed .obj files and save them as FreeSurfer .surf files. For the mne.make_bem_model() function to find them, they need to be saved using their original names in the surf folder, e.g. bem/inner_skull.surf. Be sure to first backup the original surfaces in case you make a mistake!

Sometimes the head surfaces are faulty and require manual editing. We use mne.write_head_bem() to convert the fixed surfaces to .fif files.

For EEG forward modeling, it is possible that outer_skin.surf would be manually edited. In that case, remember to save the fixed version of -head.fif from the edited surface file for coregistration.

We use mne.read_bem_surfaces() to read the head surface files. After editing, we again output the head file with mne.write_head_bem(). Here we use -head.fif for speed.

See also Cleaning up a bad dense head surface by smoothing for a possible alternative high-resolution head fix using FreeSurfer smoothing instead of blender.

A particularly useful operation is the Shrinkwrap functionality, that will restrict one surface inside another surface (for example the Skull inside the Outer Skin). Here is how to use it:

Select the surface that is creating the problem.

In Edit Mode, press C to use the circle selection tool to select the vertices that are outside.

In the Object Data Properties tab use the + button to add a Vertex Group and click Assign to assign the current selection to the group.

In the Modifiers tab go to Add Modifier add a Shrinkwrap modifier and set it to snap Inside with the outer surface as the Target and the Group that you created before as the Vertex Group. You can then use the Offset parameter to adjust the distance.

If nothing happens, the normals of the inner skull surface may be inverted. To fix this select all the vertices or faces of the inner skull and go to Mesh>Normals>Flip in the toolbar.

In Object Mode click on the down-pointing arrow of the Shrinkwrap modifier and click on Apply.

That‚Äôs it! You are ready to continue with your analysis pipeline (e.g. running mne.make_bem_model()).

When editing BEM surfaces/meshes in Blender, make sure to use tools that do not change the number or order of vertices, or the geometry of triangular faces. For example, avoid the extrusion tool, because it duplicates the extruded vertices.

If you get a rough head surfaces when using mne make_scalp_surfaces, consider smoothing your T1 ahead of time with a Gaussian kernel with FreeSurfer using something like the following within the subject‚Äôs mri directory:

Here the --fwhm argument determines how much smoothing (in mm) to apply. Then delete SUBJECTS_DIR/SUBJECT/surf/lh.seghead, and re-run mne make_scalp_surfaces with the additional arguments --mri="T1_smoothed_3.mgz" --overwrite, and you should get cleaner surfaces.

MNE-Python requires that meshes satisfy some topological checks to ensure that subsequent processing like BEM solving and electrode projection can work properly.

Below are some examples of errors you might encounter when working with meshes in MNE-Python, and the likely causes of those errors.

This error is caused by having too few or too many vertices. The full error is something like:

This error can occur when trying to match the original number of triangles by removing vertices. The full error looks like:

This error (like the previous error) reflects a problem with the surface topology (i.e., the expected pattern of vertices/edges/faces is disrupted).

This error reflects a mismatch between how the surface is represented in memory (the order of the vertex/face definitions) and what is expected by MNE-Python. The full error is:

For any of these errors, it is usually easiest to start over with the unedited BEM surface and try again, making sure to only move vertices and faces without adding or deleting any. For example, select a circle of vertices, then press G to drag them to the desired location. Smoothing a group of selected vertices in Blender (by right-clicking and selecting ‚ÄúSmooth Vertices‚Äù) can also be helpful.

pymeshfix is a GPL-licensed Python module designed to produce water-tight meshes that satisfy the topological checks listed above. For example, if your 'SUBJECTS_DIR/SUBJECT/surf/lh.seghead' has topological problems and Cleaning up a bad dense head surface by smoothing does not work, you can try fixing the mesh instead. After installing pymeshfix using conda or pip, from within the 'SUBJECTS_DIR/SUBJECT/surf' directory, you could try:

In some cases this could fix the topology such that a subsequent call to mne make_scalp_surfaces will succeed without needing to use the --force parameter.

Total running time of the script: (0 minutes 6.180 seconds)

Download Jupyter notebook: 80_fix_bem_in_blender.ipynb

Download Python source code: 80_fix_bem_in_blender.py

Download zipped: 80_fix_bem_in_blender.zip

Gallery generated by Sphinx-Gallery

How MNE uses FreeSurfer‚Äôs outputs

Computing a covariance matrix

---

## Forward models and source spaces#

**URL:** https://mne.tools/stable/auto_tutorials/forward/index.html

**Contents:**
- Forward models and source spaces#

These tutorials cover how the cortical source locations (source spaces) and forward models (AKA leadfield matrices) are defined.

FreeSurfer MRI reconstruction

Source alignment and coordinate frames

Using an automated approach to coregistration

Head model and forward computation

EEG forward operator with a template MRI

How MNE uses FreeSurfer‚Äôs outputs

Fixing BEM and head surfaces

Computing a covariance matrix

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

FreeSurfer MRI reconstruction

---

## FreeSurfer MRI reconstruction#

**URL:** https://mne.tools/stable/auto_tutorials/forward/10_background_freesurfer.html

**Contents:**
- FreeSurfer MRI reconstruction#
- First steps#
- Anatomical reconstruction#
- Use with MNE-Python#
- ‚Äòfsaverage‚Äô#
- References#

Go to the end to download the full example code.

This tutorial covers how to use FreeSurfer alongside MNE-Python, to handle the structural MRI data that we use to build subject-specific anatomical models of the scalp, inner/outer skull, and cortical surface.

FreeSurfer is an open source analysis toolbox for MRI data, available from https://surfer.nmr.mgh.harvard.edu/. FreeSurfer provides graphical interfaces for visualizing MRI data, several anatomical parcellations useful for creating region-of-interest (ROI) labels, template brains such as fsaverage, and several command-line tools for tasks like finding tissue boundaries or morphing brains to align analogous anatomical regions across subjects.

These FreeSurfer capabilities are necessary for MNE-Python to compute the forward model and set up the corresponding source space (a grid of dipoles located on the cortical surface or within the brain volume).

After downloading and installing FreeSurfer, there are a few steps to set up the environment. First is to define an environment variable FREESURFER_HOME and then run the FreeSurfer setup script:

The FreeSurfer home directory will vary depending on your operating system and choices you made during installation. See the FreeSurfer installation guide for more info.

Another important step is to tell FreeSurfer where to put the anatomical reconstructions of your research subjects. This is done with an environment variable called SUBJECTS_DIR, which will contain the individual subjects‚Äô reconstructions in separate sub-folders.

Again see the FreeSurfer installation guide for more info.

The first processing stage is the creation of various surface reconstructions. Usually a full FreeSurfer reconstruction is obtained by the following commands:

where i stands for ‚Äúinput‚Äù and s for ‚Äúsubject‚Äù. Executing this will create the folder $SUBJECTS_DIR/sample and populate it with several subfolders (bem, label, mri, etc). See also the FreeSurfer wiki‚Äôs recommended reconstruction workflow for more detailed explanation.

Anatomical reconstruction can take several hours, even on a fast computer.

FreeSurfer performs a hemispheric separation so most resulting files have separate left and right hemisphere versions, indicated by the prefix lh or rh. This hemispheric separation is preserved by MNE-Python (e.g., mne.SourceEstimate objects store spatial locations (vertices) for the two hemispheres separately; cf. The SourceEstimate data structure).

Below we show an example of the results of a FreeSurfer reconstruction for the left hemisphere of the Sample dataset subject, including an overlay of an anatomical parcellation (in this case, the parcellation from [1]).

For source localization analysis to work properly, it is important that the FreeSurfer reconstruction has completed beforehand. Furthermore, for many MNE-Python functions related to inverse imaging (such as mne.setup_source_space), SUBJECTS_DIR has to be defined globally (as an environment variable or through a call to mne.set_config), or specified separately in each function call by passing the keyword argument subjects_dir='/path/to/your/subjects_dir'.

See Setting up the source space to get an idea of how this works for one particular function, and How MNE uses FreeSurfer‚Äôs outputs for more details on how MNE-Python and FreeSurfer are integrated.

During installation, FreeSurfer copies a subject called 'fsaverage' to $FREESURFER_HOME/subjects/fsaverage. fsaverage is a template brain based on a combination of 40 MRI scans of real brains. The fsaverage subject folder contains all the files that a normal subject reconstruction would yield. See https://surfer.nmr.mgh.harvard.edu/fswiki/FsAverage for an overview, and https://surfer.nmr.mgh.harvard.edu/fswiki/Buckner40Notes for details about the subjects used to create fsaverage. A copy of fsaverage is also provided as part of the Sample dataset and is also distributed as a standalone dataset.

One of the most common uses of fsaverage is as a destination space for cortical morphing / source estimate transformations. In other words, it is common to morph each individual subject‚Äôs estimated brain activity onto the fsaverage brain, so that group-level statistical comparisons can be made.

Christophe Destrieux, Bruce Fischl, Anders Dale, and Eric Halgren. Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. NeuroImage, 53(1):1‚Äì15, 2010. doi:10.1016/j.neuroimage.2010.06.010.

Total running time of the script: (0 minutes 1.932 seconds)

Download Jupyter notebook: 10_background_freesurfer.ipynb

Download Python source code: 10_background_freesurfer.py

Download zipped: 10_background_freesurfer.zip

Gallery generated by Sphinx-Gallery

Forward models and source spaces

Source alignment and coordinate frames

---

## Frequency and time-frequency sensor analysis#

**URL:** https://mne.tools/stable/auto_tutorials/time-freq/20_sensors_time_frequency.html

**Contents:**
- Frequency and time-frequency sensor analysis#
- Frequency analysis#
- Time-frequency analysis: power and inter-trial coherence#
- Inspect power#
- Joint Plot#
- Inspect ITC#
- Exercise#

Go to the end to download the full example code.

The objective is to show you how to explore the spectral content of your data (frequency and time-frequency). Here we‚Äôll work on Epochs.

We will use this dataset: Somatosensory. It contains so-called event related synchronizations (ERS) / desynchronizations (ERD) in the beta band.

We start by exploring the frequency content of our epochs.

Let‚Äôs first check out all channel types by averaging across epochs.

Now, let‚Äôs take a look at the spatial distributions of the PSD, averaged across epochs and frequency bands.

Alternatively, you can also create PSDs from Epochs methods directly.

In contrast to the methods for visualization, the compute_psd methods do not scale the data from SI units to more ‚Äúconvenient‚Äù values. So when e.g. calculating the PSD of gradiometers via compute_psd(), you will get the power as (T/m)¬≤/Hz (instead of (fT/cm)¬≤/Hz via plot_psd()).

Notably, mne.Epochs.compute_psd() supports the keyword argument average, which specifies how to estimate the PSD based on the individual windowed segments. The default is average='mean', which simply calculates the arithmetic mean across segments. Specifying average='median', in contrast, returns the PSD based on the median of the segments (corrected for bias relative to the mean), which is a more robust measure.

Lastly, we can also retrieve the unaggregated segments by passing average=None to mne.Epochs.compute_psd(). The dimensions of the returned array are (n_epochs, n_sensors, n_freqs, n_segments).

We now compute time-frequency representations (TFRs) from our Epochs. We‚Äôll look at power and inter-trial coherence (ITC).

To this we‚Äôll use the function mne.time_frequency.tfr_morlet() but you can also use mne.time_frequency.tfr_multitaper() or mne.time_frequency.tfr_stockwell().

The decim parameter reduces the sampling rate of the time-frequency decomposition by the defined factor. This is usually done to reduce memory usage. For more information refer to the documentation of mne.time_frequency.tfr_morlet().

define frequencies of interest (log-spaced)

The generated figures are interactive. In the topo you can click on an image to visualize the data for one sensor. You can also select a portion in the time-frequency plane to obtain a topomap for a certain time-frequency region.

You can also create a joint plot showing both the aggregated TFR across channels and topomaps at specific times and frequencies to obtain a quick overview regarding oscillatory effects across time and space.

Baseline correction can be applied to power or done in plots. To illustrate the baseline correction in plots, the next line is commented:

Visualize the inter-trial coherence values as topomaps as done with power.

Total running time of the script: (0 minutes 14.366 seconds)

Download Jupyter notebook: 20_sensors_time_frequency.ipynb

Download Python source code: 20_sensors_time_frequency.py

Download zipped: 20_sensors_time_frequency.zip

Gallery generated by Sphinx-Gallery

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

---

## Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset#

**URL:** https://mne.tools/stable/auto_tutorials/time-freq/50_ssvep.html

**Contents:**
- Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset#
- Data preprocessing#
- Frequency analysis#
  - Calculate power spectral density (PSD)#
  - Calculate signal to noise ratio (SNR)#
  - Plot PSD and SNR spectra#
- Extract SNR values at the stimulation frequency#
  - Get index for the stimulation frequency (12 Hz)#
  - Get indices for the different trial types#
  - Get indices of EEG channels forming the ROI#

Go to the end to download the full example code.

In this tutorial we compute the frequency spectrum and quantify signal-to-noise ratio (SNR) at a target frequency in EEG data recorded during fast periodic visual stimulation (FPVS) at 12 Hz and 15 Hz in different trials. Extracting SNR at stimulation frequency is a simple way to quantify frequency tagged responses in MEEG (a.k.a. steady state visually evoked potentials, SSVEP, or visual steady-state responses, vSSR in the visual domain, or auditory steady-state responses, ASSR in the auditory domain).

For a general introduction to the method see Norcia et al. (2015) for the visual domain, and Picton et al. (2003) for the auditory domain.

We use a simple example dataset with frequency tagged visual stimulation: N=2 participants observed checkerboard patterns inverting with a constant frequency of either 12.0 Hz of 15.0 Hz. 32 channels wet EEG was recorded. (see SSVEP for more information).

We will visualize both the power-spectral density (PSD) and the SNR spectrum of the epoched data, extract SNR at stimulation frequency, plot the topography of the response, and statistically separate 12 Hz and 15 Hz responses in the different trials. Since the evoked response is mainly generated in early visual areas of the brain the statistical analysis will be carried out on an occipital ROI.

Due to a generally high SNR in SSVEP/vSSR, typical preprocessing steps are considered optional. This doesn‚Äôt mean, that a proper cleaning would not increase your signal quality!

Raw data have FCz reference, so we will apply common-average rereferencing.

We will apply a 0.1 highpass filter.

Lastly, we will cut the data in 20 s epochs corresponding to the trials.

Now we compute the frequency spectrum of the EEG data. You will already see the peaks at the stimulation frequencies and some of their harmonics, without any further processing.

The ‚Äòclassical‚Äô PSD plot will be compared to a plot of the SNR spectrum. SNR will be computed as a ratio of the power in a given frequency bin to the average power in its neighboring bins. This procedure has two advantages over using the raw PSD:

it normalizes the spectrum and accounts for 1/f power decay.

power modulations which are not very narrow band will disappear.

The frequency spectrum will be computed using Fast Fourier transform (FFT). This seems to be common practice in the steady-state literature and is based on the exact knowledge of the stimulus and the assumed response - especially in terms of it‚Äôs stability over time. For a discussion see e.g. Bach & Meigen (1999)

We will exclude the first second of each trial from the analysis:

steady-state response often take a while to stabilize, and the transient phase in the beginning can distort the signal estimate.

this section of data is expected to be dominated by responses related to the stimulus onset, and we are not interested in this.

In MNE we call plain FFT as a special case of Welch‚Äôs method, with only a single Welch window spanning the entire trial and no specific windowing function (i.e. applying a boxcar window).

SNR - as we define it here - is a measure of relative power: it‚Äôs the ratio of power in a given frequency bin - the ‚Äòsignal‚Äô - to a ‚Äònoise‚Äô baseline - the average power in the surrounding frequency bins. This approach was initially proposed by Meigen & Bach (1999)

Hence, we need to set some parameters for this baseline - how many neighboring bins should be taken for this computation, and do we want to skip the direct neighbors (this can make sense if the stimulation frequency is not super constant, or frequency bands are very narrow).

The function below does what we want.

Now we call the function to compute our SNR spectrum.

As described above, we have to define two parameters.

how many noise bins do we want?

do we want to skip the n bins directly next to the target bin?

Tweaking these parameters can drastically impact the resulting spectrum, but mainly if you choose extremes. E.g. if you‚Äôd skip very many neighboring bins, broad band power modulations (such as the alpha peak) should reappear in the SNR spectrum. On the other hand, if you skip none you might miss or smear peaks if the induced power is distributed over two or more frequency bins (e.g. if the stimulation frequency isn‚Äôt perfectly constant, or you have very narrow bins).

Here, we want to compare power at each bin with average power of the three neighboring bins (on each side) and skip one bin directly next to it.

Now we will plot grand average PSD (in blue) and SNR (in red) ¬± sd for every frequency bin. PSD is plotted on a log scale.

You can see that the peaks at the stimulation frequencies (12 Hz, 15 Hz) and their harmonics are visible in both plots (just as the line noise at 50 Hz). Yet, the SNR spectrum shows them more prominently as peaks from a noisy but more or less constant baseline of SNR = 1. You can further see that the SNR processing removes any broad-band power differences (such as the increased power in alpha band around 10 Hz), and also removes the 1/f decay in the PSD.

Note, that while the SNR plot implies the possibility of values below 0 (mean minus sd) such values do not make sense. Each SNR value is a ratio of positive PSD values, and the lowest possible PSD value is 0 (negative Y-axis values in the upper panel only result from plotting PSD on a log scale). Hence SNR values must be positive and can minimally go towards 0.

Our processing yielded a large array of many SNR values for each trial √ó channel √ó frequency-bin of the PSD array.

For statistical analysis we obviously need to define specific subsets of this array. First of all, we are only interested in SNR at the stimulation frequency, but we also want to restrict the analysis to a spatial ROI. Lastly, answering your interesting research questions will probably rely on comparing SNR in different trials.

Therefore we will have to find the indices of trials, channels, etc. Alternatively, one could subselect the trials already at the epoching step, using MNE‚Äôs event information, and process different epoch structures separately.

Let‚Äôs only have a look at the trials with 12 Hz stimulation, for now.

Ideally, there would be a bin with the stimulation frequency exactly in its center. However, depending on your Spectral decomposition this is not always the case. We will find the bin closest to it - this one should contain our frequency tagged response.

Now we simply need to apply our selection and yield a result. Therefore, we typically report grand average SNR over the subselection.

In this tutorial we don‚Äôt verify the presence of a neural response. This is commonly done in the ASSR literature where SNR is often lower. An F-test or Hotelling T¬≤ would be appropriate for this purpose.

But wait‚Ä¶ As described in the intro, we have decided a priori to work with average SNR over a subset of occipital channels - a visual region of interest (ROI) - because we expect SNR to be higher on these channels than in other channels.

Let‚Äôs check out, whether this was a good decision!

Here we will plot average SNR for each channel location as a topoplot. Then we will do a simple paired T-test to check, whether average SNRs over the two sets of channels are significantly different.

We can see, that 1) this participant indeed exhibits a cluster of channels with high SNR in the occipital region and 2) that the average SNR over all channels is smaller than the average of the visual ROI computed above. The difference is statistically significant. Great!

Such a topography plot can be a nice tool to explore and play with your data - e.g. you could try how changing the reference will affect the spatial distribution of SNR values.

However, we also wanted to show this plot to point at a potential problem with frequency-tagged (or any other brain imaging) data: there are many channels and somewhere you will likely find some statistically significant effect. It is very easy - even unintended - to end up double-dipping or p-hacking. So if you want to work with an ROI or individual channels, ideally select them a priori - before collecting or looking at the data - and preregister this decision so people will believe you. If you end up selecting an ROI or individual channel for reporting because this channel or ROI shows an effect, e.g. in an explorative analysis, this is also fine but make it transparently and correct for multiple comparison.

After this little detour into open science, let‚Äôs move on and do the analyses we actually wanted to do:

We will show that we can easily detect and discriminate the brains responses in the trials with different stimulation frequencies.

In the frequency and SNR spectrum plot above, we had all trials mixed up. Now we will extract 12 and 15 Hz SNR in both types of trials individually, and compare the values with a simple t-test. We will also extract SNR of the 1st and 2nd harmonic for both stimulation frequencies. These are often reported as well and can show interesting interactions.

As you can easily see there are striking differences between the trials. Let‚Äôs verify this using a series of two-tailed paired T-Tests.

So that‚Äôs it, we hope you enjoyed our little tour through this example dataset.

As you could see, frequency-tagging is a very powerful tool that can yield very high signal to noise ratios and effect sizes that enable you to detect brain responses even within a single participant and single trials of only a few seconds duration.

For the overly motivated amongst you, let‚Äôs see what else we can show with these data.

Using the PSD function as implemented in MNE makes it very easy to change the amount of data that is actually used in the spectrum estimation.

Here we employ this to show you some features of frequency tagging data that you might or might not have already intuitively expected:

First we will simulate shorter trials by taking only the first x s of our 20s trials (2, 4, 6, 8, ‚Ä¶, 20 s), and compute the SNR using a FFT window that covers the entire epoch:

You can see that the signal estimate / our SNR measure increases with the trial duration.

This should be easy to understand: in longer recordings there is simply more signal (one second of additional stimulation adds, in our case, 12 cycles of signal) while the noise is (hopefully) stochastic and not locked to the stimulation frequency. In other words: with more data the signal term grows faster than the noise term.

We can further see that the very short trials with FFT windows < 2-3s are not great - here we‚Äôve either hit the noise floor and/or the transient response at the trial onset covers too much of the trial.

Again, this tutorial doesn‚Äôt statistically test for the presence of a neural response, but an F-test or Hotelling T¬≤ would be appropriate for this purpose.

..and finally we can trick MNE‚Äôs PSD implementation to make it a sliding window analysis and come up with a time resolved SNR measure. This will reveal whether a participant blinked or scratched their head..

Each of the ten trials is coded with a different color in the plot below.

Well.. turns out this was a bit too optimistic ;)

But seriously: this was a nice idea, but we‚Äôve reached the limit of what‚Äôs possible with this single-subject example dataset. However, there might be data, applications, or research questions where such an analysis makes sense.

Total running time of the script: (0 minutes 10.223 seconds)

Download Jupyter notebook: 50_ssvep.ipynb

Download Python source code: 50_ssvep.py

Download zipped: 50_ssvep.zip

Gallery generated by Sphinx-Gallery

Frequency and time-frequency sensor analysis

Forward models and source spaces

---

## Generate simulated evoked data#

**URL:** https://mne.tools/stable/auto_examples/simulation/simulate_evoked_data.html

**Contents:**
- Generate simulated evoked data#

Go to the end to download the full example code.

Use simulate_sparse_stc() to simulate evoked data.

Load real data as templates

Generate source time courses from 2 dipoles and the corresponding evoked data

Generate noisy evoked data

Total running time of the script: (0 minutes 7.794 seconds)

Download Jupyter notebook: simulate_evoked_data.ipynb

Download Python source code: simulate_evoked_data.py

Download zipped: simulate_evoked_data.zip

Gallery generated by Sphinx-Gallery

Compare simulated and estimated source activity

Generate simulated raw data

---

## Getting averaging info from .fif files#

**URL:** https://mne.tools/stable/auto_examples/io/elekta_epochs.html

**Contents:**
- Getting averaging info from .fif files#

Go to the end to download the full example code.

Parse averaging information defined in Elekta Vectorview/TRIUX DACQ (data acquisition). Extract and average epochs accordingly. Modify some averaging parameters and get epochs.

Check DACQ defined averaging categories and other info

Extract epochs corresponding to a category

Get epochs from all conditions, average

Make a new averaging category

Total running time of the script: (0 minutes 9.578 seconds)

Download Jupyter notebook: elekta_epochs.ipynb

Download Python source code: elekta_epochs.py

Download zipped: elekta_epochs.zip

Gallery generated by Sphinx-Gallery

Getting impedances from raw files

---

## Getting started with mne.Report#

**URL:** https://mne.tools/stable/auto_tutorials/intro/70_report.html

**Contents:**
- Getting started with mne.Report#
- Adding Raw data#
- Adding events#
- Adding Epochs#
- Adding Evoked#
- Adding Covariance#
- Adding Projection vectors#
- Adding ICA#
- Adding MRI with BEM#
- Adding coregistration#

Go to the end to download the full example code.

mne.Report is a way to create interactive HTML summaries of your data. These reports can show many different visualizations for one or multiple participants. A common use case is creating diagnostic summaries to check data quality at different stages in the processing pipeline. The report can show things like plots of data before and after each preprocessing step, epoch rejection statistics, MRI slices with overlaid BEM shells, all the way up to plots of estimated cortical activity.

Compared to a Jupyter notebook, mne.Report is easier to deploy, as the HTML pages it generates are self-contained and do not require a running Python environment. However, it is less flexible as you can‚Äôt change code and re-run something directly within the browser. This tutorial covers the basics of building a report. As usual, we will start by importing the modules and data we need:

The basic process for creating an HTML report is to instantiate the Report class and then use one or more of its many methods to add content, one element at a time.

You may also use the parse_folder() method to select particular files to include in the report. But more on that later.

Raw data can be added via the mne.Report.add_raw() method. It can operate with a path to a raw file and Raw objects, and will produce ‚Äì among other output ‚Äì a slider that allows you to scrub through 10 equally-spaced 1-second segments of the data:

In the following example, we crop the raw data to 60 seconds merely to speed up processing; this is not usually recommended!

Events can be added via mne.Report.add_events(). You also need to supply the sampling frequency used during the recording; this information is used to generate a meaningful time axis.

Epochs can be added via mne.Report.add_epochs(). Note that although this method accepts a path to an epochs file too, in the following example we only add epochs that we create on the fly from raw data. To demonstrate the representation of epochs metadata, we‚Äôll add some of that, too.

Evoked data can be added via mne.Report.add_evokeds(). By default, the Evoked.comment attribute of each evoked will be used as a title. We can specify custom titles via the titles parameter. Again, this method also accepts the path to an evoked file stored on disk; in the following example, however, we load the evokeds manually first, since we only want to add a subset of them to the report. The evokeds are not baseline-corrected, so we apply baseline correction, too. Lastly, by providing an (optional) noise covariance, we can add plots evokeds that were ‚Äúwhitened‚Äù using this covariance matrix.

By default, this method will produce topographic plots at 21 equally-spaced time points (or fewer, if the data contains fewer time points). We can adjust this via the n_time_points parameter.

(Noise) covariance objects can be added via mne.Report.add_covariance(). The method accepts Covariance objects and the path to a file on disk. It also expects us to pass an Info object or the path to a file to read the measurement info from, as well as a title.

Projection vectors can be added via mne.Report.add_projs(). The method requires an Info object (or the path to one) and a title. Projectors found in the Info will be visualized. You may also supply a list of Projection objects or a path to projectors stored on disk. In this case, the channel information is read from the Info, but projectors potentially included will be ignored; instead, only the explicitly passed projectors will be plotted.

ICA objects can be added via mne.Report.add_ica(). Aside from the parameters ica (that accepts an ICA instance or a path to an ICA object stored on disk) and the title, there is a third required parameter, inst. inst is used to specify a Raw or Epochs object for producing ICA property plots and overlay plots demonstrating the effects of ICA cleaning. If, instead, you only want to generate ICA component topography plots, explicitly pass inst=None.

mne.Report.add_ica() only works with fitted ICAs.

You can optionally specify for which components to produce topography and properties plots by passing picks. By default, all components will be shown. It is also possible to pass evoked signals based on ECG and EOG events via ecg_evoked and eog_evoked. This allows you directly see the effects of ICA component removal on these artifactual signals. Artifact detection scores produced by find_bads_ecg() and find_bads_eog() can be passed via the ecg_scores and eog_scores parameters, respectively, producing visualizations of the scores for each ICA component.

Lastly, by passing n_jobs, you may largely speed up the generation of the properties plots by enabling parallel execution.

In the following example, we request a small number of ICA components to estimate, set the threshold for assuming ICA convergence to a very liberal value, and only visualize 2 of the components. All of this is done to largely reduce the processing time of this tutorial, and is usually not recommended for an actual data analysis.

MRI slices with superimposed traces of the boundary element model (BEM) surfaces can be added via mne.Report.add_bem(). All you need to pass is the FreeSurfer subject name and subjects directory, and a title. To reduce the resulting file size, you may pass the decim parameter to only include every n-th volume slice, and width to specify the width of the resulting figures in pixels.

The sensor alignment (head -> mri transformation obtained by ‚Äúcoregistration‚Äù) can be visualized via mne.Report.add_trans(). The method expects the transformation either as a Transform object or as a path to a trans.fif file, the FreeSurfer subject name and subjects directory, and a title. The alpha parameter can be used to control the transparency of the head, where a value of 1 means fully opaque.

Forward solutions (‚Äúleadfields‚Äù) can be added by passing a Forward object or the path to a forward solution stored on disk to meth:mne.Report.add_forward.

An inverse operator can be added via mne.Report.add_inverse_operator(). The method expects an InverseOperator object or a path to one stored on disk, and a title.

An inverse solution (also called source estimate or source time course, STC) can be added via mne.Report.add_stc(). The method expects an SourceEstimate, the corresponding FreeSurfer subject name and subjects directory, and a title. By default, it will produce snapshots at 51 equally-spaced time points (or fewer, if the data contains fewer time points). We can adjust this via the n_time_points parameter.

It is possible to add code or scripts (e.g., the scripts you used for analysis) to the report via mne.Report.add_code(). The code blocks will be automatically syntax-highlighted. You may pass a string with the respective code snippet, or the path to a file. If you pass a path, it must be a pathlib.Path object (and not a string), otherwise it will be treated as a code literal.

Optionally, you can specify which programming language to assume for syntax highlighting by passing the language parameter. By default, we‚Äôll assume the provided code is Python.

Custom Matplotlib figures can be added via add_figure(). Required parameters are the figure and a title. Optionally, may add a caption to appear below the figure. You can also specify the image format of the image file that will be generated from the figure, so it can be embedded in the HTML report.

Multiple figures can be grouped into a single section via the section parameter.

The mne.Report.add_figure() method can also add multiple figures at once. In this case, a slider will appear, allowing users to intuitively browse the figures. To make this work, you need to provide a collection o figures, a title, and optionally a collection of captions.

In the following example, we will read the MNE logo as a Matplotlib figure and rotate it with different angles. Each rotated figure and its respective caption will be added to a list, which is then used to create the slider.

Existing images (e.g., photos, screenshots, sketches etc.) can be added to the report via mne.Report.add_image(). Supported image formats include JPEG, PNG, GIF, and SVG (and possibly others). Like with Matplotlib figures, you can specify a caption to appear below the image.

Each add_* method accepts a keyword parameter tags, which can be used to pass one or more tags to associate with the respective content elements. By default, each add_* method adds a tag describing the data type, e.g., evoked or source-estimate. When viewing the HTML report, the Filter by tags dropdown menu can be used to interactively show or hide content with specific tags. This allows you e.g. to only view evoked or participant-001 data, should you have added those tags. Visible tags will appear with blue, and hidden tags with gray background color.

To toggle the visibility of all tags, use the respective checkbox in the Filter by tags dropdown menu, or press T.

Saving to HTML is a write-only operation, meaning that we cannot read an .html file back as a Report object. In order to be able to edit a report once it‚Äôs no longer in-memory in an active Python session, save it as an HDF5 file instead of HTML:

The saved report can be read back and modified or amended. This allows the possibility to e.g. run multiple scripts in a processing pipeline, where each script adds new content to an existing report.

To make this even easier, mne.Report can be used as a context manager (note the with statement)`):

With the context manager, the updated report is also automatically saved back to report.h5 upon leaving the block.

We also provide a way to add an entire folder of files to the report at once, without having to invoke the individual add_* methods outlined above for each file. This approach, while convenient, provides less flexibility with respect to content ordering, tags, titles, etc.

Before getting started with mne.Report, make sure the files you want to render follow the filename conventions defined by MNE:

Filename convention (ends with)

-raw.fif(.gz), -raw_sss.fif(.gz), -raw_tsss.fif(.gz), _meg.fif(.gz), _eeg.fif(.gz), _ieeg.fif(.gz)

Alternatively, the dash - in the filename may be replaced with an underscore _ (except for the .stc files).

For our first example, we‚Äôll generate a barebones report for all the .fif files containing raw data in the sample dataset, by passing the pattern *raw.fif to parse_folder(). We‚Äôll omit the subject and subjects_dir parameters from the Report constructor, but we‚Äôll also pass render_bem=False to the parse_folder() method ‚Äî otherwise we would get a warning about not being able to render MRI and trans files without knowing the subject. To save some processing time in this tutorial, we‚Äôre also going to disable rendering of the butterfly plots for the Raw data by passing raw_butterfly=False.

Which files are included depends on both the pattern parameter passed to parse_folder() and also the subject and subjects_dir parameters provided to the Report constructor.

By default, the power spectral density and SSP projectors of the Raw files are not shown to speed up report generation. You can add them by passing raw_psd=True and projs=True to the Report constructor. Like in the previous example, we‚Äôre going to omit the butterfly plots by passing raw_butterfly=False. Lastly, let‚Äôs also refine our pattern to select only the filtered raw recording (omitting the unfiltered data and the empty-room noise recordings).

This time we‚Äôll pass a specific subject and subjects_dir (even though there‚Äôs only one subject in the sample dataset) and remove our render_bem=False parameter so we can see the MRI slices, with BEM contours overlaid on top if available. Since this is computationally expensive, we‚Äôll also pass the mri_decim parameter for the benefit of our documentation servers, and skip processing the .fif files.

Now let‚Äôs look at how Report handles Evoked data (we will skip the MRIs to save computation time).

The MNE sample dataset we‚Äôre using in this example has not been baseline-corrected; so let‚Äôs apply baseline correction this now for the report!

To request baseline correction, pass a baseline argument to Report, which should be a tuple with the starting and ending time of the baseline period. For more details, see the documentation on apply_baseline. Here, we will apply baseline correction for a baseline period from the beginning of the time interval to time point zero.

Lastly, we want to render the ‚Äúwhitened‚Äù evoked data, too. Whitening requires us to specify the path to a covariance matrix file via the cov_fname parameter of Report.

Now, let‚Äôs put all of this together! Here we use a temporary directory for speed so we can render a single Evoked instance, using just EEG channels.

The add_html() method allows you to add custom HTML to your report. This feature can be very convenient to add short descriptions, lists, or reminders to your report (among many other things you can think of encoding in HTML).

Total running time of the script: (1 minutes 6.279 seconds)

Download Jupyter notebook: 70_report.ipynb

Download Python source code: 70_report.py

Download zipped: 70_report.zip

Gallery generated by Sphinx-Gallery

Configuring MNE-Python

Reading data for different recording systems

---

## Handling bad channels#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/15_handling_bad_channels.html

**Contents:**
- Handling bad channels#
- Marking bad channels#
  - When to look for bad channels#
  - Why mark bad channels at all?#
- Interpolating bad channels#
  - How interpolation works#
  - Interpolation in MNE-Python#
- Summary#
- References#

Go to the end to download the full example code.

This tutorial covers manual marking of bad channels and reconstructing bad channels based on good signals at other sensors.

As usual we‚Äôll start by importing the modules we need, and loading some example data:

Sometimes individual channels malfunction and provide data that is too noisy to be usable. MNE-Python makes it easy to ignore those channels in the analysis stream without actually deleting the data in those channels. It does this by keeping track of the bad channel indices in a list and looking at that list when doing analysis or plotting tasks. The list of bad channels is stored in the 'bads' field of the Info object that is attached to Raw, Epochs, and Evoked objects.

Here you can see that the .fif file we loaded from disk must have been keeping track of channels marked as ‚Äúbad‚Äù ‚Äî which is good news, because it means any changes we make to the list of bad channels will be preserved if we save our data at intermediate stages and re-load it later. Since we saw above that EEG 053 is one of the bad channels, let‚Äôs look at it alongside some other EEG channels to see what‚Äôs bad about it. We can do this using the standard plot() method, and instead of listing the channel names one by one (['EEG 050', 'EEG 051', ...]) we‚Äôll use a regular expression to pick all the EEG channels between 050 and 059 with the pick_channels_regexp() function (the . is a wildcard character):

We can do the same thing for the bad MEG channel (MEG 2443). Since we know that Neuromag systems (like the one used to record the example data) use the last digit of the MEG channel number to indicate sensor type, here our regular expression will pick all the channels that start with 2 and end with 3:

Notice first of all that the channels marked as ‚Äúbad‚Äù are plotted in a light gray color in a layer behind the other channels, to make it easy to distinguish them from ‚Äúgood‚Äù channels. The plots make it clear that EEG 053 is not picking up scalp potentials at all, and MEG 2443 looks like it‚Äôs got a lot more internal noise than its neighbors ‚Äî its signal is a few orders of magnitude greater than the other MEG channels, making it a clear candidate for exclusion.

If you want to change which channels are marked as bad, you can edit raw.info['bads'] directly; it‚Äôs an ordinary Python list so the usual list methods will work:

If you want to build an interactive bad-channel-marking step into an analysis script, be sure to include the parameter block=True in your call to raw.plot() or epochs.plot(). This will pause the script while the plot is open, giving you time to mark bad channels before subsequent analysis or plotting steps are executed. This can be especially helpful if your script loops over multiple subjects.

You can also interactively toggle whether a channel is marked ‚Äúbad‚Äù in the plot windows of raw.plot() or epochs.plot() by clicking on the channel name along the vertical axis (in raw.plot() windows you can also do this by clicking the channel‚Äôs trace in the plot area). The bads field gets updated immediately each time you toggle a channel, and will retain its modified state after the plot window is closed.

The list of bad channels in the mne.Info object‚Äôs bads field is automatically taken into account in dozens of functions and methods across the MNE-Python codebase. This is done consistently with a parameter exclude='bads' in the function or method signature. Typically this exclude parameter also accepts a list of channel names or indices, so if you want to include the bad channels you can do so by passing exclude=[] (or some other list of channels to exclude). For example:

You can start looking for bad channels during the experiment session when the data is being acquired. If you notice any flat or excessively noisy channels, you can note them in your experiment log or protocol sheet. If your system computes online averages, these can be a good way to spot bad channels as well. After the data has been collected, you can do a more thorough check for bad channels by browsing the raw data using mne.io.Raw.plot(), without any projectors or ICA applied. Finally, you can compute offline averages (again with projectors, ICA, and EEG referencing disabled) to look for channels with unusual properties. Here‚Äôs an example of ERP/F plots where the bad channels were not properly marked:

The bad EEG channel is not so obvious, but the bad gradiometer is easy to see.

Remember, marking bad channels should be done as early as possible in the analysis pipeline. When bad channels are marked in a Raw object, the markings will be automatically transferred through the chain of derived object types: including Epochs and Evoked objects, but also noise covariance objects, forward solution computations, inverse operators, etc. If you don‚Äôt notice the badness until later stages of your analysis pipeline, you‚Äôll probably need to go back and re-run the pipeline, so it‚Äôs a good investment of time to carefully explore the data for bad channels early on.

Many analysis computations can be strongly affected by the presence of bad channels. For example, a malfunctioning channel with completely flat signal will have zero channel variance, which will cause noise estimates to be unrealistically low. This low noise estimate will lead to a strong channel weight in the estimate of cortical current, and because the channel is flat, the magnitude of cortical current estimates will shrink dramatically.

Conversely, very noisy channels can also cause problems. For example, they can lead to too many epochs being discarded based on signal amplitude rejection thresholds, which in turn can lead to less robust estimation of the noise covariance across sensors. Noisy channels can also interfere with SSP computations, because the projectors will be spatially biased in the direction of the noisy channel, which can cause adjacent good channels to be suppressed. ICA is corrupted by noisy channels for similar reasons. On the other hand, when performing machine learning analyses, bad channels may have limited, if any impact (i.e., bad channels will be uninformative and therefore ignored / deweighted by the algorithm).

In some cases simply excluding bad channels is sufficient (for example, if you plan only to analyze a specific sensor ROI, and the bad channel is outside that ROI). However, in cross-subject analyses it is often helpful to maintain the same data dimensionality for all subjects, and there is no guarantee that the same channels will be bad for all subjects. It is possible in such cases to remove each channel that is bad for even a single subject, but that can lead to a dramatic drop in data rank (and ends up discarding a fair amount of clean data in the process). In such cases it is desirable to reconstruct bad channels by interpolating its signal based on the signals of the good sensors around them.

Interpolation of EEG channels in MNE-Python is done using the spherical spline method [1], which projects the sensor locations onto a unit sphere and interpolates the signal at the bad sensor locations based on the signals at the good locations. Mathematical details are presented in Bad channel repair via interpolation. Interpolation of MEG channels uses the field mapping algorithms used in computing the forward solution.

Interpolating bad channels in Raw objects is done with the interpolate_bads() method, which automatically applies the correct method (spherical splines or field interpolation) to EEG and MEG channels, respectively (there is a corresponding method mne.Epochs.interpolate_bads() that works for Epochs objects). To illustrate how it works, we‚Äôll start by cropping the raw object to just three seconds for easier plotting:

By default, interpolate_bads() will clear out raw.info['bads'] after interpolation, so that the interpolated channels are no longer excluded from subsequent computations. Here, for illustration purposes, we‚Äôll prevent that by specifying reset_bads=False so that when we plot the data before and after interpolation, the affected channels will still plot in red:

Note that the method pick() default arguments includes exclude=() which ensures that bad channels are not automatically dropped from the selection. Here is the corresponding example with the interpolated gradiometer channel; since there are more channels we‚Äôll use a more transparent gray color this time:

Bad channel exclusion or interpolation is an important step in EEG/MEG preprocessing. MNE-Python provides tools for marking and interpolating bad channels; the list of which channels are marked as ‚Äúbad‚Äù is propagated automatically through later stages of processing. For an even more automated approach to bad channel detection and interpolation, consider using the autoreject package, which interfaces well with MNE-Python-based pipelines.

Fran√ßois M. Perrin, Jacques Pernier, Olivier M. Bertrand, and Jean Franƒáois Echallier. Spherical splines for scalp potential and current density mapping. Electroencephalography and Clinical Neurophysiology, 72(2):184‚Äì187, 1989. doi:10.1016/0013-4694(89)90180-6.

Total running time of the script: (0 minutes 20.321 seconds)

Download Jupyter notebook: 15_handling_bad_channels.ipynb

Download Python source code: 15_handling_bad_channels.py

Download zipped: 15_handling_bad_channels.zip

Gallery generated by Sphinx-Gallery

Overview of artifact detection

Rejecting bad data spans and breaks

---

## Head model and forward computation#

**URL:** https://mne.tools/stable/auto_tutorials/forward/30_forward.html

**Contents:**
- Head model and forward computation#
- Computing the forward operator#
- Compute and visualize BEM surfaces#
- Visualizing the coregistration#
- Compute Source Space#
- Compute forward solution#
- Exercise#

Go to the end to download the full example code.

The aim of this tutorial is to be a getting started for forward computation.

For more extensive details and presentation of the general concepts for forward modeling, see The forward solution.

To compute a forward operator we need:

a -trans.fif file that contains the coregistration info.

The BEM surfaces are the triangulations of the interfaces between different tissues needed for forward computation. These surfaces are for example the inner skull surface, the outer skull surface and the outer skin surface, a.k.a. scalp surface.

Computing the BEM surfaces requires FreeSurfer and makes use of the command-line tools mne watershed_bem or mne flash_bem, or the related functions mne.bem.make_watershed_bem() or mne.bem.make_flash_bem().

Here we‚Äôll assume it‚Äôs already computed. It takes a few minutes per subject.

For EEG we use 3 layers (inner skull, outer skull, and skin) while for MEG 1 layer (inner skull) is enough.

Let‚Äôs look at these surfaces. The function mne.viz.plot_bem() assumes that you have the bem folder of your subject‚Äôs FreeSurfer reconstruction, containing the necessary surface files. Here we use a smaller than default subset of slices for speed.

The coregistration is the operation that allows to position the head and the sensors in a common coordinate system. In the MNE software the transformation to align the head and the sensors in stored in a so-called trans file. It is a FIF file that ends with -trans.fif. It can be obtained with mne.gui.coregistration() (or its convenient command line equivalent mne coreg), or mrilab if you‚Äôre using a Neuromag system.

Here we assume the coregistration is done, so we just visually check the alignment with the following code. See Defining the head‚ÜîMRI trans using the GUI for instructions on creating the -trans.fif file interactively.

The source space defines the position and orientation of the candidate source locations. There are two types of source spaces:

surface-based source space when the candidates are confined to a surface.

volumetric or discrete source space when the candidates are discrete, arbitrarily located source points bounded by the surface.

Surface-based source space is computed using mne.setup_source_space(), while volumetric source space is computed using mne.setup_volume_source_space().

We will now compute a surface-based source space with an 'oct4' resolution. See Setting up the source space for details on source space definition and spacing parameter.

'oct4' is used here just for speed, for real analyses the recommended spacing is 'oct6'.

The surface based source space src contains two parts, one for the left hemisphere (258 locations) and one for the right hemisphere (258 locations). Sources can be visualized on top of the BEM surfaces in purple.

To compute a volume based source space defined with a grid of candidate dipoles inside a sphere of radius 90mm centered at (0.0, 0.0, 40.0) mm you can use the following code. Obviously here, the sphere is not perfect. It is not restricted to the brain and it can miss some parts of the cortex.

To compute a volume based source space defined with a grid of candidate dipoles inside the brain (requires the BEM surfaces) you can use the following.

Some sources may appear to be outside the BEM inner skull contour. This is because the slices are decimated for plotting here. Each slice in the figure actually represents several MRI slices, but only the MRI voxels and BEM boundaries for a single (midpoint of the given slice range) slice are shown, whereas the source space points plotted on that midpoint slice consist of all points for which that slice (out of all slices shown) was the closest.

Now let‚Äôs see how to view all sources in 3D.

We can now compute the forward solution. To reduce computation we‚Äôll just compute a single layer BEM (just inner skull) that can then be used for MEG (not EEG). We specify if we want a one-layer or a three-layer BEM using the conductivity parameter. The BEM solution requires a BEM model which describes the geometry of the head the conductivities of the different tissues.

Note that the BEM does not involve any use of the trans file. The BEM only depends on the head geometry and conductivities. It is therefore independent from the MEG data and the head position.

Let‚Äôs now compute the forward operator, commonly referred to as the gain or leadfield matrix. See mne.make_forward_solution() for details on the meaning of each parameter.

Forward computation can remove vertices that are too close to (or outside) the inner skull surface. For example, here we have gone from 516 to 474 vertices in use. For many functions, such as mne.compute_source_morph(), it is important to pass fwd['src'] or inv['src'] so that this removal is adequately accounted for.

We can explore the content of fwd to access the numpy array that contains the gain matrix.

To extract the numpy array containing the forward operator corresponding to the source space fwd['src'] with cortical orientation constraint we can use the following:

This is equivalent to the following code that explicitly applies the forward operator to a source estimate composed of the identity operator (which we omit here because it uses a lot of memory):

To save to disk a forward solution you can use mne.write_forward_solution() and to read it back from disk mne.read_forward_solution(). Don‚Äôt forget that FIF files containing forward solution should end with -fwd.fif.

To get a fixed-orientation forward solution, use mne.convert_forward_solution() to convert the free-orientation solution to (surface-oriented) fixed orientation.

By looking at Display sensitivity maps for EEG and MEG sensors plot the sensitivity maps for EEG and compare it with the MEG, can you justify the claims that:

MEG is not sensitive to radial sources

EEG is more sensitive to deep sources

How will the MEG sensitivity maps and histograms change if you use a free instead if a fixed/surface oriented orientation?

Try this changing the mode parameter in mne.sensitivity_map() accordingly. Why don‚Äôt we see any dipoles on the gyri?

Total running time of the script: (0 minutes 48.183 seconds)

Download Jupyter notebook: 30_forward.ipynb

Download Python source code: 30_forward.py

Download zipped: 30_forward.zip

Gallery generated by Sphinx-Gallery

Using an automated approach to coregistration

EEG forward operator with a template MRI

---

## How MNE uses FreeSurfer‚Äôs outputs#

**URL:** https://mne.tools/stable/auto_tutorials/forward/50_background_freesurfer_mne.html

**Contents:**
- How MNE uses FreeSurfer‚Äôs outputs#
- MRI coordinate frames#
  - ‚ÄúMRI coordinates‚Äù in MNE-Python: FreeSurfer surface RAS#
- Using FreeSurfer‚Äôs surface reconstructions#
  - Cortical alignment (spherical)#
  - Surface decimation#
  - FreeSurfer‚Äôs MNI affine transformation#
  - Understanding the inflated brain#

Go to the end to download the full example code.

This tutorial explains how MRI coordinate frames are handled in MNE-Python, and how MNE-Python integrates with FreeSurfer for handling MRI data and source space data in general.

As usual we‚Äôll start by importing the necessary packages; for this tutorial that includes nibabel to handle loading the MRI images (MNE-Python also uses nibabel under the hood). We‚Äôll also use a special Matplotlib function for adding outlines to text, so that text is readable on top of an MRI image.

Let‚Äôs start out by looking at the sample subject MRI. Following standard FreeSurfer convention, we look at T1.mgz, which gets created from the original MRI sample/mri/orig/001.mgz when you run the FreeSurfer command recon-all. Here we use nibabel to load the T1 image, and the resulting object‚Äôs orthoview() method to view it.

Notice that the axes in the orthoview() figure are labeled L-R, S-I, and P-A. These reflect the standard RAS (right-anterior-superior) coordinate system that is widely used in MRI imaging. If you are unfamiliar with RAS coordinates, see the excellent nibabel tutorial Coordinate systems and affines.

Nibabel already takes care of some coordinate frame transformations under the hood, so let‚Äôs do it manually so we understand what is happening. First let‚Äôs get our data as a 3D array and note that it‚Äôs already a standard size:

These data are voxel intensity values. Here they are unsigned integers in the range 0-255, though in general they can be floating point values. A value data[i, j, k] at a given index triplet (i, j, k) corresponds to some real-world physical location (x, y, z) in space. To get its physical location, first we have to choose what coordinate frame we‚Äôre going to use.

For example, we could choose a geographical coordinate frame, with origin is at the center of the earth, Z axis through the north pole, X axis through the prime meridian (zero degrees longitude), and Y axis orthogonal to these forming a right-handed coordinate system. This would not be a very useful choice for defining the physical locations of the voxels during the MRI acquisition for analysis, but you could nonetheless figure out the transformation that related the (i, j, k) to this coordinate frame.

Instead, each scanner defines a more practical, native coordinate system that it uses during acquisition, usually related to the physical orientation of the scanner itself and/or the subject within it. During acquisition the relationship between the voxel indices (i, j, k) and the physical location (x, y, z) in the scanner‚Äôs native coordinate frame is saved in the image‚Äôs affine transformation.

mne.transforms.apply_trans effectively does a matrix multiplication (i.e., numpy.dot()), with a little extra work to handle the shape mismatch (the affine has shape (4, 4) because it includes a translation, which is applied separately).

We can use nibabel to examine this transformation, keeping in mind that it processes everything in units of millimeters, unlike MNE where things are always in SI units (meters).

This allows us to take an arbitrary voxel or slice of data and know where it is in the scanner‚Äôs native physical space (x, y, z) (in mm) by applying the affine transformation to the voxel coordinates.

If you have a point (x, y, z) in scanner-native RAS space and you want the corresponding voxel number, you can get it using the inverse of the affine. This involves some rounding, so it‚Äôs possible to end up off by one voxel if you‚Äôre not careful:

Let‚Äôs write a short function to visualize where our voxel lies in an image, and annotate it in RAS space (rounded to the nearest millimeter):

Notice that the axis scales (i, j, and k) are still in voxels (ranging from 0-255); it‚Äôs only the annotation text that we‚Äôve translated into real-world RAS in millimeters.

While nibabel uses scanner RAS (x, y, z) coordinates, FreeSurfer uses a slightly different coordinate frame: MRI surface RAS. The transform from voxels to the FreeSurfer MRI surface RAS coordinate frame is known in the FreeSurfer documentation as Torig, and in nibabel as vox2ras_tkr. This transformation sets the center of its coordinate frame in the middle of the conformed volume dimensions (N / 2.) with the axes oriented along the axes of the volume itself. For more information, see MEG/EEG and MRI coordinate systems.

In general, you should assume that the MRI coordinate system for a given subject is specific to that subject, i.e., it is not the same coordinate MRI coordinate system that is used for any other FreeSurfer subject. Even though during processing FreeSurfer will align each subject‚Äôs MRI to fsaverage to do reconstruction, all data (surfaces, MRIs, etc.) get stored in the coordinate frame specific to that subject. This is why it‚Äôs important for group analyses to transform data to a common coordinate frame for example by surface or volumetric morphing, or even by just applying FreeSurfer‚Äôs MNI affine transformation to points.

Since MNE-Python uses FreeSurfer extensively for surface computations (e.g., white matter, inner/outer skull meshes), internally MNE-Python uses the Freeurfer surface RAS coordinate system (not the nibabel scanner RAS system) for as many computations as possible, such as all source space and BEM mesh vertex definitions.

Whenever you see ‚ÄúMRI coordinates‚Äù or ‚ÄúMRI coords‚Äù in MNE-Python‚Äôs documentation, you should assume that we are talking about the ‚ÄúFreeSurfer MRI surface RAS‚Äù coordinate frame!

We can do similar computations as before to convert the given voxel indices into FreeSurfer MRI coordinates (i.e., what we call ‚ÄúMRI coordinates‚Äù or ‚Äúsurface RAS‚Äù everywhere else in MNE), just like we did above to convert voxel indices to scanner RAS:

Knowing these relationships and being mindful about transformations, we can get from a point in any given space to any other space. Let‚Äôs start out by plotting the Nasion on a sagittal MRI slice:

When we print the nasion, it displays as a DigPoint and shows its coordinates in millimeters, but beware that the underlying data is actually stored in meters, so before transforming and plotting we‚Äôll convert to millimeters:

We can also take the digitization point from the MEG data, which is in the ‚Äúhead‚Äù coordinate frame.

Let‚Äôs look at the nasion in the head coordinate frame:

Head coordinate frame

The head coordinate frame in MNE is the ‚ÄúNeuromag‚Äù head coordinate frame. The origin is given by the intersection between a line connecting the LPA and RPA and the line orthogonal to it that runs through the nasion. It is also in RAS orientation, meaning that +X runs through the RPA, +Y goes through the nasion, and +Z is orthogonal to these pointing upward. See MEG/EEG and MRI coordinate systems for more information.

Notice that in ‚Äúhead‚Äù coordinate frame the nasion has values of 0 for the x and z directions (which makes sense given that the nasion is used to define the y axis in that system). To convert from head coordinate frame to voxels, we first apply the head ‚Üí MRI (surface RAS) transform from a trans file (typically created with the MNE-Python coregistration GUI), then convert meters ‚Üí millimeters, and finally apply the inverse of Torig to get to voxels.

Under the hood, functions like mne.setup_source_space(), mne.setup_volume_source_space(), and mne.compute_source_morph() make extensive use of these coordinate frames.

An important part of what FreeSurfer does is provide cortical surface reconstructions. For example, let‚Äôs load and view the white surface of the brain. This is a 3D mesh defined by a set of vertices (conventionally called rr) with shape (n_vertices, 3) and a set of triangles (tris) with shape (n_tris, 3) defining which vertices in rr form each triangular facet of the mesh.

Let‚Äôs actually plot it:

We can also plot the mesh on top of an MRI slice. The mesh surfaces are defined in millimeters in the MRI (FreeSurfer surface RAS) coordinate frame, so we can convert them to voxels by applying the inverse of the Torig transform:

This is the method used by mne.viz.plot_bem() to show the BEM surfaces.

A critical function provided by FreeSurfer is spherical surface alignment of cortical surfaces, maximizing sulcal-gyral alignment. FreeSurfer first expands the cortical surface to a sphere, then aligns it optimally with fsaverage. Because the vertex ordering is preserved when expanding to a sphere, a given vertex in the source (sample) mesh can be mapped easily to the same location in the destination (fsaverage) mesh, and vice-versa.

Let‚Äôs look a bit more closely at the spherical alignment by overlaying the two spherical meshes as wireframes and zooming way in (the vertices of the black mesh are separated by about 1 mm):

You can see that the fsaverage (black) mesh is uniformly spaced, and the mesh for subject ‚Äúsample‚Äù (in cyan) has been deformed along the spherical surface by FreeSurfer. This deformation is designed to optimize the sulcal-gyral alignment.

These surfaces have a lot of vertices, and in general we only need to use a subset of these vertices for creating source spaces. A uniform sampling can easily be achieved by subsampling in the spherical space. To do this, we use a recursively subdivided icosahedron or octahedron. For example, let‚Äôs load a standard oct-6 source space, and at the same zoom level as before visualize how it subsampled (in red) the dense mesh:

We can also then look at how these two meshes compare by plotting the original, high-density mesh as well as our decimated mesh white surfaces.

Some source space vertices can be removed during forward computation. See Head model and forward computation for more information.

In addition to surface-based approaches, FreeSurfer also provides a simple affine coregistration of each subject‚Äôs data to the fsaverage subject. Let‚Äôs pick a point for sample and plot it on the brain:

We can take this point and transform it to MNI space:

And because fsaverage is special in that it‚Äôs already in MNI space (its MRI-to-MNI transform is identity), it should land in the equivalent anatomical location:

It takes a minute to interpret data displayed on an inflated brain. This visualization is very helpful in showing more of a brain in one image since it is difficult to visualize inside the sulci. Below is a video relating the pial surface to an inflated surface. If you‚Äôre interested in how this was created, here is the gist used to create the video: https://gist.github.com/alexrockhill/b5a1ce6c6ba363cf3f277cd321a763bf.

Total running time of the script: (0 minutes 14.103 seconds)

Download Jupyter notebook: 50_background_freesurfer_mne.ipynb

Download Python source code: 50_background_freesurfer_mne.py

Download zipped: 50_background_freesurfer_mne.zip

Gallery generated by Sphinx-Gallery

EEG forward operator with a template MRI

Fixing BEM and head surfaces

---

## Identify EEG Electrodes Bridged by too much Gel#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/eeg_bridging.html

**Contents:**
- Identify EEG Electrodes Bridged by too much Gel#
- Compute Electrical Distance Metric#
- Examine an Electrical Distance Matrix#
- Examine the Distribution of Electrical Distances#
- Plot Electrical Distances on a Topomap#
- Plot the Raw Voltage Time Series for Bridged Electrodes#
- Compare Bridging Across Subjects in the EEGBCI Dataset#
- The Relationship Between Bridging and Impedances#
- Summary#
- References#

Go to the end to download the full example code.

Research-grade EEG often uses a gel based system, and when too much gel is applied the gel conducting signal from the scalp to the electrode for one electrode connects with the gel conducting signal from another electrode ‚Äúbridging‚Äù the two signals. This is undesirable because the signals from the two (or more) electrodes are not as independent as they would otherwise be; they are very similar to each other introducing additional spatial smearing. An algorithm has been developed to detect electrode bridging [1], which has been implemented in EEGLAB [2]. Unfortunately, there is not a lot to be done about electrode brigding once the data has been collected as far as preprocessing other than interpolating bridged channels. Therefore, our recommendation is to check for electrode bridging early in data collection and address the problem. Or, if the data has already been collected, quantify the extent of the bridging so as not to introduce bias into the data from this effect and exclude subjects with bridging that might effect the outcome of a study. Preventing electrode bridging is ideal but awareness of the problem at least will mitigate its potential as a confound to a study. This tutorial follows the eBridge tutorial from https://psychophysiology.cpmc.columbia.edu.

First, let‚Äôs compute electrical distance metrics for a group of example subjects from the EEGBCI dataset in order to estimate electrode bridging. The electrical distance is just the variance of signals subtracted pairwise. Channels with activity that mirror another channel nearly exactly will have very low electrical distance. By inspecting the distribution of electrical distances, we can look for pairwise distances that are consistently near zero which are indicative of bridging.

It is likely to be sufficient to run this algorithm on a small portion (~3 minutes is probably plenty) of the data but that gel might settle over the course of a study causing more bridging so using the last segment of the data will give the most conservative estimate.

Before we look at the electrical distance distributions across subjects, let‚Äôs look at the distance matrix for one subject and try and understand how the algorithm works. We‚Äôll use subject 6 as it is a good example of bridging. In the zoomed out color scale version on the right, we can see that there is a distribution of electrical distances that are specific to that subject‚Äôs head physiology/geometry and brain activity during the recording. On the right, when we clip the color range to zoom in, we can see several electrical distance outliers that are near zero; these indicate bridging.

Now let‚Äôs plot a histogram of the electrical distance matrix. Note that the electrical distance matrix from the previous plot is upper triangular but does not include the diagonal. This means that the pairwise electrical distances are not computed between the same channel (which makes sense as the differences between a channel and itself would just be zero). The initial peak near zero therefore represents pairs of different channels that are nearly identical which is indicative of bridging. EEG recordings without bridged electrodes do not have a peak near zero.

Now, let‚Äôs look at the topography of the electrical distance matrix and see where our bridged channels are and check that their spatial arrangement makes sense. Here, we are looking at the minimum electrical distance for each channel and taking the median across all epochs (the raw data is epoched into 2 second non-overlapping intervals). This example is of the subject from the EEGBCI dataset with the most bridged channels so there are many light areas and red lines. They are generally grouped together and are biased toward horizontal connections (this may be because the EEG experimenter usually stands to the side and may have inserted the gel syringe tip in too far).

Finally, let‚Äôs do a sanity check and make sure that the bridged electrodes are indeed implausibly similar. We‚Äôll plot two bridged electrode pairs: F2-F4 and FC2-FC4, for subject 6 where they are bridged and subject 1 where they are not. As we can see, the pairs are nearly identical for subject 6 confirming that they are likely bridged. Interestingly, even though the two pairs are adjacent to each other, there are two distinctive pairs, meaning that it is unlikely that all four of these electrodes are bridged.

Now, let‚Äôs look at the histograms of electrical distances for the whole EEGBCI dataset. As we can see in the zoomed in insert on the right, for subjects 6, 7 and 8 (and to a lesser extent 2 and 4), there is a different shape of the distribution of electrical distances around 0 \({\mu}V^2\) than for the other subjects. These subjects‚Äô distributions have a peak around 0 \({\mu}V^2\) distance and a trough around 5 \({\mu}V^2\) which is indicative of electrode bridging. The rest of the subjects‚Äô distributions increase monotonically, indicating normal spatial separation of sources. The large discrepancy in shapes of distributions is likely driven primarily by artifacts such as blinks which are an order of magnitude larger than neural data since this data has not been preprocessed but likely reflect neural or at least anatomical differences as well (i.e. the distance from the sensors to the brain).

For the group of subjects, let‚Äôs look at their electrical distances and bridging. Especially since this is the same task, the lack of low electrical distances in many of the subjects is compelling evidence that the low electrical distance is caused by bridging and that it is avoidable given more judicious application of gel or other conductive electrolyte solution.

For subjects with many bridged channels like Subject 6 shown in the example above, it is advisable to exclude the subject. This because EEG recording montage will not be comparable with the other subjects. And, if we tried to interpole, the interpolation would depend on other channels which are also bridged in that case. However, for subjects with only a few bridged channels, those channels can be interpolated. Since the bridged data is still biological (i.e. it is recording the subject‚Äôs brain), it‚Äôs just spatially smeared, we can use mne.preprocessing.interpolate_bridged_electrodes() to make a virtual channel midway between the two bridged channels to aid in interpolation.

Let‚Äôs make sure that our virtual channel aided the interpolation. We can do this by simulating a bridge to make sure that we recover the original data better with the virtual channel method. If we make two channels nearly the same to simulate a bridged electrode but save the original data, we can compare the two interpolation methods. As we can see, the virtual channel recovers the original data more slightly closely. However, as shown in the plots, there is still residual signal for both methods implying that it is there is still a loss of data compared to unbridged channels.

Electrode bridging is often brought about by inserting more gel in order to bring impendances down. Thus it can be helpful to compare bridging to impedances in the quest to be an ideal EEG technician! Low impedances lead to less noisy data and EEG without bridging is more spatially precise. Brain Imaging Data Structure (BIDS) recommends that impedances be stored in an EEG dataset in the electrodes.tsv file. Since the impedances are not stored for this dataset, we will fake them to demonstrate how they would be plotted. Here, the impedances are plotted as is typical at the end of a setup; most channels are good but there are a few that need to have their impedance lowered. The impedances should ideally all be less than 25 KOhm before starting an experiment when using active systems and less than 5 KOhm when using a passive system.

In this example, we have shown a dataset where electrical bridging occurred during the EEG setup for several subjects. Hopefully this is convincing as to the importance of proper technique as well as checking your work to learn and improve as an EEG experimenter, and hopefully this tool will help us all collect better EEG data in the future.

C. E. Tenke and J. Kayser. A convenient method for detecting electrolyte bridges in multichannel electroencephalogram and event-related potential recordings. Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology, 112(3):545‚Äì550, March 2001. doi:10.1016/s1388-2457(00)00553-8.

Arnaud Delorme and Scott Makeig. EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. Journal of Neuroscience Methods, 134(1):9‚Äì21, March 2004. doi:10.1016/j.jneumeth.2003.10.009.

Total running time of the script: (0 minutes 55.961 seconds)

Download Jupyter notebook: eeg_bridging.ipynb

Download Python source code: eeg_bridging.py

Download zipped: eeg_bridging.zip

Gallery generated by Sphinx-Gallery

Define target events based on time lag, plot evoked response

Transform EEG data using current source density (CSD)

---

## Importing data from EEG devices#

**URL:** https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html

**Contents:**
- Importing data from EEG devices#
- BrainVision (.vhdr, .vmrk, .eeg)#
- European data format (.edf)#
- BioSemi data format (.bdf)#
- General data format (.gdf)#
- Neuroscan CNT (.cnt)#
- ANT Neuro CNT (.cnt)#
- EGI simple binary (.egi)#
- EGI MFF (.mff)#
- EEGLAB files (.set, .fdt)#

Go to the end to download the full example code.

MNE includes various functions and utilities for reading EEG data and electrode locations.

The BrainVision file format consists of three separate files:

A text header file (.vhdr) containing meta data.

A text marker file (.vmrk) containing information about events in the data.

A binary data file (.eeg) containing the voltage values of the EEG.

Both text files are based on the INI format consisting of

sections marked as [square brackets],

comments marked as ; comment,

and key-value pairs marked as key=value.

Brain Products provides documentation for their core BrainVision file format. The format specification is hosted on the Brain Products website.

BrainVision EEG files can be read using mne.io.read_raw_brainvision(), passing the .vhdr header file as the argument.

Renaming BrainVision files can be problematic due to their multi-file structure. See this example for instructions.

For writing BrainVision files, take a look at the mne.export module, which used the pybv Python package.

EDF and EDF+ files can be read using mne.io.read_raw_edf(). Both variants are 16-bit formats.

EDF+ files may contain annotation channels which can be used to store trigger and event information. These annotations are available in raw.annotations.

Writing EDF files is not supported natively yet. This gist or MNELAB (both of which use pyedflib under the hood) can be used to export any mne.io.Raw object to EDF/EDF+/BDF/BDF+.

The BDF format is a 24-bit variant of the EDF format used by EEG systems manufactured by BioSemi. It can be imported with mne.io.read_raw_bdf().

BioSemi amplifiers do not perform ‚Äúcommon mode noise rejection‚Äù automatically. The signals in the EEG file are the voltages between each electrode and the CMS active electrode, which still contain some CM noise (50 Hz, ADC reference noise, etc.). The BioSemi FAQ provides more details on this topic. Therefore, it is advisable to choose a reference (e.g., a single channel like Cz, average of linked mastoids, average of all electrodes, etc.) after importing BioSemi data to avoid losing signal information. The data can be re-referenced later after cleaning if desired.

Data samples in a BDF file are represented in a 3-byte (24-bit) format. Since 3-byte raw data buffers are not presently supported in the FIF format, these data will be changed to 4-byte integers in the conversion.

GDF files can be read using mne.io.read_raw_gdf().

GDF (General Data Format) is a flexible format for biomedical signals that overcomes some of the limitations of the EDF format. The original specification (GDF v1) includes a binary header and uses an event table. An updated specification (GDF v2) was released in 2011 and adds fields for additional subject-specific information (gender, age, etc.) and allows storing several physical units and other properties. Both specifications are supported by MNE.

CNT files can be read using mne.io.read_raw_cnt(). Channel locations can be read from a montage or the file header. If read from the header, the data channels (channels that are not assigned to EOG, ECG, EMG or MISC) are fit to a sphere and assigned a z-value accordingly. If a non-data channel does not fit to the sphere, it is assigned a z-value of 0.

Reading channel locations from the file header may be dangerous, as the x_coord and y_coord in the ELECTLOC section of the header do not necessarily translate to absolute locations. Furthermore, EEG electrode locations that do not fit to a sphere will distort the layout when computing the z-values. If you are not sure about the channel locations in the header, using a montage is encouraged.

ANT Neuro also uses a file format with the .cnt extension, but it is different from the Neuroscan CNT format. The ANT Neuro format is supported by the function mne.io.read_raw_ant().

CNT files from the eego software of ANT Neuro can be read using mne.io.read_raw_ant(). The channels can be automatically recognized as auxiliary 'misc' channels if the regular expression in the argument misc correctly captures the channel names. Same for EOG channels with the regular expression in the argument eog. Note that if a montage with specific bipolar channels is applied on export, they can be loaded as EEG bipolar channel pairs by providing the argument bipolars. All other EEG channels will be loaded as regular EEG channels referenced to the same electrode.

Neuroscan also uses a file format with the .cnt extension, but it is different from the eego CNT format. The Neuroscan CNT format is supported by the function mne.io.read_raw_cnt().

EGI simple binary files can be read using mne.io.read_raw_egi(). EGI raw files are simple binary files with a header and can be exported by the EGI Netstation acquisition software.

EGI MFF files can be read with mne.io.read_raw_egi().

EEGLAB .set files (which sometimes come with a separate .fdt file) can be read using mne.io.read_raw_eeglab() and mne.read_epochs_eeglab().

These files can be read with mne.io.read_raw_nicolet().

EEG data from the Nexstim eXimia system can be read with mne.io.read_raw_eximia().

EEG data from the Persyst system can be read with mne.io.read_raw_persyst().

Note that subject metadata may not be properly imported because Persyst sometimes changes its specification from version to version. Please let us know if you encounter a problem.

EEG data from the Nihon Kohden (NK) system can be read using the mne.io.read_raw_nihon() function.

Files with the following extensions will be read:

The .eeg file contains the actual raw EEG data.

The .pnt file contains metadata related to the recording such as the measurement date.

The .log file contains annotations for the recording.

The .21e file contains channel and electrode information.

Reading .11d, .cmt, .cn2, and .edf files is currently not supported.

Note that not all subject metadata may be properly read because NK changes the specification sometimes from version to version. Please let us know if you encounter a problem.

MNE-Python does not support loading XDF files out of the box, because the inherent flexibility of the XDF format makes it difficult to provide a one-size-fits-all function. For example, XDF supports signals from various modalities recorded with different sampling rates. However, it is relatively straightforward to import only a specific stream (such as EEG signals) using the pyxdf package. See Reading XDF EEG data for a simple example.

A more sophisticated version, which supports selection of specific streams as well as converting marker streams into annotations, is available in MNELAB. If you want to use this functionality in a script, MNELAB records its history (View - History), which contains all commands required to load an XDF file after successfully loading that file with the graphical user interface.

The preferred method for applying an EEG reference in MNE is mne.set_eeg_reference(), or equivalent instance methods like raw.set_eeg_reference(). By default, the data are assumed to already be properly referenced. See Setting the EEG reference for more information.

Some EEG formats (e.g., EGI, EDF/EDF+, BDF) contain neither electrode locations nor head shape digitization information. Therefore, this information has to be provided separately. For that purpose, all raw instances have a mne.io.Raw.set_montage() method to set electrode locations.

When using locations of fiducial points, the digitization data are converted to the MEG head coordinate system employed in the MNE software, see MEG/EEG and MRI coordinate systems.

Download Jupyter notebook: 20_reading_eeg_data.ipynb

Download Python source code: 20_reading_eeg_data.py

Download zipped: 20_reading_eeg_data.zip

Gallery generated by Sphinx-Gallery

Importing data from MEG devices

Importing data from fNIRS devices

---

## Importing Data from Eyetracking devices#

**URL:** https://mne.tools/stable/auto_tutorials/io/70_reading_eyetracking_data.html

**Contents:**
- Importing Data from Eyetracking devices#
- SR Research (Eyelink) (.asc)#
  - Eye Position Data#
    - Gaze#
    - Visualizing the data#
    - Head-Referenced Eye Angle (HREF)#
    - Pupil Position#
  - Pupil Size Data#
  - Velocity, resolution, and head position data#

Go to the end to download the full example code.

Eyetracking devices record a persons point of gaze, usually in relation to a screen. Typically, gaze position (also referred to as eye or pupil position) and pupil size are recorded as separate channels. This section describes how to read data from supported eyetracking manufacturers.

MNE-Python provides functions for reading eyetracking data. When possible, MNE-Python will internally convert and store eyetracking data according to an SI unit (for example radians for position data, and meters for pupil size).

If you have eye tracking data in a format that MNE does not support yet, you can try reading it using other tools and create an MNE object from a numpy array. Then you can use mne.preprocessing.eyetracking.set_channel_types_eyetrack() to assign the correct eyetrack channel types.

Some MNE functions may not be available to eyetracking and other physiological data, because MNE does not consider them to be data channels. See the Glossary of Common Terms and API Elements for more information.

MNE-Python currently only supports reading Eyelink eyetracking data stored in the ASCII (.asc) format.

Eyelink recordings are stored in the Eyelink Data Format (EDF; .edf), which are binary files and thus relatively complex to support. To make the data in EDF files accessible, Eyelink provides the application EDF2ASC, which converts EDF files to a plain text ASCII format (.asc). These files can be imported into MNE using mne.io.read_raw_eyelink().

The Eyelink Data Format (EDF), should not be confused with the European Data Format, the common EEG data format that also uses the .edf extension.

Supported measurement types from Eyelink files include eye position, pupil size, saccadic velocity, resolution, and head position (for recordings collected in remote mode). Eyelink files often report ocular events (blinks, saccades, and fixations), MNE will store these events as mne.Annotations. Blink annotation descriptions will be 'BAD_blink'. For more information on the various measurement types that can be present in Eyelink files. read below.

Eyelink samples can report eye position data in pixels, units of visual degrees, or as raw pupil coordinates. Samples are written as (x, y) coordinate pairs (or two pairs for binocular data). The type of position data present in an ASCII file will be detected automatically by MNE. The three types of position data are explained below.

Gaze position data report the estimated (x, y) pixel coordinates of the participants‚Äôs gaze on the stimulus screen, compensating for head position changes and distance from the screen. This datatype may be preferable if you are interested in knowing where the participant was looking at on the stimulus screen. The default (0, 0) location for Eyelink systems is at the top left of the screen.

This may be best demonstrated with an example. In the file plotted below, eyetracking data was recorded while the participant read text on a display. In this file, as the participant read the each line from left to right, the x-coordinate increased. When the participant moved their gaze down to read a new line, the y-coordinate increased, which is why the ypos_right channel in the plot below increases over time (for example, at about 4-seconds, and at about 8-seconds).

Working with eye tracker data in MNE-Python

Note that we passed a custom dict to the 'scalings' argument of mne.io.Raw.plot. This is because MNE expects the data to be in SI units (radians for eyegaze data, and meters for pupil size data), but we did not convert the pupil size data in this example.

HREF position data measures eye rotation angles relative to the head. It does not take into account changes in subject head position and angle, or distance from the stimulus screen. This datatype might be preferable for analyses that are interested in eye movement velocities and amplitudes, or for simultaneous and EEG/MEG eyetracking recordings where eye position data are used to identify EOG artifacts.

HREF coordinates are stored in the ASCII file as integer values, with 260 or more units per visual degree, however MNE will convert and store these coordinates in radians. The (0, 0) point of HREF data is arbitrary, as the relationship between the screen position and the coordinates changes as the subject‚Äôs head moves.

Below is the same text reading recording that we plotted above, except a new ASCII file was generated, this time using HREF eye position data.

Pupil position data contains (x, y) coordinate pairs from the eye camera. It has not been converted to pixels (gaze) or eye angles (HREF). Most use cases do not require this data type, and caution should be taken when analyzing raw pupil positions. Note that when plotting data from a Raw object containing raw pupil position data, the plot scalings will likely be incorrect. You can pass custom scalings into the scalings parameter of mne.io.Raw.plot so that the signals are legible when plotting.

If a calibration was not performed prior to data collection, the EyeLink system cannot convert raw pupil position data to pixels (gaze) or eye angle (HREF).

Pupil size is measured by the EyeLink system at up to 500 samples per second. It may be reported as pupil area, or pupil diameter (i.e. the diameter of a circle/ellipse model fit to the pupil area). Which of these datatypes you get is specified by your recording- and/or your EDF2ASC settings. The pupil size data is not calibrated and reported in arbitrary units. Typical pupil area data range between 800 to 2000 units, with a precision of 1 unit, while pupil diameter data range between 1800-3000 units.

Eyelink files can produce data on saccadic velocity, resolution, and head position for each sample in the file. MNE will read in these data if they are present in the file, but will label their channel types as 'misc'.

Eyelink‚Äôs EDF2ASC API allows for modification of the data and format that is converted to ASCII. However, MNE-Python assumes a specific structure, which the default parameters of EDF2ASC follow. ASCII files should be tab-deliminted, and both Samples and Events should be output. If the data were recorded at 2000Hz, timestamps should be floating point numbers. Manual modification of ASCII conversion via EDF2ASC is not recommended.

Total running time of the script: (0 minutes 4.855 seconds)

Download Jupyter notebook: 70_reading_eyetracking_data.ipynb

Download Python source code: 70_reading_eyetracking_data.py

Download zipped: 70_reading_eyetracking_data.zip

Gallery generated by Sphinx-Gallery

Working with CTF data: the Brainstorm auditory dataset

Working with continuous data

---

## Importing data from fNIRS devices#

**URL:** https://mne.tools/stable/auto_tutorials/io/30_reading_fnirs_data.html

**Contents:**
- Importing data from fNIRS devices#
- Standardized data#
  - SNIRF (.snirf)#
    - Specifying the coordinate system#
- Continuous Wave Devices#
  - NIRx (directory or hdr)#
  - Hitachi (.csv)#
- Frequency Domain Devices#
  - BOXY (.txt)#
- Custom Data Import#

Go to the end to download the full example code.

fNIRS devices consist of two kinds of optodes: light sources (AKA ‚Äúemitters‚Äù or ‚Äútransmitters‚Äù) and light detectors (AKA ‚Äúreceivers‚Äù). Channels are defined as source-detector pairs, and channel locations are defined as the midpoint between source and detector.

MNE-Python provides functions for reading fNIRS data and optode locations from several file formats. Regardless of the device manufacturer or file format, MNE-Python‚Äôs fNIRS functions will internally store the measurement data and its metadata in the same way (e.g., data values are always converted into SI units). Supported measurement types include amplitude, optical density, oxyhaemoglobin concentration, and deoxyhemoglobin concentration (for continuous wave fNIRS), and additionally AC amplitude and phase (for frequency domain fNIRS).

MNE-Python stores metadata internally with a specific structure, and internal functions expect specific naming conventions. Manual modification of channel names and metadata is not recommended.

The Shared Near Infrared Spectroscopy Format (SNIRF) is designed by the fNIRS community in an effort to facilitate sharing and analysis of fNIRS data. And is the official format of the Society for functional near-infrared spectroscopy (SfNIRS). The manufacturers Gowerlabs, NIRx, Kernel, Artinis, and Cortivision export data in the SNIRF format, and these files can be imported in to MNE. SNIRF is the preferred format for reading data in to MNE-Python. Data stored in the SNIRF format can be read in using mne.io.read_raw_snirf().

The SNIRF format has provisions for many different types of fNIRS recordings. MNE-Python currently only supports reading continuous wave or haemoglobin data stored in the .snirf format.

There are a variety of coordinate systems used to specify the location of sensors (see Source alignment and coordinate frames for details). Where possible the coordinate system will be determined automatically when reading a SNIRF file. However, sometimes this is not possible and you must manually specify the coordinate frame the optodes are in. This is done using the optode_frame argument when loading data.

The coordinate system is automatically detected for Gowerlabs SNIRF files.

NIRx produce continuous wave fNIRS devices. NIRx recordings can be read in using mne.io.read_raw_nirx(). The NIRx device stores data directly to a directory with multiple file types, MNE-Python extracts the appropriate information from each file. MNE-Python only supports NIRx files recorded with NIRStar version 15.0 and above and Aurora version 2021 and above. MNE-Python supports reading data from NIRScout and NIRSport devices.

Hitachi produce continuous wave fNIRS devices. Hitachi fNIRS recordings can be read using mne.io.read_raw_hitachi(). No optode information is stored so you‚Äôll need to set the montage manually, see the Notes section of mne.io.read_raw_hitachi().

BOXY recordings can be read in using mne.io.read_raw_boxy(). The BOXY software and ISS Imagent I and II devices are frequency domain systems that store data in a single .txt file containing what they call (with MNE-Python‚Äôs name for that type of data in parens):

All light collected by the detector (fnirs_cw_amplitude)

High-frequency modulated light intensity (fnirs_fd_ac_amplitude)

Phase of the modulated light (fnirs_fd_phase)

DC data is stored as the type fnirs_cw_amplitude because it collects both the modulated and any unmodulated light, and hence is analogous to what is collected by continuous wave systems such as NIRx. This helps with conformance to SNIRF standard types.

These raw data files can be saved by the acquisition devices as parsed or unparsed .txt files, which affects how the data in the file is organised. MNE-Python will read either file type and extract the raw DC, AC, and Phase data. If triggers are sent using the digaux port of the recording hardware, MNE-Python will also read the digaux data and create annotations for any triggers.

This method is not supported and users are discouraged to use it. You should convert your data to the SNIRF format using the tools provided by the Society for functional Near-Infrared Spectroscopy, and then load it using mne.io.read_raw_snirf().

fNIRS measurements may be stored in a non-standardised format that is not supported by MNE-Python and cannot be converted easily into SNIRF. This legacy data is often in CSV or TSV format, we show here a way to load it even though it is not officially supported by MNE-Python due to the lack of standardisation of the file format (the naming and ordering of channels, the type and scaling of data, and specification of sensor positions varies between each vendor). You will likely have to adapt this depending on the system from which your CSV originated.

First, we generate an example CSV file which will then be loaded in to MNE-Python. This step would be skipped if you have actual data you wish to load. We simulate 16 channels with 100 samples of data and save this to a file called fnirs.csv.

Next, we will load the example CSV file.

Then, the metadata must be specified manually as the CSV file does not contain information about channel names, types, sample rate etc.

In MNE-Python the naming of channels MUST follow the structure S#_D# type where # is replaced by the appropriate source and detector numbers and type is either hbo, hbr or the wavelength.

Finally, the data can be converted in to an MNE-Python data structure. The metadata above is used to create an mne.Info data structure, and this is combined with the data to create an MNE-Python Raw object. For more details on the info structure see The Info data structure, and for additional details on how continuous data is stored in MNE-Python see The Raw data structure: continuous data. For a more extensive description of how to create MNE-Python data structures from raw array data see Creating MNE-Python data structures from scratch.

Having information about optode locations may assist in your analysis. Beyond the general benefits this provides (e.g. creating regions of interest, etc), this is may be particularly important for fNIRS as information about the optode locations is required to convert the optical density data in to an estimate of the haemoglobin concentrations. MNE-Python provides methods to load standard sensor configurations (montages) from some vendors, and this is demonstrated below. Some handy tutorials for understanding sensor locations, coordinate systems, and how to store and view this information in MNE-Python are: Working with sensor locations, Source alignment and coordinate frames, and Plotting EEG sensors on the scalp.

Below is an example of how to load the optode positions for an Artinis OctaMon device.

It is also possible to create a custom montage from a file for fNIRS with mne.channels.read_custom_montage() by setting coord_frame to 'mri'.

To validate the positions were loaded correctly it is also possible to view the location of the sources (red), detectors (black), and channels (white lines and orange dots) in a 3D representation. The ficiduals are marked in blue, green and red. See Source alignment and coordinate frames for more details.

Total running time of the script: (0 minutes 6.812 seconds)

Download Jupyter notebook: 30_reading_fnirs_data.ipynb

Download Python source code: 30_reading_fnirs_data.py

Download zipped: 30_reading_fnirs_data.zip

Gallery generated by Sphinx-Gallery

Importing data from EEG devices

Working with CTF data: the Brainstorm auditory dataset

---

## Importing data from MEG devices#

**URL:** https://mne.tools/stable/auto_tutorials/io/10_reading_meg_data.html

**Contents:**
- Importing data from MEG devices#
- MEGIN/Elekta Neuromag VectorView and TRIUX (.fif)#
- FIL OPM (.bin)#
- Artemis123 (.bin)#
- 4-D Neuroimaging / BTI data (dir)#
- CTF data (dir)#
  - CTF Polhemus data#
  - Applying software gradient compensation#
- Ricoh/KIT MEG system data (.con/.sqd)#
- FieldTrip MEG/EEG data (.mat)#

Go to the end to download the full example code.

This section describes how to read data for various MEG manufacturers.

Neuromag Raw FIF files can be loaded using mne.io.read_raw_fif().

If the data were recorded with MaxShield on and have not been processed with MaxFilter, they may need to be loaded with mne.io.read_raw_fif(..., allow_maxshield=True).

MEG data from the OPM system used by the FIL at UCL can be read with mne.io.read_raw_fil(). For related OPM processing methods, see Preprocessing optically pumped magnetometer (OPM) MEG data.

MEG data from the Artemis123 system can be read with mne.io.read_raw_artemis123().

MNE-Python provides mne.io.read_raw_bti() to read and convert 4D / BTI data. This reader function will by default replace the original channel names, typically composed of the letter A and the channel number with Neuromag. To import the data, the following input files are mandatory:

A data file (typically c,rfDC) containing the recorded MEG time series.

A hs_file containing the digitizer data.

A config file containing acquisition information and metadata.

By default mne.io.read_raw_bti() assumes that these three files are located in the same folder.

While reading the reference or compensation channels, the compensation weights are currently not processed. As a result, the mne.io.Raw object and the corresponding fif file does not include information about the compensation channels and the weights to be applied to realize software gradient compensation. If the data are saved in the Magnes system are already compensated, there will be a small error in the forward calculations, whose significance has not been evaluated carefully at this time.

The function mne.io.read_raw_ctf() can be used to read CTF data.

The function mne.channels.read_dig_polhemus_isotrak() can be used to read Polhemus data.

Since the software gradient compensation employed in CTF systems is a reversible operation, it is possible to change the compensation status of CTF data in the data files as desired. This section contains information about the technical details of the compensation procedure and a description of mne.io.Raw.apply_gradient_compensation().

The raw instances returned by mne.io.read_raw_ctf() contain several compensation matrices which are employed to suppress external disturbances with help of the reference channel data. The reference sensors are located further away from the brain than the helmet sensors and are thus measuring mainly the external disturbances rather than magnetic fields originating in the brain. Most often, a compensation matrix corresponding to a scheme nicknamed Third-order gradient compensation is employed.

Let us assume that the data contain \(n_1\) MEG sensor channels, \(n_2\) reference sensor channels, and \(n_3\) other channels. The data from all channels can be concatenated into a single vector

where \(x_1\), \(x_2\), and \(x_3\) are the data vectors corresponding to the MEG sensor channels, reference sensor channels, and other channels, respectively. The data before and after compensation, denoted here by \(x_{(0)}\) and \(x_{(k)}\), respectively, are related by

where the composite compensation matrix is

In the above, \(C_{(k)}\) is a \(n_1\) by \(n_2\) compensation data matrix corresponding to compensation ‚Äúgrade‚Äù \(k\). It is easy to see that

To convert from compensation grade \(k\) to \(p\) one can simply multiply the inverse of one compensate compensation matrix by another and apply the product to the data:

This operation is performed by mne.io.Raw.apply_gradient_compensation().

MNE-Python includes the mne.io.read_raw_kit() and mne.read_epochs_kit() to read and convert Ricoh/KIT MEG data.

In MNE 0.21 This reader function will by default replace the original channel names, which typically with index starting with zero, with ones with an index starting with one. In 0.22 it will use native names when possible. Use the standardize_names argument to control this behavior.

To import continuous data, only the input .sqd or .con file is needed. For epochs, an Nx3 matrix containing the event number/corresponding trigger value in the third column is needed.

The following input files are optional:

A KIT marker file (mrk file) or an array-like containing the locations of the HPI coils in the MEG device coordinate system. These data are used together with the elp file to establish the coordinate transformation between the head and device coordinate systems.

A Polhemus points file (elp file) or an array-like containing the locations of the fiducials and the head-position indicator (HPI) coils. These data are usually given in the Polhemus head coordinate system.

A Polhemus head shape data file (hsp file) or an array-like containing locations of additional points from the head surface. These points must be given in the same coordinate system as that used for the elp file.

Modern Ricoh systems may encode this information it the file itself, in which case mrk, elp, and hsp can all be None and the data will be read from the file itself.

The output fif file will use the Neuromag head coordinate system convention, see MEG/EEG and MRI coordinate systems. A coordinate transformation between the Polhemus head coordinates and the Neuromag head coordinates is included.

By default, KIT-157 systems assume the first 157 channels are the MEG channels, the next 3 channels are the reference compensation channels, and channels 160 onwards are designated as miscellaneous input channels (MISC 001, MISC 002, etc.). By default, KIT-208 systems assume the first 208 channels are the MEG channels, the next 16 channels are the reference compensation channels, and channels 224 onwards are designated as miscellaneous input channels (MISC 001, MISC 002, etc.).

In addition, it is possible to synthesize the digital trigger channel (STI 014) from available analog trigger channel data by specifying the following parameters:

A list of trigger channels (stim) or default triggers with order: ‚Äò<‚Äô | ‚Äò>‚Äô Channel-value correspondence when converting KIT trigger channels to a Neuromag-style stim channel. By default, we assume the first eight miscellaneous channels are trigger channels. For ‚Äò<‚Äô, the largest values are assigned to the first channel (little endian; default). For ‚Äò>‚Äô, the largest values are assigned to the last channel (big endian). Can also be specified as a list of trigger channel indexes.

The trigger channel slope (slope) : ‚Äò+‚Äô | ‚Äò-‚Äô How to interpret values on KIT trigger channels when synthesizing a Neuromag-style stim channel. With ‚Äò+‚Äô, a positive slope (low-to-high) is interpreted as an event. With ‚Äò-‚Äô, a negative slope (high-to-low) is interpreted as an event.

A stimulus threshold (stimthresh) : float The threshold level for accepting voltage changes in KIT trigger channels as a trigger event.

The synthesized trigger channel data value at sample \(k\) will be:

where \(t_p(k)\) are the thresholded from the input channel data d_p(k):

The threshold value \(t\) can be adjusted with the stimthresh parameter.

MNE-Python includes mne.io.read_raw_fieldtrip(), mne.read_epochs_fieldtrip() and mne.read_evoked_fieldtrip() to read data coming from FieldTrip.

The data is imported directly from a .mat file.

The info parameter can be explicitly set to None. The import functions will still work but:

All channel locations will be in head coordinates.

Channel orientations cannot be guaranteed to be accurate.

All channel types will be set to generic types.

This is probably fine for anything that does not need that information, but if you intent to do things like interpolation of missing channels, source analysis or look at the RMS pairs of planar gradiometers, you most likely run into problems.

It is highly recommended to provide the info parameter as well. The info dictionary can be extracted by loading the original raw data file with the corresponding MNE-Python functions:

The imported data can have less channels than the original data. Only the information for the present ones is extracted from the info dictionary.

As of version 0.17, importing FieldTrip data has been tested on a variety of systems with the following results:

Data imported as microvolts. Otherwise fine.

Data imported as microvolts. Otherwise fine.

Data imported as microvolts. Otherwise fine.

Mostly Ok. Data imported as microvolts. FieldTrip does not apply calibration.

Mostly Ok. Data imported as microvolts. FieldTrip does not apply calibration.

Mostly Ok. Data imported as microvolts. FieldTrip does not apply calibration.

Does not work. Channel names are different in MNE-Python and FieldTrip.

Does not work. Channel names are different in MNE-Python and FieldTrip.

Does not work. Channel names are different in MNE-Python and FieldTrip.

Arbitrary (e.g., simulated or manually read in) raw data can be constructed from memory by making use of mne.io.RawArray, mne.EpochsArray or mne.EvokedArray in combination with mne.create_info().

This functionality is illustrated in Creating MNE-Python data structures from scratch. Using 3rd party libraries such as NEO in combination with these functions abundant electrophysiological file formats can be easily loaded into MNE.

Download Jupyter notebook: 10_reading_meg_data.ipynb

Download Python source code: 10_reading_meg_data.py

Download zipped: 10_reading_meg_data.zip

Gallery generated by Sphinx-Gallery

Reading data for different recording systems

Importing data from EEG devices

---

## Interpolate bad channels for MEG/EEG channels#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/interpolate_bad_channels.html

**Contents:**
- Interpolate bad channels for MEG/EEG channels#
- References#

Go to the end to download the full example code.

This example shows how to interpolate bad MEG/EEG channels

Using spherical splines from [1] for EEG data.

Using field interpolation for MEG and EEG data.

In this example, the bad channels will still be marked as bad. Only the data in those channels is replaced.

Compute interpolation (also works with Raw and Epochs objects)

You can also use minimum-norm for EEG as well as MEG

Fran√ßois M. Perrin, Jacques Pernier, Olivier M. Bertrand, and Jean Franƒáois Echallier. Spherical splines for scalp potential and current density mapping. Electroencephalography and Clinical Neurophysiology, 72(2):184‚Äì187, 1989. doi:10.1016/0013-4694(89)90180-6.

Total running time of the script: (0 minutes 12.664 seconds)

Download Jupyter notebook: interpolate_bad_channels.ipynb

Download Python source code: interpolate_bad_channels.py

Download zipped: interpolate_bad_channels.zip

Gallery generated by Sphinx-Gallery

Compare the different ICA algorithms in MNE

Interpolate EEG data to any montage

---

## Interpolate EEG data to any montage#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/interpolate_to.html

**Contents:**
- Interpolate EEG data to any montage#
- References#

Go to the end to download the full example code.

This example demonstrates how to interpolate EEG channels to match a given montage. This can be useful for standardizing EEG channel layouts across different datasets (see [1]).

Using the field interpolation for EEG data.

Using the target montage ‚Äúbiosemi16‚Äù.

In this example, the data from the original EEG channels will be interpolated onto the positions defined by the ‚Äúbiosemi16‚Äù montage.

Define the target montage

Use interpolate_to to project EEG data to the standard montage

Use interpolate_to to project EEG data to the standard montage

Comparing before and after interpolation

Apolline Mellot, Antoine Collas, Sylvain Chevallier, Denis Engemann, and Alexandre Gramfort. Physics-informed and unsupervised riemannian domain adaptation for machine learning on heterogeneous eeg datasets. In Proceedings of the 32nd European Signal Processing Conference (EUSIPCO). Lyon, France, 2024.

Total running time of the script: (0 minutes 4.523 seconds)

Download Jupyter notebook: interpolate_to.ipynb

Download Python source code: interpolate_to.py

Download zipped: interpolate_to.zip

Gallery generated by Sphinx-Gallery

Interpolate bad channels for MEG/EEG channels

Maxwell filter data with movement compensation

---

## Introductory tutorials#

**URL:** https://mne.tools/stable/auto_tutorials/intro/index.html

**Contents:**
- Introductory tutorials#

These tutorials cover the basic EEG/MEG pipeline for event-related analysis, introduce the mne.Info, events, and mne.Annotations data structures, discuss how sensor locations are handled, and introduce some of the configuration options available.

Overview of MEG/EEG analysis with MNE-Python

Modifying data in-place

Parsing events from raw data

The Info data structure

Working with sensor locations

Configuring MNE-Python

Getting started with mne.Report

Overview of MEG/EEG analysis with MNE-Python

---

## Inverse problem and source analysis#

**URL:** https://mne.tools/stable/auto_examples/inverse/index.html

**Contents:**
- Inverse problem and source analysis#

Estimate source activations, extract activations in labels, morph data between subjects etc.

Compute MNE-dSPM inverse solution on single epochs

Compute sLORETA inverse solution on raw data

Compute MNE-dSPM inverse solution on evoked data in volume source space

Source localization with a custom inverse solver

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Extracting time course from source_estimate object

Generate a functional label from source estimates

Extracting the time series of activations in a label

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Compute source power estimate by projecting the covariance with MNE

Morph surface source estimate

Morph volumetric source estimate

Computing source timecourses with an XFit-like multi-dipole model

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Visualize source leakage among labels using a circular graph

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Compute cross-talk functions for LCMV beamformers

Plot point-spread functions (PSFs) for a volume

Compute Rap-Music on evoked data

Reading an inverse operator

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Estimate data SNR using an inverse

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Plotting the full vector-valued MNE solution

Use source space morphing

Compute MNE-dSPM inverse solution on single epochs

---

## Inverse Solutions#

**URL:** https://mne.tools/stable/api/inverse.html

**Contents:**
- Inverse Solutions#

Linear inverse solvers based on L2 Minimum Norm Estimates (MNE).

InverseOperator class to represent info from inverse operator.

apply_inverse(evoked, inverse_operator[, ...])

Apply inverse operator to evoked data.

apply_inverse_cov(cov, info, inverse_operator)

Apply inverse operator to covariance data.

apply_inverse_epochs(epochs, ...[, method, ...])

Apply inverse operator to Epochs.

apply_inverse_raw(raw, inverse_operator, lambda2)

Apply inverse operator to Raw data.

apply_inverse_tfr_epochs(epochs_tfr, ...[, ...])

Apply inverse operator to EpochsTFR.

compute_source_psd(raw, inverse_operator[, ...])

Compute source power spectral density (PSD).

compute_source_psd_epochs(epochs, ...[, ...])

Compute source power spectral density (PSD) from Epochs.

compute_rank_inverse(inv)

Compute the rank of a linear inverse operator (MNE, dSPM, etc.).

estimate_snr(evoked, inv[, verbose])

Estimate the SNR as a function of time for evoked data.

make_inverse_operator(info, forward, noise_cov)

Assemble inverse operator.

prepare_inverse_operator(orig, nave, lambda2)

Prepare an inverse operator for actually computing the inverse.

read_inverse_operator(fname, *[, verbose])

Read the inverse operator decomposition from a FIF file.

source_band_induced_power(epochs, ...[, ...])

Compute source space induced power in given frequency bands.

source_induced_power(epochs, ...[, label, ...])

Compute induced power and phase lock.

write_inverse_operator(fname, inv, *[, ...])

Write an inverse operator to a FIF file.

make_inverse_resolution_matrix(forward, ...)

Compute resolution matrix for linear inverse operator.

resolution_metrics(resmat, src[, function, ...])

Compute spatial resolution metrics for linear solvers.

get_cross_talk(resmat, src, idx[, mode, ...])

Get cross-talk (CTFs) function for vertices.

get_point_spread(resmat, src, idx[, mode, ...])

Get point-spread (PSFs) functions for vertices.

Non-Linear sparse inverse solvers.

mixed_norm(evoked, forward, noise_cov[, ...])

Mixed-norm estimate (MxNE) and iterative reweighted MxNE (irMxNE).

tf_mixed_norm(evoked, forward, noise_cov[, ...])

Time-Frequency Mixed-norm estimate (TF-MxNE).

gamma_map(evoked, forward, noise_cov, alpha)

Hierarchical Bayes (Gamma-MAP) sparse source localization method.

make_stc_from_dipoles(dipoles, src[, verbose])

Convert a list of spatio-temporal dipoles into a SourceEstimate.

Beamformers for source localization.

A computed beamformer.

read_beamformer(fname)

Read a beamformer filter.

make_lcmv(info, forward, data_cov[, reg, ...])

Compute LCMV spatial filter.

apply_lcmv(evoked, filters, *[, verbose])

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.

apply_lcmv_epochs(epochs, filters, *[, ...])

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.

apply_lcmv_raw(raw, filters[, start, stop, ...])

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.

apply_lcmv_cov(data_cov, filters[, verbose])

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.

make_dics(info, forward, csd[, reg, ...])

Compute a Dynamic Imaging of Coherent Sources (DICS) spatial filter.

apply_dics(evoked, filters[, verbose])

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.

apply_dics_csd(csd, filters[, verbose])

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.

apply_dics_epochs(epochs, filters[, ...])

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.

apply_dics_tfr_epochs(epochs_tfr, filters[, ...])

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.

rap_music(evoked, forward, noise_cov[, ...])

RAP-MUSIC source localization method.

trap_music(evoked, forward, noise_cov[, ...])

TRAP-MUSIC source localization method.

make_lcmv_resolution_matrix(filters, ...)

Compute resolution matrix for LCMV beamformer.

Dipole(times, pos, amplitude, ori, gof[, ...])

Dipole class for sequential dipole fits.

DipoleFixed(info, data, times, nave, aspect_kind)

Dipole class for fixed-position dipole fits.

fit_dipole(evoked, cov, bem[, trans, ...])

Single-dipole functions and classes.

get_phantom_dipoles([kind])

Get standard phantom dipole locations and orientations.

mne.bem.distance_to_bem

mne.minimum_norm.InverseOperator

---

## KIT phantom dataset tutorial#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/95_phantom_KIT.html

**Contents:**
- KIT phantom dataset tutorial#

Go to the end to download the full example code.

Here we read KIT data obtained from a phantom with 49 dipoles sequentially activated with 2-cycle 11 Hz sinusoidal bursts to verify source localization accuracy.

We can also look at the power spectral density to see the phantom oscillations at 11 Hz plus the expected frequency-domain sinc-like oscillations due to the time-domain boxcar windowing of the 11 Hz sinusoid.

Now we can figure out our epoching parameters and epoch the data and plot it.

Now we can average the epochs for each dipole, get the activation at the peak time, and create an mne.EvokedArray from the result.

Let‚Äôs fit dipoles at each dipole‚Äôs peak activation time.

Finally let‚Äôs look at the results.

Total running time of the script: (0 minutes 25.055 seconds)

Download Jupyter notebook: 95_phantom_KIT.ipynb

Download Python source code: 95_phantom_KIT.py

Download zipped: 95_phantom_KIT.zip

Gallery generated by Sphinx-Gallery

4D Neuroimaging/BTi phantom dataset tutorial

Statistical analysis of sensor data

---

## Machine learning models of neural activity#

**URL:** https://mne.tools/stable/auto_tutorials/machine-learning/index.html

**Contents:**
- Machine learning models of neural activity#

These tutorials cover some of the machine learning methods available in MNE-Python.

Spectro-temporal receptive field (STRF) estimation on continuous data

Repeated measures ANOVA on source data with spatio-temporal clustering

Spectro-temporal receptive field (STRF) estimation on continuous data

---

## Make figures more publication ready#

**URL:** https://mne.tools/stable/auto_tutorials/visualization/10_publication_figure.html

**Contents:**
- Make figures more publication ready#
- Imports#
- Evoked plot with brain activation#
- Custom timecourse with montage inset#

Go to the end to download the full example code.

In this example, we show several use cases to take MNE plots and customize them for a more publication-ready look.

We are importing everything we need for this example:

Suppose we want a figure with an evoked plot on top, and the brain activation below, with the brain subplot slightly bigger than the evoked plot. Let‚Äôs start by loading some example data.

During interactive plotting, we might see figures like this:

To make a publication-ready figure, first we‚Äôll re-plot the brain on a white background, take a screenshot of it, and then crop out the white margins. While we‚Äôre at it, let‚Äôs change the colormap, set custom colormap limits and remove the default colorbar (so we can add a smaller, vertical one later):

Now let‚Äôs crop out the white margins and the white gap between hemispheres. The screenshot has dimensions (h, w, 3), with the last axis being R, G, B values for each pixel, encoded as integers between 0 and 255. (255, 255, 255) encodes a white pixel, so we‚Äôll detect any pixels that differ from that:

A lot of figure settings can be adjusted after the figure is created, but many can also be adjusted in advance by updating the rcParams dictionary. This is especially useful when your script generates several figures that you want to all have the same style:

Now let‚Äôs create our custom figure. There are lots of ways to do this step. Here we‚Äôll create the figure and the subplot axes in one step, specifying overall figure size, number and arrangement of subplots, and the ratio of subplot heights for each row using GridSpec keywords. Other approaches (using subplot2grid(), or adding each axes manually) are shown commented out, for reference.

Suppose we want a figure with some mean timecourse extracted from a number of sensors, and we want a smaller panel within the figure to show a head outline with the positions of those sensors clearly marked. If you are familiar with MNE, you know that this is something that mne.viz.plot_compare_evokeds() does, see an example output in HF-SEF dataset at the bottom.

In this part of the example, we will show you how to achieve this result on your own figure, without having to use mne.viz.plot_compare_evokeds()!

Let‚Äôs start by loading some example data.

So far so good. Now let‚Äôs add the smaller figure within the figure to show exactly, which sensors we used to make the timecourse. For that, we use an ‚Äúinset_axes‚Äù that we plot into our existing axes. The head outline with the sensor positions can be plotted using the Raw object that is the source of our data. Specifically, that object already contains all the sensor positions, and we can plot them using the plot_sensors method.

That looks nice. But the sensor dots are way too big for our taste. Luckily, all MNE-Python plots use Matplotlib under the hood and we can customize each and every facet of them. To make the sensor dots smaller, we need to first get a handle on them to then apply a *.set_* method on them.

That‚Äôs quite a a lot of objects, but we know that we want to change the sensor dots, and those are most certainly a ‚ÄúPathCollection‚Äù object. So let‚Äôs have a look at how many ‚Äúcollections‚Äù we have in the axes.

There is only one! Those must be the sensor dots we were looking for. We finally found exactly what we needed. Sometimes this can take a bit of experimentation.

Total running time of the script: (0 minutes 5.688 seconds)

Download Jupyter notebook: 10_publication_figure.ipynb

Download Python source code: 10_publication_figure.py

Download zipped: 10_publication_figure.zip

Gallery generated by Sphinx-Gallery

Visualization tutorials

Using the event system to link figures

---

## Mass-univariate twoway repeated measures ANOVA on single trial power#

**URL:** https://mne.tools/stable/auto_tutorials/stats-sensor-space/70_cluster_rmANOVA_time_freq.html

**Contents:**
- Mass-univariate twoway repeated measures ANOVA on single trial power#
- Set parameters#
- Create TFR representations for all conditions#
- Setup repeated measures ANOVA#
- Account for multiple comparisons using FDR versus permutation clustering test#

Go to the end to download the full example code.

This script shows how to conduct a mass-univariate repeated measures ANOVA. As the model to be fitted assumes two fully crossed factors, we will study the interplay between perceptual modality (auditory VS visual) and the location of stimulus presentation (left VS right). Here we use single trials as replications (subjects) while iterating over time slices plus frequency bands for to fit our mass-univariate model. For the sake of simplicity we will confine this analysis to one single channel of which we know that it exposes a strong induced response. We will then visualize each effect by creating a corresponding mass-univariate effect image. We conclude with accounting for multiple comparisons by performing a permutation clustering test using the ANOVA as clustering function. The results final will be compared to multiple comparisons using False Discovery Rate correction.

We have to make sure all conditions have the same counts, as the ANOVA expects a fully balanced data matrix and does not forgive imbalances that generously (risk of type-I error).

We will tell the ANOVA how to interpret the data matrix in terms of factors. This is done via the factor levels argument which is a list of the number factor levels for each factor.

Now we‚Äôll assemble the data matrix and swap axes so the trial replications are the first dimension and the conditions are the second dimension.

While the iteration scheme used above for assembling the data matrix makes sure the first two dimensions are organized as expected (with A = modality and B = location):

Now we‚Äôre ready to run our repeated measures ANOVA.

Note. As we treat trials as subjects, the test only accounts for time locked responses despite the ‚Äòinduced‚Äô approach. For analysis for induced power at the group level averaged TRFs are required.

First we need to slightly modify the ANOVA function to be suitable for the clustering procedure. Also want to set some defaults. Let‚Äôs first override effects to confine the analysis to the interaction

A stat_fun must deal with a variable number of input arguments. Inside the clustering function each condition will be passed as flattened array, necessitated by the clustering procedure. The ANOVA however expects an input array of dimensions: subjects √ó conditions √ó observations (optional). The following function catches the list input and swaps the first and the second dimension and finally calls the ANOVA function.

Create new stats image with only significant clusters:

Both cluster-level and FDR correction help get rid of potential false-positives that we saw in the naive f-images. The cluster permutation correction is biased toward time-frequencies with contiguous areas of high or low power, which is likely appropriate given the highly correlated nature of this data. This is the most likely explanation for why one cluster was preserved by the cluster permutation correction, but no time-frequencies were significant using the FDR correction.

Total running time of the script: (0 minutes 9.902 seconds)

Download Jupyter notebook: 70_cluster_rmANOVA_time_freq.ipynb

Download Python source code: 70_cluster_rmANOVA_time_freq.py

Download zipped: 70_cluster_rmANOVA_time_freq.zip

Gallery generated by Sphinx-Gallery

Non-parametric between conditions cluster statistic on single trial power

Spatiotemporal permutation F-test on full sensor data

---

## Maxwell filter data with movement compensation#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/movement_compensation.html

**Contents:**
- Maxwell filter data with movement compensation#

Go to the end to download the full example code.

Demonstrate movement compensation on simulated data. The simulated data contains bilateral activation of auditory cortices, repeated over 14 different head rotations (head center held fixed). See the following for details:

mne-tools/mne-misc-data

Visualize the ‚Äúsubject‚Äù head movements. By providing the measurement information, the distance to the nearest sensor in each direction (e.g., left/right for the X direction, forward/backward for Y) can be shown in blue, and the destination (if given) shown in red.

This can also be visualized using a quiver.

Process our simulated raw data (taking into account head movements).

First, take the average of stationary data (bilateral auditory patterns).

Second, take a naive average, which averages across epochs that have been simulated to have different head positions and orientations, thereby spatially smearing the activity.

Third, use raw movement compensation (restores pattern).

Fourth, use evoked movement compensation. For these data, which contain very large rotations, it does not as cleanly restore the pattern.

Total running time of the script: (0 minutes 8.369 seconds)

Download Jupyter notebook: movement_compensation.ipynb

Download Python source code: movement_compensation.py

Download zipped: movement_compensation.zip

Gallery generated by Sphinx-Gallery

Interpolate EEG data to any montage

Annotate movement artifacts and reestimate dev_head_t

---

## mne.BaseEpochs#

**URL:** https://mne.tools/stable/generated/mne.BaseEpochs.html

**Contents:**
- mne.BaseEpochs#

Abstract base class for Epochs-type classes.

This class should not be instantiated directly via mne.BaseEpochs(...). Instead, use one of the functions listed in the See Also section below.

The mne.Info object with information about the sensors and methods of measurement.

If None, data will be read from the Raw object. If ndarray, must be of shape (n_epochs, n_channels, n_times).

The identity and timing of experimental events, around which the epochs were created. See events for more information.Events that don‚Äôt match the events of interest as specified by event_id will be marked as IGNORED in the drop log.

The id of the events to consider. If dict, the keys can later be used to access associated events. Example: dict(auditory=1, visual=3). If int, a dict will be created with the id as string. If a list of int, all events with the IDs specified in the list are used. If a str or list of str, events must be None to use annotations and then the IDs must be the name(s) of the annotations to use. If None, all events will be used and a dict is created with string integer names corresponding to the event id integers.

Start and end time of the epochs in seconds, relative to the time-locked event. The closest or matching samples corresponding to the start and end time are included. Defaults to -0.2 and 0.5, respectively.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each epoch and channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire epoch.

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Reject epochs based on maximum peak-to-peak signal amplitude (PTP), i.e. the absolute difference between the lowest and the highest signal value. In each individual epoch, the PTP is calculated for every channel. If the PTP of any one channel exceeds the rejection threshold, the respective epoch will be dropped.

The dictionary keys correspond to the different channel types; valid keys can be any channel type present in the object.

Since rejection is based on a signal difference calculated for each channel separately, applying baseline correction does not affect the rejection procedure, as the difference will be preserved.

To constrain the time period used for estimation of signal quality, pass the reject_tmin and reject_tmax parameters.

If reject is None (default), no rejection is performed.

Reject epochs based on minimum peak-to-peak signal amplitude (PTP). Valid keys can be any channel type present in the object. The values are floats that set the minimum acceptable PTP. If the PTP is smaller than this threshold, the epoch will be dropped. If None then no rejection is performed based on flatness of the signal.

To constrain the time period used for estimation of signal quality, pass the reject_tmin and reject_tmax parameters.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Start and end of the time window used to reject epochs based on peak-to-peak (PTP) amplitudes as specified via reject and flat. The default None corresponds to the first and last time points of the epochs, respectively.

This parameter controls the time period used in conjunction with both, reject and flat.

If 0 or 1, the data channels (MEG and EEG) will be detrended when loaded. 0 is a constant (DC) detrend, 1 is a linear detrend. None is no detrending. Note that detrending is performed before baseline correction. If no DC offset is preferred (zeroth order detrending), either turn off baseline correction, as this may introduce a DC shift, or set baseline correction to use the entire time interval (will yield equivalent results but be slower).

Apply SSP projection vectors. If proj is ‚Äòdelayed‚Äô and reject is not None the single epochs will be projected before the rejection decision, but used in unprojected state if they are kept. This way deciding which projection vectors are good can be postponed to the evoked stage without resulting in lower epoch counts and without producing results different from early SSP application given comparable parameters. Note that in this case baselining, detrending and temporal decimation will be postponed. If proj is False no projections will be applied which is the recommended value if SSPs are not used for cleaning the data.

What to do if one or several event ids are not found in the recording. Valid keys are ‚Äòraise‚Äô | ‚Äòwarn‚Äô | ‚Äòignore‚Äô Default is 'raise'. If 'warn', it will proceed but warn; if 'ignore', it will proceed silently.

If none of the event ids are found in the data, an error will be automatically generated irrespective of this parameter.

Load all epochs from disk when creating the object or wait before accessing each epoch (more memory efficient but can be slower).

Iterable of indices of selected epochs. If None, will be automatically generated, corresponding to all non-zero events.

Tuple of tuple of strings indicating which epochs have been marked to be ignored.

The filename (if the epochs are read from disk).

A pandas.DataFrame specifying metadata about each epoch. If not None, len(metadata) must equal len(events). For save/load compatibility, the DataFrame may only contain str, int, float, and bool values. If not None, then pandas-style queries may be used to select subsets of data, see mne.Epochs.__getitem__(). When the Epochs object is subsetted, the metadata is subsetted accordingly, and the row indices will be modified to match Epochs.selection.

How to handle duplicates in events[:, 0]. Can be 'error' (default), to raise an error, ‚Äòdrop‚Äô to only retain the row occurring first in the events, or 'merge' to combine the coinciding events (=duplicates) into a new event (see Notes for details).

The original Raw object sampling rate. If None, then it is set to info['sfreq'].

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The current gradient compensation grade.

The filename if the epochs are loaded from disk.

Whether or not projections are active.

Time vector in seconds.

__contains__(ch_type)

Check channel type membership.

Return an Epochs object with a copied subset of epochs.

Facilitate iteration over epochs.

Return the number of epochs.

add_annotations_to_metadata([overwrite, ...])

Add raw annotations into the Epochs metadata data frame.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_proj(projs[, remove_existing, verbose])

Add SSP projection vectors.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

anonymize([daysback, keep_his, verbose])

Anonymize measurement information in place.

apply_baseline([baseline, verbose])

Baseline correct epochs.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of channels.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

apply_proj([verbose])

Apply the signal space projection (SSP) operators to the data.

as_type([ch_type, mode])

Compute virtual epochs using interpolated fields.

average([picks, method, by_event_type])

Compute an average over epochs.

compute_psd([method, fmin, fmax, tmin, ...])

Perform spectral analysis on sensor data.

compute_tfr(method, freqs, *[, tmin, tmax, ...])

Compute a time-frequency representation of epoched data.

Return copy of Epochs instance.

crop([tmin, tmax, include_tmax, verbose])

Crop a time interval from the epochs.

decimate(decim[, offset, verbose])

Decimate the time-series data.

Remove SSP projection vector.

drop(indices[, reason, verbose])

Drop epochs based on indices or boolean mask.

drop_bad([reject, flat, verbose])

Drop bad epochs without retaining the epochs data.

drop_channels(ch_names[, on_missing])

drop_log_stats([ignore])

Compute the channel stats based on a drop_log from Epochs.

equalize_event_counts([event_ids, method, ...])

Equalize the number of trials in each condition.

export(fname[, fmt, overwrite, verbose])

Export Epochs to external formats.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_annotations_per_epoch(*[, with_extras])

Get a list of annotations that occur during each epoch.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, item, units, tmin, tmax, ...])

Get all epochs as a 3D array.

Get a DigMontage from instance.

interpolate_bads([reset_bads, mode, origin, ...])

Interpolate bad MEG and EEG channels.

interpolate_to(sensors[, origin, method, reg])

Interpolate EEG data onto a new montage.

Iterate over epochs as a sequence of Evoked objects.

Load the data if not already preloaded.

next([return_event_id])

Iterate over epoch data.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, scalings, n_epochs, ...])

plot_drop_log([threshold, n_max_plot, ...])

Show the channel stats based on a drop_log from Epochs.

plot_image([picks, sigma, vmin, vmax, ...])

Plot Event Related Potential / Fields image.

plot_projs_topomap([ch_type, sensors, ...])

plot_psd([fmin, fmax, tmin, tmax, picks, ...])

Plot power or amplitude spectra.

plot_psd_topo([tmin, tmax, fmin, fmax, ...])

plot_psd_topomap([bands, tmin, tmax, ...])

plot_sensors([kind, ch_type, title, ...])

Plot sensor positions.

plot_topo_image([layout, sigma, vmin, vmax, ...])

Plot Event Related Potential / Fields image on topographies.

rename_channels(mapping[, allow_duplicates, ...])

reorder_channels(ch_names)

resample(sfreq, *[, npad, window, n_jobs, ...])

reset_drop_log_selection()

Reset the drop_log and selection entries.

save(fname[, split_size, fmt, overwrite, ...])

Save epochs in a fif file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

set_annotations(annotations[, on_missing, ...])

Setter for Epoch annotations from Raw.

set_channel_types(mapping, *[, ...])

Specify the sensor types of channels.

set_eeg_reference([ref_channels, ...])

Specify which reference to use for EEG data.

set_meas_date(meas_date)

Set the measurement start date.

set_montage(montage[, match_case, ...])

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

standard_error([picks, by_event_type])

Compute standard error over epochs.

subtract_evoked([evoked])

Subtract an evoked response from each epoch.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

The BaseEpochs class is public to allow for stable type-checking in user code (i.e., isinstance(my_epochs, BaseEpochs)) but should not be used as a constructor for Epochs objects (use instead mne.Epochs).

mne.io.get_channel_type_constants

Creating data objects from arrays

---

## mne.beamformer.apply_dics_epochs#

**URL:** https://mne.tools/stable/generated/mne.beamformer.apply_dics_epochs.html

**Contents:**
- mne.beamformer.apply_dics_epochs#

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights on single trial data.

The result of this function is meant as an intermediate step for further processing (such as computing connectivity). If you are interested in estimating source time courses, use an LCMV beamformer (make_lcmv(), apply_lcmv()) instead. If you are interested in estimating spectral power at the source level, use apply_dics_csd().

This implementation has not been heavily tested so please report any issue or suggestions.

DICS spatial filter (beamformer weights) Filter weights returned from make_dics(). The DICS filters must have been computed for a single frequency only.

Return a generator object instead of a list. This allows iterating over the stcs without having to keep them all in memory.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimates for all epochs.

mne.beamformer.apply_dics_csd

mne.beamformer.apply_dics_tfr_epochs

---

## mne.beamformer.apply_dics_tfr_epochs#

**URL:** https://mne.tools/stable/generated/mne.beamformer.apply_dics_tfr_epochs.html

**Contents:**
- mne.beamformer.apply_dics_tfr_epochs#
- Examples using mne.beamformer.apply_dics_tfr_epochs#

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.

Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights on single trial time-frequency data.

Single trial time-frequency epochs.

DICS spatial filter (beamformer weights) Filter weights returned from make_dics().

Return a generator object instead of a list. This allows iterating over the stcs without having to keep them all in memory.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimates for all epochs (outside list) and for all frequencies (inside list).

Compute source level time-frequency timecourses using a DICS beamformer

mne.beamformer.apply_dics_epochs

mne.beamformer.rap_music

---

## mne.beamformer.apply_lcmv_epochs#

**URL:** https://mne.tools/stable/generated/mne.beamformer.apply_lcmv_epochs.html

**Contents:**
- mne.beamformer.apply_lcmv_epochs#

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.

Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights on single trial data.

LCMV spatial filter (beamformer weights) Filter weights returned from make_lcmv().

Return a generator object instead of a list. This allows iterating over the stcs without having to keep them all in memory.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimates for all epochs.

mne.beamformer.apply_lcmv

mne.beamformer.apply_lcmv_raw

---

## mne.channels.combine_channels#

**URL:** https://mne.tools/stable/generated/mne.channels.combine_channels.html

**Contents:**
- mne.channels.combine_channels#
- Examples using mne.channels.combine_channels#

Combine channels based on specified channel grouping.

An MNE-Python object to combine the channels for. The object can be of type Raw, Epochs, or Evoked.

Specifies which channels are aggregated into a single channel, with aggregation method determined by the method parameter. One new pseudo-channel is made per dict entry; the dict values must be lists of picks (integer indices of ch_names). For example:

Note that within a dict entry all channels must have the same type.

Which method to use to combine channels. If a str, must be one of ‚Äòmean‚Äô, ‚Äòmedian‚Äô, or ‚Äòstd‚Äô (standard deviation). If callable, the callable must accept one positional input (data of shape (n_channels, n_times), or (n_epochs, n_channels, n_times)) and return an array of shape (n_times,), or (n_epochs, n_times). For example with an instance of Raw or Evoked:

Another example with an instance of Epochs:

If True, include stimulus channels in the resulting object. Defaults to False.

If True, drop channels marked as bad before combining. Defaults to False.

What to do if one or several event ids are not found in the recording. Valid keys are ‚Äòraise‚Äô | ‚Äòwarn‚Äô | ‚Äòignore‚Äô Default is 'raise'. If 'warn', it will proceed but warn; if 'ignore', it will proceed silently.

If none of the event ids are found in the data, an error will be automatically generated irrespective of this parameter.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

An MNE-Python object of the same type as the input inst, containing one virtual channel for each group in groups (and, if keep_stim is True, also containing stimulus channels).

EEG analysis - Event-Related Potentials (ERPs)

mne.channels.make_1020_channel_selections

mne.preprocessing.ICA

---

## mne.channels.equalize_channels#

**URL:** https://mne.tools/stable/generated/mne.channels.equalize_channels.html

**Contents:**
- mne.channels.equalize_channels#

Equalize channel picks and ordering across multiple MNE-Python objects.

First, all channels that are not common to each object are dropped. Then, using the first object in the list as a template, the channels of each object are re-ordered to match the template. The end result is that all given objects define the same channels, in the same order.

A list of MNE-Python objects to equalize the channels for. Objects can be of type Raw, Epochs, Evoked, Spectrum, AverageTFR, Forward, Covariance, CrossSpectralDensity or Info.

Changed in version 1.11: Added support for mne.time_frequency.Spectrum objects.

When dropping and/or re-ordering channels, an object will be copied when this parameter is set to True. When set to False (the default) the dropping and re-ordering of channels happens in-place.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of MNE-Python objects that have the same channels defined in the same order.

mne.channels.read_ch_adjacency

mne.channels.unify_bad_channels

---

## mne.channels.unify_bad_channels#

**URL:** https://mne.tools/stable/generated/mne.channels.unify_bad_channels.html

**Contents:**
- mne.channels.unify_bad_channels#

Unify bad channels across a list of instances.

All instances must be of the same type and have matching channel names and channel order. The .info["bads"] of each instance will be set to the union of .info["bads"] across all instances.

List of instances (Raw, Epochs, Evoked, Spectrum, EpochsSpectrum) across which to unify bad channels.

List of instances with bad channels unified across instances.

This function modifies the instances in-place.

mne.channels.equalize_channels

mne.channels.rename_channels

---

## mne.combine_evoked#

**URL:** https://mne.tools/stable/generated/mne.combine_evoked.html

**Contents:**
- mne.combine_evoked#
- Examples using mne.combine_evoked#

Merge evoked data by weighted addition or subtraction.

Each Evoked in all_evoked should have the same channels and the same time instants. Subtraction can be performed by passing weights=[1, -1].

Other than cases like simple subtraction mentioned above (where all weights are -1 or 1), if you provide numeric weights instead of using 'equal' or 'nave', the resulting Evoked object‚Äôs .nave attribute (which is used to scale noise covariance when applying the inverse operator) may not be suitable for inverse imaging.

The weights to apply to the data of each evoked instance, or a string describing the weighting strategy to apply: 'nave' computes sum-to-one weights proportional to each object‚Äôs nave attribute; 'equal' weights each Evoked by 1 / len(all_evoked).

Single trial linear regression analysis with the LIMO dataset

From raw data to dSPM on SPM Faces dataset

Regression on continuous data (rER[P/F])

Regression-based baseline correction

Auto-generating Epochs metadata

The Evoked data structure: evoked/averaged data

EEG analysis - Event-Related Potentials (ERPs)

Overview of MEG/EEG analysis with MNE-Python

Source localization with equivalent current dipole (ECD) fit

Working with CTF data: the Brainstorm auditory dataset

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Visualising statistical significance thresholds on EEG data

Non-parametric between conditions cluster statistic on single trial power

Using the event system to link figures

---

## mne.compute_proj_epochs#

**URL:** https://mne.tools/stable/generated/mne.compute_proj_epochs.html

**Contents:**
- mne.compute_proj_epochs#
- Examples using mne.compute_proj_epochs#

Compute SSP (signal-space projection) vectors on epoched data.

This function aims to find those SSP vectors that will project out the n most prominent signals from the data for each specified sensor type. Consequently, if the provided input data contains high levels of noise, the produced SSP vectors can then be used to eliminate that noise from the data.

The epochs containing the artifact.

Number of vectors for gradiometers. Either an integer or a float between 0 and 1 to select the number of vectors to explain the cumulative variance greater than n_grad.

Number of vectors for magnetometers. Either an integer or a float between 0 and 1 to select the number of vectors to explain the cumulative variance greater than n_mag.

Number of vectors for EEG channels. Either an integer or a float between 0 and 1 to select the number of vectors to explain the cumulative variance greater than n_eeg.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Number of jobs to use to compute covariance.

The description prefix to use. If None, one will be created based on the event_id, tmin, and tmax.

Can be 'separate' (default) or 'combined' to compute projectors for magnetometers and gradiometers separately or jointly. If 'combined', n_mag == n_grad is required and the number of projectors computed for MEG will be n_mag.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of projection vectors.

Working with CTF data: the Brainstorm auditory dataset

Repairing artifacts with SSP

mne.compute_proj_evoked

---

## mne.compute_proj_evoked#

**URL:** https://mne.tools/stable/generated/mne.compute_proj_evoked.html

**Contents:**
- mne.compute_proj_evoked#
- Examples using mne.compute_proj_evoked#

Compute SSP (signal-space projection) vectors on evoked data.

This function aims to find those SSP vectors that will project out the n most prominent signals from the data for each specified sensor type. Consequently, if the provided input data contains high levels of noise, the produced SSP vectors can then be used to eliminate that noise from the data.

The Evoked obtained by averaging the artifact.

Number of vectors for gradiometers. Either an integer or a float between 0 and 1 to select the number of vectors to explain the cumulative variance greater than n_grad.

Number of vectors for magnetometers. Either an integer or a float between 0 and 1 to select the number of vectors to explain the cumulative variance greater than n_mag.

Number of vectors for EEG channels. Either an integer or a float between 0 and 1 to select the number of vectors to explain the cumulative variance greater than n_eeg.

The description prefix to use. If None, one will be created based on tmin and tmax.

Can be 'separate' (default) or 'combined' to compute projectors for magnetometers and gradiometers separately or jointly. If 'combined', n_mag == n_grad is required and the number of projectors computed for MEG will be n_mag.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of projection vectors.

Brainstorm raw (median nerve) dataset

mne.compute_proj_epochs

---

## mne.concatenate_epochs#

**URL:** https://mne.tools/stable/generated/mne.concatenate_epochs.html

**Contents:**
- mne.concatenate_epochs#
- Examples using mne.concatenate_epochs#

Concatenate a list of Epochs into one Epochs object.

Unlike concatenate_raws, this function does not modify any of the input data.

List of Epochs instances to concatenate (in that order).

If True, a fixed offset is added to the event times from different Epochs sets, such that they are easy to distinguish after the concatenation. If False, the event times are unaltered during the concatenation.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when the device-to-head transformation differs between instances.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The result of the concatenation. All data will be loaded into memory.

Working with CTF data: the Brainstorm auditory dataset

mne.events_from_annotations

---

## mne.decoding.Scaler#

**URL:** https://mne.tools/stable/generated/mne.decoding.Scaler.html

**Contents:**
- mne.decoding.Scaler#
- Examples using mne.decoding.Scaler#

Standardize channel data.

This class scales data for each channel. It differs from scikit-learn classes (e.g., sklearn.preprocessing.StandardScaler) in that it scales each channel by estimating Œº and œÉ using data from all time points and epochs, as opposed to standardizing each feature (i.e., each time point for each channel) by estimating using Œº and œÉ using data from all epochs.

The mne.Info object with information about the sensors and methods of measurement. Only necessary if scalings is a dict or None.

Scaling method to be applied to data channel wise.

if scalings is None (default), scales mag by 1e15, grad by 1e13, and eeg by 1e6.

if scalings is dict, keys are channel types and values are scale factors.

if scalings=='median', sklearn.preprocessing.RobustScaler is used (requires sklearn version 0.17+).

if scalings=='mean', sklearn.preprocessing.StandardScaler is used.

If True, center the data using mean (or median) before scaling. Ignored for channel-type scaling.

If True, scale the data to unit variance (scalings='mean'), quantile range (scalings='median), or using channel type if scalings is a dict or None).

fit(epochs_data[, y])

Standardize data across channels.

fit_transform(epochs_data[, y])

Fit to data, then transform it.

get_metadata_routing()

Get metadata routing of this object.

Get parameters for this estimator.

inverse_transform(epochs_data)

Invert standardization of data across channels.

set_fit_request(*[, epochs_data])

Configure whether metadata should be requested to be passed to the fit method.

set_inverse_transform_request(*[, epochs_data])

Configure whether metadata should be requested to be passed to the inverse_transform method.

set_output(*[, transform])

Set output container.

Set the parameters of this estimator.

set_transform_request(*[, epochs_data])

Configure whether metadata should be requested to be passed to the transform method.

transform(epochs_data)

Standardize data across channels.

Standardize data across channels.

The data to concatenate channels.

The label for each epoch.

The modified instance.

Fit to data, then transform it.

Fits transformer to epochs_data and y and returns a transformed version of epochs_data.

The label for each epoch. Defaults to None.

The data concatenated over channels.

This function makes a copy of the data before the operations and the memory usage may be large with big data.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Invert standardization of data across channels.

The data concatenated over channels.

This function makes a copy of the data before the operations and the memory usage may be large with big data.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config()). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Metadata routing for epochs_data parameter in fit.

Configure whether metadata should be requested to be passed to the inverse_transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config()). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to inverse_transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to inverse_transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Metadata routing for epochs_data parameter in inverse_transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

‚Äúdefault‚Äù: Default output format of a transformer

‚Äúpandas‚Äù: DataFrame output

‚Äúpolars‚Äù: Polars output

None: Transform configuration is unchanged

New in v1.4: ‚Äúpolars‚Äù option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it‚Äôs possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config()). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Metadata routing for epochs_data parameter in transform.

Standardize data across channels.

The data concatenated over channels.

This function makes a copy of the data before the operations and the memory usage may be large with big data.

mne.decoding.PSDEstimator

mne.decoding.TemporalFilter

---

## mne.decoding.XdawnTransformer#

**URL:** https://mne.tools/stable/generated/mne.decoding.XdawnTransformer.html

**Contents:**
- mne.decoding.XdawnTransformer#
- Examples using mne.decoding.XdawnTransformer#

Implementation of the Xdawn Algorithm compatible with scikit-learn.

Xdawn is a spatial filtering method designed to improve the signal to signal + noise ratio (SSNR) of the event related responses. Xdawn was originally designed for P300 evoked potential by enhancing the target response with respect to the non-target response. This implementation is a generalization to any type of event related response.

XdawnTransformer does not correct for epochs overlap. To correct overlaps see mne.preprocessing.Xdawn.

The number of components to decompose the signals.

If not None (same as 'empirical', default), allow regularization for covariance estimation. If float, shrinkage is used (0 <= shrinkage <= 1). For str options, reg will be passed to method to mne.compute_covariance().

The signal covariance used for whitening of the data. if None, the covariance is estimated from the epochs signal.

Parameters to pass to mne.compute_covariance().

Restricting transformation for covariance matrices before performing generalized eigendecomposition. If ‚Äúrestricting‚Äù only restriction to the principal subspace of signal_cov will be performed. If ‚Äúwhitening‚Äù, covariance matrices will be additionally rescaled according to the whitening for the signal_cov. If None, no restriction will be applied. Defaults to None.

The mne.Info object with information about the sensors and methods of measurement used for covariance estimation and generalized eigendecomposition. If None, one channel type and no projections will be assumed and if rank is dict, it will be sum of ranks per channel type. Defaults to None.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

The default is 'full'.

The event indices of the classes.

The Xdawn components used to decompose the data for each event type.

The Xdawn patterns used to restore the signals for each event type.

Fit Xdawn spatial filters.

fit_transform(X[, y])

Fit to data, then transform it.

get_metadata_routing()

Get metadata routing of this object.

Get parameters for this estimator.

Remove selected components from the signal.

set_output(*[, transform])

Set output container.

Set the parameters of this estimator.

Transform data with spatial filters.

Fit Xdawn spatial filters.

The target labels. If None, Xdawn fit on the average evoked.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Remove selected components from the signal.

Given the unmixing matrix, transform data, zero out components, and inverse transform the data. This procedure will reconstruct the signals from which the dynamics described by the excluded components is subtracted.

The transformed data.

The inverse transform data.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

‚Äúdefault‚Äù: Default output format of a transformer

‚Äúpandas‚Äù: DataFrame output

‚Äúpolars‚Äù: Polars output

None: Transform configuration is unchanged

New in v1.4: ‚Äúpolars‚Äù option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it‚Äôs possible to update each component of a nested object.

Estimator parameters.

Transform data with spatial filters.

The transformed data.

XDAWN Decoding From EEG data

mne.decoding.SpatialFilter

---

## mne.EpochsArray#

**URL:** https://mne.tools/stable/generated/mne.EpochsArray.html

**Contents:**
- mne.EpochsArray#
- Examples using mne.EpochsArray#

Epochs object from numpy array.

The channels‚Äô time series for each epoch. See notes for proper units of measure.

The mne.Info object with information about the sensors and methods of measurement. Consider using mne.create_info() to populate this structure.

The identity and timing of experimental events, around which the epochs were created. See events for more information.Events that don‚Äôt match the events of interest as specified by event_id will be marked as IGNORED in the drop log.

Start time before event. If nothing provided, defaults to 0.

The id of the events to consider. If dict, the keys can later be used to access associated events. Example: dict(auditory=1, visual=3). If int, a dict will be created with the id as string. If a list of int, all events with the IDs specified in the list are used. If a str or list of str, events must be None to use annotations and then the IDs must be the name(s) of the annotations to use. If None, all events will be used and a dict is created with string integer names corresponding to the event id integers.

Reject epochs based on maximum peak-to-peak signal amplitude (PTP), i.e. the absolute difference between the lowest and the highest signal value. In each individual epoch, the PTP is calculated for every channel. If the PTP of any one channel exceeds the rejection threshold, the respective epoch will be dropped.

The dictionary keys correspond to the different channel types; valid keys can be any channel type present in the object.

Since rejection is based on a signal difference calculated for each channel separately, applying baseline correction does not affect the rejection procedure, as the difference will be preserved.

To constrain the time period used for estimation of signal quality, pass the reject_tmin and reject_tmax parameters.

If reject is None (default), no rejection is performed.

Reject epochs based on minimum peak-to-peak signal amplitude (PTP). Valid keys can be any channel type present in the object. The values are floats that set the minimum acceptable PTP. If the PTP is smaller than this threshold, the epoch will be dropped. If None then no rejection is performed based on flatness of the signal.

To constrain the time period used for estimation of signal quality, pass the reject_tmin and reject_tmax parameters.

Start and end of the time window used to reject epochs based on peak-to-peak (PTP) amplitudes as specified via reject and flat. The default None corresponds to the first and last time points of the epochs, respectively.

This parameter controls the time period used in conjunction with both, reject and flat.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each epoch and channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire epoch.

Defaults to None, i.e. no baseline correction.

Apply SSP projection vectors. If proj is ‚Äòdelayed‚Äô and reject is not None the single epochs will be projected before the rejection decision, but used in unprojected state if they are kept. This way deciding which projection vectors are good can be postponed to the evoked stage without resulting in lower epoch counts and without producing results different from early SSP application given comparable parameters. Note that in this case baselining, detrending and temporal decimation will be postponed. If proj is False no projections will be applied which is the recommended value if SSPs are not used for cleaning the data.

What to do if one or several event ids are not found in the recording. Valid keys are ‚Äòraise‚Äô | ‚Äòwarn‚Äô | ‚Äòignore‚Äô Default is 'raise'. If 'warn', it will proceed but warn; if 'ignore', it will proceed silently.

If none of the event ids are found in the data, an error will be automatically generated irrespective of this parameter.

A pandas.DataFrame specifying metadata about each epoch. If not None, len(metadata) must equal len(events). For save/load compatibility, the DataFrame may only contain str, int, float, and bool values. If not None, then pandas-style queries may be used to select subsets of data, see mne.Epochs.__getitem__(). When the Epochs object is subsetted, the metadata is subsetted accordingly, and the row indices will be modified to match Epochs.selection.

Iterable of indices of selected epochs. If None, will be automatically generated, corresponding to all non-zero events.

Tuple of tuple of strings indicating which epochs have been marked to be ignored.

The original Raw object sampling rate. If None, then it is set to info['sfreq'].

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The current gradient compensation grade.

The filename if the epochs are loaded from disk.

Whether or not projections are active.

Time vector in seconds.

__contains__(ch_type)

Check channel type membership.

Return an Epochs object with a copied subset of epochs.

Facilitate iteration over epochs.

Return the number of epochs.

add_annotations_to_metadata([overwrite, ...])

Add raw annotations into the Epochs metadata data frame.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_proj(projs[, remove_existing, verbose])

Add SSP projection vectors.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

anonymize([daysback, keep_his, verbose])

Anonymize measurement information in place.

apply_baseline([baseline, verbose])

Baseline correct epochs.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of channels.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

apply_proj([verbose])

Apply the signal space projection (SSP) operators to the data.

as_type([ch_type, mode])

Compute virtual epochs using interpolated fields.

average([picks, method, by_event_type])

Compute an average over epochs.

compute_psd([method, fmin, fmax, tmin, ...])

Perform spectral analysis on sensor data.

compute_tfr(method, freqs, *[, tmin, tmax, ...])

Compute a time-frequency representation of epoched data.

Return copy of Epochs instance.

crop([tmin, tmax, include_tmax, verbose])

Crop a time interval from the epochs.

decimate(decim[, offset, verbose])

Decimate the time-series data.

Remove SSP projection vector.

drop(indices[, reason, verbose])

Drop epochs based on indices or boolean mask.

drop_bad([reject, flat, verbose])

Drop bad epochs without retaining the epochs data.

drop_channels(ch_names[, on_missing])

drop_log_stats([ignore])

Compute the channel stats based on a drop_log from Epochs.

equalize_event_counts([event_ids, method, ...])

Equalize the number of trials in each condition.

export(fname[, fmt, overwrite, verbose])

Export Epochs to external formats.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_annotations_per_epoch(*[, with_extras])

Get a list of annotations that occur during each epoch.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, item, units, tmin, tmax, ...])

Get all epochs as a 3D array.

Get a DigMontage from instance.

interpolate_bads([reset_bads, mode, origin, ...])

Interpolate bad MEG and EEG channels.

interpolate_to(sensors[, origin, method, reg])

Interpolate EEG data onto a new montage.

Iterate over epochs as a sequence of Evoked objects.

Load the data if not already preloaded.

next([return_event_id])

Iterate over epoch data.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, scalings, n_epochs, ...])

plot_drop_log([threshold, n_max_plot, ...])

Show the channel stats based on a drop_log from Epochs.

plot_image([picks, sigma, vmin, vmax, ...])

Plot Event Related Potential / Fields image.

plot_projs_topomap([ch_type, sensors, ...])

plot_psd([fmin, fmax, tmin, tmax, picks, ...])

Plot power or amplitude spectra.

plot_psd_topo([tmin, tmax, fmin, fmax, ...])

plot_psd_topomap([bands, tmin, tmax, ...])

plot_sensors([kind, ch_type, title, ...])

Plot sensor positions.

plot_topo_image([layout, sigma, vmin, vmax, ...])

Plot Event Related Potential / Fields image on topographies.

rename_channels(mapping[, allow_duplicates, ...])

reorder_channels(ch_names)

resample(sfreq, *[, npad, window, n_jobs, ...])

reset_drop_log_selection()

Reset the drop_log and selection entries.

save(fname[, split_size, fmt, overwrite, ...])

Save epochs in a fif file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

set_annotations(annotations[, on_missing, ...])

Setter for Epoch annotations from Raw.

set_channel_types(mapping, *[, ...])

Specify the sensor types of channels.

set_eeg_reference([ref_channels, ...])

Specify which reference to use for EEG data.

set_meas_date(meas_date)

Set the measurement start date.

set_montage(montage[, match_case, ...])

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

standard_error([picks, by_event_type])

Compute standard error over epochs.

subtract_evoked([evoked])

Subtract an evoked response from each epoch.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

Proper units of measure:

V: eeg, eog, seeg, dbs, emg, ecg, bio, ecog

EpochsArray does not set Annotations. If you would like to create simulated data with Annotations that are then preserved in the Epochs object, you would use mne.io.RawArray first and then create an mne.Epochs object.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Return an Epochs object with a copied subset of epochs.

See Notes for use cases.

The subset of epochs.

Epochs can be accessed as epochs[...] in several ways:

Integer or slice: epochs[idx] will return an Epochs object with a subset of epochs chosen by index (supports single index and Python-style slicing).

String: epochs['name'] will return an Epochs object comprising only the epochs labeled 'name' (i.e., epochs created around events with the label 'name').

If there are no epochs labeled 'name' but there are epochs labeled with /-separated tags (e.g. 'name/left', 'name/right'), then epochs['name'] will select the epochs with labels that contain that tag (e.g., epochs['left'] selects epochs labeled 'audio/left' and 'visual/left', but not 'audio_left').

If multiple tags are provided as a single string (e.g., epochs['name_1/name_2']), this selects epochs containing all provided tags. For example, epochs['audio/left'] selects 'audio/left' and 'audio/quiet/left', but not 'audio/right'. Note that tag-based selection is insensitive to order: tags like 'audio/left' and 'left/audio' will be treated the same way when selecting via tag.

List of strings: epochs[['name_1', 'name_2', ... ]] will return an Epochs object comprising epochs that match any of the provided names (i.e., the list of names is treated as an inclusive-or condition). If none of the provided names match any epoch labels, a KeyError will be raised.

If epoch labels are /-separated tags, then providing multiple tags as separate list entries will likewise act as an inclusive-or filter. For example, epochs[['audio', 'left']] would select 'audio/left', 'audio/right', and 'visual/left', but not 'visual/right'.

Pandas query: epochs['pandas query'] will return an Epochs object with a subset of epochs (and matching metadata) selected by the query called with self.metadata.eval, e.g.:

would return all epochs whose associated col_a metadata was greater than two, and whose col_b metadata was the string ‚Äòfoo‚Äô. Query-based indexing only works if Pandas is installed and self.metadata is a pandas.DataFrame.

Facilitate iteration over epochs.

This method resets the object iteration state to the first epoch.

This enables the use of this Python pattern:

Where epoch is given by successive outputs of mne.Epochs.next().

Return the number of epochs.

The number of remaining epochs.

This function only works if bad epochs have been dropped.

Add raw annotations into the Epochs metadata data frame.

Adds three columns to the metadata consisting of a list in each row: - annot_onset: the onset of each Annotation within the Epoch relative to the start time of the Epoch (in seconds). - annot_duration: the duration of each Annotation within the Epoch in seconds. - annot_description: the free-form text description of each Annotation.

Whether to overwrite existing columns in metadata or not. Default is False.

Whether to include the annotations extra fields in the output, as an additional last element of the tuple. Default is True.

The modified instance (instance is also modified inplace).

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add SSP projection vectors.

List with projection vectors.

Remove the projection vectors currently in the file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Anonymize measurement information in place.

Number of days to subtract from all dates. If None (default), the acquisition date, info['meas_date'], will be set to January 1À¢·µó, 2000. This parameter is ignored if info['meas_date'] is None (i.e., no acquisition date has been set).

If True, his_id of subject_info will not be overwritten. Defaults to False.

This could mean that info is not fully anonymized. Use with caution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Removes potentially identifying information if it exists in info. Specifically for each of the following we use:

A default value, or as specified by daysback.

Default values, except for ‚Äòbirthday‚Äô which is adjusted to maintain the subject age.

Dates use the meas_date logic, and experimenter a default string.

Dates use the meas_date logic, meta info uses defaults.

If info['meas_date'] is None, it will remain None during processing the above fields.

Baseline correct epochs.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each epoch and channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire epoch.

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected Epochs object.

Baseline correction can be done multiple times, but can never be reverted once the data has been loaded.

Apply a function to a subset of channels.

The function fun is applied to the channels defined in picks. The epochs object‚Äôs data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to channels in picks). The object has to have the data loaded e.g. with preload=True or self.load_data().

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) if channel_wise=True and (len(picks), n_times) otherwise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if channel_wise=False as the workload is split across channels.

Whether to apply the function to each channel in each epoch individually. If False, the function will be applied to all epochs and channels at once. Default True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The epochs object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‚Äòauto‚Äô, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal ‚Äúx_a(t)‚Äù of ‚Äúx(t)‚Äù is:

where ‚ÄúF‚Äù is the Fourier transform, ‚ÄúU‚Äù the unit step function, and ‚Äúy‚Äù the Hilbert transform of ‚Äúx‚Äù. One usage of the analytic signal is the computation of the envelope signal, which is given by ‚Äúe(t) = abs(x_a(t))‚Äù. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Apply the signal space projection (SSP) operators to the data.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Once the projectors have been applied, they can no longer be removed. It is usually not recommended to apply the projectors at too early stages, as they are applied automatically later on (e.g. when computing inverse solutions). Hint: using the copy method individual projection vectors can be tested without affecting the original data. With evoked data, consider the following example:

Compute virtual epochs using interpolated fields.

Using virtual epochs to compute inverse can yield unexpected results. The virtual channels have '_v' appended at the end of the names to emphasize that the data contained in them are interpolated.

The destination channel type. It can be ‚Äòmag‚Äô or ‚Äògrad‚Äô.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used. 'fast' should be sufficient for most applications.

The transformed epochs object containing only virtual channels.

This method returns a copy and does not modify the data it operates on. It also returns an EpochsArray instance.

Compute an average over epochs.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

How to combine the data. If ‚Äúmean‚Äù/‚Äùmedian‚Äù, the mean/median are returned. Otherwise, must be a callable which, when passed an array of shape (n_epochs, n_channels, n_time) returns an array of shape (n_channels, n_time). Note that due to file type limitations, the kind for all these will be ‚Äúaverage‚Äù.

When False (the default) all epochs are processed together and a single Evoked object is returned. When True, epochs are first grouped by event type (as specified using the event_id parameter) and a list is returned containing a separate Evoked object for each event type. The .comment attribute is set to the label of the event type.

The averaged epochs. When by_event_type=True was specified, a list is returned containing a separate Evoked object for each event type. The list has the same order as the event types as specified in the event_id dictionary.

Computes an average of all epochs in the instance, even if they correspond to different conditions. To average by condition, do epochs[condition].average() for each condition separately.

When picks is None and epochs contain only ICA channels, no channels are selected, resulting in an error. This is because ICA channels are not considered data channels (they are of misc type) and only data channels are selected when picks is None.

The method parameter allows e.g. robust averaging. For example, one could do:

This would compute the trimmed mean.

The current gradient compensation grade.

Perform spectral analysis on sensor data.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. Default is 'multitaper'.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

If True, the mean is subtracted from each segment before computing its spectrum.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

The spectral representation of each epoch.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70‚Äì73, 1967. doi:10.1109/TAU.1967.1161901.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371‚Äì1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Compute a time-frequency representation of epoched data.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [2], and 'stockwell' uses the S-transform [3][4][5][6]. None (the default) only works when using __setstate__ and will raise an error otherwise.

The frequencies at which to compute the power estimates. If method='stockwell' this must be a length 2 iterable specifying lowest and highest frequencies, or 'auto' (to use all available frequencies). For other methods, must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

What kind of estimate to return. Allowed values are "complex", "phase", and "power". Default is "power".

Whether to return average power across epochs (instead of single-trial power). average=True is not compatible with output="complex" or output="phase". Ignored if method="stockwell" (Stockwell method requires averaging). Default is False.

Whether to return inter-trial coherence (ITC) as well as power estimates. If True then must specify average=True (or method="stockwell", average="auto"). Default is False.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method, n_fft, width for Stockwell method, or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet(), tfr_array_stockwell(), and tfr_array_multitaper() for additional details.

The time-frequency-resolved power estimates.

The inter-trial coherence (ITC). Only returned if return_itc=True.

If average=True (or method="stockwell", average="auto") the result will be an AverageTFR instead of an EpochsTFR.

R. G. Stockwell. Why use the S-transform? In Luigi Rodino, Bert-Wolfgang Schulze, and M. W. Wong, editors, Pseudo-Differential Operators: Partial Differential Equations and Time-Frequency Analysis, number 52 in Fields Institute Communications, pages 279‚Äì309. American Mathematical Society, Providence, RI, 2007. doi:10.1090/fic/052.

Ali Moukadem, Zied Bouguila, Djaffar Ould Abdeslam, and Alain Dieterlen. Stockwell transform optimization applied on the detection of split in heart sounds. In Proceedings of EUSIPCO-2014, 2015‚Äì2019. Lisbon, 2014. IEEE. URL: https://ieeexplore.ieee.org/document/6952743.

Katherine L. Wheat, Piers L. Cornelissen, Stephen J. Frost, and Peter C. Hansen. During visual word recognition, phonology is accessed within 100 ms and may be mediated by a speech production code: evidence from magnetoencephalography. Journal of Neuroscience, 30(15):5229‚Äì5233, 2010. doi:10.1523/JNEUROSCI.4448-09.2010.

Kevin A. Jones, Bernice Porjesz, David Chorlian, Madhavi Rangaswamy, Chella Kamarajan, Ajayan Padmanabhapillai, Arthur Stimus, and Henri Begleiter. S-transform time-frequency analysis of P300 reveals deficits in individuals diagnosed with alcoholism. Clinical Neurophysiology, 117(10):2128‚Äì2143, 2006. doi:10.1016/j.clinph.2006.02.028.

Return copy of Epochs instance.

A copy of the object.

Crop a time interval from the epochs.

Start time of selection in seconds.

End time of selection in seconds.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped epochs object, modified in-place.

Unlike Python slices, MNE time intervals by default include both their end points; crop(tmin, tmax) returns the interval tmin <= t <= tmax. Pass include_tmax=False to specify the half-open interval tmin <= t < tmax instead.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / ‚Äúdecimation‚Äù refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [7], p. 172; which cites [8]):

‚Äú‚Ä¶ a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).‚Äù

Hence ‚Äúdecimation‚Äù in MNE is what is considered ‚Äúcompression‚Äù in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Remove SSP projection vector.

The projection vector can only be removed if it is inactive (has not been applied to the data).

Index of the projector to remove. Can also be ‚Äúall‚Äù (default) to remove all projectors.

Drop epochs based on indices or boolean mask.

The indices refer to the current set of undropped epochs rather than the complete set of dropped and undropped epochs. They are therefore not necessarily consistent with any external indices (e.g., behavioral logs). To drop epochs based on external criteria, do not use the preload=True flag when constructing an Epochs object, and call this method before calling the mne.Epochs.drop_bad() or mne.Epochs.load_data() methods.

Set epochs to remove by specifying indices to remove or a boolean mask to apply (where True values get removed). Events are correspondingly modified.

Reason(s) for dropping the epochs (‚ÄòECG‚Äô, ‚Äòtimeout‚Äô, ‚Äòblink‚Äô etc). Reason(s) are applied to all indices specified. Default: ‚ÄòUSER‚Äô.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs with indices dropped. Operates in-place.

Drop bad epochs without retaining the epochs data.

Should be used before slicing operations.

This operation is slow since all epochs have to be read from disk. To avoid reading epochs from disk multiple times, use mne.Epochs.load_data().

To constrain the time period used for estimation of signal quality, set epochs.reject_tmin and epochs.reject_tmax, respectively.

Reject epochs based on maximum peak-to-peak signal amplitude (PTP) or custom functions. Peak-to-peak signal amplitude is defined as the absolute difference between the lowest and the highest signal value. In each individual epoch, the PTP is calculated for every channel. If the PTP of any one channel exceeds the rejection threshold, the respective epoch will be dropped.

The dictionary keys correspond to the different channel types; valid keys can be any channel type present in the object.

Custom rejection criteria can be also be used by passing a callable, e.g., to check for 99th percentile of absolute values of any channel across time being bigger than 1 mV. The callable must return a (good, reason) tuple: good must be bool and reason must be str, list, or tuple where each entry is a str:

If rejection is based on a signal difference calculated for each channel separately, applying baseline correction does not affect the rejection procedure, as the difference will be preserved.

If reject is a callable, than any criteria can be used to reject epochs (including maxima and minima).

If reject is None, no rejection is performed. If 'existing' (default), then the rejection parameters set at instantiation are used.

Reject epochs based on minimum peak-to-peak signal amplitude (PTP) or a custom function. Valid keys can be any channel type present in the object. If using PTP, values are floats that set the minimum acceptable PTP. If the PTP is smaller than this threshold, the epoch will be dropped. If None then no rejection is performed based on flatness of the signal. If a custom function is used than flat can be used to reject epochs based on any criteria (including maxima and minima). If 'existing', then the flat parameters set during epoch creation are used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs with bad epochs dropped. Operates in-place.

Dropping bad epochs can be done multiple times with different reject and flat parameters. However, once an epoch is dropped, it is dropped forever, so if more lenient thresholds may subsequently be applied, epochs.copy should be used.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Examples using drop_channels:

Single trial linear regression analysis with the LIMO dataset

Compute the channel stats based on a drop_log from Epochs.

The drop reasons to ignore.

Total percentage of epochs dropped.

Equalize the number of trials in each condition.

It tries to make the remaining epochs occurring as close as possible in time. This method works based on the idea that if there happened to be some time-varying (like on the scale of minutes) noise characteristics during a recording, they could be compensated for (to some extent) in the equalization process. This method thus seeks to reduce any of those effects by minimizing the differences in the times of the events within a Epochs instance. For example, if one event type occurred at time points [1, 2, 3, 4, 120, 121] and the another one at [3.5, 4.5, 120.5, 121.5], this method would remove the events at times [1, 2] for the first event type ‚Äì and not the events at times [120, 121].

The event types to equalize.

If None (default), equalize the counts of all event types present in the Epochs instance.

If a list, each element can either be a string (event name) or a list of strings. In the case where one of the entries is a list of strings, event types in that list will be grouped together before equalizing trial counts across conditions.

If a dictionary, the keys are considered as the event names whose counts to equalize, i.e., passing dict(A=1, B=2) will have the same effect as passing ['A', 'B']. This is useful if you intend to pass an event_id dictionary that was used when creating Epochs.

In the case where partial matching is used (using / in the event names), the event types will be matched according to the provided tags, that is, processing works as if the event_ids matched by the provided tags had been supplied instead. The event_ids must identify non-overlapping subsets of the epochs.

If 'truncate', events will be truncated from the end of each event list. If 'mintime', timing differences between each event list will be minimized. If 'random', events will be randomly selected from each event list.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state. Used only if method='random'.

The modified instance. It is modified in-place.

Indices from the original events list that were dropped.

For example (if epochs.event_id was {'Left': 1, 'Right': 2, 'Nonspatial':3}:

epochs.equalize_event_counts([[‚ÄòLeft‚Äô, ‚ÄòRight‚Äô], ‚ÄòNonspatial‚Äô])

would equalize the number of trials in the 'Nonspatial' condition with the total number of trials in the 'Left' and 'Right' conditions combined.

If multiple indices are provided (e.g. 'Left' and 'Right' in the example above), it is not guaranteed that after equalization the conditions will contribute equally. E.g., it is possible to end up with 70 'Nonspatial' epochs, 69 'Left' and 1 'Right'.

Changed in version 0.23: Default to equalizing all events in the passed instance if no event names were specified explicitly.

Export Epochs to external formats.

EEGLAB (.set, uses eeglabio)

Since we are exporting to external formats, there‚Äôs no guarantee that all the info will be preserved in the external format. See Notes for details.

Name of the output file.

Format of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.Epochs.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.Epochs.apply_proj().

For EEGLAB exports, channel locations are expanded to full EEGLAB format. For more details see eeglabio.utils.cart_to_eeglab().

The filename if the epochs are loaded from disk.

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‚Äòauto‚Äô (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=‚Äôhamming‚Äô and fir_design=‚Äùfirwin2‚Äù, and half that for ‚Äúfirwin‚Äù).

str: A human-readable time in units of ‚Äús‚Äù or ‚Äúms‚Äù (e.g., ‚Äú10s‚Äù or ‚Äú5500ms‚Äù) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=‚Äùfirwin‚Äù, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be ‚Äúauto‚Äù (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be ‚Äúauto‚Äù (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be ‚Äúhamming‚Äù (default), ‚Äúhann‚Äù (default in 0.13), or ‚Äúblackman‚Äù.

Can be ‚Äúfirwin‚Äù (default) to use scipy.signal.firwin(), or ‚Äúfirwin2‚Äù to use scipy.signal.firwin2(). ‚Äúfirwin‚Äù uses a time-domain design technique that generally gives improved attenuation using fewer samples than ‚Äúfirwin2‚Äù.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Get a list of annotations that occur during each epoch.

Whether to include the annotations extra fields in the output, as an additional last element of the tuple. Default is False.

A list of lists (with length equal to number of epochs) where each inner list contains any annotations that overlap the corresponding epoch. Annotations are stored as a tuple of onset, duration, description (not as a Annotations object), where the onset is now relative to time=0 of the epoch, rather than time=0 of the original continuous (raw) data.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get all epochs as a 3D array.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The items to get. See mne.Epochs.__getitem__() for a description of valid options. This can be substantially faster for obtaining an ndarray than __getitem__() for repeated access on large Epochs objects. None (default) is an alias for slice(None).

Specify the unit(s) that the data should be returned in. If None (default), the data is returned in the channel-type-specific default units, which are SI units (see Internal representation (units) and data channels). If a string, must be a sub-multiple of SI units that will be used to scale the data from all channels of the type associated with that unit. This only works if the data contains one channel type that has a unit (unitless channel types are left unchanged). For example if there are only EEG and STIM channels, units='uV' will scale EEG channels to micro-Volts while STIM channels will be unchanged. Finally, if a dictionary is provided, keys must be channel types, and values must be units to scale the data of that channel type to. For example dict(grad='fT/cm', mag='fT') will scale the corresponding types accordingly, but all other channel types will remain in their channel-type-specific default unit.

Start time of data to get in seconds.

End time of data to get in seconds.

Whether to return a copy of the object‚Äôs data, or (if possible) a view. See the NumPy docs for an explanation. Default is False in 1.6 but will change to True in 1.7, set it explicitly to avoid a warning in some cases. A view is only possible when item is None, picks is None, units is None, and data are preloaded.

Using copy=False and then modifying the returned data will in turn modify the Epochs object. Use with caution!

Changed in version 1.7: The default changed from False to True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs data. Will be a copy when copy=True and will be a view when possible when copy=False.

Get a DigMontage from instance.

A copy of the channel positions, if available, otherwise None.

Interpolate bad MEG and EEG channels.

If True, remove the bads from info.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used for interpolation of channels using the minimum-norm method.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for each channel type.

"meg" channels support "MNE" (default) and "nan"

"eeg" channels support "spline" (default), "MNE" and "nan"

"fnirs" channels support "nearest" (default) and "nan"

"ecog" channels support "spline" (default) and "nan"

"seeg" channels support "spline" (default) and "nan"

None is an alias for:

If a str is provided, the method will be applied to all channel types supported and available in the instance. The method "nan" will replace the channel data with np.nan.

Be careful when using method="nan"; the default value reset_bads=True may not be what you want.

The channels to exclude from interpolation. If excluded a bad channel will stay in bads.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

The "MNE" method uses minimum-norm projection to a sphere and back.

Examples using interpolate_bads:

Single trial linear regression analysis with the LIMO dataset

Interpolate EEG data onto a new montage.

Be careful, only EEG channels are interpolated. Other channel types are not interpolated.

The target montage containing channel positions to interpolate onto.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for EEG channels. Supported methods are ‚Äòspline‚Äô (default) and ‚ÄòMNE‚Äô.

The regularization parameter for the interpolation method (only used when the method is ‚Äòspline‚Äô).

The instance with updated channel locations and data.

This method is useful for standardizing EEG layouts across datasets. However, some attributes may be lost after interpolation.

Iterate over epochs as a sequence of Evoked objects.

The Evoked objects yielded will each contain a single epoch (i.e., no averaging is performed).

This method resets the object iteration state to the first epoch.

If False copies of data and measurement info will be omitted to save time.

Load the data if not already preloaded.

This function operates in-place.

Iterate over epoch data.

If True, return both the epoch data and an event_id.

The event id. Only returned if return_event_id is True.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Bad epochs can be marked with a left click on top of the epoch. Bad channels can be selected by clicking the channel name on the left side of the main axes. Calling this function drops all the selected bad epochs as well as bad epochs marked beforehand with rejection parameters.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Scaling factors for the traces. If a dictionary where any value is 'auto', the scaling factor is set to match the 99.5th percentile of the respective data. If 'auto', all scalings (for all channel types) are set to 'auto'. If any values are 'auto' and the data is not preloaded, a subset up to 100 MB will be loaded. If None, defaults to:

A particular scaling value s corresponds to half of the visualized signal range around zero (i.e. from 0 to +s or from 0 to -s). For example, the default scaling of 20e-6 (20¬µV) for EEG signals means that the visualized range will be 40 ¬µV (20 ¬µV in the positive direction and 20 ¬µV in the negative direction).

The number of epochs per view. Defaults to 20.

The number of channels per view. Defaults to 20.

The title of the window. If None, the event names (from epochs.event_id) will be displayed. Defaults to None.

Events to show with vertical bars. You can use plot_events as a legend for the colors. By default, the coloring scheme is the same. True plots epochs.events. Defaults to False (do not plot events).

If the epochs have been resampled, the events no longer align with the data.

Changed in version 1.6: Passing events=None was disallowed. The new equivalent is events=False.

Color(s) to use for events. To show all events in the same color, pass any matplotlib-compatible color. To color events differently, pass a dict that maps event names or integer event numbers to colors (must include entries for all events, or include a ‚Äúfallback‚Äù entry with key -1). If None, colors are chosen from the current Matplotlib color cycle. Defaults to None.

Order in which to plot channel types.

Show figure if True. Defaults to True.

Whether to halt program execution until the figure is closed. Useful for rejecting bad trials on the fly by clicking on an epoch. Defaults to False.

Amount to decimate the data during display for speed purposes. You should only decimate if the data are sufficiently low-passed, otherwise aliasing can occur. The ‚Äòauto‚Äô mode (default) uses the decimation that results in a sampling rate at least three times larger than info['lowpass'] (e.g., a 40 Hz lowpass will result in at least a 120 Hz displayed sample rate).

Noise covariance used to whiten the data while plotting. Whitened data channels are scaled by scalings['whitened'], and their channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().

Whether to directly call the butterfly view.

Whether to show scrollbars when the plot is initialized. Can be toggled after initialization by pressing z (‚Äúzen mode‚Äù) while the plot window is focused. Default is True.

Whether to show scale bars when the plot is initialized. Can be toggled after initialization by pressing s while the plot window is focused. Default is True.

Colors to use for individual epochs. If None, use default colors.

Determines to label the event markers on the plot. If True, uses epochs.event_id. If False, uses integer event codes instead of IDs. If a dict is passed, uses its keys as event labels on the plot for entries whose values are integer codes for events being drawn. Ignored if events=False.

How to group channels. 'type' groups by channel type, 'original' plots in the order of ch_names, 'selection' uses Elekta‚Äôs channel groupings (only works for Neuromag data), 'position' groups the channels by the positions of the sensors. 'selection' and 'position' modes allow custom selections by using a lasso selector on the topomap. In butterfly mode, 'type' and 'original' group the channels by type, whereas 'selection' and 'position' use regional grouping. 'type' and 'original' modes are ignored when order is not None. Defaults to 'type'.

Whether to load all data (not just the visible portion) into RAM and apply preprocessing (e.g., projectors) to the full data array in a separate processor thread, instead of window-by-window during scrolling. The default None uses the MNE_BROWSER_PRECOMPUTE variable, which defaults to 'auto'. 'auto' compares available RAM space to the expected size of the precomputed data, and precomputes only if enough RAM is available. This is only used with the Qt backend.

Changed in version 1.0: Support for the MNE_BROWSER_PRECOMPUTE config variable.

Whether to use OpenGL when rendering the plot (requires pyopengl). May increase performance, but effect is dependent on system CPU and graphics hardware. Only works if using the Qt backend. Default is None, which will use False unless the user configuration variable MNE_BROWSER_USE_OPENGL is set to 'true', see mne.set_config().

Can be ‚Äúauto‚Äù, ‚Äúlight‚Äù, or ‚Äúdark‚Äù or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_BROWSER_THEME will be used, defaulting to ‚Äúauto‚Äù if it‚Äôs not found. Only supported by the 'qt' backend.

Can be ‚Äúchannels‚Äù, ‚Äúempty‚Äù, or ‚Äúhidden‚Äù to set the overview bar mode for the 'qt' backend. If None (default), the config option MNE_BROWSER_OVERVIEW_MODE will be used, defaulting to ‚Äúchannels‚Äù if it‚Äôs not found.

If True (default), a splash screen is shown during the application startup. Only applicable to the qt backend.

The arrow keys (up/down/left/right) can be used to navigate between channels and epochs and the scaling can be adjusted with - and + (or =) keys, but this depends on the backend matplotlib is configured to use (e.g., mpl.use(TkAgg) should work). Full screen mode can be toggled with f11 key. The amount of epochs and channels per view can be adjusted with home/end and page down/page up keys. h key plots a histogram of peak-to-peak values along with the used rejection thresholds. Butterfly plot can be toggled with b key. Left mouse click adds a vertical line to the plot. Click ‚Äòhelp‚Äô button at bottom left corner of the plotter to view all the options.

MNE-Python provides two different backends for browsing plots (i.e., raw.plot(), epochs.plot(), and ica.plot_sources()). One is based on matplotlib, and the other is based on PyQtGraph. You can set the backend temporarily with the context manager mne.viz.use_browser_backend(), you can set it for the duration of a Python session using mne.viz.set_browser_backend(), and you can set the default for your computer via mne.set_config('MNE_BROWSER_BACKEND', 'matplotlib') (or 'qt').

For the PyQtGraph backend to run in IPython with block=False you must run the magic command %gui qt5 first.

To report issues with the PyQtGraph backend, please use the issues of mne-qt-browser.

Creating MNE-Python data structures from scratch

Show the channel stats based on a drop_log from Epochs.

The percentage threshold to use to decide whether or not to plot. Default is zero (always plot).

Maximum number of channels to show stats for.

The subject name to use in the title of the plot. If None, do not display a subject name.

Changed in version 0.23: Added support for None.

Changed in version 1.0: Defaults to None.

Color to use for the bars.

The drop reasons to ignore.

Plot Event Related Potential / Fields image.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided. picks interacts with group_by and combine to determine the number of figures generated; see Notes.

The standard deviation of a Gaussian smoothing window applied along the epochs axis of the image. If 0, no smoothing is applied. Defaults to 0.

The min value in the image (and the ER[P/F]). The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers. If vmin is None and multiple plots are returned, the limit is equalized within channel types. Hint: to specify the lower limit of the data, use vmin=lambda data: data.min().

The max value in the image (and the ER[P/F]). The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers. If vmin is None and multiple plots are returned, the limit is equalized within channel types.

Display or not a colorbar.

If not None, order is used to reorder the epochs along the y-axis of the image. If it is an array of int, its length should match the number of good epochs. If it is a callable it should accept two positional parameters (times and data, where data.shape == (len(good_epochs), len(times))) and return an array of indices that will sort data along its first axis.

The units of the channel types used for axes labels. If None, defaults to units=dict(eeg='¬µV', grad='fT/cm', mag='fT').

The scalings of the channel types to be applied for plotting. If None, defaults to scalings=dict(eeg=1e6, grad=1e13, mag=1e15, eog=1e6).

Colormap. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the scale. Up and down arrows can be used to change the colormap. If ‚Äòinteractive‚Äô, translates to (‚ÄòRdBu_r‚Äô, True). If None, ‚ÄúRdBu_r‚Äù is used, unless the data is all positive, in which case ‚ÄúReds‚Äù is used.

Figure instance to draw the image to. Figure must contain the correct number of axes for drawing the epochs image, the evoked response, and a colorbar (depending on values of evoked and colorbar). If None a new figure is created. Defaults to None.

List of Axes objects in which to draw the image, evoked response, and colorbar (in that order). Length of list must be 1, 2, or 3 (depending on values of colorbar and evoked parameters). If a dict, each entry must be a list of Axes objects with the same constraints as above. If both axes and group_by are dicts, their keys must match. Providing non-None values for both fig and axes results in an error. Defaults to None.

Times (in seconds) at which to draw a line on the corresponding row of the image (e.g., a reaction time associated with each epoch). Note that overlay_times should be ordered to correspond with the Epochs object (i.e., overlay_times[0] corresponds to epochs[0], etc).

How to aggregate across channels. If None, channels are combined by computing GFP/RMS, unless group_by is also None and picks is a list of specific channels (not channel types), in which case no combining is performed and each channel gets its own figure. If a string, "mean" uses numpy.mean(), "median" computes the marginal median, "std" uses numpy.std(), and "gfp" computes global field power for EEG channels and RMS amplitude for MEG channels. If callable(), it must operate on an array of shape (n_epochs, n_channels, n_times) and return an array of shape (n_epochs, n_times). For example:

See Notes for further details. Defaults to None.

Specifies which channels are aggregated into a single figure, with aggregation method determined by the combine parameter. If not None, one Figure is made per dict entry; the dict key will be used as the figure title and the dict values must be lists of picks (either channel names or integer indices of epochs.ch_names). For example:

Note that within a dict entry all channels must have the same type. group_by interacts with picks and combine to determine the number of figures generated; see Notes. Defaults to None.

Draw the ER[P/F] below the image or not.

Arguments passed to a call to plot_compare_evokeds to style the evoked plot below the image. Defaults to an empty dictionary, meaning plot_compare_evokeds will be called with default parameters.

If str, will be plotted as figure title. Otherwise, the title will indicate channel(s) or channel type being plotted. Defaults to None.

Whether to clear the axes before plotting (if fig or axes are provided). Defaults to False.

One figure per channel, channel type, or group, depending on values of picks, group_by, and combine. See Notes.

You can control how channels are aggregated into one figure or plotted in separate figures through a combination of the picks, group_by, and combine parameters. If group_by is a dict, the result is one Figure per dictionary key (for any valid values of picks and combine). If group_by is None, the number and content of the figures generated depends on the values of picks and combine, as summarized in this table:

None, int, list of int, ch_name, list of ch_names, ch_type, list of ch_types

None, string, or callable

1 figure per dict key

None, ch_type, list of ch_types

None, string, or callable

int, ch_name, list of int, list of ch_names

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None it will return all channel types present.. If a list of ch_types is provided, it will return multiple figures. Defaults to None.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches. Only applies when plotting multiple topomaps at a time.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all projectors of the same channel type (instead of separately for each projector), using the min/max of the data for that channel type. If vlim is "joint", info must not be None. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of projectors. Default is None.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (‚ïé) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (‚ãÆ). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

If False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap.

Plot power spectral density (PSD) in units (dB/Hz) if dB=True and estimate='power'. Plot PSD in units (amplitude**2/Hz) if dB=False and estimate='power'. Plot amplitude spectral density (ASD) in units (amplitude/sqrt(Hz)) if dB=False and estimate='amplitude'. Plot ASD in units (dB/sqrt(Hz)) if dB=True and estimate='amplitude'.

Can be ‚Äúpower‚Äù for power spectral density (PSD; default), ‚Äúamplitude‚Äù for amplitude spectrum density (ASD).

Scale of the frequency axis. Default is 'linear'.

Mode for plotting area. If ‚Äòstd‚Äô, the mean +/- 1 STD (across channels) will be plotted. If ‚Äòrange‚Äô, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Alpha for the PSD line. Can be None (default) to use 1.0 when average=True and 0.1 when average=False.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channels names to exclude from being shown. If ‚Äòbads‚Äô, the bad channels are excluded. Pass an empty list to plot all channels (including channels marked ‚Äúbad‚Äù, if any).

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of channel types present in the object.. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure with frequency spectra of the data channels.

This method exists to support legacy code; for new code the preferred idiom is inst.compute_psd().plot() (where inst is an instance of Raw, Epochs, or Evoked).

LEGACY: New code should use .compute_psd().plot_topo().

Plot power spectral density, separately for each channel.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=100.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch(). Defaults to dict(n_fft=2048).

Figure distributing one image per channel across sensor topography.

LEGACY: New code should use .compute_psd().plot_topomap().

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‚Äò%0.3f‚Äô if dB=False and ‚Äò%0.1f‚Äô if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure showing one scalp topography per frequency band.

Plot sensor positions.

Whether to plot the sensors as 3d, topomap or as an interactive sensor selection dialog. Available options ‚Äòtopomap‚Äô, ‚Äò3d‚Äô, ‚Äòselect‚Äô. If ‚Äòselect‚Äô, a set of channels can be selected interactively by using lasso selector or clicking while holding control key. The selected channels are returned along with the figure instance. Defaults to ‚Äòtopomap‚Äô.

The channel type to plot. Available options 'mag', 'grad', 'eeg', 'seeg', 'dbs', 'ecog', 'all'. If 'all', all the available mag, grad, eeg, seeg, dbs, and ecog channels are plotted. If None (default), then channels are chosen in the order given above.

Title for the figure. If None (default), equals to 'Sensor positions (%s)' % ch_type.

Whether to display all channel names. If an array, only the channel names in the array are shown. Defaults to False.

Channel groups for coloring the sensors. If None (default), default coloring scheme is used. If ‚Äòposition‚Äô, the sensors are divided into 8 regions. See order kwarg of mne.viz.plot_raw(). If array, the channels are divided by picks given in the array.

Whether to project the 3d locations to a sphere. When False, the sensor array appears similar as to looking downwards straight above the subject‚Äôs head. Has no effect when kind=‚Äô3d‚Äô. Defaults to True.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Whether to halt program execution until the figure is closed. Defaults to False.

Show figure if True. Defaults to True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the sensor topography.

A list of selected channels. Only returned if kind=='select'.

This function plots the sensor locations from the info structure using matplotlib. For drawing the sensors using PyVista see mne.viz.plot_alignment().

Plot Event Related Potential / Fields image on topographies.

System specific sensor positions.

The standard deviation of the Gaussian smoothing to apply along the epoch axis to apply in the image. If 0., no smoothing is applied.

The min value in the image. The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers.

The max value in the image. The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers.

Whether to display a colorbar or not. If None a colorbar will be shown only if all channels are of the same type. Defaults to None.

If not None, order is used to reorder the epochs on the y-axis of the image. If it‚Äôs an array of int it should be of length the number of good epochs. If it‚Äôs a callable the arguments passed are the times vector and the data as 2d array (data.shape[1] == len(times)).

Colors to be mapped to the values.

Scaling factor for adjusting the relative size of the layout on the canvas.

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

Matplotlib borders style to be used for each sensor plot.

The figure face color. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

Whether to enable the lasso-selection tool to enable the user to select channels. The selected channels will be available in fig.lasso.selection.

Whether to show the figure. Defaults to True.

Figure distributing one image per channel across sensor topography.

In an interactive Python session, this plot will be interactive; clicking on a channel image will pop open a larger view of the image; this image will always have a colorbar even when the topo plot does not (because it shows multiple sensor types).

Whether or not projections are active.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be "auto" to use a padding that will result in a power-of-two size (can be much faster).

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly.

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn().

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled object.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent ‚Äì check your data!

Reset the drop_log and selection entries.

This method will simplify self.drop_log and self.selection so that they are meaningless (tuple of empty tuples and increasing integers, respectively). This can be useful when concatenating many Epochs instances, as drop_log can accumulate many entries which can become problematic when saving.

Save epochs in a fif file.

The name of the file, which should end with -epo.fif or -epo.fif.gz.

Large raw files are automatically split into multiple pieces. This parameter specifies the maximum size of each piece. If the parameter is an integer, it specifies the size in Bytes. It is also possible to pass a human-readable string, e.g., 100MB. Note: Due to FIFF file limitations, the maximum split size is 2GB.

Format to save data. Valid options are ‚Äòdouble‚Äô or ‚Äòsingle‚Äô for 64- or 32-bit float, or for 128- or 64-bit complex numbers respectively. Note: Data are processed with double precision. Choosing single-precision, the saved data will slightly differ due to the reduction in precision.

If True (default False), overwrite the destination file if it exists. To overwrite original file (the same one that was loaded), data must be preloaded upon reading. This defaults to True in 0.18 but will change to False in 0.19.

When splitting files, append a filename partition with the appropriate naming schema. For 'neuromag', a split file fname.fif will be named fname.fif, fname-1.fif, fname-2.fif, and so on. For 'bids', a filename is expected to consist of parts separated by underscores, like <part-1>_<part-N>_<suffix>.fif, and the according split naming will return filenames like <part-1>_<part-N>_split-01_<suffix>.fif, <part-1>_<part-N>_split-02_<suffix>.fif, and so on.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of path-like objects containing the path to each file split.

Bad epochs will be dropped before saving the epochs to disk.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [9] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627‚Äì1639, 1964. doi:10.1021/ac60214a047.

Setter for Epoch annotations from Raw.

This method does not handle offsetting the times based on first_samp or measurement dates, since that is expected to occur in Raw.set_annotations().

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs object with annotations.

Annotation onsets and offsets are stored as time in seconds (not as sample numbers).

If you have an -epo.fif file saved to disk created before 1.0, annotations can be added correctly only if no decimation or resampling was performed. We thus suggest to regenerate your mne.Epochs from raw and re-save to disk with 1.0+ if you want to safely work with Annotations in epochs.

Since this method does not handle offsetting the times based on first_samp or measurement dates, the recommended way to add Annotations is:

Specify the sensor types of channels.

A dictionary mapping channel names to sensor types, e.g., {'EEG061': 'eog'}.

What to do if the measurement unit of a channel is changed automatically to match the new sensor type.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The following sensor types are accepted:

bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci, eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase, fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp, seeg, stim, syst, temperature.

When working with eye-tracking data, see mne.preprocessing.eyetracking.set_channel_types_eyetrack().

Specify which reference to use for EEG data.

Use this function to explicitly specify the desired reference for EEG. This can be either an existing electrode or a new virtual channel. This function will re-reference the data according to the desired reference.

The name(s) of the channel(s) used to construct the reference for every channel of ch_type.

'average' to apply an average reference (default)

'REST' to use the Reference Electrode Standardization Technique infinity reference [10].

A dictionary mapping names of data channels to (lists of) names of reference channels. For example, {‚ÄòA1‚Äô: ‚ÄòA3‚Äô} would replace the data in channel ‚ÄòA1‚Äô with the difference between ‚ÄòA1‚Äô and ‚ÄòA3‚Äô. To take the average of multiple channels as reference, supply a list of channel names as the dictionary value, e.g. {‚ÄòA1‚Äô: [‚ÄòA2‚Äô, ‚ÄòA3‚Äô]} would replace channel A1 with A1 - mean(A2, A3).

An empty list, in which case MNE will not attempt any re-referencing of the data

If ref_channels='average' this argument specifies if the average reference should be computed as a projection (True) or not (False; default). If projection=True, the average reference is added as a projection and is not applied to the data (it can be applied afterwards with the apply_proj method). If projection=False, the average reference is directly applied to the data. If ref_channels is not 'average', projection must be set to False (the default in this case).

The name of the channel type to apply the reference to. Valid channel types are 'auto', 'eeg', 'ecog', 'seeg', 'dbs'. If 'auto', the first channel type of eeg, ecog, seeg or dbs that is found (in that order) will be selected.

Changed in version 1.2: list-of-str is now supported with projection=True.

Forward solution to use. Only used with ref_channels='REST'.

How to handle list-of-str ch_type. If False (default), one projector is created per channel type. If True, one projector is created across all channel types. This is only used when projection=True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data with EEG channels re-referenced. If ref_channels='average' and projection=True a projection will be added instead of directly re-referencing the data.

Convenience function for creating bipolar references.

Some common referencing schemes and the corresponding value for the ref_channels parameter:

A new virtual reference electrode is created by averaging the current EEG signal by setting ref_channels='average'. Bad EEG channels are automatically excluded if they are properly set in info['bads'].

Set ref_channels to a list containing the name of the channel that will act as the new reference, for example ref_channels=['Cz'].

A new virtual reference electrode is created by computing the average of the current EEG signal recorded from two or more selected channels. Set ref_channels to a list of channel names, indicating which channels to use. For example, to apply an average mastoid reference, when using the 10-20 naming scheme, set ref_channels=['M1', 'M2'].

The given EEG electrodes are referenced to a point at infinity using the lead fields in forward, which helps standardize the signals.

Set ref_channels to a dictionary mapping source channel names (str) to the reference channel names (str or list of str). Unlike the other approaches where the same reference is applied globally, you can set different references for different channels with this method. For example, to re-reference channel ‚ÄòA1‚Äô to ‚ÄòA2‚Äô and ‚ÄòB1‚Äô to the average of ‚ÄòB2‚Äô and ‚ÄòB3‚Äô, set ref_channels={'A1': 'A2', 'B1': ['B2', 'B3']}. Warnings are issued when a mapping involves bad channels or channels of different types.

If a reference is requested that is not the average reference, this function removes any pre-existing average reference projections.

During source localization, the EEG signal should have an average reference.

In order to apply a reference, the data must be preloaded. This is not necessary if ref_channels='average' and projection=True.

For an average or REST reference, bad EEG channels are automatically excluded if they are properly set in info['bads'].

D. Yao. A method to standardize a reference of scalp EEG recordings to a point at infinity. Physiological Measurement, 22(4):693‚Äì711, 2001. doi:10.1088/0967-3334/22/4/305.

Set the measurement start date.

The new measurement date. If datetime object, it must be timezone-aware and in UTC. A tuple of (seconds, microseconds) or float (alias for (meas_date, 0)) can also be passed and a datetime object will be automatically created. If None, will remove the time reference.

The modified raw instance. Operates in place.

If you want to remove all time references in the file, call mne.io.anonymize_info(inst.info) after calling inst.set_meas_date(None).

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

A montage containing channel positions. If a string or DigMontage is specified, the existing channel information will be updated with the channel positions from the montage. Valid strings are the names of the built-in montages that ship with MNE-Python; you can list those via mne.channels.get_builtin_montages(). If None (default), the channel positions will be removed from the Info.

If True (default), channel name matching will be case sensitive.

Whether to use a lookup table to match unrecognized channel location names to their known aliases. If True, uses the mapping in mne.io.constants.CHANNEL_LOC_ALIASES. If a dict is passed, it will be used instead, and should map from non-standard channel names to names in the specified montage. Default is False.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when channels have missing coordinates.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

Only EEG/sEEG/ECoG/DBS/fNIRS channels can have their positions set using a montage. Other channel types (e.g., MEG channels) should have their positions defined properly using their data reading functions.

Applying a montage will only set locations of channels that exist at the time it is applied. This means when re-referencing make sure to apply the montage only after calling mne.add_reference_channels()

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Compute standard error over epochs.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

When False (the default) all epochs are processed together and a single Evoked object is returned. When True, epochs are first grouped by event type (as specified using the event_id parameter) and a list is returned containing a separate Evoked object for each event type. The .comment attribute is set to the label of the event type.

The standard error over epochs. When by_event_type=True was specified, a list is returned containing a separate Evoked object for each event type. The list has the same order as the event types as specified in the event_id dictionary.

Subtract an evoked response from each epoch.

Can be used to exclude the evoked response when analyzing induced activity, see e.g. [1].

The evoked response to subtract. If None, the evoked response is computed from Epochs itself.

The modified instance (instance is also modified inplace).

David et al. ‚ÄúMechanisms of evoked and induced responses in MEG/EEG‚Äù, NeuroImage, vol. 31, no. 4, pp. 1580-1591, July 2006.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

Time vector in seconds.

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, additional columns ‚Äútime‚Äù, ‚Äúepoch‚Äù (epoch number), and ‚Äúcondition‚Äù (epoch event description) are added, unless index is not None (in which case the columns specified in index will be used to form the DataFrame‚Äôs index instead).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). If a list of two or more string values, a pandas.MultiIndex will be created. Valid string values are ‚Äòtime‚Äô, ‚Äòepoch‚Äô, and ‚Äòcondition‚Äô. Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) ‚Äî i.e., converts EEG to ¬µV, magnetometers to fT, and gradiometers to fT/cm.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point, channel, epoch number, and condition. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Single trial linear regression analysis with the LIMO dataset

Creating MNE-Python data structures from scratch

---

## mne.epochs.average_movements#

**URL:** https://mne.tools/stable/generated/mne.epochs.average_movements.html

**Contents:**
- mne.epochs.average_movements#
- Examples using mne.epochs.average_movements#

Average data using Maxwell filtering, transforming using head positions.

The epochs to operate on.

If array, movement compensation will be performed. The array should be of shape (N, 10), holding the position parameters as returned by e.g. read_head_pos.

The original sample frequency of the data (that matches the event sample numbers in epochs.events). Can be None if data have not been decimated or resampled.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Origin of internal and external multipolar moment space in meters. The default is 'auto', which means (0., 0., 0.) when coord_frame='meg', and a head-digitization-based origin fit using fit_sphere_to_headshape() when coord_frame='head'. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually.

If True, all channels are weighted by the SSS basis weights. If False, only MEG channels are weighted, other channels receive uniform weight per epoch.

Order of internal component of spherical expansion.

Order of external component of spherical expansion.

The destination location for the head. Can be:

Will not change the head position.

A MEG device<->head transformation, e.g. info["dev_head_t"].

A 3-element array giving the coordinates to translate to (with no rotations). For example, destination=(0, 0, 0.04) would translate the bases as --trans default would in MaxFilter‚Ñ¢ (i.e., to the default head location).

A path to a FIF file containing the destination MEG device<->head transformation.

If True, do not include reference channels in compensation. This option should be True for KIT files, since Maxwell filtering with reference channels is not currently supported.

If True, return the mapping matrix.

The magenetometer scale-factor used to bring the magnetometers to approximately the same order of magnitude as the gradiometers (default 100.), as they have different units (T vs T/m). Can be 'auto' to use the reciprocal of the physical distance between the gradiometer pickup loops (e.g., 0.0168 m yields 59.5 for VectorView).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The Maxwell filtering version of this algorithm is described in [1], in section V.B ‚ÄúVirtual signals and movement correction‚Äù, equations 40-44. For additional validation, see [2].

Regularization has not been added because in testing it appears to decrease dipole localization accuracy relative to using all components. Fine calibration and cross-talk cancellation, however, could be added to this algorithm based on user demand.

Taulu S. and Kajola M. ‚ÄúPresentation of electromagnetic multichannel data: The signal space separation method,‚Äù Journal of Applied Physics, vol. 97, pp. 124905 1-10, 2005.

Wehner DT, H√§m√§l√§inen MS, Mody M, Ahlfors SP. ‚ÄúHead movements of children in MEG: Quantification, effects on source estimation, and compensation. NeuroImage 40:541‚Äì550, 2008.

Maxwell filter data with movement compensation

Signal-space separation (SSS) and Maxwell filtering

mne.event.shift_time_events

mne.epochs.combine_event_ids

---

## mne.epochs.combine_event_ids#

**URL:** https://mne.tools/stable/generated/mne.epochs.combine_event_ids.html

**Contents:**
- mne.epochs.combine_event_ids#

Collapse event_ids from an epochs instance into a new event_id.

The epochs to operate on.

Conditions to collapse together.

A one-element dict (or a single integer) for the new condition. Note that for safety, this cannot be any existing id (in epochs.event_id.values()).

Whether to return a new instance or modify in place.

This For example (if epochs.event_id was {'Left': 1, 'Right': 2}:

would create a ‚ÄòDirectional‚Äô entry in epochs.event_id replacing ‚ÄòLeft‚Äô and ‚ÄòRight‚Äô (combining their trials).

mne.epochs.average_movements

mne.epochs.equalize_epoch_counts

---

## mne.epochs.equalize_epoch_counts#

**URL:** https://mne.tools/stable/generated/mne.epochs.equalize_epoch_counts.html

**Contents:**
- mne.epochs.equalize_epoch_counts#
- Examples using mne.epochs.equalize_epoch_counts#

Equalize the number of trials in multiple Epochs or EpochsTFR instances.

The Epochs instances to equalize trial counts for.

If 'truncate', events will be truncated from the end of each event list. If 'mintime', timing differences between each event list will be minimized. If 'random', events will be randomly selected from each event list.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state. Used only if method='random'.

The method 'mintime' tries to make the remaining epochs occurring as close as possible in time. This method is motivated by the possibility that if there happened to be some time-varying (like on the scale of minutes) noise characteristics during a recording, they could be compensated for (to some extent) in the equalization process. This method thus seeks to reduce any of those effects by minimizing the differences in the times of the events in the two sets of epochs. For example, if one had event times [1, 2, 3, 4, 120, 121] and the other one had [3.5, 4.5, 120.5, 121.5], it would remove events at times [1, 2] in the first epochs and not [120, 121].

Permutation t-test on source data with spatio-temporal clustering

mne.epochs.combine_event_ids

mne.epochs.make_metadata

---

## mne.epochs.make_metadata#

**URL:** https://mne.tools/stable/generated/mne.epochs.make_metadata.html

**Contents:**
- mne.epochs.make_metadata#
- Examples using mne.epochs.make_metadata#

Automatically generate metadata for use with mne.Epochs from events.

This function mimics the epoching process (it constructs time windows around time-locked ‚Äúevents of interest‚Äù) and collates information about any other events that occurred within those time windows. The information is returned as a pandas.DataFrame, suitable for use as Epochs metadata: one row per time-locked event, and columns indicating presence or absence and latency of each ancillary event type.

The function will also return a new events array and event_id dictionary that correspond to the generated metadata, which together can then be readily fed into Epochs.

The events array. By default, the returned metadata DataFrame will have as many rows as the events array. To create rows for only a subset of events, pass the row_events parameter.

A mapping from event names (keys) to event IDs (values). The event names will be incorporated as columns of the returned metadata DataFrame.

If float, start and end of the time interval for metadata generation in seconds, relative to the time-locked event of the respective time window (the ‚Äúrow events‚Äù).

If you are planning to attach the generated metadata to Epochs and intend to include only events that fall inside your epoch‚Äôs time interval, pass the same tmin and tmax values here as you use for your epochs.

If None, the time window used for metadata generation is bounded by the row_events. This is can be particularly practical if trial duration varies greatly, but each trial starts with a known event (e.g., a visual cue or fixation).

If tmin=None, the first time window for metadata generation starts with the first row event. If tmax=None, the last time window for metadata generation ends with the last event in events.

If a string or a list of strings, the events bounding the metadata around each ‚Äúrow event‚Äù. For tmin, the events are assumed to occur before the row event, and for tmax, the events are assumed to occur after ‚Äì unless tmin or tmax are equal to a row event, in which case the row event serves as the bound.

Changed in version 1.6.0: Added support for None.

New in v1.7.0: Added support for strings.

The sampling frequency of the data from which the events array was extracted.

Event types around which to create the time windows. For each of these time-locked events, we will create a row in the returned metadata pandas.DataFrame. If provided, the string(s) must be keys of event_id. If None (default), rows are created for all event types present in event_id.

Specify subsets of hierarchical event descriptors (HEDs, inspired by [1]) matching events of which the first occurrence within each time window shall be stored in addition to the original events.

There is currently no way to retain all occurrences of a repeated event. The keep_first parameter can be used to specify subsets of HEDs, effectively creating a new event type that is the union of all events types described by the matching HED pattern. Only the very first event of this set will be kept.

For example, you might have two response events types, response/left and response/right; and in trials with both responses occurring, you want to keep only the first response. In this case, you can pass keep_first='response'. This will add two new columns to the metadata: response, indicating at what time the event occurred, relative to the time-locked event; and first_response, stating which type ('left' or 'right') of event occurred. To match specific subsets of HEDs describing different sets of events, pass a list of these subsets, e.g. keep_first=['response', 'stimulus']. If None (default), no event aggregation will take place and no new columns will be created.

By default, this function will always retain the first instance of any event in each time window. For example, if a time window contains two 'response' events, the generated response column will automatically refer to the first of the two events. In this specific case, it is therefore not necessary to make use of the keep_first parameter ‚Äì unless you need to differentiate between two types of responses, like in the example above.

Same as keep_first, but for keeping only the last occurrence of matching events. The column indicating the type of an event myevent will be named last_myevent.

Metadata for each row event, with the following columns:

event_name, with strings indicating the name of the time-locked event (‚Äúrow event‚Äù) for that specific time window

one column per event type in event_id, with the same name; floats indicating the latency of the event in seconds, relative to the time-locked event

if applicable, additional columns named after the keep_first and keep_last event types; floats indicating the latency of the event in seconds, relative to the time-locked event

if applicable, additional columns first_{event_type} and last_{event_type} for keep_first and keep_last event types, respetively; the values will be strings indicating which event types were matched by the provided HED patterns

The events corresponding to the generated metadata, i.e. one time-locked event per row.

The event dictionary corresponding to the new events array. This will be identical to the input dictionary unless row_events is supplied, in which case it will only contain the events provided there.

The time window used for metadata generation need not correspond to the time window used to create the Epochs, to which the metadata will be attached; it may well be much shorter or longer, or not overlap at all, if desired. This can be useful, for example, to include events that occurred before or after an epoch, e.g. during the inter-trial interval. If either tmin, tmax, or both are None, or a string referring e.g. to a response event, the time window will typically vary, too.

Nima Bigdely-Shamlo, Kenneth Kreutz-Delgado, Kay Robbins, Makoto Miyakoshi, Marissa Westerfield, Tarik Bel-Bahar, Christian Kothe, Jessica Hsi, and Scott Makeig. Hierarchical event descriptor (HED) tags for analysis of event-related EEG studies. In 2013 IEEE Global Conference on Signal and Information Processing, 1‚Äì4. IEEE, 2013. doi:10.1109/GlobalSIP.2013.6736796.

Automated epochs metadata generation with variable time windows

Auto-generating Epochs metadata

Getting started with mne.Report

mne.epochs.equalize_epoch_counts

---

## mne.Epochs#

**URL:** https://mne.tools/stable/generated/mne.Epochs.html

**Contents:**
- mne.Epochs#
- Examples using mne.Epochs#

Epochs extracted from a Raw instance.

If raw contains annotations, Epochs can be constructed around raw.annotations.onset, but note that the durations of the annotations are ignored in this case.

The identity and timing of experimental events, around which the epochs were created. See events for more information.Events that don‚Äôt match the events of interest as specified by event_id will be marked as IGNORED in the drop log.

Changed in version 1.7: Allow events=None to use raw.annotations.onset as the source of epoch times.

The id of the events to consider. If dict, the keys can later be used to access associated events. Example: dict(auditory=1, visual=3). If int, a dict will be created with the id as string. If a list of int, all events with the IDs specified in the list are used. If a str or list of str, events must be None to use annotations and then the IDs must be the name(s) of the annotations to use. If None, all events will be used and a dict is created with string integer names corresponding to the event id integers.

Start and end time of the epochs in seconds, relative to the time-locked event. The closest or matching samples corresponding to the start and end time are included. Defaults to -0.2 and 0.5, respectively.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each epoch and channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire epoch.

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Load all epochs from disk when creating the object or wait before accessing each epoch (more memory efficient but can be slower).

Reject epochs based on maximum peak-to-peak signal amplitude (PTP), i.e. the absolute difference between the lowest and the highest signal value. In each individual epoch, the PTP is calculated for every channel. If the PTP of any one channel exceeds the rejection threshold, the respective epoch will be dropped.

The dictionary keys correspond to the different channel types; valid keys can be any channel type present in the object.

Since rejection is based on a signal difference calculated for each channel separately, applying baseline correction does not affect the rejection procedure, as the difference will be preserved.

To constrain the time period used for estimation of signal quality, pass the reject_tmin and reject_tmax parameters.

If reject is None (default), no rejection is performed.

Reject epochs based on minimum peak-to-peak signal amplitude (PTP). Valid keys can be any channel type present in the object. The values are floats that set the minimum acceptable PTP. If the PTP is smaller than this threshold, the epoch will be dropped. If None then no rejection is performed based on flatness of the signal.

To constrain the time period used for estimation of signal quality, pass the reject_tmin and reject_tmax parameters.

Apply SSP projection vectors. If proj is ‚Äòdelayed‚Äô and reject is not None the single epochs will be projected before the rejection decision, but used in unprojected state if they are kept. This way deciding which projection vectors are good can be postponed to the evoked stage without resulting in lower epoch counts and without producing results different from early SSP application given comparable parameters. Note that in this case baselining, detrending and temporal decimation will be postponed. If proj is False no projections will be applied which is the recommended value if SSPs are not used for cleaning the data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Start and end of the time window used to reject epochs based on peak-to-peak (PTP) amplitudes as specified via reject and flat. The default None corresponds to the first and last time points of the epochs, respectively.

This parameter controls the time period used in conjunction with both, reject and flat.

If 0 or 1, the data channels (MEG and EEG) will be detrended when loaded. 0 is a constant (DC) detrend, 1 is a linear detrend. None is no detrending. Note that detrending is performed before baseline correction. If no DC offset is preferred (zeroth order detrending), either turn off baseline correction, as this may introduce a DC shift, or set baseline correction to use the entire time interval (will yield equivalent results but be slower).

What to do if one or several event ids are not found in the recording. Valid keys are ‚Äòraise‚Äô | ‚Äòwarn‚Äô | ‚Äòignore‚Äô Default is 'raise'. If 'warn', it will proceed but warn; if 'ignore', it will proceed silently.

If none of the event ids are found in the data, an error will be automatically generated irrespective of this parameter.

Whether to reject based on annotations. If True (default), epochs overlapping with segments whose description begins with 'bad' are rejected. If False, no rejection based on annotations is performed.

A pandas.DataFrame specifying metadata about each epoch. If not None, len(metadata) must equal len(events). For save/load compatibility, the DataFrame may only contain str, int, float, and bool values. If not None, then pandas-style queries may be used to select subsets of data, see mne.Epochs.__getitem__(). When the Epochs object is subsetted, the metadata is subsetted accordingly, and the row indices will be modified to match Epochs.selection.

How to handle duplicates in events[:, 0]. Can be 'error' (default), to raise an error, ‚Äòdrop‚Äô to only retain the row occurring first in the events, or 'merge' to combine the coinciding events (=duplicates) into a new event (see Notes for details).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The mne.Info object with information about the sensors and methods of measurement.

Mapping from condition descriptions (strings) to integer event codes.

Array of indices of selected epochs (i.e., epochs that were not rejected, dropped, or ignored).

Indicates whether epochs are in memory.

A tuple of the same length as the event array used to initialize the Epochs object. If the i-th original event is still part of the selection, drop_log[i] will be an empty tuple; otherwise it will be a tuple of the reasons the event is not longer in the selection, e.g.:

If it isn‚Äôt part of the current subset defined by the user

If epoch didn‚Äôt contain enough data names of channels that exceeded the amplitude threshold

See equalize_event_counts()

For user-defined reasons (see drop()).

When dropping based on flat or reject parameters the tuple of reasons contains a tuple of channels that satisfied the rejection criteria.

The filename if the epochs are loaded from disk.

Time vector in seconds.

__contains__(ch_type)

Check channel type membership.

Return an Epochs object with a copied subset of epochs.

Facilitate iteration over epochs.

Return the number of epochs.

add_annotations_to_metadata([overwrite, ...])

Add raw annotations into the Epochs metadata data frame.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_proj(projs[, remove_existing, verbose])

Add SSP projection vectors.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

anonymize([daysback, keep_his, verbose])

Anonymize measurement information in place.

apply_baseline([baseline, verbose])

Baseline correct epochs.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of channels.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

apply_proj([verbose])

Apply the signal space projection (SSP) operators to the data.

as_type([ch_type, mode])

Compute virtual epochs using interpolated fields.

average([picks, method, by_event_type])

Compute an average over epochs.

compute_psd([method, fmin, fmax, tmin, ...])

Perform spectral analysis on sensor data.

compute_tfr(method, freqs, *[, tmin, tmax, ...])

Compute a time-frequency representation of epoched data.

Return copy of Epochs instance.

crop([tmin, tmax, include_tmax, verbose])

Crop a time interval from the epochs.

decimate(decim[, offset, verbose])

Decimate the time-series data.

Remove SSP projection vector.

drop(indices[, reason, verbose])

Drop epochs based on indices or boolean mask.

drop_bad([reject, flat, verbose])

Drop bad epochs without retaining the epochs data.

drop_channels(ch_names[, on_missing])

drop_log_stats([ignore])

Compute the channel stats based on a drop_log from Epochs.

equalize_event_counts([event_ids, method, ...])

Equalize the number of trials in each condition.

export(fname[, fmt, overwrite, verbose])

Export Epochs to external formats.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_annotations_per_epoch(*[, with_extras])

Get a list of annotations that occur during each epoch.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, item, units, tmin, tmax, ...])

Get all epochs as a 3D array.

Get a DigMontage from instance.

interpolate_bads([reset_bads, mode, origin, ...])

Interpolate bad MEG and EEG channels.

interpolate_to(sensors[, origin, method, reg])

Interpolate EEG data onto a new montage.

Iterate over epochs as a sequence of Evoked objects.

Load the data if not already preloaded.

next([return_event_id])

Iterate over epoch data.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, scalings, n_epochs, ...])

plot_drop_log([threshold, n_max_plot, ...])

Show the channel stats based on a drop_log from Epochs.

plot_image([picks, sigma, vmin, vmax, ...])

Plot Event Related Potential / Fields image.

plot_projs_topomap([ch_type, sensors, ...])

plot_psd([fmin, fmax, tmin, tmax, picks, ...])

Plot power or amplitude spectra.

plot_psd_topo([tmin, tmax, fmin, fmax, ...])

plot_psd_topomap([bands, tmin, tmax, ...])

plot_sensors([kind, ch_type, title, ...])

Plot sensor positions.

plot_topo_image([layout, sigma, vmin, vmax, ...])

Plot Event Related Potential / Fields image on topographies.

rename_channels(mapping[, allow_duplicates, ...])

reorder_channels(ch_names)

resample(sfreq, *[, npad, window, n_jobs, ...])

reset_drop_log_selection()

Reset the drop_log and selection entries.

save(fname[, split_size, fmt, overwrite, ...])

Save epochs in a fif file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

set_annotations(annotations[, on_missing, ...])

Setter for Epoch annotations from Raw.

set_channel_types(mapping, *[, ...])

Specify the sensor types of channels.

set_eeg_reference([ref_channels, ...])

Specify which reference to use for EEG data.

set_meas_date(meas_date)

Set the measurement start date.

set_montage(montage[, match_case, ...])

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

standard_error([picks, by_event_type])

Compute standard error over epochs.

subtract_evoked([evoked])

Subtract an evoked response from each epoch.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

When accessing data, Epochs are detrended, baseline-corrected, and decimated, then projectors are (optionally) applied.

For indexing and slicing using epochs[...], see mne.Epochs.__getitem__().

All methods for iteration over objects (using mne.Epochs.__iter__(), mne.Epochs.iter_evoked() or mne.Epochs.next()) use the same internal state.

If event_repeated is set to 'merge', the coinciding events (duplicates) will be merged into a single event_id and assigned a new id_number as:

For example with the event_id {'aud': 1, 'vis': 2} and the events [[0, 0, 1], [0, 0, 2]], the ‚Äúmerge‚Äù behavior will update both event_id and events to be: {'aud/vis': 3} and [[0, 0, 3]] respectively.

There is limited support for Annotations in the Epochs class. Currently annotations that are present in the Raw object will be preserved in the resulting Epochs object, but:

It is not yet possible to add annotations to the Epochs object programmatically (via code) or interactively (through the plot window)

Concatenating Epochs objects that contain annotations is not supported, and any annotations will be dropped when concatenating.

Annotations will be lost on save.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Return an Epochs object with a copied subset of epochs.

See Notes for use cases.

The subset of epochs.

Epochs can be accessed as epochs[...] in several ways:

Integer or slice: epochs[idx] will return an Epochs object with a subset of epochs chosen by index (supports single index and Python-style slicing).

String: epochs['name'] will return an Epochs object comprising only the epochs labeled 'name' (i.e., epochs created around events with the label 'name').

If there are no epochs labeled 'name' but there are epochs labeled with /-separated tags (e.g. 'name/left', 'name/right'), then epochs['name'] will select the epochs with labels that contain that tag (e.g., epochs['left'] selects epochs labeled 'audio/left' and 'visual/left', but not 'audio_left').

If multiple tags are provided as a single string (e.g., epochs['name_1/name_2']), this selects epochs containing all provided tags. For example, epochs['audio/left'] selects 'audio/left' and 'audio/quiet/left', but not 'audio/right'. Note that tag-based selection is insensitive to order: tags like 'audio/left' and 'left/audio' will be treated the same way when selecting via tag.

List of strings: epochs[['name_1', 'name_2', ... ]] will return an Epochs object comprising epochs that match any of the provided names (i.e., the list of names is treated as an inclusive-or condition). If none of the provided names match any epoch labels, a KeyError will be raised.

If epoch labels are /-separated tags, then providing multiple tags as separate list entries will likewise act as an inclusive-or filter. For example, epochs[['audio', 'left']] would select 'audio/left', 'audio/right', and 'visual/left', but not 'visual/right'.

Pandas query: epochs['pandas query'] will return an Epochs object with a subset of epochs (and matching metadata) selected by the query called with self.metadata.eval, e.g.:

would return all epochs whose associated col_a metadata was greater than two, and whose col_b metadata was the string ‚Äòfoo‚Äô. Query-based indexing only works if Pandas is installed and self.metadata is a pandas.DataFrame.

Facilitate iteration over epochs.

This method resets the object iteration state to the first epoch.

This enables the use of this Python pattern:

Where epoch is given by successive outputs of mne.Epochs.next().

Return the number of epochs.

The number of remaining epochs.

This function only works if bad epochs have been dropped.

Add raw annotations into the Epochs metadata data frame.

Adds three columns to the metadata consisting of a list in each row: - annot_onset: the onset of each Annotation within the Epoch relative to the start time of the Epoch (in seconds). - annot_duration: the duration of each Annotation within the Epoch in seconds. - annot_description: the free-form text description of each Annotation.

Whether to overwrite existing columns in metadata or not. Default is False.

Whether to include the annotations extra fields in the output, as an additional last element of the tuple. Default is True.

The modified instance (instance is also modified inplace).

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add SSP projection vectors.

List with projection vectors.

Remove the projection vectors currently in the file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Examples using add_proj:

Visualizing epoched data

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Anonymize measurement information in place.

Number of days to subtract from all dates. If None (default), the acquisition date, info['meas_date'], will be set to January 1À¢·µó, 2000. This parameter is ignored if info['meas_date'] is None (i.e., no acquisition date has been set).

If True, his_id of subject_info will not be overwritten. Defaults to False.

This could mean that info is not fully anonymized. Use with caution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Removes potentially identifying information if it exists in info. Specifically for each of the following we use:

A default value, or as specified by daysback.

Default values, except for ‚Äòbirthday‚Äô which is adjusted to maintain the subject age.

Dates use the meas_date logic, and experimenter a default string.

Dates use the meas_date logic, meta info uses defaults.

If info['meas_date'] is None, it will remain None during processing the above fields.

Baseline correct epochs.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each epoch and channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire epoch.

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected Epochs object.

Baseline correction can be done multiple times, but can never be reverted once the data has been loaded.

Examples using apply_baseline:

Repairing artifacts with regression

Working with eye tracker data in MNE-Python

Apply a function to a subset of channels.

The function fun is applied to the channels defined in picks. The epochs object‚Äôs data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to channels in picks). The object has to have the data loaded e.g. with preload=True or self.load_data().

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) if channel_wise=True and (len(picks), n_times) otherwise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if channel_wise=False as the workload is split across channels.

Whether to apply the function to each channel in each epoch individually. If False, the function will be applied to all epochs and channels at once. Default True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The epochs object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‚Äòauto‚Äô, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal ‚Äúx_a(t)‚Äù of ‚Äúx(t)‚Äù is:

where ‚ÄúF‚Äù is the Fourier transform, ‚ÄúU‚Äù the unit step function, and ‚Äúy‚Äù the Hilbert transform of ‚Äúx‚Äù. One usage of the analytic signal is the computation of the envelope signal, which is given by ‚Äúe(t) = abs(x_a(t))‚Äù. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Examples using apply_hilbert:

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Apply the signal space projection (SSP) operators to the data.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Once the projectors have been applied, they can no longer be removed. It is usually not recommended to apply the projectors at too early stages, as they are applied automatically later on (e.g. when computing inverse solutions). Hint: using the copy method individual projection vectors can be tested without affecting the original data. With evoked data, consider the following example:

Examples using apply_proj:

Visualizing epoched data

Compute virtual epochs using interpolated fields.

Using virtual epochs to compute inverse can yield unexpected results. The virtual channels have '_v' appended at the end of the names to emphasize that the data contained in them are interpolated.

The destination channel type. It can be ‚Äòmag‚Äô or ‚Äògrad‚Äô.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used. 'fast' should be sufficient for most applications.

The transformed epochs object containing only virtual channels.

This method returns a copy and does not modify the data it operates on. It also returns an EpochsArray instance.

Compute an average over epochs.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

How to combine the data. If ‚Äúmean‚Äù/‚Äùmedian‚Äù, the mean/median are returned. Otherwise, must be a callable which, when passed an array of shape (n_epochs, n_channels, n_time) returns an array of shape (n_channels, n_time). Note that due to file type limitations, the kind for all these will be ‚Äúaverage‚Äù.

When False (the default) all epochs are processed together and a single Evoked object is returned. When True, epochs are first grouped by event type (as specified using the event_id parameter) and a list is returned containing a separate Evoked object for each event type. The .comment attribute is set to the label of the event type.

The averaged epochs. When by_event_type=True was specified, a list is returned containing a separate Evoked object for each event type. The list has the same order as the event types as specified in the event_id dictionary.

Computes an average of all epochs in the instance, even if they correspond to different conditions. To average by condition, do epochs[condition].average() for each condition separately.

When picks is None and epochs contain only ICA channels, no channels are selected, resulting in an error. This is because ICA channels are not considered data channels (they are of misc type) and only data channels are selected when picks is None.

The method parameter allows e.g. robust averaging. For example, one could do:

This would compute the trimmed mean.

Examples using average:

Brainstorm raw (median nerve) dataset

From raw data to dSPM on SPM Faces dataset

Compute MNE-dSPM inverse solution on single epochs

Compute source power estimate by projecting the covariance with MNE

Getting averaging info from .fif files

Reduce EOG artifacts through regression

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Maxwell filter data with movement compensation

Compare simulated and estimated source activity

Generate simulated raw data

Generate simulated source data

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Whitening evoked data with a noise covariance

Working with sEEG data

Plotting whitened data

Computing a covariance matrix

Overview of MEG/EEG analysis with MNE-Python

Getting started with mne.Report

4D Neuroimaging/BTi phantom dataset tutorial

Overview of artifact detection

Rejecting bad data spans and breaks

Repairing artifacts with regression

Repairing artifacts with SSP

Preprocessing optically pumped magnetometer (OPM) MEG data

Corrupt known signal with point spread

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Permutation t-test on source data with spatio-temporal clustering

The current gradient compensation grade.

Perform spectral analysis on sensor data.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. Default is 'multitaper'.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

If True, the mean is subtracted from each segment before computing its spectrum.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

The spectral representation of each epoch.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70‚Äì73, 1967. doi:10.1109/TAU.1967.1161901.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371‚Äì1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Examples using compute_psd:

Sleep stage classification from polysomnography (PSG) data

Visualizing epoched data

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency and time-frequency sensor analysis

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

Compute a time-frequency representation of epoched data.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [2], and 'stockwell' uses the S-transform [3][4][5][6]. None (the default) only works when using __setstate__ and will raise an error otherwise.

The frequencies at which to compute the power estimates. If method='stockwell' this must be a length 2 iterable specifying lowest and highest frequencies, or 'auto' (to use all available frequencies). For other methods, must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

What kind of estimate to return. Allowed values are "complex", "phase", and "power". Default is "power".

Whether to return average power across epochs (instead of single-trial power). average=True is not compatible with output="complex" or output="phase". Ignored if method="stockwell" (Stockwell method requires averaging). Default is False.

Whether to return inter-trial coherence (ITC) as well as power estimates. If True then must specify average=True (or method="stockwell", average="auto"). Default is False.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method, n_fft, width for Stockwell method, or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet(), tfr_array_stockwell(), and tfr_array_multitaper() for additional details.

The time-frequency-resolved power estimates.

The inter-trial coherence (ITC). Only returned if return_itc=True.

If average=True (or method="stockwell", average="auto") the result will be an AverageTFR instead of an EpochsTFR.

R. G. Stockwell. Why use the S-transform? In Luigi Rodino, Bert-Wolfgang Schulze, and M. W. Wong, editors, Pseudo-Differential Operators: Partial Differential Equations and Time-Frequency Analysis, number 52 in Fields Institute Communications, pages 279‚Äì309. American Mathematical Society, Providence, RI, 2007. doi:10.1090/fic/052.

Ali Moukadem, Zied Bouguila, Djaffar Ould Abdeslam, and Alain Dieterlen. Stockwell transform optimization applied on the detection of split in heart sounds. In Proceedings of EUSIPCO-2014, 2015‚Äì2019. Lisbon, 2014. IEEE. URL: https://ieeexplore.ieee.org/document/6952743.

Katherine L. Wheat, Piers L. Cornelissen, Stephen J. Frost, and Peter C. Hansen. During visual word recognition, phonology is accessed within 100 ms and may be mediated by a speech production code: evidence from magnetoencephalography. Journal of Neuroscience, 30(15):5229‚Äì5233, 2010. doi:10.1523/JNEUROSCI.4448-09.2010.

Kevin A. Jones, Bernice Porjesz, David Chorlian, Madhavi Rangaswamy, Chella Kamarajan, Ajayan Padmanabhapillai, Arthur Stimus, and Henri Begleiter. S-transform time-frequency analysis of P300 reveals deficits in individuals diagnosed with alcoholism. Clinical Neurophysiology, 117(10):2128‚Äì2143, 2006. doi:10.1016/j.clinph.2006.02.028.

Examples using compute_tfr:

Compute source level time-frequency timecourses using a DICS beamformer

Compute and visualize ERDS maps

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Overview of MEG/EEG analysis with MNE-Python

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

Frequency and time-frequency sensor analysis

Return copy of Epochs instance.

A copy of the object.

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Linear classifier on sensor data with plot patterns and filters

Compute power and phase lock in label of the source space

The Epochs data structure: discontinuous data

Regression-based baseline correction

Repairing artifacts with regression

Crop a time interval from the epochs.

Start time of selection in seconds.

End time of selection in seconds.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped epochs object, modified in-place.

Unlike Python slices, MNE time intervals by default include both their end points; crop(tmin, tmax) returns the interval tmin <= t <= tmax. Pass include_tmax=False to specify the half-open interval tmin <= t < tmax instead.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / ‚Äúdecimation‚Äù refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [7], p. 172; which cites [8]):

‚Äú‚Ä¶ a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).‚Äù

Hence ‚Äúdecimation‚Äù in MNE is what is considered ‚Äúcompression‚Äù in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Remove SSP projection vector.

The projection vector can only be removed if it is inactive (has not been applied to the data).

Index of the projector to remove. Can also be ‚Äúall‚Äù (default) to remove all projectors.

Drop epochs based on indices or boolean mask.

The indices refer to the current set of undropped epochs rather than the complete set of dropped and undropped epochs. They are therefore not necessarily consistent with any external indices (e.g., behavioral logs). To drop epochs based on external criteria, do not use the preload=True flag when constructing an Epochs object, and call this method before calling the mne.Epochs.drop_bad() or mne.Epochs.load_data() methods.

Set epochs to remove by specifying indices to remove or a boolean mask to apply (where True values get removed). Events are correspondingly modified.

Reason(s) for dropping the epochs (‚ÄòECG‚Äô, ‚Äòtimeout‚Äô, ‚Äòblink‚Äô etc). Reason(s) are applied to all indices specified. Default: ‚ÄòUSER‚Äô.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs with indices dropped. Operates in-place.

Drop bad epochs without retaining the epochs data.

Should be used before slicing operations.

This operation is slow since all epochs have to be read from disk. To avoid reading epochs from disk multiple times, use mne.Epochs.load_data().

To constrain the time period used for estimation of signal quality, set epochs.reject_tmin and epochs.reject_tmax, respectively.

Reject epochs based on maximum peak-to-peak signal amplitude (PTP) or custom functions. Peak-to-peak signal amplitude is defined as the absolute difference between the lowest and the highest signal value. In each individual epoch, the PTP is calculated for every channel. If the PTP of any one channel exceeds the rejection threshold, the respective epoch will be dropped.

The dictionary keys correspond to the different channel types; valid keys can be any channel type present in the object.

Custom rejection criteria can be also be used by passing a callable, e.g., to check for 99th percentile of absolute values of any channel across time being bigger than 1 mV. The callable must return a (good, reason) tuple: good must be bool and reason must be str, list, or tuple where each entry is a str:

If rejection is based on a signal difference calculated for each channel separately, applying baseline correction does not affect the rejection procedure, as the difference will be preserved.

If reject is a callable, than any criteria can be used to reject epochs (including maxima and minima).

If reject is None, no rejection is performed. If 'existing' (default), then the rejection parameters set at instantiation are used.

Reject epochs based on minimum peak-to-peak signal amplitude (PTP) or a custom function. Valid keys can be any channel type present in the object. If using PTP, values are floats that set the minimum acceptable PTP. If the PTP is smaller than this threshold, the epoch will be dropped. If None then no rejection is performed based on flatness of the signal. If a custom function is used than flat can be used to reject epochs based on any criteria (including maxima and minima). If 'existing', then the flat parameters set during epoch creation are used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs with bad epochs dropped. Operates in-place.

Dropping bad epochs can be done multiple times with different reject and flat parameters. However, once an epoch is dropped, it is dropped forever, so if more lenient thresholds may subsequently be applied, epochs.copy should be used.

Examples using drop_bad:

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Visualizing epoched data

EEG analysis - Event-Related Potentials (ERPs)

Rejecting bad data spans and breaks

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Examples using drop_channels:

Spatiotemporal permutation F-test on full sensor data

Compute the channel stats based on a drop_log from Epochs.

The drop reasons to ignore.

Total percentage of epochs dropped.

Equalize the number of trials in each condition.

It tries to make the remaining epochs occurring as close as possible in time. This method works based on the idea that if there happened to be some time-varying (like on the scale of minutes) noise characteristics during a recording, they could be compensated for (to some extent) in the equalization process. This method thus seeks to reduce any of those effects by minimizing the differences in the times of the events within a Epochs instance. For example, if one event type occurred at time points [1, 2, 3, 4, 120, 121] and the another one at [3.5, 4.5, 120.5, 121.5], this method would remove the events at times [1, 2] for the first event type ‚Äì and not the events at times [120, 121].

The event types to equalize.

If None (default), equalize the counts of all event types present in the Epochs instance.

If a list, each element can either be a string (event name) or a list of strings. In the case where one of the entries is a list of strings, event types in that list will be grouped together before equalizing trial counts across conditions.

If a dictionary, the keys are considered as the event names whose counts to equalize, i.e., passing dict(A=1, B=2) will have the same effect as passing ['A', 'B']. This is useful if you intend to pass an event_id dictionary that was used when creating Epochs.

In the case where partial matching is used (using / in the event names), the event types will be matched according to the provided tags, that is, processing works as if the event_ids matched by the provided tags had been supplied instead. The event_ids must identify non-overlapping subsets of the epochs.

If 'truncate', events will be truncated from the end of each event list. If 'mintime', timing differences between each event list will be minimized. If 'random', events will be randomly selected from each event list.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state. Used only if method='random'.

The modified instance. It is modified in-place.

Indices from the original events list that were dropped.

For example (if epochs.event_id was {'Left': 1, 'Right': 2, 'Nonspatial':3}:

epochs.equalize_event_counts([[‚ÄòLeft‚Äô, ‚ÄòRight‚Äô], ‚ÄòNonspatial‚Äô])

would equalize the number of trials in the 'Nonspatial' condition with the total number of trials in the 'Left' and 'Right' conditions combined.

If multiple indices are provided (e.g. 'Left' and 'Right' in the example above), it is not guaranteed that after equalization the conditions will contribute equally. E.g., it is possible to end up with 70 'Nonspatial' epochs, 69 'Left' and 1 'Right'.

Changed in version 0.23: Default to equalizing all events in the passed instance if no event names were specified explicitly.

Examples using equalize_event_counts:

Compute effect-matched-spatial filtering (EMS)

EEG analysis - Event-Related Potentials (ERPs)

Overview of MEG/EEG analysis with MNE-Python

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

Repeated measures ANOVA on source data with spatio-temporal clustering

Export Epochs to external formats.

EEGLAB (.set, uses eeglabio)

Since we are exporting to external formats, there‚Äôs no guarantee that all the info will be preserved in the external format. See Notes for details.

Name of the output file.

Format of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.Epochs.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.Epochs.apply_proj().

For EEGLAB exports, channel locations are expanded to full EEGLAB format. For more details see eeglabio.utils.cart_to_eeglab().

The filename if the epochs are loaded from disk.

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‚Äòauto‚Äô (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=‚Äôhamming‚Äô and fir_design=‚Äùfirwin2‚Äù, and half that for ‚Äúfirwin‚Äù).

str: A human-readable time in units of ‚Äús‚Äù or ‚Äúms‚Äù (e.g., ‚Äú10s‚Äù or ‚Äú5500ms‚Äù) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=‚Äùfirwin‚Äù, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be ‚Äúauto‚Äù (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be ‚Äúauto‚Äù (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be ‚Äúhamming‚Äù (default), ‚Äúhann‚Äù (default in 0.13), or ‚Äúblackman‚Äù.

Can be ‚Äúfirwin‚Äù (default) to use scipy.signal.firwin(), or ‚Äúfirwin2‚Äù to use scipy.signal.firwin2(). ‚Äúfirwin‚Äù uses a time-domain design technique that generally gives improved attenuation using fewer samples than ‚Äúfirwin2‚Äù.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Examples using filter:

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Get a list of annotations that occur during each epoch.

Whether to include the annotations extra fields in the output, as an additional last element of the tuple. Default is False.

A list of lists (with length equal to number of epochs) where each inner list contains any annotations that overlap the corresponding epoch. Annotations are stored as a tuple of onset, duration, description (not as a Annotations object), where the onset is now relative to time=0 of the epoch, rather than time=0 of the original continuous (raw) data.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Examples using get_channel_types:

The Epochs data structure: discontinuous data

Get all epochs as a 3D array.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The items to get. See mne.Epochs.__getitem__() for a description of valid options. This can be substantially faster for obtaining an ndarray than __getitem__() for repeated access on large Epochs objects. None (default) is an alias for slice(None).

Specify the unit(s) that the data should be returned in. If None (default), the data is returned in the channel-type-specific default units, which are SI units (see Internal representation (units) and data channels). If a string, must be a sub-multiple of SI units that will be used to scale the data from all channels of the type associated with that unit. This only works if the data contains one channel type that has a unit (unitless channel types are left unchanged). For example if there are only EEG and STIM channels, units='uV' will scale EEG channels to micro-Volts while STIM channels will be unchanged. Finally, if a dictionary is provided, keys must be channel types, and values must be units to scale the data of that channel type to. For example dict(grad='fT/cm', mag='fT') will scale the corresponding types accordingly, but all other channel types will remain in their channel-type-specific default unit.

Start time of data to get in seconds.

End time of data to get in seconds.

Whether to return a copy of the object‚Äôs data, or (if possible) a view. See the NumPy docs for an explanation. Default is False in 1.6 but will change to True in 1.7, set it explicitly to avoid a warning in some cases. A view is only possible when item is None, picks is None, units is None, and data are preloaded.

Using copy=False and then modifying the returned data will in turn modify the Epochs object. Use with caution!

Changed in version 1.7: The default changed from False to True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs data. Will be a copy when copy=True and will be a view when possible when copy=False.

Examples using get_data:

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Continuous Target Decoding with SPoC

Analysis of evoked response using ICA and PCA reduction techniques

XDAWN Decoding From EEG data

Compute effect-matched-spatial filtering (EMS)

Linear classifier on sensor data with plot patterns and filters

Compute spatial filters with Spatio-Spectral Decomposition (SSD)

Show EOG artifact timing

Permutation F-test on sensor data with 1D cluster level

FDR correction on T-test on sensor data

Permutation T-test on sensor data

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

The Epochs data structure: discontinuous data

Divide continuous data into equally-spaced epochs

Overview of MEG/EEG analysis with MNE-Python

Get a DigMontage from instance.

A copy of the channel positions, if available, otherwise None.

Examples using get_montage:

Working with sEEG data

Interpolate bad MEG and EEG channels.

If True, remove the bads from info.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used for interpolation of channels using the minimum-norm method.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for each channel type.

"meg" channels support "MNE" (default) and "nan"

"eeg" channels support "spline" (default), "MNE" and "nan"

"fnirs" channels support "nearest" (default) and "nan"

"ecog" channels support "spline" (default) and "nan"

"seeg" channels support "spline" (default) and "nan"

None is an alias for:

If a str is provided, the method will be applied to all channel types supported and available in the instance. The method "nan" will replace the channel data with np.nan.

Be careful when using method="nan"; the default value reset_bads=True may not be what you want.

The channels to exclude from interpolation. If excluded a bad channel will stay in bads.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

The "MNE" method uses minimum-norm projection to a sphere and back.

Interpolate EEG data onto a new montage.

Be careful, only EEG channels are interpolated. Other channel types are not interpolated.

The target montage containing channel positions to interpolate onto.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for EEG channels. Supported methods are ‚Äòspline‚Äô (default) and ‚ÄòMNE‚Äô.

The regularization parameter for the interpolation method (only used when the method is ‚Äòspline‚Äô).

The instance with updated channel locations and data.

This method is useful for standardizing EEG layouts across datasets. However, some attributes may be lost after interpolation.

Iterate over epochs as a sequence of Evoked objects.

The Evoked objects yielded will each contain a single epoch (i.e., no averaging is performed).

This method resets the object iteration state to the first epoch.

If False copies of data and measurement info will be omitted to save time.

Load the data if not already preloaded.

This function operates in-place.

Examples using load_data:

Plotting eye-tracking heatmaps in MNE-Python

Divide continuous data into equally-spaced epochs

Rejecting bad data spans and breaks

Iterate over epoch data.

If True, return both the epoch data and an event_id.

The event id. Only returned if return_event_id is True.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Compute effect-matched-spatial filtering (EMS)

Linear classifier on sensor data with plot patterns and filters

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Bad epochs can be marked with a left click on top of the epoch. Bad channels can be selected by clicking the channel name on the left side of the main axes. Calling this function drops all the selected bad epochs as well as bad epochs marked beforehand with rejection parameters.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Scaling factors for the traces. If a dictionary where any value is 'auto', the scaling factor is set to match the 99.5th percentile of the respective data. If 'auto', all scalings (for all channel types) are set to 'auto'. If any values are 'auto' and the data is not preloaded, a subset up to 100 MB will be loaded. If None, defaults to:

A particular scaling value s corresponds to half of the visualized signal range around zero (i.e. from 0 to +s or from 0 to -s). For example, the default scaling of 20e-6 (20¬µV) for EEG signals means that the visualized range will be 40 ¬µV (20 ¬µV in the positive direction and 20 ¬µV in the negative direction).

The number of epochs per view. Defaults to 20.

The number of channels per view. Defaults to 20.

The title of the window. If None, the event names (from epochs.event_id) will be displayed. Defaults to None.

Events to show with vertical bars. You can use plot_events as a legend for the colors. By default, the coloring scheme is the same. True plots epochs.events. Defaults to False (do not plot events).

If the epochs have been resampled, the events no longer align with the data.

Changed in version 1.6: Passing events=None was disallowed. The new equivalent is events=False.

Color(s) to use for events. To show all events in the same color, pass any matplotlib-compatible color. To color events differently, pass a dict that maps event names or integer event numbers to colors (must include entries for all events, or include a ‚Äúfallback‚Äù entry with key -1). If None, colors are chosen from the current Matplotlib color cycle. Defaults to None.

Order in which to plot channel types.

Show figure if True. Defaults to True.

Whether to halt program execution until the figure is closed. Useful for rejecting bad trials on the fly by clicking on an epoch. Defaults to False.

Amount to decimate the data during display for speed purposes. You should only decimate if the data are sufficiently low-passed, otherwise aliasing can occur. The ‚Äòauto‚Äô mode (default) uses the decimation that results in a sampling rate at least three times larger than info['lowpass'] (e.g., a 40 Hz lowpass will result in at least a 120 Hz displayed sample rate).

Noise covariance used to whiten the data while plotting. Whitened data channels are scaled by scalings['whitened'], and their channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().

Whether to directly call the butterfly view.

Whether to show scrollbars when the plot is initialized. Can be toggled after initialization by pressing z (‚Äúzen mode‚Äù) while the plot window is focused. Default is True.

Whether to show scale bars when the plot is initialized. Can be toggled after initialization by pressing s while the plot window is focused. Default is True.

Colors to use for individual epochs. If None, use default colors.

Determines to label the event markers on the plot. If True, uses epochs.event_id. If False, uses integer event codes instead of IDs. If a dict is passed, uses its keys as event labels on the plot for entries whose values are integer codes for events being drawn. Ignored if events=False.

How to group channels. 'type' groups by channel type, 'original' plots in the order of ch_names, 'selection' uses Elekta‚Äôs channel groupings (only works for Neuromag data), 'position' groups the channels by the positions of the sensors. 'selection' and 'position' modes allow custom selections by using a lasso selector on the topomap. In butterfly mode, 'type' and 'original' group the channels by type, whereas 'selection' and 'position' use regional grouping. 'type' and 'original' modes are ignored when order is not None. Defaults to 'type'.

Whether to load all data (not just the visible portion) into RAM and apply preprocessing (e.g., projectors) to the full data array in a separate processor thread, instead of window-by-window during scrolling. The default None uses the MNE_BROWSER_PRECOMPUTE variable, which defaults to 'auto'. 'auto' compares available RAM space to the expected size of the precomputed data, and precomputes only if enough RAM is available. This is only used with the Qt backend.

Changed in version 1.0: Support for the MNE_BROWSER_PRECOMPUTE config variable.

Whether to use OpenGL when rendering the plot (requires pyopengl). May increase performance, but effect is dependent on system CPU and graphics hardware. Only works if using the Qt backend. Default is None, which will use False unless the user configuration variable MNE_BROWSER_USE_OPENGL is set to 'true', see mne.set_config().

Can be ‚Äúauto‚Äù, ‚Äúlight‚Äù, or ‚Äúdark‚Äù or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_BROWSER_THEME will be used, defaulting to ‚Äúauto‚Äù if it‚Äôs not found. Only supported by the 'qt' backend.

Can be ‚Äúchannels‚Äù, ‚Äúempty‚Äù, or ‚Äúhidden‚Äù to set the overview bar mode for the 'qt' backend. If None (default), the config option MNE_BROWSER_OVERVIEW_MODE will be used, defaulting to ‚Äúchannels‚Äù if it‚Äôs not found.

If True (default), a splash screen is shown during the application startup. Only applicable to the qt backend.

The arrow keys (up/down/left/right) can be used to navigate between channels and epochs and the scaling can be adjusted with - and + (or =) keys, but this depends on the backend matplotlib is configured to use (e.g., mpl.use(TkAgg) should work). Full screen mode can be toggled with f11 key. The amount of epochs and channels per view can be adjusted with home/end and page down/page up keys. h key plots a histogram of peak-to-peak values along with the used rejection thresholds. Butterfly plot can be toggled with b key. Left mouse click adds a vertical line to the plot. Click ‚Äòhelp‚Äô button at bottom left corner of the plotter to view all the options.

MNE-Python provides two different backends for browsing plots (i.e., raw.plot(), epochs.plot(), and ica.plot_sources()). One is based on matplotlib, and the other is based on PyQtGraph. You can set the backend temporarily with the context manager mne.viz.use_browser_backend(), you can set it for the duration of a Python session using mne.viz.set_browser_backend(), and you can set the default for your computer via mne.set_config('MNE_BROWSER_BACKEND', 'matplotlib') (or 'qt').

For the PyQtGraph backend to run in IPython with block=False you must run the magic command %gui qt5 first.

To report issues with the PyQtGraph backend, please use the issues of mne-qt-browser.

Working with sEEG data

The Epochs data structure: discontinuous data

Visualizing epoched data

EEG analysis - Event-Related Potentials (ERPs)

Plotting whitened data

KIT phantom dataset tutorial

Rejecting bad data spans and breaks

Creating MNE-Python data structures from scratch

DICS for power mapping

Show the channel stats based on a drop_log from Epochs.

The percentage threshold to use to decide whether or not to plot. Default is zero (always plot).

Maximum number of channels to show stats for.

The subject name to use in the title of the plot. If None, do not display a subject name.

Changed in version 0.23: Added support for None.

Changed in version 1.0: Defaults to None.

Color to use for the bars.

The drop reasons to ignore.

Examples using plot_drop_log:

EEG analysis - Event-Related Potentials (ERPs)

Rejecting bad data spans and breaks

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Plot Event Related Potential / Fields image.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided. picks interacts with group_by and combine to determine the number of figures generated; see Notes.

The standard deviation of a Gaussian smoothing window applied along the epochs axis of the image. If 0, no smoothing is applied. Defaults to 0.

The min value in the image (and the ER[P/F]). The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers. If vmin is None and multiple plots are returned, the limit is equalized within channel types. Hint: to specify the lower limit of the data, use vmin=lambda data: data.min().

The max value in the image (and the ER[P/F]). The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers. If vmin is None and multiple plots are returned, the limit is equalized within channel types.

Display or not a colorbar.

If not None, order is used to reorder the epochs along the y-axis of the image. If it is an array of int, its length should match the number of good epochs. If it is a callable it should accept two positional parameters (times and data, where data.shape == (len(good_epochs), len(times))) and return an array of indices that will sort data along its first axis.

The units of the channel types used for axes labels. If None, defaults to units=dict(eeg='¬µV', grad='fT/cm', mag='fT').

The scalings of the channel types to be applied for plotting. If None, defaults to scalings=dict(eeg=1e6, grad=1e13, mag=1e15, eog=1e6).

Colormap. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the scale. Up and down arrows can be used to change the colormap. If ‚Äòinteractive‚Äô, translates to (‚ÄòRdBu_r‚Äô, True). If None, ‚ÄúRdBu_r‚Äù is used, unless the data is all positive, in which case ‚ÄúReds‚Äù is used.

Figure instance to draw the image to. Figure must contain the correct number of axes for drawing the epochs image, the evoked response, and a colorbar (depending on values of evoked and colorbar). If None a new figure is created. Defaults to None.

List of Axes objects in which to draw the image, evoked response, and colorbar (in that order). Length of list must be 1, 2, or 3 (depending on values of colorbar and evoked parameters). If a dict, each entry must be a list of Axes objects with the same constraints as above. If both axes and group_by are dicts, their keys must match. Providing non-None values for both fig and axes results in an error. Defaults to None.

Times (in seconds) at which to draw a line on the corresponding row of the image (e.g., a reaction time associated with each epoch). Note that overlay_times should be ordered to correspond with the Epochs object (i.e., overlay_times[0] corresponds to epochs[0], etc).

How to aggregate across channels. If None, channels are combined by computing GFP/RMS, unless group_by is also None and picks is a list of specific channels (not channel types), in which case no combining is performed and each channel gets its own figure. If a string, "mean" uses numpy.mean(), "median" computes the marginal median, "std" uses numpy.std(), and "gfp" computes global field power for EEG channels and RMS amplitude for MEG channels. If callable(), it must operate on an array of shape (n_epochs, n_channels, n_times) and return an array of shape (n_epochs, n_times). For example:

See Notes for further details. Defaults to None.

Specifies which channels are aggregated into a single figure, with aggregation method determined by the combine parameter. If not None, one Figure is made per dict entry; the dict key will be used as the figure title and the dict values must be lists of picks (either channel names or integer indices of epochs.ch_names). For example:

Note that within a dict entry all channels must have the same type. group_by interacts with picks and combine to determine the number of figures generated; see Notes. Defaults to None.

Draw the ER[P/F] below the image or not.

Arguments passed to a call to plot_compare_evokeds to style the evoked plot below the image. Defaults to an empty dictionary, meaning plot_compare_evokeds will be called with default parameters.

If str, will be plotted as figure title. Otherwise, the title will indicate channel(s) or channel type being plotted. Defaults to None.

Whether to clear the axes before plotting (if fig or axes are provided). Defaults to False.

One figure per channel, channel type, or group, depending on values of picks, group_by, and combine. See Notes.

You can control how channels are aggregated into one figure or plotted in separate figures through a combination of the picks, group_by, and combine parameters. If group_by is a dict, the result is one Figure per dictionary key (for any valid values of picks and combine). If group_by is None, the number and content of the figures generated depends on the values of picks and combine, as summarized in this table:

None, int, list of int, ch_name, list of ch_names, ch_type, list of ch_types

None, string, or callable

1 figure per dict key

None, ch_type, list of ch_types

None, string, or callable

int, ch_name, list of int, list of ch_names

Examples using plot_image:

Plot single trial activity, grouped by ROI and sorted by RT

Visualizing epoched data

Divide continuous data into equally-spaced epochs

Visualizing Evoked data

Overview of MEG/EEG analysis with MNE-Python

Overview of artifact detection

Rejecting bad data spans and breaks

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None it will return all channel types present.. If a list of ch_types is provided, it will return multiple figures. Defaults to None.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches. Only applies when plotting multiple topomaps at a time.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all projectors of the same channel type (instead of separately for each projector), using the min/max of the data for that channel type. If vlim is "joint", info must not be None. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of projectors. Default is None.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Examples using plot_projs_topomap:

Visualizing epoched data

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (‚ïé) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (‚ãÆ). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

If False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap.

Plot power spectral density (PSD) in units (dB/Hz) if dB=True and estimate='power'. Plot PSD in units (amplitude**2/Hz) if dB=False and estimate='power'. Plot amplitude spectral density (ASD) in units (amplitude/sqrt(Hz)) if dB=False and estimate='amplitude'. Plot ASD in units (dB/sqrt(Hz)) if dB=True and estimate='amplitude'.

Can be ‚Äúpower‚Äù for power spectral density (PSD; default), ‚Äúamplitude‚Äù for amplitude spectrum density (ASD).

Scale of the frequency axis. Default is 'linear'.

Mode for plotting area. If ‚Äòstd‚Äô, the mean +/- 1 STD (across channels) will be plotted. If ‚Äòrange‚Äô, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Alpha for the PSD line. Can be None (default) to use 1.0 when average=True and 0.1 when average=False.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channels names to exclude from being shown. If ‚Äòbads‚Äô, the bad channels are excluded. Pass an empty list to plot all channels (including channels marked ‚Äúbad‚Äù, if any).

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of channel types present in the object.. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure with frequency spectra of the data channels.

This method exists to support legacy code; for new code the preferred idiom is inst.compute_psd().plot() (where inst is an instance of Raw, Epochs, or Evoked).

Examples using plot_psd:

Visualizing epoched data

LEGACY: New code should use .compute_psd().plot_topo().

Plot power spectral density, separately for each channel.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=100.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch(). Defaults to dict(n_fft=2048).

Figure distributing one image per channel across sensor topography.

LEGACY: New code should use .compute_psd().plot_topomap().

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‚Äò%0.3f‚Äô if dB=False and ‚Äò%0.1f‚Äô if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure showing one scalp topography per frequency band.

Examples using plot_psd_topomap:

Visualizing epoched data

Plot sensor positions.

Whether to plot the sensors as 3d, topomap or as an interactive sensor selection dialog. Available options ‚Äòtopomap‚Äô, ‚Äò3d‚Äô, ‚Äòselect‚Äô. If ‚Äòselect‚Äô, a set of channels can be selected interactively by using lasso selector or clicking while holding control key. The selected channels are returned along with the figure instance. Defaults to ‚Äòtopomap‚Äô.

The channel type to plot. Available options 'mag', 'grad', 'eeg', 'seeg', 'dbs', 'ecog', 'all'. If 'all', all the available mag, grad, eeg, seeg, dbs, and ecog channels are plotted. If None (default), then channels are chosen in the order given above.

Title for the figure. If None (default), equals to 'Sensor positions (%s)' % ch_type.

Whether to display all channel names. If an array, only the channel names in the array are shown. Defaults to False.

Channel groups for coloring the sensors. If None (default), default coloring scheme is used. If ‚Äòposition‚Äô, the sensors are divided into 8 regions. See order kwarg of mne.viz.plot_raw(). If array, the channels are divided by picks given in the array.

Whether to project the 3d locations to a sphere. When False, the sensor array appears similar as to looking downwards straight above the subject‚Äôs head. Has no effect when kind=‚Äô3d‚Äô. Defaults to True.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Whether to halt program execution until the figure is closed. Defaults to False.

Show figure if True. Defaults to True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the sensor topography.

A list of selected channels. Only returned if kind=='select'.

This function plots the sensor locations from the info structure using matplotlib. For drawing the sensors using PyVista see mne.viz.plot_alignment().

Examples using plot_sensors:

Visualizing epoched data

Plot Event Related Potential / Fields image on topographies.

System specific sensor positions.

The standard deviation of the Gaussian smoothing to apply along the epoch axis to apply in the image. If 0., no smoothing is applied.

The min value in the image. The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers.

The max value in the image. The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers.

Whether to display a colorbar or not. If None a colorbar will be shown only if all channels are of the same type. Defaults to None.

If not None, order is used to reorder the epochs on the y-axis of the image. If it‚Äôs an array of int it should be of length the number of good epochs. If it‚Äôs a callable the arguments passed are the times vector and the data as 2d array (data.shape[1] == len(times)).

Colors to be mapped to the values.

Scaling factor for adjusting the relative size of the layout on the canvas.

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

Matplotlib borders style to be used for each sensor plot.

The figure face color. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

Whether to enable the lasso-selection tool to enable the user to select channels. The selected channels will be available in fig.lasso.selection.

Whether to show the figure. Defaults to True.

Figure distributing one image per channel across sensor topography.

In an interactive Python session, this plot will be interactive; clicking on a channel image will pop open a larger view of the image; this image will always have a colorbar even when the topo plot does not (because it shows multiple sensor types).

Examples using plot_topo_image:

Visualizing epoched data

Whether or not projections are active.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

Examples using rename_channels:

The Epochs data structure: discontinuous data

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be "auto" to use a padding that will result in a power-of-two size (can be much faster).

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly.

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn().

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled object.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent ‚Äì check your data!

Examples using resample:

Filtering and resampling data

Reset the drop_log and selection entries.

This method will simplify self.drop_log and self.selection so that they are meaningless (tuple of empty tuples and increasing integers, respectively). This can be useful when concatenating many Epochs instances, as drop_log can accumulate many entries which can become problematic when saving.

Save epochs in a fif file.

The name of the file, which should end with -epo.fif or -epo.fif.gz.

Large raw files are automatically split into multiple pieces. This parameter specifies the maximum size of each piece. If the parameter is an integer, it specifies the size in Bytes. It is also possible to pass a human-readable string, e.g., 100MB. Note: Due to FIFF file limitations, the maximum split size is 2GB.

Format to save data. Valid options are ‚Äòdouble‚Äô or ‚Äòsingle‚Äô for 64- or 32-bit float, or for 128- or 64-bit complex numbers respectively. Note: Data are processed with double precision. Choosing single-precision, the saved data will slightly differ due to the reduction in precision.

If True (default False), overwrite the destination file if it exists. To overwrite original file (the same one that was loaded), data must be preloaded upon reading. This defaults to True in 0.18 but will change to False in 0.19.

When splitting files, append a filename partition with the appropriate naming schema. For 'neuromag', a split file fname.fif will be named fname.fif, fname-1.fif, fname-2.fif, and so on. For 'bids', a filename is expected to consist of parts separated by underscores, like <part-1>_<part-N>_<suffix>.fif, and the according split naming will return filenames like <part-1>_<part-N>_split-01_<suffix>.fif, <part-1>_<part-N>_split-02_<suffix>.fif, and so on.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of path-like objects containing the path to each file split.

Bad epochs will be dropped before saving the epochs to disk.

The Epochs data structure: discontinuous data

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [9] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627‚Äì1639, 1964. doi:10.1021/ac60214a047.

Setter for Epoch annotations from Raw.

This method does not handle offsetting the times based on first_samp or measurement dates, since that is expected to occur in Raw.set_annotations().

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs object with annotations.

Annotation onsets and offsets are stored as time in seconds (not as sample numbers).

If you have an -epo.fif file saved to disk created before 1.0, annotations can be added correctly only if no decimation or resampling was performed. We thus suggest to regenerate your mne.Epochs from raw and re-save to disk with 1.0+ if you want to safely work with Annotations in epochs.

Since this method does not handle offsetting the times based on first_samp or measurement dates, the recommended way to add Annotations is:

Specify the sensor types of channels.

A dictionary mapping channel names to sensor types, e.g., {'EEG061': 'eog'}.

What to do if the measurement unit of a channel is changed automatically to match the new sensor type.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The following sensor types are accepted:

bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci, eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase, fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp, seeg, stim, syst, temperature.

When working with eye-tracking data, see mne.preprocessing.eyetracking.set_channel_types_eyetrack().

Examples using set_channel_types:

The Epochs data structure: discontinuous data

Specify which reference to use for EEG data.

Use this function to explicitly specify the desired reference for EEG. This can be either an existing electrode or a new virtual channel. This function will re-reference the data according to the desired reference.

The name(s) of the channel(s) used to construct the reference for every channel of ch_type.

'average' to apply an average reference (default)

'REST' to use the Reference Electrode Standardization Technique infinity reference [10].

A dictionary mapping names of data channels to (lists of) names of reference channels. For example, {‚ÄòA1‚Äô: ‚ÄòA3‚Äô} would replace the data in channel ‚ÄòA1‚Äô with the difference between ‚ÄòA1‚Äô and ‚ÄòA3‚Äô. To take the average of multiple channels as reference, supply a list of channel names as the dictionary value, e.g. {‚ÄòA1‚Äô: [‚ÄòA2‚Äô, ‚ÄòA3‚Äô]} would replace channel A1 with A1 - mean(A2, A3).

An empty list, in which case MNE will not attempt any re-referencing of the data

If ref_channels='average' this argument specifies if the average reference should be computed as a projection (True) or not (False; default). If projection=True, the average reference is added as a projection and is not applied to the data (it can be applied afterwards with the apply_proj method). If projection=False, the average reference is directly applied to the data. If ref_channels is not 'average', projection must be set to False (the default in this case).

The name of the channel type to apply the reference to. Valid channel types are 'auto', 'eeg', 'ecog', 'seeg', 'dbs'. If 'auto', the first channel type of eeg, ecog, seeg or dbs that is found (in that order) will be selected.

Changed in version 1.2: list-of-str is now supported with projection=True.

Forward solution to use. Only used with ref_channels='REST'.

How to handle list-of-str ch_type. If False (default), one projector is created per channel type. If True, one projector is created across all channel types. This is only used when projection=True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data with EEG channels re-referenced. If ref_channels='average' and projection=True a projection will be added instead of directly re-referencing the data.

Convenience function for creating bipolar references.

Some common referencing schemes and the corresponding value for the ref_channels parameter:

A new virtual reference electrode is created by averaging the current EEG signal by setting ref_channels='average'. Bad EEG channels are automatically excluded if they are properly set in info['bads'].

Set ref_channels to a list containing the name of the channel that will act as the new reference, for example ref_channels=['Cz'].

A new virtual reference electrode is created by computing the average of the current EEG signal recorded from two or more selected channels. Set ref_channels to a list of channel names, indicating which channels to use. For example, to apply an average mastoid reference, when using the 10-20 naming scheme, set ref_channels=['M1', 'M2'].

The given EEG electrodes are referenced to a point at infinity using the lead fields in forward, which helps standardize the signals.

Set ref_channels to a dictionary mapping source channel names (str) to the reference channel names (str or list of str). Unlike the other approaches where the same reference is applied globally, you can set different references for different channels with this method. For example, to re-reference channel ‚ÄòA1‚Äô to ‚ÄòA2‚Äô and ‚ÄòB1‚Äô to the average of ‚ÄòB2‚Äô and ‚ÄòB3‚Äô, set ref_channels={'A1': 'A2', 'B1': ['B2', 'B3']}. Warnings are issued when a mapping involves bad channels or channels of different types.

If a reference is requested that is not the average reference, this function removes any pre-existing average reference projections.

During source localization, the EEG signal should have an average reference.

In order to apply a reference, the data must be preloaded. This is not necessary if ref_channels='average' and projection=True.

For an average or REST reference, bad EEG channels are automatically excluded if they are properly set in info['bads'].

D. Yao. A method to standardize a reference of scalp EEG recordings to a point at infinity. Physiological Measurement, 22(4):693‚Äì711, 2001. doi:10.1088/0967-3334/22/4/305.

Set the measurement start date.

The new measurement date. If datetime object, it must be timezone-aware and in UTC. A tuple of (seconds, microseconds) or float (alias for (meas_date, 0)) can also be passed and a datetime object will be automatically created. If None, will remove the time reference.

The modified raw instance. Operates in place.

If you want to remove all time references in the file, call mne.io.anonymize_info(inst.info) after calling inst.set_meas_date(None).

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

A montage containing channel positions. If a string or DigMontage is specified, the existing channel information will be updated with the channel positions from the montage. Valid strings are the names of the built-in montages that ship with MNE-Python; you can list those via mne.channels.get_builtin_montages(). If None (default), the channel positions will be removed from the Info.

If True (default), channel name matching will be case sensitive.

Whether to use a lookup table to match unrecognized channel location names to their known aliases. If True, uses the mapping in mne.io.constants.CHANNEL_LOC_ALIASES. If a dict is passed, it will be used instead, and should map from non-standard channel names to names in the specified montage. Default is False.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when channels have missing coordinates.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

Only EEG/sEEG/ECoG/DBS/fNIRS channels can have their positions set using a montage. Other channel types (e.g., MEG channels) should have their positions defined properly using their data reading functions.

Applying a montage will only set locations of channels that exist at the time it is applied. This means when re-referencing make sure to apply the montage only after calling mne.add_reference_channels()

Examples using set_montage:

Working with sEEG data

Working with sensor locations

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Compute standard error over epochs.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

When False (the default) all epochs are processed together and a single Evoked object is returned. When True, epochs are first grouped by event type (as specified using the event_id parameter) and a list is returned containing a separate Evoked object for each event type. The .comment attribute is set to the label of the event type.

The standard error over epochs. When by_event_type=True was specified, a list is returned containing a separate Evoked object for each event type. The list has the same order as the event types as specified in the event_id dictionary.

Subtract an evoked response from each epoch.

Can be used to exclude the evoked response when analyzing induced activity, see e.g. [1].

The evoked response to subtract. If None, the evoked response is computed from Epochs itself.

The modified instance (instance is also modified inplace).

David et al. ‚ÄúMechanisms of evoked and induced responses in MEG/EEG‚Äù, NeuroImage, vol. 31, no. 4, pp. 1580-1591, July 2006.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

Time vector in seconds.

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, additional columns ‚Äútime‚Äù, ‚Äúepoch‚Äù (epoch number), and ‚Äúcondition‚Äù (epoch event description) are added, unless index is not None (in which case the columns specified in index will be used to form the DataFrame‚Äôs index instead).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). If a list of two or more string values, a pandas.MultiIndex will be created. Valid string values are ‚Äòtime‚Äô, ‚Äòepoch‚Äô, and ‚Äòcondition‚Äô. Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) ‚Äî i.e., converts EEG to ¬µV, magnetometers to fT, and gradiometers to fT/cm.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point, channel, epoch number, and condition. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Examples using to_data_frame:

The Epochs data structure: discontinuous data

Exporting Epochs to Pandas DataFrames

Visualising statistical significance thresholds on EEG data

Brainstorm raw (median nerve) dataset

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Decoding source space data

Continuous Target Decoding with SPoC

Decoding sensor space data with generalization across time and conditions

Analysis of evoked response using ICA and PCA reduction techniques

XDAWN Decoding From EEG data

Compute effect-matched-spatial filtering (EMS)

Linear classifier on sensor data with plot patterns and filters

Compute spatial filters with Spatio-Spectral Decomposition (SSD)

Compute MNE-dSPM inverse solution on single epochs

Compute source level time-frequency timecourses using a DICS beamformer

Compute source power using DICS beamformer

Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM

Compute source power estimate by projecting the covariance with MNE

Computing source timecourses with an XFit-like multi-dipole model

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Compute cross-talk functions for LCMV beamformers

Getting averaging info from .fif files

Define target events based on time lag, plot evoked response

Transform EEG data using current source density (CSD)

Show EOG artifact timing

Reduce EOG artifacts through regression

Automated epochs metadata generation with variable time windows

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Maxwell filter data with movement compensation

Plot sensor denoising using oversampled temporal projection

Compare simulated and estimated source activity

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

Permutation F-test on sensor data with 1D cluster level

FDR correction on T-test on sensor data

Regression on continuous data (rER[P/F])

Permutation T-test on sensor data

Compute a cross-spectral density (CSD) matrix

Compute Power Spectral Density of inverse solution from single epochs

Compute power and phase lock in label of the source space

Compute induced power in the source space with dSPM

Compute and visualize ERDS maps

Explore event-related dynamics for specific frequency bands

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Visualize channel over epochs as an image

Whitening evoked data with a noise covariance

Plotting eye-tracking heatmaps in MNE-Python

Plot single trial activity, grouped by ROI and sorted by RT

Compare evoked responses for different conditions

Working with sEEG data

Working with ECoG data

Sleep stage classification from polysomnography (PSG) data

The Epochs data structure: discontinuous data

Regression-based baseline correction

Visualizing epoched data

Working with Epoch metadata

Auto-generating Epochs metadata

Exporting Epochs to Pandas DataFrames

Divide continuous data into equally-spaced epochs

The Evoked data structure: evoked/averaged data

Visualizing Evoked data

EEG analysis - Event-Related Potentials (ERPs)

Plotting whitened data

Computing a covariance matrix

Overview of MEG/EEG analysis with MNE-Python

Modifying data in-place

Parsing events from raw data

The Info data structure

Getting started with mne.Report

Source localization with MNE, dSPM, sLORETA, and eLORETA

Source reconstruction using an LCMV beamformer

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

Working with CTF data: the Brainstorm auditory dataset

Overview of artifact detection

Handling bad channels

Rejecting bad data spans and breaks

Filtering and resampling data

Repairing artifacts with regression

Repairing artifacts with ICA

Repairing artifacts with SSP

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Preprocessing optically pumped magnetometer (OPM) MEG data

Working with eye tracker data in MNE-Python

Creating MNE-Python data structures from scratch

Corrupt known signal with point spread

DICS for power mapping

Visualising statistical significance thresholds on EEG data

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency and time-frequency sensor analysis

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

---

## mne.equalize_channels#

**URL:** https://mne.tools/stable/generated/mne.equalize_channels.html

**Contents:**
- mne.equalize_channels#

Equalize channel picks and ordering across multiple MNE-Python objects.

First, all channels that are not common to each object are dropped. Then, using the first object in the list as a template, the channels of each object are re-ordered to match the template. The end result is that all given objects define the same channels, in the same order.

A list of MNE-Python objects to equalize the channels for. Objects can be of type Raw, Epochs, Evoked, Spectrum, AverageTFR, Forward, Covariance, CrossSpectralDensity or Info.

Changed in version 1.11: Added support for mne.time_frequency.Spectrum objects.

When dropping and/or re-ordering channels, an object will be copied when this parameter is set to True. When set to False (the default) the dropping and re-ordering of channels happens in-place.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of MNE-Python objects that have the same channels defined in the same order.

---

## mne.EvokedArray#

**URL:** https://mne.tools/stable/generated/mne.EvokedArray.html

**Contents:**
- mne.EvokedArray#
- Examples using mne.EvokedArray#

Evoked object from numpy array.

The channels‚Äô evoked response. See notes for proper units of measure.

The mne.Info object with information about the sensors and methods of measurement. Consider using mne.create_info() to populate this structure.

Start time before event. Defaults to 0.

Comment on dataset. Can be the condition. Defaults to ‚Äò‚Äô.

Number of averaged epochs. Defaults to 1.

Type of data, either average or standard_error. Defaults to ‚Äòaverage‚Äô.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire Evoked.

Defaults to None, i.e. no baseline correction.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The current gradient compensation grade.

The filename of the evoked object, if it exists.

Whether or not projections are active.

Time vector in seconds.

__contains__(ch_type)

Check channel type membership.

Negate channel responses.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_proj(projs[, remove_existing, verbose])

Add SSP projection vectors.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

animate_topomap([ch_type, times, ...])

Make animation of evoked data as topomap timeseries.

anonymize([daysback, keep_his, verbose])

Anonymize measurement information in place.

apply_baseline([baseline, verbose])

Baseline correct evoked data.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of channels.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

apply_proj([verbose])

Apply the signal space projection (SSP) operators to the data.

as_type([ch_type, mode])

Compute virtual evoked using interpolated fields.

compute_psd([method, fmin, fmax, tmin, ...])

Perform spectral analysis on sensor data.

compute_tfr(method, freqs, *[, tmin, tmax, ...])

Compute a time-frequency representation of evoked data.

Copy the instance of evoked.

crop([tmin, tmax, include_tmax, verbose])

Crop data to a given time interval.

decimate(decim[, offset, verbose])

Decimate the time-series data.

Remove SSP projection vector.

detrend([order, picks])

drop_channels(ch_names[, on_missing])

export(fname[, fmt, overwrite, verbose])

Export Evoked to external formats.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, units, tmin, tmax])

Get evoked data as 2D array.

Get a DigMontage from instance.

get_peak([ch_type, tmin, tmax, mode, ...])

Get location and latency of peak amplitude.

interpolate_bads([reset_bads, mode, origin, ...])

Interpolate bad MEG and EEG channels.

interpolate_to(sensors[, origin, method, reg])

Interpolate EEG data onto a new montage.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, exclude, unit, show, ylim, ...])

Plot evoked data using butterfly plots.

plot_field(surf_maps[, time, time_label, ...])

Plot MEG/EEG fields on head surface and helmet in 3D.

plot_image([picks, exclude, unit, show, ...])

Plot evoked data as images.

plot_joint([times, title, picks, exclude, ...])

Plot evoked data as butterfly plot and add topomaps for time points.

plot_projs_topomap([ch_type, sensors, ...])

plot_psd([fmin, fmax, tmin, tmax, picks, ...])

Plot power or amplitude spectra.

plot_psd_topo([tmin, tmax, fmin, fmax, ...])

plot_psd_topomap([bands, tmin, tmax, ...])

plot_sensors([kind, ch_type, title, ...])

Plot sensor positions.

plot_topo([layout, layout_scale, color, ...])

Plot 2D topography of evoked responses.

plot_topomap([times, average, ch_type, ...])

Plot topographic maps of specific time points of evoked data.

plot_white(noise_cov[, show, rank, ...])

Plot whitened evoked response.

rename_channels(mapping[, allow_duplicates, ...])

reorder_channels(ch_names)

resample(sfreq, *[, npad, window, n_jobs, ...])

save(fname, *[, overwrite, verbose])

Save evoked data to a file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

set_channel_types(mapping, *[, ...])

Specify the sensor types of channels.

set_eeg_reference([ref_channels, ...])

Specify which reference to use for EEG data.

set_meas_date(meas_date)

Set the measurement start date.

set_montage(montage[, match_case, ...])

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

Proper units of measure:

V: eeg, eog, seeg, dbs, emg, ecg, bio, ecog

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Negate channel responses.

The Evoked instance with channel data negated and ‚Äò-‚Äô prepended to the comment.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add SSP projection vectors.

List with projection vectors.

Remove the projection vectors currently in the file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Examples using add_proj:

Brainstorm raw (median nerve) dataset

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Make animation of evoked data as topomap timeseries.

The animation can be paused/resumed with left mouse button. Left and right arrow keys can be used to move backward or forward in time.

Channel type to plot. Accepted data types: ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòeeg‚Äô, ‚Äòhbo‚Äô, ‚Äòhbr‚Äô, ‚Äòfnirs_cw_amplitude‚Äô, ‚Äòfnirs_fd_ac_amplitude‚Äô, ‚Äòfnirs_fd_phase‚Äô, and ‚Äòfnirs_od‚Äô. If None, first available channel type from the above list is used. Defaults to None.

The time points to plot. If None, 10 evenly spaced samples are calculated over the evoked time series. Defaults to None.

Frame rate for the animation in Hz. If None, frame rate = sfreq / 10. Defaults to None.

Whether to plot the data as butterfly plot under the topomap. Defaults to False.

Whether to use blit to optimize drawing. In general, it is recommended to use blit in combination with show=True. If you intend to save the animation it is better to disable blit. Defaults to True.

Whether to show the animation. Defaults to True.

The units for the time axis, can be ‚Äúms‚Äù (default in 0.16) or ‚Äús‚Äù (will become the default in 0.17).

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Lower and upper bounds of the colormap, in the same units as the data. If vmin and vmax are both None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0). If only one of vmin, vmax is None, will use min(data) or max(data), respectively. If callable, should accept a NumPy array of data and return a float.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Animation of the topomap.

Anonymize measurement information in place.

Number of days to subtract from all dates. If None (default), the acquisition date, info['meas_date'], will be set to January 1À¢·µó, 2000. This parameter is ignored if info['meas_date'] is None (i.e., no acquisition date has been set).

If True, his_id of subject_info will not be overwritten. Defaults to False.

This could mean that info is not fully anonymized. Use with caution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Removes potentially identifying information if it exists in info. Specifically for each of the following we use:

A default value, or as specified by daysback.

Default values, except for ‚Äòbirthday‚Äô which is adjusted to maintain the subject age.

Dates use the meas_date logic, and experimenter a default string.

Dates use the meas_date logic, meta info uses defaults.

If info['meas_date'] is None, it will remain None during processing the above fields.

Baseline correct evoked data.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire Evoked.

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected Evoked object.

Baseline correction can be done multiple times.

Examples using apply_baseline:

Repairing artifacts with regression

Repairing artifacts with ICA

Repairing artifacts with SSP

Apply a function to a subset of channels.

The function fun is applied to the channels defined in picks. The evoked object‚Äôs data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to channels in picks).

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) because it will apply channel-wise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if channel_wise=False as the workload is split across channels.

Whether to apply the function to each channel individually. If False, the function will be applied to all channels at once. Default True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The evoked object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‚Äòauto‚Äô, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal ‚Äúx_a(t)‚Äù of ‚Äúx(t)‚Äù is:

where ‚ÄúF‚Äù is the Fourier transform, ‚ÄúU‚Äù the unit step function, and ‚Äúy‚Äù the Hilbert transform of ‚Äúx‚Äù. One usage of the analytic signal is the computation of the envelope signal, which is given by ‚Äúe(t) = abs(x_a(t))‚Äù. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Apply the signal space projection (SSP) operators to the data.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Once the projectors have been applied, they can no longer be removed. It is usually not recommended to apply the projectors at too early stages, as they are applied automatically later on (e.g. when computing inverse solutions). Hint: using the copy method individual projection vectors can be tested without affecting the original data. With evoked data, consider the following example:

Examples using apply_proj:

Brainstorm raw (median nerve) dataset

Compute virtual evoked using interpolated fields.

Using virtual evoked to compute inverse can yield unexpected results. The virtual channels have '_v' appended at the end of the names to emphasize that the data contained in them are interpolated.

The destination channel type. It can be ‚Äòmag‚Äô or ‚Äògrad‚Äô.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used. 'fast' should be sufficient for most applications.

The transformed evoked object containing only virtual channels.

This method returns a copy and does not modify the data it operates on. It also returns an EvokedArray instance.

The current gradient compensation grade.

Perform spectral analysis on sensor data.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. Default is 'multitaper'.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

If True, the mean is subtracted from each segment before computing its spectrum.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

The spectral representation of the data.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70‚Äì73, 1967. doi:10.1109/TAU.1967.1161901.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371‚Äì1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Examples using compute_psd:

The Spectrum and EpochsSpectrum classes: frequency-domain data

Compute a time-frequency representation of evoked data.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [2]. None (the default) only works when using __setstate__ and will raise an error otherwise.

The frequencies at which to compute the power estimates. Must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

What kind of estimate to return. Allowed values are "complex", "phase", and "power". Default is "power".

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet() and tfr_array_multitaper() for additional details.

The time-frequency-resolved power estimates of the data.

Copy the instance of evoked.

A copy of the object.

Brainstorm raw (median nerve) dataset

Optically pumped magnetometer (OPM) data

Computing source timecourses with an XFit-like multi-dipole model

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Compute source power spectral density (PSD) of VectorView and OPM data

Working with ECoG data

Auto-generating Epochs metadata

The Evoked data structure: evoked/averaged data

EEG analysis - Event-Related Potentials (ERPs)

Computing a covariance matrix

4D Neuroimaging/BTi phantom dataset tutorial

Preprocessing optically pumped magnetometer (OPM) MEG data

Crop data to a given time interval.

Start time of selection in seconds.

End time of selection in seconds.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped time-series object, modified in-place.

Unlike Python slices, MNE time intervals by default include both their end points; crop(tmin, tmax) returns the interval tmin <= t <= tmax. Pass include_tmax=False to specify the half-open interval tmin <= t < tmax instead.

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Brainstorm CTF phantom dataset tutorial

Non-parametric 1 sample cluster statistic on single trial power

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / ‚Äúdecimation‚Äù refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [3], p. 172; which cites [4]):

‚Äú‚Ä¶ a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).‚Äù

Hence ‚Äúdecimation‚Äù in MNE is what is considered ‚Äúcompression‚Äù in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Remove SSP projection vector.

The projection vector can only be removed if it is inactive (has not been applied to the data).

Index of the projector to remove. Can also be ‚Äúall‚Äù (default) to remove all projectors.

Examples using del_proj:

Repairing artifacts with SSP

This function operates in-place.

Either 0 or 1, the order of the detrending. 0 is a constant (DC) detrend, 1 is a linear detrend.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The detrended evoked object.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Examples using drop_channels:

Compute source power estimate by projecting the covariance with MNE

Export Evoked to external formats.

MFF (.mff, uses mne.export.export_evokeds_mff())

Since we are exporting to external formats, there‚Äôs no guarantee that all the info will be preserved in the external format. See Notes for details.

Name of the output file.

Format of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.Evoked.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.Evoked.apply_proj().

The filename of the evoked object, if it exists.

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‚Äòauto‚Äô (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=‚Äôhamming‚Äô and fir_design=‚Äùfirwin2‚Äù, and half that for ‚Äúfirwin‚Äù).

str: A human-readable time in units of ‚Äús‚Äù or ‚Äúms‚Äù (e.g., ‚Äú10s‚Äù or ‚Äú5500ms‚Äù) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=‚Äùfirwin‚Äù, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be ‚Äúauto‚Äù (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be ‚Äúauto‚Äù (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be ‚Äúhamming‚Äù (default), ‚Äúhann‚Äù (default in 0.13), or ‚Äúblackman‚Äù.

Can be ‚Äúfirwin‚Äù (default) to use scipy.signal.firwin(), or ‚Äúfirwin2‚Äù to use scipy.signal.firwin2(). ‚Äúfirwin‚Äù uses a time-domain design technique that generally gives improved attenuation using fewer samples than ‚Äúfirwin2‚Äù.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Examples using filter:

Working with CTF data: the Brainstorm auditory dataset

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get evoked data as 2D array.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Specify the unit(s) that the data should be returned in. If None (default), the data is returned in the channel-type-specific default units, which are SI units (see Internal representation (units) and data channels). If a string, must be a sub-multiple of SI units that will be used to scale the data from all channels of the type associated with that unit. This only works if the data contains one channel type that has a unit (unitless channel types are left unchanged). For example if there are only EEG and STIM channels, units='uV' will scale EEG channels to micro-Volts while STIM channels will be unchanged. Finally, if a dictionary is provided, keys must be channel types, and values must be units to scale the data of that channel type to. For example dict(grad='fT/cm', mag='fT') will scale the corresponding types accordingly, but all other channel types will remain in their channel-type-specific default unit.

Start time of data to get in seconds.

End time of data to get in seconds.

A view on evoked data.

Examples using get_data:

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Regression-based baseline correction

Get a DigMontage from instance.

A copy of the channel positions, if available, otherwise None.

Get location and latency of peak amplitude.

The channel type to use. Defaults to None. If more than one channel type is present in the data, this value must be provided.

The minimum point in time to be considered for peak getting. If None (default), the beginning of the data is used.

The maximum point in time to be considered for peak getting. If None (default), the end of the data is used.

How to deal with the sign of the data. If ‚Äòpos‚Äô only positive values will be considered. If ‚Äòneg‚Äô only negative values will be considered. If ‚Äòabs‚Äô absolute values will be considered. Defaults to ‚Äòabs‚Äô.

Whether to return the time index instead of the latency in seconds.

If True, compute peak from merged gradiometer data.

If True, return also the amplitude at the maximum response.

If True, raise an error if values are all positive when detecting a minimum (mode=‚Äôneg‚Äô), or all negative when detecting a maximum (mode=‚Äôpos‚Äô). Defaults to True.

The channel exhibiting the maximum response.

The time point of the maximum response, either latency in seconds or index.

The amplitude of the maximum response. Only returned if return_amplitude is True.

Examples using get_peak:

The Evoked data structure: evoked/averaged data

EEG analysis - Event-Related Potentials (ERPs)

Interpolate bad MEG and EEG channels.

If True, remove the bads from info.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used for interpolation of channels using the minimum-norm method.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for each channel type.

"meg" channels support "MNE" (default) and "nan"

"eeg" channels support "spline" (default), "MNE" and "nan"

"fnirs" channels support "nearest" (default) and "nan"

"ecog" channels support "spline" (default) and "nan"

"seeg" channels support "spline" (default) and "nan"

None is an alias for:

If a str is provided, the method will be applied to all channel types supported and available in the instance. The method "nan" will replace the channel data with np.nan.

Be careful when using method="nan"; the default value reset_bads=True may not be what you want.

The channels to exclude from interpolation. If excluded a bad channel will stay in bads.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

The "MNE" method uses minimum-norm projection to a sphere and back.

Interpolate EEG data onto a new montage.

Be careful, only EEG channels are interpolated. Other channel types are not interpolated.

The target montage containing channel positions to interpolate onto.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for EEG channels. Supported methods are ‚Äòspline‚Äô (default) and ‚ÄòMNE‚Äô.

The regularization parameter for the interpolation method (only used when the method is ‚Äòspline‚Äô).

The instance with updated channel locations and data.

This method is useful for standardizing EEG layouts across datasets. However, some attributes may be lost after interpolation.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Computing source timecourses with an XFit-like multi-dipole model

Overview of MEG/EEG analysis with MNE-Python

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot evoked data using butterfly plots.

Left click to a line shows the channel name. Selecting an area by clicking and holding left mouse button plots a topographic map of the painted area.

If bad channels are not excluded they are shown in red.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channels names to exclude from being shown. If 'bads', the bad channels are excluded.

Scale plot with channel (SI) unit.

Y-axis limits for plots (after scaling has been applied). dict keys should match channel types; valid keys are for instance eeg, mag, grad, misc, csd, .. (example: ylim=dict(eeg=[-20, 20])). If None, the y-axis limits will be set automatically by matplotlib. Defaults to None.

Limits for the X-axis of the plots.

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown. If 'reconstruct', projection vectors will be applied and then M/EEG data will be reconstructed via field mapping to reduce the signal bias caused by projection.

Changed in version 0.21: Support for ‚Äòreconstruct‚Äô was added.

The values at which to show an horizontal line.

The units of the channel types used for axes labels. If None, defaults to dict(eeg='¬µV', grad='fT/cm', mag='fT').

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

The titles associated with the channels. If None, defaults to dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers').

The axes to plot to. If list, the list must be a list of Axes of the same length as the number of channel types. If instance of Axes, there must be only one channel type plotted.

Plot the global field power (GFP) or the root mean square (RMS) of the data. For MEG data, this will plot the RMS. For EEG, it plots GFP, i.e. the standard deviation of the signal across channels. The GFP is equivalent to the RMS of an average-referenced signal.

Plot GFP or RMS (for EEG and MEG, respectively) and traces for all channels.

Plot GFP or RMS (for EEG and MEG, respectively), and omit the traces for individual channels.

The color of the GFP/RMS trace will be green if spatial_colors=False, and black otherwise.

Changed in version 0.23: Plot GFP for EEG instead of RMS. Label RMS traces correctly as such.

The title to put at the top of the figure.

If True, the lines are color coded by mapping physical sensor coordinates into color values. Spatially similar channels will have similar colors. Bad channels will be dotted. If False, the good channels are plotted black and bad channels red. If 'auto', uses True if channel locations are present, and False if channel locations are missing or if the data contains only a single channel. Defaults to 'auto'.

Which channels to put in the front or back. Only matters if spatial_colors is used. If str, must be std or unsorted (defaults to unsorted). If std, data with the lowest standard deviation (weakest effects) will be put in front so that they are not obscured by those with stronger effects. If unsorted, channels are z-sorted as in the evoked instance. If callable, must take one argument: a numpy array of the same dimensionality as the evoked raw data; and return a list of unique integers corresponding to the number of channels.

Whether to use interactive features. If True (default), it is possible to paint an area to draw topomaps. When False, the interactive features are disabled. Disabling interactive features reduces memory consumption and is useful when using axes parameter to draw multiaxes figures.

Noise covariance used to whiten the data while plotting. Whitened data channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().

The units for the time axis, can be ‚Äús‚Äù (default) or ‚Äúms‚Äù.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Segments of the data to highlight by means of a light-yellow background color. Can be used to put visual emphasis on certain time periods. The time periods must be specified as array-like objects in the form of (t_start, t_end) in the unit given by the time_unit parameter. Multiple time periods can be specified by passing an array-like object of individual time periods (e.g., for 3 time periods, the shape of the passed object would be (3, 2). If None, no highlighting is applied.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the butterfly plots.

Brainstorm raw (median nerve) dataset

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Analysis of evoked response using ICA and PCA reduction techniques

Compute source power estimate by projecting the covariance with MNE

Define target events based on time lag, plot evoked response

Reduce EOG artifacts through regression

Interpolate EEG data to any montage

Generate simulated evoked data

Simulate raw data using subject anatomy

Generate simulated source data

Regression on continuous data (rER[P/F])

Whitening evoked data with a noise covariance

Regression-based baseline correction

Auto-generating Epochs metadata

The Evoked data structure: evoked/averaged data

EEG analysis - Event-Related Potentials (ERPs)

Plotting whitened data

Source localization with MNE, dSPM, sLORETA, and eLORETA

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

Working with CTF data: the Brainstorm auditory dataset

Repairing artifacts with regression

Repairing artifacts with SSP

Creating MNE-Python data structures from scratch

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Plot MEG/EEG fields on head surface and helmet in 3D.

The surface mapping information obtained with make_field_map.

The time point at which the field map shall be displayed. If None, the average peak latency (across sensor types) is used.

How to print info about the time instant visualized.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

If None (default), a new figure will be created, otherwise it will plot into the given figure.

New in v1.4: fig can also be a Brain figure.

Maximum intensity. Can be a dictionary with two entries "eeg" and "meg" to specify separate values for EEG and MEG fields respectively. Can be None to use the maximum value of the data.

New in v1.4: vmax can be a dictionary to specify separate values for EEG and MEG fields.

The number of contours.

Whether to draw the field density as an overlay on top of the helmet/head surface. Defaults to True.

Opacity of the meshes (between 0 and 1). Can be a dictionary with two entries "eeg" and "meg" to specify separate values for EEG and MEG fields respectively. Can be None to use 1.0 when a single field map is shown, or dict(eeg=1.0, meg=0.5) when both field maps are shown.

Interpolation method (scipy.interpolate.interp1d parameter). Must be one of 'linear', 'nearest', 'zero', 'slinear', 'quadratic' or 'cubic'.

How interactions with the scene via an input device (e.g., mouse or trackpad) modify the camera position. If 'terrain', one axis is fixed, enabling ‚Äúturntable-style‚Äù rotations. If 'trackball', movement along all axes is possible, which provides more freedom of movement, but you may incidentally perform unintentional rotations along some axes. Defaults to 'terrain'.

Display time viewer GUI. Can also be "auto", which will mean True if there is more than one time point and False otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Without the time viewer active, the figure is returned. With the time viewer active, an object is returned that can be used to control different aspects of the figure.

Plot evoked data as images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided. This parameter can also be used to set the order the channels are shown in, as the channel image is sorted by the order of picks.

Channels names to exclude from being shown. If ‚Äòbads‚Äô, the bad channels are excluded.

Scale plot with channel (SI) unit.

Color limits for plots (after scaling has been applied). e.g. clim = dict(eeg=[-20, 20]). Valid keys are eeg, mag, grad, misc. If None, the clim parameter for each channel equals the pyplot default.

If true SSP projections are applied before display. If ‚Äòinteractive‚Äô, a check box for reversible selection of SSP projection vectors will be shown.

The units of the channel types used for axes labels. If None, defaults to dict(eeg='¬µV', grad='fT/cm', mag='fT').

The scalings of the channel types to be applied for plotting. If None,` defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

The titles associated with the channels. If None, defaults to dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers').

The axes to plot to. If list, the list must be a list of Axes of the same length as the number of channel types. If instance of Axes, there must be only one channel type plotted. If group_by is a dict, this cannot be a list, but it can be a dict of lists of axes, with the keys matching those of group_by. In that case, the provided axes will be used for the corresponding groups. Defaults to None.

Colormap. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the scale. Up and down arrows can be used to change the colormap. If ‚Äòinteractive‚Äô, translates to ('RdBu_r', True). Defaults to 'RdBu_r'.

If True, plot a colorbar. Defaults to True.

An array of booleans of the same shape as the data. Entries of the data that correspond to False in the mask are masked (see do_mask below). Useful for, e.g., masking for statistical significance.

If mask is not None: if ‚Äòcontour‚Äô, a contour line is drawn around the masked areas (True in mask). If ‚Äòmask‚Äô, entries not True in mask are shown transparently. If ‚Äòboth‚Äô, both a contour and transparency are used. If None, defaults to ‚Äòboth‚Äô if mask is not None, and is ignored otherwise.

The colormap chosen for masked parts of the image (see below), if mask is not None. If None, cmap is reused. Defaults to Greys. Not interactive. Otherwise, as cmap.

A float between 0 and 1. If mask is not None, this sets the alpha level (degree of transparency) for the masked-out segments. I.e., if 0, masked-out segments are not visible at all. Defaults to .25.

The units for the time axis, can be ‚Äúms‚Äù or ‚Äús‚Äù (default).

Determines if channel names should be plotted on the y axis. If False, no names are shown. If True, ticks are set automatically by matplotlib and the corresponding channel names are shown. If ‚Äúall‚Äù, all channel names are shown. If ‚Äúauto‚Äù, is set to False if picks is None, to True if picks contains 25 or more entries, or to ‚Äúall‚Äù if picks contains fewer than 25 entries.

If a dict, the values must be picks, and axes must also be a dict with matching keys, or None. If axes is None, one figure and one axis will be created for each entry in group_by.Then, for each entry, the picked channels will be plotted to the corresponding axis. If titles are None, keys will become plot titles. This is useful for e.g. ROIs. Each entry must contain only one channel type. For example:

If None, all picked channels are plotted to the same axis.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Figure containing the images.

Examples using plot_image:

Analysing continuous features with binning and regression in sensor space

Visualising statistical significance thresholds on EEG data

Plot evoked data as butterfly plot and add topomaps for time points.

Axes to plot in can be passed by the user through ts_args or topomap_args. In that case both ts_args and topomap_args axes have to be used. Be aware that when the axes are provided, their position may be slightly modified.

The time point(s) to plot. If "auto", 5 evenly spaced topographies between the first and last time instant will be shown. If "peaks", finds time points automatically by checking for 3 local maxima in Global Field Power. Defaults to "peaks".

The title. If None, suppress printing channel type title. If an empty string, a default title is created. Defaults to ‚Äò‚Äô. If custom axes are passed make sure to set title=None, otherwise some of your axes may be removed during placement of the title axis.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channels names to exclude from being shown. If 'bads', the bad channels are excluded. Defaults to 'bads'.

Show figure if True. Defaults to True.

A dict of kwargs that are forwarded to mne.Evoked.plot() to style the butterfly plot. If they are not in this dict, the following defaults are passed: spatial_colors=True, zorder='std'. show and exclude are illegal. If None, no customizable arguments will be passed. Defaults to None.

A dict of kwargs that are forwarded to mne.Evoked.plot_topomap() to style the topomaps. If it is not in this dict, outlines='head' will be passed. show, times, colorbar are illegal. If None, no customizable arguments will be passed. Defaults to None.

The figure object containing the plot. If evoked has multiple channel types, a list of figures, one for each channel type, is returned.

Examples using plot_joint:

Single trial linear regression analysis with the LIMO dataset

Transform EEG data using current source density (CSD)

EEG analysis - Event-Related Potentials (ERPs)

Overview of MEG/EEG analysis with MNE-Python

Source reconstruction using an LCMV beamformer

EEG source localization given electrode locations on an MRI

KIT phantom dataset tutorial

Overview of artifact detection

Repairing artifacts with ICA

Repairing artifacts with SSP

Preprocessing optically pumped magnetometer (OPM) MEG data

Visualising statistical significance thresholds on EEG data

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None it will return all channel types present.. If a list of ch_types is provided, it will return multiple figures. Defaults to None.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches. Only applies when plotting multiple topomaps at a time.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all projectors of the same channel type (instead of separately for each projector), using the min/max of the data for that channel type. If vlim is "joint", info must not be None. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of projectors. Default is None.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (‚ïé) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (‚ãÆ). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

If False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap.

Plot power spectral density (PSD) in units (dB/Hz) if dB=True and estimate='power'. Plot PSD in units (amplitude**2/Hz) if dB=False and estimate='power'. Plot amplitude spectral density (ASD) in units (amplitude/sqrt(Hz)) if dB=False and estimate='amplitude'. Plot ASD in units (dB/sqrt(Hz)) if dB=True and estimate='amplitude'.

Can be ‚Äúpower‚Äù for power spectral density (PSD; default), ‚Äúamplitude‚Äù for amplitude spectrum density (ASD).

Scale of the frequency axis. Default is 'linear'.

Mode for plotting area. If ‚Äòstd‚Äô, the mean +/- 1 STD (across channels) will be plotted. If ‚Äòrange‚Äô, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Alpha for the PSD line. Can be None (default) to use 1.0 when average=True and 0.1 when average=False.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channels names to exclude from being shown. If ‚Äòbads‚Äô, the bad channels are excluded. Pass an empty list to plot all channels (including channels marked ‚Äúbad‚Äù, if any).

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of channel types present in the object.. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure with frequency spectra of the data channels.

This method exists to support legacy code; for new code the preferred idiom is inst.compute_psd().plot() (where inst is an instance of Raw, Epochs, or Evoked).

LEGACY: New code should use .compute_psd().plot_topo().

Plot power spectral density, separately for each channel.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=100.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch(). Defaults to dict(n_fft=2048).

Figure distributing one image per channel across sensor topography.

LEGACY: New code should use .compute_psd().plot_topomap().

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‚Äò%0.3f‚Äô if dB=False and ‚Äò%0.1f‚Äô if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure showing one scalp topography per frequency band.

Plot sensor positions.

Whether to plot the sensors as 3d, topomap or as an interactive sensor selection dialog. Available options ‚Äòtopomap‚Äô, ‚Äò3d‚Äô, ‚Äòselect‚Äô. If ‚Äòselect‚Äô, a set of channels can be selected interactively by using lasso selector or clicking while holding control key. The selected channels are returned along with the figure instance. Defaults to ‚Äòtopomap‚Äô.

The channel type to plot. Available options 'mag', 'grad', 'eeg', 'seeg', 'dbs', 'ecog', 'all'. If 'all', all the available mag, grad, eeg, seeg, dbs, and ecog channels are plotted. If None (default), then channels are chosen in the order given above.

Title for the figure. If None (default), equals to 'Sensor positions (%s)' % ch_type.

Whether to display all channel names. If an array, only the channel names in the array are shown. Defaults to False.

Channel groups for coloring the sensors. If None (default), default coloring scheme is used. If ‚Äòposition‚Äô, the sensors are divided into 8 regions. See order kwarg of mne.viz.plot_raw(). If array, the channels are divided by picks given in the array.

Whether to project the 3d locations to a sphere. When False, the sensor array appears similar as to looking downwards straight above the subject‚Äôs head. Has no effect when kind=‚Äô3d‚Äô. Defaults to True.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Whether to halt program execution until the figure is closed. Defaults to False.

Show figure if True. Defaults to True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the sensor topography.

A list of selected channels. Only returned if kind=='select'.

This function plots the sensor locations from the info structure using matplotlib. For drawing the sensors using PyVista see mne.viz.plot_alignment().

Plot 2D topography of evoked responses.

Clicking on the plot of an individual sensor opens a new figure showing the evoked response for the selected sensor.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If possible, the correct layout is inferred from the data.

Scaling factor for adjusting the relative size of the layout on the canvas.

Everything matplotlib accepts to specify colors. If not list-like, the color specified will be repeated. If None, colors are automatically drawn.

Matplotlib borders style to be used for each sensor plot.

Y-axis limits for plots (after scaling has been applied). dict keys should match channel types; valid keys are for instance eeg, mag, grad, misc, csd, .. (example: ylim=dict(eeg=[-20, 20])). If None, the y-axis limits will be set automatically by matplotlib. Defaults to None.

The scalings of the channel types to be applied for plotting. If None,` defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown.

The values at which to show a vertical line.

A background image for the figure. This must work with a call to plt.imshow. Defaults to None.

Whether to use RMS value of gradiometer pairs. Only works for Neuromag data. Defaults to False.

If True, create a legend based on evoked.comment. If False, disable the legend. Otherwise, the legend is created and the parameter value is passed as the location parameter to the matplotlib legend call. It can be an integer (e.g. 0 corresponds to upper right corner of the plot), a string (e.g. 'upper right'), or a tuple (x, y coordinates of the lower left corner of the legend in the axes coordinate system). See matplotlib documentation for more details.

Axes to plot into. If None, axes will be created.

Background color. Typically 'k' (black) or 'w' (white; default).

Noise covariance used to whiten the data while plotting. Whitened data channel names are shown in italic. Can be a string to load a covariance from disk.

Channels names to exclude from the plot. If 'bads', the bad channels are excluded. By default, exclude is set to 'bads'.

Whether to enable the lasso-selection tool to enable the user to select channels. The selected channels will be available in fig.lasso.selection.

Channels names to exclude from the plot. If 'bads', the bad channels are excluded. By default, exclude is set to 'bads'.

Images of evoked responses at sensor locations.

Examples using plot_topo:

Plotting whitened data

Plot topographic maps of specific time points of evoked data.

The time point(s) to plot. If ‚Äúauto‚Äù, the number of axes determines the amount of time point(s). If axes is also None, at most 10 topographies will be shown with a regular time spacing between the first and last time instant. If ‚Äúpeaks‚Äù, finds time points automatically by checking for local maxima in global field power. If ‚Äúinteractive‚Äù, the time can be set interactively at run-time by using a slider.

The time window (in seconds) around a given time point to be used for averaging. For example, 0.2 would translate into a time window that starts 0.1 s before and ends 0.1 s after the given time point. If the time window exceeds the duration of the data, it will be clipped. Different time windows (one per time point) can be provided by passing an array-like object (e.g., [0.1, 0.2, 0.3]). If None (default), no averaging will take place.

Changed in version 1.1: Support for array-like input.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown. If 'reconstruct', projection vectors will be applied and then M/EEG data will be reconstructed via field mapping to reduce the signal bias caused by projection.

Changed in version 0.21: Support for ‚Äòreconstruct‚Äô was added.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None and scalings=None the unit is automatically determined, otherwise the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of times provided (unless times is None). Default is None.

The units for the time axis, can be ‚Äúms‚Äù or ‚Äús‚Äù (default).

String format for topomap values. Defaults (None) to ‚Äú%01d ms‚Äù if time_unit='ms', ‚Äú%0.3f s‚Äù if time_unit='s', and ‚Äú%g‚Äù otherwise. Can be an empty string to omit the time label.

The number of rows and columns of topographies to plot. If either nrows or ncols is 'auto', the necessary number will be inferred. Defaults to nrows=1, ncols='auto'. Ignored when times == ‚Äòinteractive‚Äô.

Show the figure if True.

When existing axes are provided and colorbar=True, note that the colorbar scale will only accurately reflect topomaps that are generated in the same call as the colorbar. Note also that the colorbar will not be resized automatically when axes are provided; use Matplotlib‚Äôs axes.set_position() method or gridspec interface to adjust the colorbar size yourself.

The defaults for contours and vlim are handled as follows:

When neither vlim nor a list of contours is passed, MNE sets vlim at ¬± the maximum absolute value of the data and then chooses contours within those bounds.

When vlim but not a list of contours is passed, MNE chooses contours to be within the vlim.

When a list of contours but not vlim is passed, MNE chooses vlim to encompass the contours and the maximum absolute value of the data.

When both a list of contours and vlim are passed, MNE uses them as-is.

When time=="interactive", the figure will publish and subscribe to the following UI events:

TimeChange whenever a new time is selected.

Examples using plot_topomap:

Brainstorm raw (median nerve) dataset

Compute effect-matched-spatial filtering (EMS)

Compute source power estimate by projecting the covariance with MNE

Transform EEG data using current source density (CSD)

Maxwell filter data with movement compensation

Remap MEG channel types

Permutation T-test on sensor data

Regression-based baseline correction

Auto-generating Epochs metadata

EEG analysis - Event-Related Potentials (ERPs)

Overview of MEG/EEG analysis with MNE-Python

Source localization with equivalent current dipole (ECD) fit

Source localization with MNE, dSPM, sLORETA, and eLORETA

Working with CTF data: the Brainstorm auditory dataset

Overview of artifact detection

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Spatiotemporal permutation F-test on full sensor data

Plot whitened evoked response.

Plots the whitened evoked response and the whitened GFP as described in [5]. This function is especially useful for investigating noise covariance properties to determine if data are properly whitened (e.g., achieving expected values in line with model assumptions, see Notes below).

The noise covariance. Can be a string to load a covariance from disk.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

The units for the time axis, can be ‚Äúms‚Äù or ‚Äús‚Äù (default).

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

List of axes to plot into.

If True, the lines are color coded by mapping physical sensor coordinates into color values. Spatially similar channels will have similar colors. Bad channels will be dotted. If False, the good channels are plotted black and bad channels red. If 'auto', uses True if channel locations are present, and False if channel locations are missing or if the data contains only a single channel. Defaults to 'auto'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure object containing the plot.

If baseline signals match the assumption of Gaussian white noise, values should be centered at 0, and be within 2 standard deviations (¬±1.96) for 95% of the time points. For the global field power (GFP), we expect it to fluctuate around a value of 1.

If one single covariance object is passed, the GFP panel (bottom) will depict different sensor types. If multiple covariance objects are passed as a list, the left column will display the whitened evoked responses for each channel based on the whitener from the noise covariance that has the highest log-likelihood. The left column will depict the whitened GFPs based on each estimator separately for each sensor type. Instead of numbers of channels the GFP display shows the estimated rank. Note. The rank estimation will be printed by the logger (if verbose=True) for each noise covariance estimator that is passed.

Engemann D. and Gramfort A. (2015) Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals, vol. 108, 328-342, NeuroImage.

Examples using plot_white:

Generate simulated raw data

Whitening evoked data with a noise covariance

Plotting whitened data

Computing a covariance matrix

Source localization with MNE, dSPM, sLORETA, and eLORETA

Whether or not projections are active.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be "auto" to use a padding that will result in a power-of-two size (can be much faster).

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly.

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn().

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled object.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent ‚Äì check your data!

Examples using resample:

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

Save evoked data to a file.

The name of the file, which should end with -ave.fif(.gz) or _ave.fif(.gz).

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

To write multiple conditions into a single file, use mne.write_evokeds.

Changed in version 0.23: Information on baseline correction will be stored with the data, and will be restored when reading again via mne.read_evokeds.

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [6] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Denis A. Engemann and Alexandre Gramfort. Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals. NeuroImage, 108:328‚Äì342, 2015. doi:10.1016/j.neuroimage.2014.12.040.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627‚Äì1639, 1964. doi:10.1021/ac60214a047.

Specify the sensor types of channels.

A dictionary mapping channel names to sensor types, e.g., {'EEG061': 'eog'}.

What to do if the measurement unit of a channel is changed automatically to match the new sensor type.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The following sensor types are accepted:

bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci, eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase, fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp, seeg, stim, syst, temperature.

When working with eye-tracking data, see mne.preprocessing.eyetracking.set_channel_types_eyetrack().

Specify which reference to use for EEG data.

Use this function to explicitly specify the desired reference for EEG. This can be either an existing electrode or a new virtual channel. This function will re-reference the data according to the desired reference.

The name(s) of the channel(s) used to construct the reference for every channel of ch_type.

'average' to apply an average reference (default)

'REST' to use the Reference Electrode Standardization Technique infinity reference [7].

A dictionary mapping names of data channels to (lists of) names of reference channels. For example, {‚ÄòA1‚Äô: ‚ÄòA3‚Äô} would replace the data in channel ‚ÄòA1‚Äô with the difference between ‚ÄòA1‚Äô and ‚ÄòA3‚Äô. To take the average of multiple channels as reference, supply a list of channel names as the dictionary value, e.g. {‚ÄòA1‚Äô: [‚ÄòA2‚Äô, ‚ÄòA3‚Äô]} would replace channel A1 with A1 - mean(A2, A3).

An empty list, in which case MNE will not attempt any re-referencing of the data

If ref_channels='average' this argument specifies if the average reference should be computed as a projection (True) or not (False; default). If projection=True, the average reference is added as a projection and is not applied to the data (it can be applied afterwards with the apply_proj method). If projection=False, the average reference is directly applied to the data. If ref_channels is not 'average', projection must be set to False (the default in this case).

The name of the channel type to apply the reference to. Valid channel types are 'auto', 'eeg', 'ecog', 'seeg', 'dbs'. If 'auto', the first channel type of eeg, ecog, seeg or dbs that is found (in that order) will be selected.

Changed in version 1.2: list-of-str is now supported with projection=True.

Forward solution to use. Only used with ref_channels='REST'.

How to handle list-of-str ch_type. If False (default), one projector is created per channel type. If True, one projector is created across all channel types. This is only used when projection=True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data with EEG channels re-referenced. If ref_channels='average' and projection=True a projection will be added instead of directly re-referencing the data.

Convenience function for creating bipolar references.

Some common referencing schemes and the corresponding value for the ref_channels parameter:

A new virtual reference electrode is created by averaging the current EEG signal by setting ref_channels='average'. Bad EEG channels are automatically excluded if they are properly set in info['bads'].

Set ref_channels to a list containing the name of the channel that will act as the new reference, for example ref_channels=['Cz'].

A new virtual reference electrode is created by computing the average of the current EEG signal recorded from two or more selected channels. Set ref_channels to a list of channel names, indicating which channels to use. For example, to apply an average mastoid reference, when using the 10-20 naming scheme, set ref_channels=['M1', 'M2'].

The given EEG electrodes are referenced to a point at infinity using the lead fields in forward, which helps standardize the signals.

Set ref_channels to a dictionary mapping source channel names (str) to the reference channel names (str or list of str). Unlike the other approaches where the same reference is applied globally, you can set different references for different channels with this method. For example, to re-reference channel ‚ÄòA1‚Äô to ‚ÄòA2‚Äô and ‚ÄòB1‚Äô to the average of ‚ÄòB2‚Äô and ‚ÄòB3‚Äô, set ref_channels={'A1': 'A2', 'B1': ['B2', 'B3']}. Warnings are issued when a mapping involves bad channels or channels of different types.

If a reference is requested that is not the average reference, this function removes any pre-existing average reference projections.

During source localization, the EEG signal should have an average reference.

In order to apply a reference, the data must be preloaded. This is not necessary if ref_channels='average' and projection=True.

For an average or REST reference, bad EEG channels are automatically excluded if they are properly set in info['bads'].

D. Yao. A method to standardize a reference of scalp EEG recordings to a point at infinity. Physiological Measurement, 22(4):693‚Äì711, 2001. doi:10.1088/0967-3334/22/4/305.

Set the measurement start date.

The new measurement date. If datetime object, it must be timezone-aware and in UTC. A tuple of (seconds, microseconds) or float (alias for (meas_date, 0)) can also be passed and a datetime object will be automatically created. If None, will remove the time reference.

The modified raw instance. Operates in place.

If you want to remove all time references in the file, call mne.io.anonymize_info(inst.info) after calling inst.set_meas_date(None).

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

A montage containing channel positions. If a string or DigMontage is specified, the existing channel information will be updated with the channel positions from the montage. Valid strings are the names of the built-in montages that ship with MNE-Python; you can list those via mne.channels.get_builtin_montages(). If None (default), the channel positions will be removed from the Info.

If True (default), channel name matching will be case sensitive.

Whether to use a lookup table to match unrecognized channel location names to their known aliases. If True, uses the mapping in mne.io.constants.CHANNEL_LOC_ALIASES. If a dict is passed, it will be used instead, and should map from non-standard channel names to names in the specified montage. Default is False.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when channels have missing coordinates.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

Only EEG/sEEG/ECoG/DBS/fNIRS channels can have their positions set using a montage. Other channel types (e.g., MEG channels) should have their positions defined properly using their data reading functions.

Applying a montage will only set locations of channels that exist at the time it is applied. This means when re-referencing make sure to apply the montage only after calling mne.add_reference_channels()

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Examples using shift_time:

Brainstorm raw (median nerve) dataset

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

Time vector in seconds.

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, an additional column ‚Äútime‚Äù is added, unless index='time' (in which case time values form the DataFrame‚Äôs index).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) ‚Äî i.e., converts EEG to ¬µV, magnetometers to fT, and gradiometers to fT/cm.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and channel. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Examples using to_data_frame:

Working with ECoG data

Brainstorm raw (median nerve) dataset

Kernel OPM phantom data

Single trial linear regression analysis with the LIMO dataset

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Analysis of evoked response using ICA and PCA reduction techniques

Compute effect-matched-spatial filtering (EMS)

Compute MNE-dSPM inverse solution on single epochs

Compute source power estimate by projecting the covariance with MNE

Computing source timecourses with an XFit-like multi-dipole model

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Getting averaging info from .fif files

Cortical Signal Suppression (CSS) for removal of cortical signals

Define target events based on time lag, plot evoked response

Transform EEG data using current source density (CSD)

Reduce EOG artifacts through regression

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Interpolate EEG data to any montage

Maxwell filter data with movement compensation

Plot sensor denoising using oversampled temporal projection

Remap MEG channel types

Compare simulated and estimated source activity

Generate simulated evoked data

Generate simulated raw data

Simulate raw data using subject anatomy

Generate simulated source data

Regression on continuous data (rER[P/F])

Permutation T-test on sensor data

Analysing continuous features with binning and regression in sensor space

Compute source power spectral density (PSD) of VectorView and OPM data

Explore event-related dynamics for specific frequency bands

Whitening evoked data with a noise covariance

Working with sEEG data

Working with ECoG data

Regression-based baseline correction

Auto-generating Epochs metadata

The Evoked data structure: evoked/averaged data

EEG analysis - Event-Related Potentials (ERPs)

Plotting whitened data

Computing a covariance matrix

Overview of MEG/EEG analysis with MNE-Python

Source localization with equivalent current dipole (ECD) fit

Source localization with MNE, dSPM, sLORETA, and eLORETA

Source reconstruction using an LCMV beamformer

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

Working with CTF data: the Brainstorm auditory dataset

Overview of artifact detection

Repairing artifacts with regression

Repairing artifacts with ICA

Repairing artifacts with SSP

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Preprocessing optically pumped magnetometer (OPM) MEG data

Creating MNE-Python data structures from scratch

Corrupt known signal with point spread

Visualising statistical significance thresholds on EEG data

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Spatiotemporal permutation F-test on full sensor data

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

The Spectrum and EpochsSpectrum classes: frequency-domain data

Creating data objects from arrays

---

## mne.Evoked#

**URL:** https://mne.tools/stable/generated/mne.Evoked.html

**Contents:**
- mne.Evoked#
- Examples using mne.Evoked#

Name of evoked/average FIF file to load. If None no data is loaded.

Dataset ID number (int) or comment/name (str). Optional if there is only one data set in file.

Apply SSP projection vectors.

Either 'average' or 'standard_error'. The type of data to read. Only used if ‚Äòcondition‚Äô is a str.

If True, allow loading of data that has been recorded with internal active compensation (MaxShield). Data recorded with MaxShield should generally not be loaded directly, but should first be processed using SSS/tSSS to remove the compensation signals that may also affect brain activity. Can also be "yes" to load without eliciting a warning.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The mne.Info object with information about the sensors and methods of measurement.

Number of averaged epochs.

Comment on dataset. Can be the condition.

Time vector in seconds.

This attribute reflects whether the data has been baseline-corrected (it will be a tuple then) or not (it will be None).

__contains__(ch_type)

Check channel type membership.

Negate channel responses.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_proj(projs[, remove_existing, verbose])

Add SSP projection vectors.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

animate_topomap([ch_type, times, ...])

Make animation of evoked data as topomap timeseries.

anonymize([daysback, keep_his, verbose])

Anonymize measurement information in place.

apply_baseline([baseline, verbose])

Baseline correct evoked data.

apply_function(fun[, picks, dtype, n_jobs, ...])

Apply a function to a subset of channels.

apply_hilbert([picks, envelope, n_jobs, ...])

Compute analytic signal or envelope for a subset of channels/vertices.

apply_proj([verbose])

Apply the signal space projection (SSP) operators to the data.

as_type([ch_type, mode])

Compute virtual evoked using interpolated fields.

compute_psd([method, fmin, fmax, tmin, ...])

Perform spectral analysis on sensor data.

compute_tfr(method, freqs, *[, tmin, tmax, ...])

Compute a time-frequency representation of evoked data.

Copy the instance of evoked.

crop([tmin, tmax, include_tmax, verbose])

Crop data to a given time interval.

decimate(decim[, offset, verbose])

Decimate the time-series data.

Remove SSP projection vector.

detrend([order, picks])

drop_channels(ch_names[, on_missing])

export(fname[, fmt, overwrite, verbose])

Export Evoked to external formats.

filter(l_freq, h_freq[, picks, ...])

Filter a subset of channels/vertices.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, units, tmin, tmax])

Get evoked data as 2D array.

Get a DigMontage from instance.

get_peak([ch_type, tmin, tmax, mode, ...])

Get location and latency of peak amplitude.

interpolate_bads([reset_bads, mode, origin, ...])

Interpolate bad MEG and EEG channels.

interpolate_to(sensors[, origin, method, reg])

Interpolate EEG data onto a new montage.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, exclude, unit, show, ylim, ...])

Plot evoked data using butterfly plots.

plot_field(surf_maps[, time, time_label, ...])

Plot MEG/EEG fields on head surface and helmet in 3D.

plot_image([picks, exclude, unit, show, ...])

Plot evoked data as images.

plot_joint([times, title, picks, exclude, ...])

Plot evoked data as butterfly plot and add topomaps for time points.

plot_projs_topomap([ch_type, sensors, ...])

plot_psd([fmin, fmax, tmin, tmax, picks, ...])

Plot power or amplitude spectra.

plot_psd_topo([tmin, tmax, fmin, fmax, ...])

plot_psd_topomap([bands, tmin, tmax, ...])

plot_sensors([kind, ch_type, title, ...])

Plot sensor positions.

plot_topo([layout, layout_scale, color, ...])

Plot 2D topography of evoked responses.

plot_topomap([times, average, ch_type, ...])

Plot topographic maps of specific time points of evoked data.

plot_white(noise_cov[, show, rank, ...])

Plot whitened evoked response.

rename_channels(mapping[, allow_duplicates, ...])

reorder_channels(ch_names)

resample(sfreq, *[, npad, window, n_jobs, ...])

save(fname, *[, overwrite, verbose])

Save evoked data to a file.

savgol_filter(h_freq[, verbose])

Filter the data using Savitzky-Golay polynomial method.

set_channel_types(mapping, *[, ...])

Specify the sensor types of channels.

set_eeg_reference([ref_channels, ...])

Specify which reference to use for EEG data.

set_meas_date(meas_date)

Set the measurement start date.

set_montage(montage[, match_case, ...])

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, scalings, ...])

Export data in tabular structure as a pandas DataFrame.

Evoked objects can only contain the average of a single set of conditions.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Negate channel responses.

The Evoked instance with channel data negated and ‚Äò-‚Äô prepended to the comment.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add SSP projection vectors.

List with projection vectors.

Remove the projection vectors currently in the file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Examples using add_proj:

Brainstorm raw (median nerve) dataset

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Make animation of evoked data as topomap timeseries.

The animation can be paused/resumed with left mouse button. Left and right arrow keys can be used to move backward or forward in time.

Channel type to plot. Accepted data types: ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòeeg‚Äô, ‚Äòhbo‚Äô, ‚Äòhbr‚Äô, ‚Äòfnirs_cw_amplitude‚Äô, ‚Äòfnirs_fd_ac_amplitude‚Äô, ‚Äòfnirs_fd_phase‚Äô, and ‚Äòfnirs_od‚Äô. If None, first available channel type from the above list is used. Defaults to None.

The time points to plot. If None, 10 evenly spaced samples are calculated over the evoked time series. Defaults to None.

Frame rate for the animation in Hz. If None, frame rate = sfreq / 10. Defaults to None.

Whether to plot the data as butterfly plot under the topomap. Defaults to False.

Whether to use blit to optimize drawing. In general, it is recommended to use blit in combination with show=True. If you intend to save the animation it is better to disable blit. Defaults to True.

Whether to show the animation. Defaults to True.

The units for the time axis, can be ‚Äúms‚Äù (default in 0.16) or ‚Äús‚Äù (will become the default in 0.17).

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Lower and upper bounds of the colormap, in the same units as the data. If vmin and vmax are both None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0). If only one of vmin, vmax is None, will use min(data) or max(data), respectively. If callable, should accept a NumPy array of data and return a float.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Animation of the topomap.

Examples using animate_topomap:

Plotting topographic maps of evoked data

Anonymize measurement information in place.

Number of days to subtract from all dates. If None (default), the acquisition date, info['meas_date'], will be set to January 1À¢·µó, 2000. This parameter is ignored if info['meas_date'] is None (i.e., no acquisition date has been set).

If True, his_id of subject_info will not be overwritten. Defaults to False.

This could mean that info is not fully anonymized. Use with caution.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Removes potentially identifying information if it exists in info. Specifically for each of the following we use:

A default value, or as specified by daysback.

Default values, except for ‚Äòbirthday‚Äô which is adjusted to maintain the subject age.

Dates use the meas_date logic, and experimenter a default string.

Dates use the meas_date logic, meta info uses defaults.

If info['meas_date'] is None, it will remain None during processing the above fields.

Baseline correct evoked data.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire Evoked.

Defaults to (None, 0), i.e. beginning of the the data until time point zero.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The baseline-corrected Evoked object.

Baseline correction can be done multiple times.

Examples using apply_baseline:

Getting started with mne.Report

Repairing artifacts with regression

Repairing artifacts with ICA

Repairing artifacts with SSP

Using the event system to link figures

Apply a function to a subset of channels.

The function fun is applied to the channels defined in picks. The evoked object‚Äôs data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to channels in picks).

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

If the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.

A function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) because it will apply channel-wise. The function must return an ndarray shaped like its input.

If channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Data type to use after applying the function. If None (default) the data type is not modified.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if channel_wise=False as the workload is split across channels.

Whether to apply the function to each channel individually. If False, the function will be applied to all channels at once. Default True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments to pass to fun.

The evoked object with transformed data.

Compute analytic signal or envelope for a subset of channels/vertices.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Compute the envelope signal of each channel/vertex. Default False. See Notes.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Points to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‚Äòauto‚Äô, the next highest fast FFT length will be use.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw object with transformed data.

If envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).

If envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.

If envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

Also note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.

The analytic signal ‚Äúx_a(t)‚Äù of ‚Äúx(t)‚Äù is:

where ‚ÄúF‚Äù is the Fourier transform, ‚ÄúU‚Äù the unit step function, and ‚Äúy‚Äù the Hilbert transform of ‚Äúx‚Äù. One usage of the analytic signal is the computation of the envelope signal, which is given by ‚Äúe(t) = abs(x_a(t))‚Äù. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.

Apply the signal space projection (SSP) operators to the data.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Once the projectors have been applied, they can no longer be removed. It is usually not recommended to apply the projectors at too early stages, as they are applied automatically later on (e.g. when computing inverse solutions). Hint: using the copy method individual projection vectors can be tested without affecting the original data. With evoked data, consider the following example:

Examples using apply_proj:

Brainstorm raw (median nerve) dataset

Compute virtual evoked using interpolated fields.

Using virtual evoked to compute inverse can yield unexpected results. The virtual channels have '_v' appended at the end of the names to emphasize that the data contained in them are interpolated.

The destination channel type. It can be ‚Äòmag‚Äô or ‚Äògrad‚Äô.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used. 'fast' should be sufficient for most applications.

The transformed evoked object containing only virtual channels.

This method returns a copy and does not modify the data it operates on. It also returns an EvokedArray instance.

Examples using as_type:

Remap MEG channel types

The current gradient compensation grade.

Perform spectral analysis on sensor data.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. Default is 'multitaper'.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

If True, the mean is subtracted from each segment before computing its spectrum.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

The spectral representation of the data.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70‚Äì73, 1967. doi:10.1109/TAU.1967.1161901.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371‚Äì1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Examples using compute_psd:

The Spectrum and EpochsSpectrum classes: frequency-domain data

Compute a time-frequency representation of evoked data.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [2]. None (the default) only works when using __setstate__ and will raise an error otherwise.

The frequencies at which to compute the power estimates. Must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

What kind of estimate to return. Allowed values are "complex", "phase", and "power". Default is "power".

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet() and tfr_array_multitaper() for additional details.

The time-frequency-resolved power estimates of the data.

Copy the instance of evoked.

A copy of the object.

Brainstorm raw (median nerve) dataset

Optically pumped magnetometer (OPM) data

Computing source timecourses with an XFit-like multi-dipole model

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Computing source space SNR

Interpolate bad channels for MEG/EEG channels

Interpolate EEG data to any montage

Compute source power spectral density (PSD) of VectorView and OPM data

Plotting topographic arrowmaps of evoked data

Working with ECoG data

Auto-generating Epochs metadata

The Evoked data structure: evoked/averaged data

EEG analysis - Event-Related Potentials (ERPs)

Computing a covariance matrix

Source localization with equivalent current dipole (ECD) fit

4D Neuroimaging/BTi phantom dataset tutorial

Preprocessing optically pumped magnetometer (OPM) MEG data

Crop data to a given time interval.

Start time of selection in seconds.

End time of selection in seconds.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The cropped time-series object, modified in-place.

Unlike Python slices, MNE time intervals by default include both their end points; crop(tmin, tmax) returns the interval tmin <= t <= tmax. Pass include_tmax=False to specify the half-open interval tmin <= t < tmax instead.

Source localization with a custom inverse solver

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary

Compute Rap-Music on evoked data

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Source localization with equivalent current dipole (ECD) fit

Computing various MNE solutions

Visualize source time courses (stcs)

Brainstorm CTF phantom dataset tutorial

Non-parametric 1 sample cluster statistic on single trial power

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / ‚Äúdecimation‚Äù refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [3], p. 172; which cites [4]):

‚Äú‚Ä¶ a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).‚Äù

Hence ‚Äúdecimation‚Äù in MNE is what is considered ‚Äúcompression‚Äù in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Examples using decimate:

Visualize source time courses (stcs)

Remove SSP projection vector.

The projection vector can only be removed if it is inactive (has not been applied to the data).

Index of the projector to remove. Can also be ‚Äúall‚Äù (default) to remove all projectors.

Examples using del_proj:

Repairing artifacts with SSP

This function operates in-place.

Either 0 or 1, the order of the detrending. 0 is a constant (DC) detrend, 1 is a linear detrend.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The detrended evoked object.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Examples using drop_channels:

Compute source power estimate by projecting the covariance with MNE

Export Evoked to external formats.

MFF (.mff, uses mne.export.export_evokeds_mff())

Since we are exporting to external formats, there‚Äôs no guarantee that all the info will be preserved in the external format. See Notes for details.

Name of the output file.

Format of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.Evoked.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.Evoked.apply_proj().

The filename of the evoked object, if it exists.

Filter a subset of channels/vertices.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Length of the FIR filter to use (if applicable):

‚Äòauto‚Äô (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=‚Äôhamming‚Äô and fir_design=‚Äùfirwin2‚Äù, and half that for ‚Äúfirwin‚Äù).

str: A human-readable time in units of ‚Äús‚Äù or ‚Äúms‚Äù (e.g., ‚Äú10s‚Äù or ‚Äú5500ms‚Äù) will be converted to that number of samples if phase="zero", or the shortest power-of-two length at least that duration for phase="zero-double".

int: Specified length in samples. For fir_design=‚Äùfirwin‚Äù, this should not be used.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be ‚Äúauto‚Äù (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be ‚Äúauto‚Äù (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.

'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).

Dictionary of parameters to use for IIR filtering. If iir_params=None and method="iir", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().

Phase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method="fir":

The delay of this filter is compensated for, making it non-causal.

A minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().

This is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).

This is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.

When method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().

Changed in version 1.7: The behavior for phase="minimum" was fixed to use a filter of the requested length and improved suppression.

The window to use in FIR design, can be ‚Äúhamming‚Äù (default), ‚Äúhann‚Äù (default in 0.13), or ‚Äúblackman‚Äù.

Can be ‚Äúfirwin‚Äù (default) to use scipy.signal.firwin(), or ‚Äúfirwin2‚Äù to use scipy.signal.firwin2(). ‚Äúfirwin‚Äù uses a time-domain design technique that generally gives improved attenuation using fewer samples than ‚Äúfirwin2‚Äù.

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.

The type of padding to use. Supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.

The object has to have the data loaded e.g. with preload=True or self.load_data().

l_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:

l_freq < h_freq: band-pass filter

l_freq > h_freq: band-stop filter

l_freq is not None and h_freq is None: high-pass filter

l_freq is None and h_freq is not None: low-pass filter

self.info['lowpass'] and self.info['highpass'] are only updated with picks=None.

If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

For more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().

Examples using filter:

Working with CTF data: the Brainstorm auditory dataset

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get evoked data as 2D array.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Specify the unit(s) that the data should be returned in. If None (default), the data is returned in the channel-type-specific default units, which are SI units (see Internal representation (units) and data channels). If a string, must be a sub-multiple of SI units that will be used to scale the data from all channels of the type associated with that unit. This only works if the data contains one channel type that has a unit (unitless channel types are left unchanged). For example if there are only EEG and STIM channels, units='uV' will scale EEG channels to micro-Volts while STIM channels will be unchanged. Finally, if a dictionary is provided, keys must be channel types, and values must be units to scale the data of that channel type to. For example dict(grad='fT/cm', mag='fT') will scale the corresponding types accordingly, but all other channel types will remain in their channel-type-specific default unit.

Start time of data to get in seconds.

End time of data to get in seconds.

A view on evoked data.

Examples using get_data:

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Regression-based baseline correction

Get a DigMontage from instance.

A copy of the channel positions, if available, otherwise None.

Get location and latency of peak amplitude.

The channel type to use. Defaults to None. If more than one channel type is present in the data, this value must be provided.

The minimum point in time to be considered for peak getting. If None (default), the beginning of the data is used.

The maximum point in time to be considered for peak getting. If None (default), the end of the data is used.

How to deal with the sign of the data. If ‚Äòpos‚Äô only positive values will be considered. If ‚Äòneg‚Äô only negative values will be considered. If ‚Äòabs‚Äô absolute values will be considered. Defaults to ‚Äòabs‚Äô.

Whether to return the time index instead of the latency in seconds.

If True, compute peak from merged gradiometer data.

If True, return also the amplitude at the maximum response.

If True, raise an error if values are all positive when detecting a minimum (mode=‚Äôneg‚Äô), or all negative when detecting a maximum (mode=‚Äôpos‚Äô). Defaults to True.

The channel exhibiting the maximum response.

The time point of the maximum response, either latency in seconds or index.

The amplitude of the maximum response. Only returned if return_amplitude is True.

Examples using get_peak:

The Evoked data structure: evoked/averaged data

EEG analysis - Event-Related Potentials (ERPs)

Make figures more publication ready

Interpolate bad MEG and EEG channels.

If True, remove the bads from info.

Either 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used for interpolation of channels using the minimum-norm method.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for each channel type.

"meg" channels support "MNE" (default) and "nan"

"eeg" channels support "spline" (default), "MNE" and "nan"

"fnirs" channels support "nearest" (default) and "nan"

"ecog" channels support "spline" (default) and "nan"

"seeg" channels support "spline" (default) and "nan"

None is an alias for:

If a str is provided, the method will be applied to all channel types supported and available in the instance. The method "nan" will replace the channel data with np.nan.

Be careful when using method="nan"; the default value reset_bads=True may not be what you want.

The channels to exclude from interpolation. If excluded a bad channel will stay in bads.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

The "MNE" method uses minimum-norm projection to a sphere and back.

Interpolate EEG data onto a new montage.

Be careful, only EEG channels are interpolated. Other channel types are not interpolated.

The target montage containing channel positions to interpolate onto.

Origin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.

Method to use for EEG channels. Supported methods are ‚Äòspline‚Äô (default) and ‚ÄòMNE‚Äô.

The regularization parameter for the interpolation method (only used when the method is ‚Äòspline‚Äô).

The instance with updated channel locations and data.

This method is useful for standardizing EEG layouts across datasets. However, some attributes may be lost after interpolation.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Source localization with a custom inverse solver

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Computing source timecourses with an XFit-like multi-dipole model

Compute Rap-Music on evoked data

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Interpolate EEG data to any montage

EEG analysis - Event-Related Potentials (ERPs)

Overview of MEG/EEG analysis with MNE-Python

Getting started with mne.Report

Source localization with equivalent current dipole (ECD) fit

Visualize source time courses (stcs)

Make figures more publication ready

Using the event system to link figures

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

Examples using pick_channels:

EEG analysis - Event-Related Potentials (ERPs)

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot evoked data using butterfly plots.

Left click to a line shows the channel name. Selecting an area by clicking and holding left mouse button plots a topographic map of the painted area.

If bad channels are not excluded they are shown in red.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channels names to exclude from being shown. If 'bads', the bad channels are excluded.

Scale plot with channel (SI) unit.

Y-axis limits for plots (after scaling has been applied). dict keys should match channel types; valid keys are for instance eeg, mag, grad, misc, csd, .. (example: ylim=dict(eeg=[-20, 20])). If None, the y-axis limits will be set automatically by matplotlib. Defaults to None.

Limits for the X-axis of the plots.

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown. If 'reconstruct', projection vectors will be applied and then M/EEG data will be reconstructed via field mapping to reduce the signal bias caused by projection.

Changed in version 0.21: Support for ‚Äòreconstruct‚Äô was added.

The values at which to show an horizontal line.

The units of the channel types used for axes labels. If None, defaults to dict(eeg='¬µV', grad='fT/cm', mag='fT').

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

The titles associated with the channels. If None, defaults to dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers').

The axes to plot to. If list, the list must be a list of Axes of the same length as the number of channel types. If instance of Axes, there must be only one channel type plotted.

Plot the global field power (GFP) or the root mean square (RMS) of the data. For MEG data, this will plot the RMS. For EEG, it plots GFP, i.e. the standard deviation of the signal across channels. The GFP is equivalent to the RMS of an average-referenced signal.

Plot GFP or RMS (for EEG and MEG, respectively) and traces for all channels.

Plot GFP or RMS (for EEG and MEG, respectively), and omit the traces for individual channels.

The color of the GFP/RMS trace will be green if spatial_colors=False, and black otherwise.

Changed in version 0.23: Plot GFP for EEG instead of RMS. Label RMS traces correctly as such.

The title to put at the top of the figure.

If True, the lines are color coded by mapping physical sensor coordinates into color values. Spatially similar channels will have similar colors. Bad channels will be dotted. If False, the good channels are plotted black and bad channels red. If 'auto', uses True if channel locations are present, and False if channel locations are missing or if the data contains only a single channel. Defaults to 'auto'.

Which channels to put in the front or back. Only matters if spatial_colors is used. If str, must be std or unsorted (defaults to unsorted). If std, data with the lowest standard deviation (weakest effects) will be put in front so that they are not obscured by those with stronger effects. If unsorted, channels are z-sorted as in the evoked instance. If callable, must take one argument: a numpy array of the same dimensionality as the evoked raw data; and return a list of unique integers corresponding to the number of channels.

Whether to use interactive features. If True (default), it is possible to paint an area to draw topomaps. When False, the interactive features are disabled. Disabling interactive features reduces memory consumption and is useful when using axes parameter to draw multiaxes figures.

Noise covariance used to whiten the data while plotting. Whitened data channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().

The units for the time axis, can be ‚Äús‚Äù (default) or ‚Äúms‚Äù.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Segments of the data to highlight by means of a light-yellow background color. Can be used to put visual emphasis on certain time periods. The time periods must be specified as array-like objects in the form of (t_start, t_end) in the unit given by the time_unit parameter. Multiple time periods can be specified by passing an array-like object of individual time periods (e.g., for 3 time periods, the shape of the passed object would be (3, 2). If None, no highlighting is applied.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the butterfly plots.

Brainstorm raw (median nerve) dataset

Kernel OPM phantom data

Optically pumped magnetometer (OPM) data

From raw data to dSPM on SPM Faces dataset

Analysis of evoked response using ICA and PCA reduction techniques

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute source power estimate by projecting the covariance with MNE

Compute Rap-Music on evoked data

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Define target events based on time lag, plot evoked response

Reduce EOG artifacts through regression

Interpolate bad channels for MEG/EEG channels

Interpolate EEG data to any montage

Shifting time-scale in evoked data

Generate simulated evoked data

Simulate raw data using subject anatomy

Generate simulated source data

Regression on continuous data (rER[P/F])

Whitening evoked data with a noise covariance

Regression-based baseline correction

Auto-generating Epochs metadata

The Evoked data structure: evoked/averaged data

Visualizing Evoked data

EEG analysis - Event-Related Potentials (ERPs)

Plotting whitened data

Source localization with MNE, dSPM, sLORETA, and eLORETA

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

Working with CTF data: the Brainstorm auditory dataset

Repairing artifacts with regression

Repairing artifacts with SSP

Creating MNE-Python data structures from scratch

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Make figures more publication ready

Plot MEG/EEG fields on head surface and helmet in 3D.

The surface mapping information obtained with make_field_map.

The time point at which the field map shall be displayed. If None, the average peak latency (across sensor types) is used.

How to print info about the time instant visualized.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

If None (default), a new figure will be created, otherwise it will plot into the given figure.

New in v1.4: fig can also be a Brain figure.

Maximum intensity. Can be a dictionary with two entries "eeg" and "meg" to specify separate values for EEG and MEG fields respectively. Can be None to use the maximum value of the data.

New in v1.4: vmax can be a dictionary to specify separate values for EEG and MEG fields.

The number of contours.

Whether to draw the field density as an overlay on top of the helmet/head surface. Defaults to True.

Opacity of the meshes (between 0 and 1). Can be a dictionary with two entries "eeg" and "meg" to specify separate values for EEG and MEG fields respectively. Can be None to use 1.0 when a single field map is shown, or dict(eeg=1.0, meg=0.5) when both field maps are shown.

Interpolation method (scipy.interpolate.interp1d parameter). Must be one of 'linear', 'nearest', 'zero', 'slinear', 'quadratic' or 'cubic'.

How interactions with the scene via an input device (e.g., mouse or trackpad) modify the camera position. If 'terrain', one axis is fixed, enabling ‚Äúturntable-style‚Äù rotations. If 'trackball', movement along all axes is possible, which provides more freedom of movement, but you may incidentally perform unintentional rotations along some axes. Defaults to 'terrain'.

Display time viewer GUI. Can also be "auto", which will mean True if there is more than one time point and False otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Without the time viewer active, the figure is returned. With the time viewer active, an object is returned that can be used to control different aspects of the figure.

Examples using plot_field:

Plot the MNE brain and helmet

Visualizing Evoked data

Plot evoked data as images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided. This parameter can also be used to set the order the channels are shown in, as the channel image is sorted by the order of picks.

Channels names to exclude from being shown. If ‚Äòbads‚Äô, the bad channels are excluded.

Scale plot with channel (SI) unit.

Color limits for plots (after scaling has been applied). e.g. clim = dict(eeg=[-20, 20]). Valid keys are eeg, mag, grad, misc. If None, the clim parameter for each channel equals the pyplot default.

If true SSP projections are applied before display. If ‚Äòinteractive‚Äô, a check box for reversible selection of SSP projection vectors will be shown.

The units of the channel types used for axes labels. If None, defaults to dict(eeg='¬µV', grad='fT/cm', mag='fT').

The scalings of the channel types to be applied for plotting. If None,` defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

The titles associated with the channels. If None, defaults to dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers').

The axes to plot to. If list, the list must be a list of Axes of the same length as the number of channel types. If instance of Axes, there must be only one channel type plotted. If group_by is a dict, this cannot be a list, but it can be a dict of lists of axes, with the keys matching those of group_by. In that case, the provided axes will be used for the corresponding groups. Defaults to None.

Colormap. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the scale. Up and down arrows can be used to change the colormap. If ‚Äòinteractive‚Äô, translates to ('RdBu_r', True). Defaults to 'RdBu_r'.

If True, plot a colorbar. Defaults to True.

An array of booleans of the same shape as the data. Entries of the data that correspond to False in the mask are masked (see do_mask below). Useful for, e.g., masking for statistical significance.

If mask is not None: if ‚Äòcontour‚Äô, a contour line is drawn around the masked areas (True in mask). If ‚Äòmask‚Äô, entries not True in mask are shown transparently. If ‚Äòboth‚Äô, both a contour and transparency are used. If None, defaults to ‚Äòboth‚Äô if mask is not None, and is ignored otherwise.

The colormap chosen for masked parts of the image (see below), if mask is not None. If None, cmap is reused. Defaults to Greys. Not interactive. Otherwise, as cmap.

A float between 0 and 1. If mask is not None, this sets the alpha level (degree of transparency) for the masked-out segments. I.e., if 0, masked-out segments are not visible at all. Defaults to .25.

The units for the time axis, can be ‚Äúms‚Äù or ‚Äús‚Äù (default).

Determines if channel names should be plotted on the y axis. If False, no names are shown. If True, ticks are set automatically by matplotlib and the corresponding channel names are shown. If ‚Äúall‚Äù, all channel names are shown. If ‚Äúauto‚Äù, is set to False if picks is None, to True if picks contains 25 or more entries, or to ‚Äúall‚Äù if picks contains fewer than 25 entries.

If a dict, the values must be picks, and axes must also be a dict with matching keys, or None. If axes is None, one figure and one axis will be created for each entry in group_by.Then, for each entry, the picked channels will be plotted to the corresponding axis. If titles are None, keys will become plot titles. This is useful for e.g. ROIs. Each entry must contain only one channel type. For example:

If None, all picked channels are plotted to the same axis.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Figure containing the images.

Examples using plot_image:

Analysing continuous features with binning and regression in sensor space

Visualizing Evoked data

Visualising statistical significance thresholds on EEG data

Plot evoked data as butterfly plot and add topomaps for time points.

Axes to plot in can be passed by the user through ts_args or topomap_args. In that case both ts_args and topomap_args axes have to be used. Be aware that when the axes are provided, their position may be slightly modified.

The time point(s) to plot. If "auto", 5 evenly spaced topographies between the first and last time instant will be shown. If "peaks", finds time points automatically by checking for 3 local maxima in Global Field Power. Defaults to "peaks".

The title. If None, suppress printing channel type title. If an empty string, a default title is created. Defaults to ‚Äò‚Äô. If custom axes are passed make sure to set title=None, otherwise some of your axes may be removed during placement of the title axis.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channels names to exclude from being shown. If 'bads', the bad channels are excluded. Defaults to 'bads'.

Show figure if True. Defaults to True.

A dict of kwargs that are forwarded to mne.Evoked.plot() to style the butterfly plot. If they are not in this dict, the following defaults are passed: spatial_colors=True, zorder='std'. show and exclude are illegal. If None, no customizable arguments will be passed. Defaults to None.

A dict of kwargs that are forwarded to mne.Evoked.plot_topomap() to style the topomaps. If it is not in this dict, outlines='head' will be passed. show, times, colorbar are illegal. If None, no customizable arguments will be passed. Defaults to None.

The figure object containing the plot. If evoked has multiple channel types, a list of figures, one for each channel type, is returned.

Examples using plot_joint:

Single trial linear regression analysis with the LIMO dataset

Transform EEG data using current source density (CSD)

EEG analysis - Event-Related Potentials (ERPs)

Overview of MEG/EEG analysis with MNE-Python

Source reconstruction using an LCMV beamformer

EEG source localization given electrode locations on an MRI

KIT phantom dataset tutorial

Overview of artifact detection

Repairing artifacts with ICA

Repairing artifacts with SSP

Preprocessing optically pumped magnetometer (OPM) MEG data

Visualising statistical significance thresholds on EEG data

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None it will return all channel types present.. If a list of ch_types is provided, it will return multiple figures. Defaults to None.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches. Only applies when plotting multiple topomaps at a time.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all projectors of the same channel type (instead of separately for each projector), using the min/max of the data for that channel type. If vlim is "joint", info must not be None. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of projectors. Default is None.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (‚ïé) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (‚ãÆ). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

If False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap.

Plot power spectral density (PSD) in units (dB/Hz) if dB=True and estimate='power'. Plot PSD in units (amplitude**2/Hz) if dB=False and estimate='power'. Plot amplitude spectral density (ASD) in units (amplitude/sqrt(Hz)) if dB=False and estimate='amplitude'. Plot ASD in units (dB/sqrt(Hz)) if dB=True and estimate='amplitude'.

Can be ‚Äúpower‚Äù for power spectral density (PSD; default), ‚Äúamplitude‚Äù for amplitude spectrum density (ASD).

Scale of the frequency axis. Default is 'linear'.

Mode for plotting area. If ‚Äòstd‚Äô, the mean +/- 1 STD (across channels) will be plotted. If ‚Äòrange‚Äô, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Alpha for the PSD line. Can be None (default) to use 1.0 when average=True and 0.1 when average=False.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channels names to exclude from being shown. If ‚Äòbads‚Äô, the bad channels are excluded. Pass an empty list to plot all channels (including channels marked ‚Äúbad‚Äù, if any).

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of channel types present in the object.. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure with frequency spectra of the data channels.

This method exists to support legacy code; for new code the preferred idiom is inst.compute_psd().plot() (where inst is an instance of Raw, Epochs, or Evoked).

LEGACY: New code should use .compute_psd().plot_topo().

Plot power spectral density, separately for each channel.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=100.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch(). Defaults to dict(n_fft=2048).

Figure distributing one image per channel across sensor topography.

LEGACY: New code should use .compute_psd().plot_topomap().

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2]. 'auto' (default) uses Welch‚Äôs method for continuous data and multitaper for Epochs or Evoked data.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‚Äò%0.3f‚Äô if dB=False and ‚Äò%0.1f‚Äô if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Figure showing one scalp topography per frequency band.

Plot sensor positions.

Whether to plot the sensors as 3d, topomap or as an interactive sensor selection dialog. Available options ‚Äòtopomap‚Äô, ‚Äò3d‚Äô, ‚Äòselect‚Äô. If ‚Äòselect‚Äô, a set of channels can be selected interactively by using lasso selector or clicking while holding control key. The selected channels are returned along with the figure instance. Defaults to ‚Äòtopomap‚Äô.

The channel type to plot. Available options 'mag', 'grad', 'eeg', 'seeg', 'dbs', 'ecog', 'all'. If 'all', all the available mag, grad, eeg, seeg, dbs, and ecog channels are plotted. If None (default), then channels are chosen in the order given above.

Title for the figure. If None (default), equals to 'Sensor positions (%s)' % ch_type.

Whether to display all channel names. If an array, only the channel names in the array are shown. Defaults to False.

Channel groups for coloring the sensors. If None (default), default coloring scheme is used. If ‚Äòposition‚Äô, the sensors are divided into 8 regions. See order kwarg of mne.viz.plot_raw(). If array, the channels are divided by picks given in the array.

Whether to project the 3d locations to a sphere. When False, the sensor array appears similar as to looking downwards straight above the subject‚Äôs head. Has no effect when kind=‚Äô3d‚Äô. Defaults to True.

Axes to draw the sensors to. If kind='3d', axes must be an instance of Axes3D. If None (default), a new axes will be created.

Whether to halt program execution until the figure is closed. Defaults to False.

Show figure if True. Defaults to True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the sensor topography.

A list of selected channels. Only returned if kind=='select'.

This function plots the sensor locations from the info structure using matplotlib. For drawing the sensors using PyVista see mne.viz.plot_alignment().

Plot 2D topography of evoked responses.

Clicking on the plot of an individual sensor opens a new figure showing the evoked response for the selected sensor.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If possible, the correct layout is inferred from the data.

Scaling factor for adjusting the relative size of the layout on the canvas.

Everything matplotlib accepts to specify colors. If not list-like, the color specified will be repeated. If None, colors are automatically drawn.

Matplotlib borders style to be used for each sensor plot.

Y-axis limits for plots (after scaling has been applied). dict keys should match channel types; valid keys are for instance eeg, mag, grad, misc, csd, .. (example: ylim=dict(eeg=[-20, 20])). If None, the y-axis limits will be set automatically by matplotlib. Defaults to None.

The scalings of the channel types to be applied for plotting. If None,` defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown.

The values at which to show a vertical line.

A background image for the figure. This must work with a call to plt.imshow. Defaults to None.

Whether to use RMS value of gradiometer pairs. Only works for Neuromag data. Defaults to False.

If True, create a legend based on evoked.comment. If False, disable the legend. Otherwise, the legend is created and the parameter value is passed as the location parameter to the matplotlib legend call. It can be an integer (e.g. 0 corresponds to upper right corner of the plot), a string (e.g. 'upper right'), or a tuple (x, y coordinates of the lower left corner of the legend in the axes coordinate system). See matplotlib documentation for more details.

Axes to plot into. If None, axes will be created.

Background color. Typically 'k' (black) or 'w' (white; default).

Noise covariance used to whiten the data while plotting. Whitened data channel names are shown in italic. Can be a string to load a covariance from disk.

Channels names to exclude from the plot. If 'bads', the bad channels are excluded. By default, exclude is set to 'bads'.

Whether to enable the lasso-selection tool to enable the user to select channels. The selected channels will be available in fig.lasso.selection.

Channels names to exclude from the plot. If 'bads', the bad channels are excluded. By default, exclude is set to 'bads'.

Images of evoked responses at sensor locations.

Examples using plot_topo:

Visualizing Evoked data

Plotting whitened data

Overview of MEG/EEG analysis with MNE-Python

Plot topographic maps of specific time points of evoked data.

The time point(s) to plot. If ‚Äúauto‚Äù, the number of axes determines the amount of time point(s). If axes is also None, at most 10 topographies will be shown with a regular time spacing between the first and last time instant. If ‚Äúpeaks‚Äù, finds time points automatically by checking for local maxima in global field power. If ‚Äúinteractive‚Äù, the time can be set interactively at run-time by using a slider.

The time window (in seconds) around a given time point to be used for averaging. For example, 0.2 would translate into a time window that starts 0.1 s before and ends 0.1 s after the given time point. If the time window exceeds the duration of the data, it will be clipped. Different time windows (one per time point) can be provided by passing an array-like object (e.g., [0.1, 0.2, 0.3]). If None (default), no averaging will take place.

Changed in version 1.1: Support for array-like input.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown. If 'reconstruct', projection vectors will be applied and then M/EEG data will be reconstructed via field mapping to reduce the signal bias caused by projection.

Changed in version 0.21: Support for ‚Äòreconstruct‚Äô was added.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None and scalings=None the unit is automatically determined, otherwise the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of times provided (unless times is None). Default is None.

The units for the time axis, can be ‚Äúms‚Äù or ‚Äús‚Äù (default).

String format for topomap values. Defaults (None) to ‚Äú%01d ms‚Äù if time_unit='ms', ‚Äú%0.3f s‚Äù if time_unit='s', and ‚Äú%g‚Äù otherwise. Can be an empty string to omit the time label.

The number of rows and columns of topographies to plot. If either nrows or ncols is 'auto', the necessary number will be inferred. Defaults to nrows=1, ncols='auto'. Ignored when times == ‚Äòinteractive‚Äô.

Show the figure if True.

When existing axes are provided and colorbar=True, note that the colorbar scale will only accurately reflect topomaps that are generated in the same call as the colorbar. Note also that the colorbar will not be resized automatically when axes are provided; use Matplotlib‚Äôs axes.set_position() method or gridspec interface to adjust the colorbar size yourself.

The defaults for contours and vlim are handled as follows:

When neither vlim nor a list of contours is passed, MNE sets vlim at ¬± the maximum absolute value of the data and then chooses contours within those bounds.

When vlim but not a list of contours is passed, MNE chooses contours to be within the vlim.

When a list of contours but not vlim is passed, MNE chooses vlim to encompass the contours and the maximum absolute value of the data.

When both a list of contours and vlim are passed, MNE uses them as-is.

When time=="interactive", the figure will publish and subscribe to the following UI events:

TimeChange whenever a new time is selected.

Examples using plot_topomap:

Brainstorm raw (median nerve) dataset

Compute effect-matched-spatial filtering (EMS)

Compute source power estimate by projecting the covariance with MNE

Transform EEG data using current source density (CSD)

Maxwell filter data with movement compensation

Remap MEG channel types

Permutation T-test on sensor data

Plotting topographic maps of evoked data

Regression-based baseline correction

Auto-generating Epochs metadata

EEG analysis - Event-Related Potentials (ERPs)

Overview of MEG/EEG analysis with MNE-Python

Source localization with equivalent current dipole (ECD) fit

Source localization with MNE, dSPM, sLORETA, and eLORETA

Working with CTF data: the Brainstorm auditory dataset

Overview of artifact detection

Repairing artifacts with SSP

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Spatiotemporal permutation F-test on full sensor data

Using the event system to link figures

Plot whitened evoked response.

Plots the whitened evoked response and the whitened GFP as described in [5]. This function is especially useful for investigating noise covariance properties to determine if data are properly whitened (e.g., achieving expected values in line with model assumptions, see Notes below).

The noise covariance. Can be a string to load a covariance from disk.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

The units for the time axis, can be ‚Äúms‚Äù or ‚Äús‚Äù (default).

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

List of axes to plot into.

If True, the lines are color coded by mapping physical sensor coordinates into color values. Spatially similar channels will have similar colors. Bad channels will be dotted. If False, the good channels are plotted black and bad channels red. If 'auto', uses True if channel locations are present, and False if channel locations are missing or if the data contains only a single channel. Defaults to 'auto'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure object containing the plot.

If baseline signals match the assumption of Gaussian white noise, values should be centered at 0, and be within 2 standard deviations (¬±1.96) for 95% of the time points. For the global field power (GFP), we expect it to fluctuate around a value of 1.

If one single covariance object is passed, the GFP panel (bottom) will depict different sensor types. If multiple covariance objects are passed as a list, the left column will display the whitened evoked responses for each channel based on the whitener from the noise covariance that has the highest log-likelihood. The left column will depict the whitened GFPs based on each estimator separately for each sensor type. Instead of numbers of channels the GFP display shows the estimated rank. Note. The rank estimation will be printed by the logger (if verbose=True) for each noise covariance estimator that is passed.

Engemann D. and Gramfort A. (2015) Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals, vol. 108, 328-342, NeuroImage.

Examples using plot_white:

Generate simulated raw data

Whitening evoked data with a noise covariance

Plotting whitened data

Computing a covariance matrix

Source localization with MNE, dSPM, sLORETA, and eLORETA

Whether or not projections are active.

A dictionary mapping the old channel to a new channel name e.g. {'EEG061' : 'EEG161'}. Can also be a callable function that takes and returns a string.

Changed in version 0.10.0: Support for a callable function.

If True (default False), allow duplicates, which will automatically be renamed with -N at the end.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

If appropriate, an anti-aliasing filter is applied before resampling. See Resampling and decimating data for more information.

New sample rate to use.

Amount to pad the start and end of the data. Can also be "auto" to use a padding that will result in a power-of-two size (can be much faster).

When method="fft", this is the frequency-domain window to use in resampling, and should be the same length as the signal; see scipy.signal.resample() for details. When method="polyphase", this is the time-domain linear-phase window to use after upsampling the signal; see scipy.signal.resample_poly() for details. The default "auto" will use "boxcar" for method="fft" and ("kaiser", 5.0) for method="polyphase".

Number of jobs to run in parallel. Can be 'cuda' if cupy is installed properly.

The type of padding to use. When method="fft", supports all numpy.pad() mode options. Can also be "reflect_limited", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. When method="polyphase", supports all modes of scipy.signal.upfirdn().

Resampling method to use. Can be "fft" (default) or "polyphase" to use FFT-based on polyphase FIR resampling, respectively. These wrap to scipy.signal.resample() and scipy.signal.resample_poly(), respectively.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The resampled object.

For some data, it may be more accurate to use npad=0 to reduce artifacts. This is dataset dependent ‚Äì check your data!

Examples using resample:

Filtering and resampling data

Permutation t-test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

Save evoked data to a file.

The name of the file, which should end with -ave.fif(.gz) or _ave.fif(.gz).

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

To write multiple conditions into a single file, use mne.write_evokeds.

Changed in version 0.23: Information on baseline correction will be stored with the data, and will be restored when reading again via mne.read_evokeds.

Getting started with mne.Report

Filter the data using Savitzky-Golay polynomial method.

Approximate high cut-off frequency in Hz. Note that this is not an exact cutoff, since Savitzky-Golay filtering [6] is done using polynomial fits instead of FIR/IIR filtering. This parameter is thus used to determine the length of the window over which a 5th-order polynomial smoothing is used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The object with the filtering applied.

For Savitzky-Golay low-pass approximation, see:

https://gist.github.com/larsoner/bbac101d50176611136b

When working on SourceEstimates the sample rate of the original data is inferred from tstep.

Denis A. Engemann and Alexandre Gramfort. Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals. NeuroImage, 108:328‚Äì342, 2015. doi:10.1016/j.neuroimage.2014.12.040.

Abraham Savitzky and Marcel J. E. Golay. Smoothing and differentiation of data by simplified least squares procedures. Analytical Chemistry, 36(8):1627‚Äì1639, 1964. doi:10.1021/ac60214a047.

Specify the sensor types of channels.

A dictionary mapping channel names to sensor types, e.g., {'EEG061': 'eog'}.

What to do if the measurement unit of a channel is changed automatically to match the new sensor type.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance (modified in place).

Changed in version 0.20: Return the instance.

The following sensor types are accepted:

bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci, eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase, fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp, seeg, stim, syst, temperature.

When working with eye-tracking data, see mne.preprocessing.eyetracking.set_channel_types_eyetrack().

Specify which reference to use for EEG data.

Use this function to explicitly specify the desired reference for EEG. This can be either an existing electrode or a new virtual channel. This function will re-reference the data according to the desired reference.

The name(s) of the channel(s) used to construct the reference for every channel of ch_type.

'average' to apply an average reference (default)

'REST' to use the Reference Electrode Standardization Technique infinity reference [7].

A dictionary mapping names of data channels to (lists of) names of reference channels. For example, {‚ÄòA1‚Äô: ‚ÄòA3‚Äô} would replace the data in channel ‚ÄòA1‚Äô with the difference between ‚ÄòA1‚Äô and ‚ÄòA3‚Äô. To take the average of multiple channels as reference, supply a list of channel names as the dictionary value, e.g. {‚ÄòA1‚Äô: [‚ÄòA2‚Äô, ‚ÄòA3‚Äô]} would replace channel A1 with A1 - mean(A2, A3).

An empty list, in which case MNE will not attempt any re-referencing of the data

If ref_channels='average' this argument specifies if the average reference should be computed as a projection (True) or not (False; default). If projection=True, the average reference is added as a projection and is not applied to the data (it can be applied afterwards with the apply_proj method). If projection=False, the average reference is directly applied to the data. If ref_channels is not 'average', projection must be set to False (the default in this case).

The name of the channel type to apply the reference to. Valid channel types are 'auto', 'eeg', 'ecog', 'seeg', 'dbs'. If 'auto', the first channel type of eeg, ecog, seeg or dbs that is found (in that order) will be selected.

Changed in version 1.2: list-of-str is now supported with projection=True.

Forward solution to use. Only used with ref_channels='REST'.

How to handle list-of-str ch_type. If False (default), one projector is created per channel type. If True, one projector is created across all channel types. This is only used when projection=True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data with EEG channels re-referenced. If ref_channels='average' and projection=True a projection will be added instead of directly re-referencing the data.

Convenience function for creating bipolar references.

Some common referencing schemes and the corresponding value for the ref_channels parameter:

A new virtual reference electrode is created by averaging the current EEG signal by setting ref_channels='average'. Bad EEG channels are automatically excluded if they are properly set in info['bads'].

Set ref_channels to a list containing the name of the channel that will act as the new reference, for example ref_channels=['Cz'].

A new virtual reference electrode is created by computing the average of the current EEG signal recorded from two or more selected channels. Set ref_channels to a list of channel names, indicating which channels to use. For example, to apply an average mastoid reference, when using the 10-20 naming scheme, set ref_channels=['M1', 'M2'].

The given EEG electrodes are referenced to a point at infinity using the lead fields in forward, which helps standardize the signals.

Set ref_channels to a dictionary mapping source channel names (str) to the reference channel names (str or list of str). Unlike the other approaches where the same reference is applied globally, you can set different references for different channels with this method. For example, to re-reference channel ‚ÄòA1‚Äô to ‚ÄòA2‚Äô and ‚ÄòB1‚Äô to the average of ‚ÄòB2‚Äô and ‚ÄòB3‚Äô, set ref_channels={'A1': 'A2', 'B1': ['B2', 'B3']}. Warnings are issued when a mapping involves bad channels or channels of different types.

If a reference is requested that is not the average reference, this function removes any pre-existing average reference projections.

During source localization, the EEG signal should have an average reference.

In order to apply a reference, the data must be preloaded. This is not necessary if ref_channels='average' and projection=True.

For an average or REST reference, bad EEG channels are automatically excluded if they are properly set in info['bads'].

D. Yao. A method to standardize a reference of scalp EEG recordings to a point at infinity. Physiological Measurement, 22(4):693‚Äì711, 2001. doi:10.1088/0967-3334/22/4/305.

Set the measurement start date.

The new measurement date. If datetime object, it must be timezone-aware and in UTC. A tuple of (seconds, microseconds) or float (alias for (meas_date, 0)) can also be passed and a datetime object will be automatically created. If None, will remove the time reference.

The modified raw instance. Operates in place.

If you want to remove all time references in the file, call mne.io.anonymize_info(inst.info) after calling inst.set_meas_date(None).

Set EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.

A montage containing channel positions. If a string or DigMontage is specified, the existing channel information will be updated with the channel positions from the montage. Valid strings are the names of the built-in montages that ship with MNE-Python; you can list those via mne.channels.get_builtin_montages(). If None (default), the channel positions will be removed from the Info.

If True (default), channel name matching will be case sensitive.

Whether to use a lookup table to match unrecognized channel location names to their known aliases. If True, uses the mapping in mne.io.constants.CHANNEL_LOC_ALIASES. If a dict is passed, it will be used instead, and should map from non-standard channel names to names in the specified montage. Default is False.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when channels have missing coordinates.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The instance, modified in-place.

Only EEG/sEEG/ECoG/DBS/fNIRS channels can have their positions set using a montage. Other channel types (e.g., MEG channels) should have their positions defined properly using their data reading functions.

Applying a montage will only set locations of channels that exist at the time it is applied. This means when re-referencing make sure to apply the montage only after calling mne.add_reference_channels()

Examples using set_montage:

Working with sensor locations

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Examples using shift_time:

Brainstorm raw (median nerve) dataset

Shifting time-scale in evoked data

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

Examples using time_as_index:

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

The Evoked data structure: evoked/averaged data

Time vector in seconds.

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, an additional column ‚Äútime‚Äù is added, unless index='time' (in which case time values form the DataFrame‚Äôs index).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). Defaults to None.

Scaling factor applied to the channels picked. If None, defaults to dict(eeg=1e6, mag=1e15, grad=1e13) ‚Äî i.e., converts EEG to ¬µV, magnetometers to fT, and gradiometers to fT/cm.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point and channel. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Examples using to_data_frame:

Working with ECoG data

Kernel OPM phantom data

Analysis of evoked response using ICA and PCA reduction techniques

Compute effect-matched-spatial filtering (EMS)

Compute MNE-dSPM inverse solution on evoked data in volume source space

Source localization with a custom inverse solver

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Generate a functional label from source estimates

Extracting the time series of activations in a label

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Morph volumetric source estimate

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Plot point-spread functions (PSFs) for a volume

Compute Rap-Music on evoked data

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Estimate data SNR using an inverse

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Plotting the full vector-valued MNE solution

Interpolate bad channels for MEG/EEG channels

Interpolate EEG data to any montage

Plot sensor denoising using oversampled temporal projection

Shifting time-scale in evoked data

Remap MEG channel types

Permutation T-test on sensor data

Analysing continuous features with binning and regression in sensor space

Compute source power spectral density (PSD) of VectorView and OPM data

Plotting with mne.viz.Brain

Plotting topographic arrowmaps of evoked data

Plotting topographic maps of evoked data

Plot the MNE brain and helmet

The Evoked data structure: evoked/averaged data

Visualizing Evoked data

EEG analysis - Event-Related Potentials (ERPs)

Overview of MEG/EEG analysis with MNE-Python

Modifying data in-place

The Info data structure

Getting started with mne.Report

Source localization with equivalent current dipole (ECD) fit

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Visualize source time courses (stcs)

Brainstorm Elekta phantom dataset tutorial

KIT phantom dataset tutorial

Rejecting bad data spans and breaks

Filtering and resampling data

Repairing artifacts with regression

Repairing artifacts with ICA

Creating MNE-Python data structures from scratch

Visualising statistical significance thresholds on EEG data

Spatiotemporal permutation F-test on full sensor data

The Spectrum and EpochsSpectrum classes: frequency-domain data

Make figures more publication ready

Using the event system to link figures

---

## mne.export.export_epochs#

**URL:** https://mne.tools/stable/generated/mne.export.export_epochs.html

**Contents:**
- mne.export.export_epochs#

Export Epochs to external formats.

EEGLAB (.set, uses eeglabio)

Since we are exporting to external formats, there‚Äôs no guarantee that all the info will be preserved in the external format. See Notes for details.

Name of the output file.

The epochs to export.

Format of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.Epochs.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.Epochs.apply_proj().

For EEGLAB exports, channel locations are expanded to full EEGLAB format. For more details see eeglabio.utils.cart_to_eeglab().

mne.export.export_evokeds

---

## mne.export.export_evokeds#

**URL:** https://mne.tools/stable/generated/mne.export.export_evokeds.html

**Contents:**
- mne.export.export_evokeds#

Export evoked dataset to external formats.

This function is a wrapper for format-specific export functions. The export function is selected based on the inferred file format. For additional options, use the format-specific functions.

MFF (.mff, uses mne.export.export_evokeds_mff())

Since we are exporting to external formats, there‚Äôs no guarantee that all the info will be preserved in the external format. See Notes for details.

Name of the output file.

The evoked dataset, or list of evoked datasets, to export to one file. Note that the measurement info from the first evoked instance is used, so be sure that information matches.

Format of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.Evoked.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.Evoked.apply_proj().

mne.export.export_epochs

mne.export.export_evokeds_mff

---

## mne.export.export_evokeds_mff#

**URL:** https://mne.tools/stable/generated/mne.export.export_evokeds_mff.html

**Contents:**
- mne.export.export_evokeds_mff#

Export evoked dataset to MFF.

Since we are exporting to external formats, there‚Äôs no guarantee that all the info will be preserved in the external format. See Notes for details.

Name of the output file.

List of evoked datasets to export to one file. Note that the measurement info from the first evoked instance is used, so be sure that information matches.

Optional list of history entries (dictionaries) to be written to history.xml. This must adhere to the format described in mffpy.xml_files.History.content. If None, no history.xml will be written.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.Evoked.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.Evoked.apply_proj().

Only EEG channels are written to the output file. info['device_info']['type'] must be a valid MFF recording device (e.g. ‚ÄòHydroCel GSN 256 1.0‚Äô). This field is automatically populated when using MFF read functions.

mne.export.export_evokeds

mne.export.export_raw

---

## mne.make_fixed_length_epochs#

**URL:** https://mne.tools/stable/generated/mne.make_fixed_length_epochs.html

**Contents:**
- mne.make_fixed_length_epochs#
- Examples using mne.make_fixed_length_epochs#

Divide continuous raw data into equal-sized consecutive epochs.

Raw data to divide into segments.

Duration of each epoch in seconds. Defaults to 1.

Preload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).

Whether to reject based on annotations. If True (default), epochs overlapping with segments whose description begins with 'bad' are rejected. If False, no rejection based on annotations is performed.

Apply SSP projection vectors. If proj is ‚Äòdelayed‚Äô and reject is not None the single epochs will be projected before the rejection decision, but used in unprojected state if they are kept. This way deciding which projection vectors are good can be postponed to the evoked stage without resulting in lower epoch counts and without producing results different from early SSP application given comparable parameters. Note that in this case baselining, detrending and temporal decimation will be postponed. If proj is False no projections will be applied which is the recommended value if SSPs are not used for cleaning the data.

The overlap between epochs, in seconds. Must be 0 <= overlap < duration. Default is 0, i.e., no overlap.

The id to use (default 1).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Divide continuous data into equally-spaced epochs

mne.make_fixed_length_events

---

## mne.match_channel_orders#

**URL:** https://mne.tools/stable/generated/mne.match_channel_orders.html

**Contents:**
- mne.match_channel_orders#

Ensure consistent channel order across instances (Raw, Epochs, or Evoked).

List of Raw, Epochs, or Evoked instances to order.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

List of instances (Raw, Epochs, or Evoked) with channel orders matched according to the order they had in the first item in the insts list.

---

## mne.minimum_norm.apply_inverse_epochs#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse_epochs.html

**Contents:**
- mne.minimum_norm.apply_inverse_epochs#
- Examples using mne.minimum_norm.apply_inverse_epochs#

Apply inverse operator to Epochs.

The regularization parameter.

Use minimum norm, dSPM (default), sLORETA, or eLORETA.

Restricts the source estimates to a given label. If None, source estimates will be computed for the entire source space.

Number of averages used to regularize the solution. Set to 1 on single Epoch by default.

Pooling is performed by taking the norm of loose/free orientations. In case of a fixed source space no norm is computed leading to signed source activity.

Only the normal to the cortical surface is kept. This is only implemented when working with loose orientations.

No pooling of the orientations is done, and the vector result will be returned in the form of a mne.VectorSourceEstimate object.

Return a generator object instead of a list. This allows iterating over the stcs without having to keep them all in memory.

If True, do not call prepare_inverse_operator().

Additional options for eLORETA. See Notes of apply_inverse().

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Only used when the inverse is free orientation (loose=1.), not in surface orientation, and pick_ori='normal'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimates for all epochs.

Apply inverse operator to raw object.

Apply inverse operator to evoked object.

Apply inverse operator to epochs tfr object.

Apply inverse operator to a covariance object.

Decoding source space data

Compute MNE-dSPM inverse solution on single epochs

Computing source timecourses with an XFit-like multi-dipole model

mne.minimum_norm.apply_inverse_cov

mne.minimum_norm.apply_inverse_raw

---

## mne.minimum_norm.apply_inverse_tfr_epochs#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse_tfr_epochs.html

**Contents:**
- mne.minimum_norm.apply_inverse_tfr_epochs#

Apply inverse operator to EpochsTFR.

Single trial, phase-amplitude (complex-valued), time-frequency epochs.

The inverse operator for each frequency or a single inverse operator to use for all frequencies.

The regularization parameter.

Use minimum norm, dSPM (default), sLORETA, or eLORETA.

Restricts the source estimates to a given label. If None, source estimates will be computed for the entire source space.

Number of averages used to regularize the solution. Set to 1 on single Epoch by default.

Pooling is performed by taking the norm of loose/free orientations. In case of a fixed source space no norm is computed leading to signed source activity.

Only the normal to the cortical surface is kept. This is only implemented when working with loose orientations.

No pooling of the orientations is done, and the vector result will be returned in the form of a mne.VectorSourceEstimate object.

Return a generator object instead of a list. This allows iterating over the stcs without having to keep them all in memory.

If True, do not call prepare_inverse_operator().

Additional options for eLORETA. See Notes of apply_inverse().

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Only used when the inverse is free orientation (loose=1.), not in surface orientation, and pick_ori='normal'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The source estimates for all frequencies (outside list) and for all epochs (inside list).

Apply inverse operator to raw object.

Apply inverse operator to evoked object.

Apply inverse operator to epochs object.

Apply inverse operator to a covariance object.

mne.minimum_norm.apply_inverse_raw

mne.minimum_norm.compute_source_psd

---

## mne.minimum_norm.compute_source_psd_epochs#

**URL:** https://mne.tools/stable/generated/mne.minimum_norm.compute_source_psd_epochs.html

**Contents:**
- mne.minimum_norm.compute_source_psd_epochs#
- Examples using mne.minimum_norm.compute_source_psd_epochs#

Compute source power spectral density (PSD) from Epochs.

This uses the multi-taper method to compute the PSD for each epoch.

The inverse operator.

The regularization parameter.

Use minimum norm, dSPM (default), sLORETA, or eLORETA.

The lower frequency of interest.

The upper frequency of interest.

If ‚Äúnormal‚Äù, rather than pooling the orientations by taking the norm, only the radial component is kept. This is only implemented when working with loose orientations.

Restricts the source estimates to a given label.

The number of averages used to scale the noise covariance matrix.

If True, the true dimension of data is estimated before running the time-frequency transforms. It reduces the computation times e.g. with a dataset that was maxfiltered (true dim is 64).

Split inverse operator into inv_split parts in order to save memory.

The bandwidth of the multi taper windowing function in Hz. Can also be a string (e.g., ‚Äòhann‚Äô) to use a single window.

Use adaptive weights to combine the tapered spectra into PSD (slow, use n_jobs >> 1 to speed up computation).

Only use tapers with more than 90% spectral concentration within bandwidth.

Return a generator object instead of a list. This allows iterating over the stcs without having to keep them all in memory.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. It is only used if adaptive=True.

If True, do not call prepare_inverse_operator().

Additional options for eLORETA. See Notes of apply_inverse().

If True, also return the sensor PSD for each epoch as an EvokedArray.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Only used when the inverse is free orientation (loose=1.), not in surface orientation, and pick_ori='normal'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list (or generator) for the source space PSD (and optionally the sensor PSD) for each epoch.

Compute Power Spectral Density of inverse solution from single epochs

mne.minimum_norm.compute_source_psd

mne.minimum_norm.compute_rank_inverse

---

## mne.preprocessing.annotate_amplitude#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.annotate_amplitude.html

**Contents:**
- mne.preprocessing.annotate_amplitude#

Annotate raw data based on peak-to-peak amplitude.

Creates annotations BAD_peak or BAD_flat for spans of data where consecutive samples exceed the threshold in peak or fall below the threshold in flat for more than min_duration. Channels where more than bad_percent of the total recording length should be annotated with either BAD_peak or BAD_flat are returned in bads instead. Note that the annotations and the bads are not automatically added to the Raw object; use set_annotations() and info['bads'] to do so.

Annotate segments based on maximum peak-to-peak signal amplitude (PTP). Valid keys can be any channel type present in the object. The values are floats that set the maximum acceptable PTP. If the PTP is larger than this threshold, the segment will be annotated. If float, the minimum acceptable PTP is applied to all channels.

Annotate segments based on minimum peak-to-peak signal amplitude (PTP). Valid keys can be any channel type present in the object. The values are floats that set the minimum acceptable PTP. If the PTP is smaller than this threshold, the segment will be annotated. If float, the minimum acceptable PTP is applied to all channels.

The percentage of the time a channel can be above or below thresholds. Below this percentage, Annotations are created. Above this percentage, the channel involved is return in bads. Note the returned bads are not automatically added to info['bads']. Defaults to 5, i.e. 5%.

The minimum duration (s) required by consecutives samples to be above peak or below flat thresholds to be considered. to consider as above or below threshold. For some systems, adjacent time samples with exactly the same value are not totally uncommon. Defaults to 0.005 (5 ms).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The annotated bad segments.

The channels detected as bad.

This function does not use a window to detect small peak-to-peak or large peak-to-peak amplitude changes as the reject and flat argument from Epochs does. Instead, it looks at the difference between consecutive samples.

When used to detect segments below flat, at least min_duration seconds of consecutive samples must respect abs(a[i+1] - a[i]) ‚â§ flat.

When used to detect segments above peak, at least min_duration seconds of consecutive samples must respect abs(a[i+1] - a[i]) ‚â• peak.

Thus, this function does not detect every temporal event with large peak-to-peak amplitude, but only the ones where the peak-to-peak amplitude is supra-threshold between consecutive samples. For instance, segments experiencing a DC shift will not be picked up. Only the edges from the DC shift will be annotated (and those only if the edge transitions are longer than min_duration).

This function may perform faster if data is loaded in memory, as it loads data one channel type at a time (across all time points), which is typically not an efficient way to read raw data from disk.

mne.preprocessing.EOGRegression

mne.preprocessing.annotate_break

---

## mne.preprocessing.annotate_break#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.annotate_break.html

**Contents:**
- mne.preprocessing.annotate_break#
- Examples using mne.preprocessing.annotate_break#

Create Annotations for breaks in an ongoing recording.

This function first searches for segments in the data that are not annotated or do not contain any events and are at least min_break_duration seconds long, and then proceeds to creating annotations for those break periods.

The continuous data to analyze.

If None (default), operate based solely on the annotations present in raw. If an events array, ignore any annotations in the raw data, and operate based on these events only.

The minimum time span in seconds between the offset of one and the onset of the subsequent annotation (if events is None) or between two consecutive events (if events is an array) to consider this period a ‚Äúbreak‚Äù. Defaults to 15 seconds.

This value defines the minimum duration of a break period in the data, not the minimum duration of the generated annotations! See also t_start_after_previous and t_stop_before_next for details.

Specifies how far the to-be-created ‚Äúbreak‚Äù annotation extends towards the two annotations or events spanning the break. This can be used to ensure e.g. that the break annotation doesn‚Äôt start and end immediately with a stimulation event. If, for example, your data contains a break of 30 seconds between two stimuli, and t_start_after_previous is set to 5 and t_stop_before_next is set to 3, the break annotation will start 5 seconds after the first stimulus, and end 3 seconds before the second stimulus, yielding an annotated break of 30 - 5 - 3 = 22 seconds. Both default to 5 seconds.

The beginning and the end of the recording will be annotated as breaks, too, if the period from recording start until the first annotation or event (or from last annotation or event until recording end) is at least min_break_duration seconds long.

Annotation descriptions starting with these strings will be ignored by the break-finding algorithm. The string comparison is case-insensitive, i.e., ('bad',) and ('BAD',) are equivalent. By default, all annotation descriptions starting with ‚Äúbad‚Äù and annotations indicating ‚Äúedges‚Äù (produced by data concatenation) will be ignored. Pass an empty list or tuple to take all existing annotations into account. If events is passed, this parameter has no effect.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The break annotations, each with the description 'BAD_break'. If no breaks could be found given the provided function parameters, an empty Annotations object will be returned.

Rejecting bad data spans and breaks

mne.preprocessing.annotate_amplitude

mne.preprocessing.annotate_movement

---

## mne.preprocessing.annotate_movement#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.annotate_movement.html

**Contents:**
- mne.preprocessing.annotate_movement#
- Examples using mne.preprocessing.annotate_movement#

Detect segments with movement.

Detects segments periods further from rotation_velocity_limit, translation_velocity_limit and mean_distance_limit. It returns an annotation with the bad segments.

Data to compute head position.

The position and quaternion parameters from cHPI fitting. Obtained with mne.chpi functions.

Head rotation velocity limit in degrees per second.

Head translation velocity limit in meters per second.

Head position limit from mean recording in meters.

Identify the device to head transform used to define the fixed HPI locations for computing moving distances. If average the average device to head transform is computed using compute_average_dev_head_t. If info, raw.info['dev_head_t'] is used.

Periods with head motion.

Head position over time with respect to the mean head pos.

Annotate movement artifacts and reestimate dev_head_t

Extracting and visualizing subject head movement

mne.preprocessing.annotate_break

mne.preprocessing.annotate_muscle_zscore

---

## mne.preprocessing.annotate_muscle_zscore#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.annotate_muscle_zscore.html

**Contents:**
- mne.preprocessing.annotate_muscle_zscore#
- Examples using mne.preprocessing.annotate_muscle_zscore#

Create annotations for segments that likely contain muscle artifacts.

Detects data segments containing activity in the frequency range given by filter_freq whose envelope magnitude exceeds the specified z-score threshold, when summed across channels and divided by sqrt(n_channels). False-positive transient peaks are prevented by low-pass filtering the resulting z-score time series at 4 Hz. Only operates on a single channel type, if ch_type is None it will select the first type in the list mag, grad, eeg. See [1] for background on choosing filter_freq and threshold.

Data to estimate segments with muscle artifacts.

The threshold in z-scores for marking segments as containing muscle activity artifacts.

The type of sensors to use. If None it will take the first type in mag, grad, eeg.

The shortest allowed duration of ‚Äúgood data‚Äù (in seconds) between adjacent annotations; shorter segments will be incorporated into the surrounding annotations.``None`` is equivalent to 0. Default is 0.1.

The lower and upper frequencies of the band-pass filter. Default is (110, 140).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Periods with muscle artifacts annotated as BAD_muscle.

Z-score values averaged across channels for each sample.

Suresh Muthukumaraswamy. High-frequency brain activity and muscle artifacts in MEG/EEG: a review and recommendations. Frontiers in Human Neuroscience, 7:138, 2013. doi:10.3389/fnhum.2013.00138.

Annotate muscle artifacts

mne.preprocessing.annotate_movement

mne.preprocessing.annotate_nan

---

## mne.preprocessing.annotate_nan#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.annotate_nan.html

**Contents:**
- mne.preprocessing.annotate_nan#

Detect segments with NaN and return a new Annotations instance.

Data to find segments with NaN values.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

New channel-specific annotations for the data.

mne.preprocessing.annotate_muscle_zscore

mne.preprocessing.compute_average_dev_head_t

---

## mne.preprocessing.apply_pca_obs#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.apply_pca_obs.html

**Contents:**
- mne.preprocessing.apply_pca_obs#
- Examples using mne.preprocessing.apply_pca_obs#

Apply the PCA-OBS algorithm to picks of a Raw object.

Uses the optimal basis set (OBS) algorithm from [1].

The raw data to process.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Array of times in the Raw data of detected R-peaks in ECG channel.

Number of PCA components to use to form the OBS (default 4).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

If False, modify the Raw instance in-place. If True (default), copy the raw instance before processing.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified raw instance.

R. K. Niazy, C.F. Beckmann, G.D. Iannetti, J. M. Brady, and S. M. Smith. Removal of fmri environment artifacts from eeg data using optimal basis sets. NeuroImage, 28:720‚Äì737, 2005. doi:10.1016/j.neuroimage.2005.06.067.

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Repairing artifacts with SSP

mne.preprocessing.write_fine_calibration

mne.preprocessing.nirs.optical_density

---

## mne.preprocessing.compute_average_dev_head_t#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.compute_average_dev_head_t.html

**Contents:**
- mne.preprocessing.compute_average_dev_head_t#
- Examples using mne.preprocessing.compute_average_dev_head_t#

Get new device to head transform based on good segments.

Segments starting with ‚ÄúBAD‚Äù annotations are not included for calculating the mean head position.

Data to compute head position. Can be a list containing multiple raw instances.

The position and quaternion parameters from cHPI fitting. Can be a list containing multiple position arrays, one per raw instance passed.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

New dev_head_t transformation using the averaged good head positions.

Changed in version 1.7: Support for multiple raw instances and position arrays was added.

Annotate movement artifacts and reestimate dev_head_t

mne.preprocessing.annotate_nan

mne.preprocessing.compute_current_source_density

---

## mne.preprocessing.compute_bridged_electrodes#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.compute_bridged_electrodes.html

**Contents:**
- mne.preprocessing.compute_bridged_electrodes#
- Examples using mne.preprocessing.compute_bridged_electrodes#

Compute bridged EEG electrodes using the intrinsic Hjorth algorithm.

First, an electrical distance matrix is computed by taking the pairwise variance between electrodes. Local minimums in this matrix below lm_cutoff are indicative of bridging between a pair of electrodes. Pairs of electrodes are marked as bridged as long as their electrical distance is below lm_cutoff on more than the epoch_threshold proportion of epochs.

Based on [1][2][3] and the EEGLAB implementation.

The data to compute electrode bridging on.

The distance in \({\mu}V^2\) cutoff below which to search for a local minimum (lm) indicative of bridging. EEGLAB defaults to 5 \({\mu}V^2\). MNE defaults to 16 \({\mu}V^2\) to be conservative based on the distributions in Greischar et al.[2].

The proportion of epochs with electrical distance less than lm_cutoff in order to consider the channel bridged. The default is 0.5.

The low cutoff frequency to use. Default is 0.5 Hz.

The high cutoff frequency to use. Default is 30 Hz.

The time in seconds to divide the raw into fixed-length epochs to check for consistent bridging. Only used if inst is mne.io.BaseRaw. The default is 2 seconds.

bw_method to pass to scipy.stats.gaussian_kde.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The indices of channels marked as bridged with each bridged pair stored as a tuple.

The electrical distance matrix for each pair of EEG electrodes.

C. E. Tenke and J. Kayser. A convenient method for detecting electrolyte bridges in multichannel electroencephalogram and event-related potential recordings. Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology, 112(3):545‚Äì550, March 2001. doi:10.1016/s1388-2457(00)00553-8.

Lawrence L. Greischar, Cory A. Burghy, Carien M. van Reekum, Daren C. Jackson, Diego A. Pizzagalli, Corrina Mueller, and Richard J. Davidson. Effects of electrode density and electrolyte spreading in dense array electroencephalographic recording. Clinical Neurophysiology, 115(3):710‚Äì720, March 2004. doi:10.1016/j.clinph.2003.10.028.

Arnaud Delorme and Scott Makeig. EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. Journal of Neuroscience Methods, 134(1):9‚Äì21, March 2004. doi:10.1016/j.jneumeth.2003.10.009.

Identify EEG Electrodes Bridged by too much Gel

mne.preprocessing.compute_current_source_density

mne.preprocessing.compute_fine_calibration

---

## mne.preprocessing.compute_current_source_density#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.compute_current_source_density.html

**Contents:**
- mne.preprocessing.compute_current_source_density#
- Examples using mne.preprocessing.compute_current_source_density#

Get the current source density (CSD) transformation.

Transformation based on spherical spline surface Laplacian [1][2][3][4].

This function can be used to re-reference the signal using a Laplacian (LAP) ‚Äúreference-free‚Äù transformation.

The data to be transformed.

The sphere, head-model of the form (x, y, z, r) where x, y, z is the center of the sphere and r is the radius in meters. Can also be ‚Äúauto‚Äù to use a digitization-based fit.

Regularization parameter, produces smoothness. Defaults to 1e-5.

Stiffness of the spline.

Number of Legendre terms to evaluate.

Whether to overwrite instance data or create a copy.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The transformed data. Output type will match input type.

F. Perrin, O. Bertrand, and J. Pernier. Scalp Current Density Mapping: Value and Estimation from Potential Data. IEEE Transactions on Biomedical Engineering, BME-34(4):283‚Äì288, 1987. doi:10.1109/TBME.1987.326089.

Fran√ßois M. Perrin, Jacques Pernier, Olivier M. Bertrand, and Jean Franƒáois Echallier. Spherical splines for scalp potential and current density mapping. Electroencephalography and Clinical Neurophysiology, 72(2):184‚Äì187, 1989. doi:10.1016/0013-4694(89)90180-6.

Mike X. Cohen. Analyzing Neural Time Series Data: Theory and Practice. MIT Press, 2014.

J√ºrgen Kayser and Craig E. Tenke. On the benefits of using surface Laplacian (Current Source Density) methodology in electrophysiology. International journal of psychophysiology : official journal of the International Organization of Psychophysiology, 97(3):171‚Äì173, 2015. doi:10.1016/j.ijpsycho.2015.06.001.

Transform EEG data using current source density (CSD)

mne.preprocessing.compute_average_dev_head_t

mne.preprocessing.compute_bridged_electrodes

---

## mne.preprocessing.compute_fine_calibration#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.compute_fine_calibration.html

**Contents:**
- mne.preprocessing.compute_fine_calibration#

Compute fine calibration from empty-room data.

The raw data to use. Should be from an empty-room recording, and all channels should be good.

Can be 1 or 3 (default), indicating the number of gradiometer imbalance components. Only used if gradiometers are present.

Time window to use for surface normal rotation in seconds. Default is 10.

Order of external component of spherical expansion. Default is 2, which is lower than the default (3) for mne.preprocessing.maxwell_filter() because it tends to yield more stable parameter estimates.

Origin of internal and external multipolar moment space in meters. The default is 'auto', which means (0., 0., 0.) when coord_frame='meg', and a head-digitization-based origin fit using fit_sphere_to_headshape() when coord_frame='head'. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually.

Path to the FIF file with cross-talk correction information.

Dictionary with existing calibration. If provided, the magnetometer imbalances and adjusted normals will be used and only the gradiometer imbalances will be estimated (see step 2 in Notes below).

The maximum permitted angle in degrees between the original and adjusted magnetometer normals. If the angle is exceeded, the segment is treated as an outlier and discarded.

The maximum error (in percent) for each channel in order for a segment to be used.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Fine calibration data.

The number of good segments used to compute the magnetometer parameters.

This algorithm proceeds in two steps, both optimizing the fit between the data and a reconstruction of the data based only on an external multipole expansion:

Estimate magnetometer normal directions and scale factors. All coils (mag and matching grad) are rotated by the adjusted normal direction.

Estimate gradiometer imbalance factors. These add point magnetometers in just the gradiometer difference direction or in all three directions (depending on n_imbalance).

Magnetometer normal and coefficient estimation (1) is typically the most time consuming step. Gradiometer imbalance parameters (2) can be iteratively reestimated (for example, first using n_imbalance=1 then subsequently n_imbalance=3) by passing the previous calibration output to the calibration input in the second call.

MaxFilter processes at most 120 seconds of data, so consider cropping your raw instance prior to processing. It also checks to make sure that there were some minimal usable count number of segments (default 5) that were included in the estimate.

mne.preprocessing.compute_bridged_electrodes

mne.preprocessing.compute_maxwell_basis

---

## mne.preprocessing.compute_maxwell_basis#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.compute_maxwell_basis.html

**Contents:**
- mne.preprocessing.compute_maxwell_basis#

Compute the SSS basis for a given measurement info structure.

The mne.Info object with information about the sensors and methods of measurement.

Origin of internal and external multipolar moment space in meters. The default is 'auto', which means (0., 0., 0.) when coord_frame='meg', and a head-digitization-based origin fit using fit_sphere_to_headshape() when coord_frame='head'. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually.

Order of internal component of spherical expansion.

Order of external component of spherical expansion.

Path to the '.dat' file with fine calibration coefficients. File can have 1D or 3D gradiometer imbalance correction. This file is machine/site-specific.

The coordinate frame that the origin is specified in, either 'meg' or 'head'. For empty-room recordings that do not have a head<->meg transform info['dev_head_t'], the MEG coordinate frame should be used.

Basis regularization type, must be "in" or None. "in" is the same algorithm as the -regularize in option in MaxFilter‚Ñ¢.

If True, do not include reference channels in compensation. This option should be True for KIT files, since Maxwell filtering with reference channels is not currently supported.

How to deal with ill-conditioned SSS matrices. Can be "error" (default), "warning", "info", or "ignore".

The magenetometer scale-factor used to bring the magnetometers to approximately the same order of magnitude as the gradiometers (default 100.), as they have different units (T vs T/m). Can be 'auto' to use the reciprocal of the physical distance between the gradiometer pickup loops (e.g., 0.0168 m yields 59.5 for VectorView).

The empty-room projection vectors used to extend the external SSS basis (i.e., use eSSS).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The basis that can be used to reconstruct the data.

The (stabilized) pseudoinverse of the S array.

The moments that were kept after regularization.

The number of kept moments that were in the internal space.

This outputs variants of \(\mathbf{S}\) and \(\mathbf{S^\dagger}\) from equations 27 and 37 of [1] with the coil scale for magnetometers already factored in so that the resulting denoising transform of the data to obtain \(\hat{\phi}_{in}\) from equation 38 would be:

Samu Taulu and Matti Kajola. Presentation of electromagnetic multichannel data: the signal space separation method. Journal of Applied Physics, 97(12):124905, 2005. doi:10.1063/1.1935742.

mne.preprocessing.compute_fine_calibration

mne.preprocessing.compute_proj_ecg

---

## mne.preprocessing.compute_proj_ecg#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.compute_proj_ecg.html

**Contents:**
- mne.preprocessing.compute_proj_ecg#
- Examples using mne.preprocessing.compute_proj_ecg#

Compute SSP (signal-space projection) vectors for ECG artifacts.

Filter the ECG data channel.

Find ECG R wave peaks using mne.preprocessing.find_ecg_events().

Create Epochs around the R wave peaks, capturing the heartbeats.

Optionally average the Epochs to produce an Evoked if average=True was passed (default).

Calculate SSP projection vectors on that data to capture the artifacts.

Raw data will be loaded if it hasn‚Äôt been preloaded already.

Raw file to use for event detection (if None, raw is used).

Time before event in seconds.

Time after event in seconds.

Number of SSP vectors for gradiometers.

Number of SSP vectors for magnetometers.

Number of SSP vectors for EEG.

Filter low cut-off frequency for the data channels in Hz.

Filter high cut-off frequency for the data channels in Hz.

Compute SSP after averaging. Default is True.

Number of taps to use for filtering.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Channel to use for ECG detection (Required if no ECG found).

Epoch rejection configuration (see Epochs).

Epoch flat configuration (see Epochs).

List with (additional) bad channels.

Add EEG average reference proj.

Exclude the SSP projectors currently in the fiff file.

ID to use for events.

Low pass frequency applied to the ECG channel for event detection.

High pass frequency applied to the ECG channel for event detection.

Start artifact detection after tstart seconds.

Between 0 and 1. qrs detection threshold. Can also be ‚Äúauto‚Äù to automatically choose the threshold that generates a reasonable number of heartbeats (40-160 beats / min).

Method for filtering (‚Äòiir‚Äô or ‚Äòfir‚Äô).

Dictionary of parameters to use for IIR filtering. See mne.filter.construct_iir_filter for details. If iir_params is None and method=‚Äùiir‚Äù, 4th order Butterworth will be used.

If False, filtering raw data is done in place. Defaults to True.

If True, return the drop log.

Can be 'separate' (default) or 'combined' to compute projectors for magnetometers and gradiometers separately or jointly. If 'combined', n_mag == n_grad is required and the number of projectors computed for MEG will be n_mag.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of computed projection vectors.

The drop log, if requested.

Filtering is applied to the ECG channel while finding events using ecg_l_freq and ecg_h_freq, and then to the raw instance using l_freq and h_freq before creation of the epochs used to create the projectors.

Divide continuous data into equally-spaced epochs

Repairing artifacts with SSP

mne.preprocessing.compute_maxwell_basis

mne.preprocessing.compute_proj_eog

---

## mne.preprocessing.compute_proj_eog#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.compute_proj_eog.html

**Contents:**
- mne.preprocessing.compute_proj_eog#
- Examples using mne.preprocessing.compute_proj_eog#

Compute SSP (signal-space projection) vectors for EOG artifacts.

Filter the EOG data channel.

Find the peaks of eyeblinks in the EOG data using mne.preprocessing.find_eog_events().

Create Epochs around the eyeblinks.

Optionally average the Epochs to produce an Evoked if average=True was passed (default).

Calculate SSP projection vectors on that data to capture the artifacts.

Raw data must be preloaded.

Raw file to use for event detection (if None, raw is used).

Time before event in seconds.

Time after event in seconds.

Number of SSP vectors for gradiometers.

Number of SSP vectors for magnetometers.

Number of SSP vectors for EEG.

Filter low cut-off frequency for the data channels in Hz.

Filter high cut-off frequency for the data channels in Hz.

Compute SSP after averaging. Default is True.

Number of taps to use for filtering.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Epoch rejection configuration (see Epochs).

Epoch flat configuration (see Epochs).

List with (additional) bad channels.

Add EEG average reference proj.

Exclude the SSP projectors currently in the fiff file.

ID to use for events.

Low pass frequency applied to the E0G channel for event detection.

High pass frequency applied to the EOG channel for event detection.

Start artifact detection after tstart seconds.

Method for filtering (‚Äòiir‚Äô or ‚Äòfir‚Äô).

Dictionary of parameters to use for IIR filtering. See mne.filter.construct_iir_filter for details. If iir_params is None and method=‚Äùiir‚Äù, 4th order Butterworth will be used.

If not None, specify EOG channel name.

If False, filtering raw data is done in place. Defaults to True.

If True, return the drop log.

Can be ‚Äòseparate‚Äô (default) or ‚Äòcombined‚Äô to compute projectors for magnetometers and gradiometers separately or jointly. If ‚Äòcombined‚Äô, n_mag == n_grad is required and the number of projectors computed for MEG will be n_mag.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of computed projection vectors.

The drop log, if requested.

Filtering is applied to the EOG channel while finding events using eog_l_freq and eog_h_freq, and then to the raw instance using l_freq and h_freq before creation of the epochs used to create the projectors.

Working with CTF data: the Brainstorm auditory dataset

Repairing artifacts with SSP

mne.preprocessing.compute_proj_ecg

mne.preprocessing.compute_proj_hfc

---

## mne.preprocessing.compute_proj_hfc#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.compute_proj_hfc.html

**Contents:**
- mne.preprocessing.compute_proj_hfc#
- Examples using mne.preprocessing.compute_proj_hfc#

Generate projectors to perform homogeneous/harmonic correction to data.

Remove environmental fields from magnetometer data by assuming it is explained as a homogeneous [1] or harmonic field [2]. Useful for arrays of OPMs.

The mne.Info object with information about the sensors and methods of measurement.

The order of the spherical harmonic basis set to use. Set to 1 to use only the homogeneous field component (default), 2 to add gradients, 3 to add quadrature terms, etc.

Channels to include. Default of 'meg' (same as None) will select all non-reference MEG channels. Use ('meg', 'ref_meg') to include reference sensors as well.

List of channels to exclude from HFC, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù). Specify 'bads' (the default) to exclude all channels marked as bad.

Can be "point", "normal" or "accurate" (default), defines which level of coil definition accuracy is used to generate model.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of computed projection vectors.

To apply the projectors to a dataset, use inst.add_proj(projs).apply_proj().

Tim M. Tierney, Nicholas Alexander, Stephanie Mellor, Niall Holmes, Robert Seymour, George C. O‚ÄôNeill, Eleanor A. Maguire, and Gareth R. Barnes. Modelling optically pumped magnetometer interference in meg as a spatially homogeneous magnetic field. NeuroImage, 2021. doi:10.1016/j.neuroimage.2021.118484.

Tim M. Tierney, George C. Mellor, Stephanie nd O‚ÄôNeill, Ryan C. Timms, and Gareth R. Barnes. Spherical harmonic based noise rejection and neuronal sampling with multi-axis opms. NeuroImage, 2022. doi:10.1016/j.neuroimage.2022.119338.

Kernel OPM phantom data

Preprocessing optically pumped magnetometer (OPM) MEG data

mne.preprocessing.compute_proj_eog

mne.preprocessing.cortical_signal_suppression

---

## mne.preprocessing.corrmap#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.corrmap.html

**Contents:**
- mne.preprocessing.corrmap#
- Examples using mne.preprocessing.corrmap#

Find similar Independent Components across subjects by map similarity.

Corrmap [1] identifies the best group match to a supplied template. Typically, feed it a list of fitted ICAs and a template IC, for example, the blink for the first subject, to identify specific ICs across subjects.

The specific procedure consists of two iterations. In a first step, the maps best correlating with the template are identified. In the next step, the analysis is repeated with the mean of the maps identified in the first stage.

Run with plot and show set to True and label=False to find good parameters. Then, run with labelling enabled to apply the labelling in the IC objects. (Running with both plot and labels off does nothing.)

Outputs a list of fitted ICAs with the indices of the marked ICs in a specified field.

The original Corrmap website: www.debener.de/corrmap/corrmapplugin1.html

A list of fitted ICA objects.

Either a tuple with two elements (int, int) representing the list indices of the set from which the template should be chosen, and the template. E.g., if template=(1, 0), the first IC of the 2nd ICA object is used. Or a numpy array whose size corresponds to each IC map from the supplied maps, in which case this map is chosen as the template.

Correlation threshold for identifying ICs If ‚Äúauto‚Äù, search for the best map by trying all correlations between 0.6 and 0.95. In the original proposal, lower values are considered, but this is not yet implemented. If list of floats, search for the best map in the specified range of correlation strengths. As correlation values, must be between 0 and 1 If float > 0, select ICs correlating better than this. If float > 1, use z-scoring to identify ICs within subjects (not in original Corrmap) Defaults to ‚Äúauto‚Äù.

If not None, categorised ICs are stored in a dictionary labels_ under the given name. Preexisting entries will be appended to (excluding repeats), not overwritten. If None, a dry run is performed and the supplied ICs are not changed.

The channel type to plot. Defaults to ‚Äòeeg‚Äô.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

Colormap to use. If None, ‚ÄòReds‚Äô is used for all positive data, otherwise defaults to ‚ÄòRdBu_r‚Äô.

Should constructed template and selected maps be plotted? Defaults to True.

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure showing the template.

Figure showing the labelled ICs in all ICA decompositions.

Filipa Campos Viola, Jeremy Thorne, Barrie Edmonds, Till Schneider, Tom Eichele, and Stefan Debener. Semi-automatic identification of independent components representing EEG artifact. Clinical Neurophysiology, 120(5):868‚Äì877, 2009. doi:10.1016/j.clinph.2009.01.015.

Repairing artifacts with ICA

mne.preprocessing.regress_artifact

mne.preprocessing.read_ica_eeglab

---

## mne.preprocessing.cortical_signal_suppression#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.cortical_signal_suppression.html

**Contents:**
- mne.preprocessing.cortical_signal_suppression#
- Examples using mne.preprocessing.cortical_signal_suppression#

Apply cortical signal suppression (CSS) to evoked data.

The evoked object to use for CSS. Must contain magnetometer, gradiometer, and EEG channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Array of the first set of channel indices that will be used to find the common temporal subspace. If None (default), all magnetometers will be used.

Array of the second set of channel indices that will be used to find the common temporal subspace. If None (default), all gradiometers will be used.

The number of projection vectors.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The evoked object with contributions from the mag_picks and grad_picks channels removed from the picks channels.

This method removes the common signal subspace between two sets of channels (mag_picks and grad_picks) from a set of channels (picks) via a temporal projection using n_proj number of projection vectors. In the reference publication [1], the joint subspace between magnetometers and gradiometers is used to suppress the cortical signal in the EEG data. In principle, other combinations of sensor types (or channels) could be used to suppress signals from other sources.

John Samuelsson, Sheraz Khan, Padma Sundaram, Noam Peled, and Matti H√§m√§l√§inen. Cortical signal suppression (css) for detection of subcortical activity using meg and eeg. Brain Topography, 32:215‚Äì228, 2019. doi:10.1007/s10548-018-00694-5.

Cortical Signal Suppression (CSS) for removal of cortical signals

mne.preprocessing.compute_proj_hfc

mne.preprocessing.create_ecg_epochs

---

## mne.preprocessing.create_ecg_epochs#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.create_ecg_epochs.html

**Contents:**
- mne.preprocessing.create_ecg_epochs#
- Examples using mne.preprocessing.create_ecg_epochs#

Conveniently generate epochs around ECG artifact events.

Filter the ECG data channel.

Find ECG R wave peaks using mne.preprocessing.find_ecg_events().

Create Epochs around the R wave peaks, capturing the heartbeats.

Filtering is only applied to the ECG channel while finding events. The resulting ecg_epochs will have no filtering applied (i.e., have the same filter properties as the input raw instance).

The name of the channel to use for ECG peak detection. If None (default), ECG channel is used if present. If None and no ECG channel is present, a synthetic ECG channel is created from the cross-channel average. This synthetic channel can only be created from MEG channels.

The index to assign to found ECG events.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Start time before event.

End time after event.

Low pass frequency to apply to the ECG channel while finding events.

High pass frequency to apply to the ECG channel while finding events.

Reject epochs based on maximum peak-to-peak signal amplitude (PTP), i.e. the absolute difference between the lowest and the highest signal value. In each individual epoch, the PTP is calculated for every channel. If the PTP of any one channel exceeds the rejection threshold, the respective epoch will be dropped.

The dictionary keys correspond to the different channel types; valid keys can be any channel type present in the object.

Since rejection is based on a signal difference calculated for each channel separately, applying baseline correction does not affect the rejection procedure, as the difference will be preserved.

To constrain the time period used for estimation of signal quality, pass the reject_tmin and reject_tmax parameters.

If reject is None (default), no rejection is performed.

Reject epochs based on minimum peak-to-peak signal amplitude (PTP). Valid keys can be any channel type present in the object. The values are floats that set the minimum acceptable PTP. If the PTP is smaller than this threshold, the epoch will be dropped. If None then no rejection is performed based on flatness of the signal.

To constrain the time period used for estimation of signal quality, pass the reject_tmin and reject_tmax parameters.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each epoch and channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire epoch.

Preload epochs or not (default True). Must be True if keep_ecg is True.

When ECG is synthetically created (after picking), should it be added to the epochs? Must be False when synthetic channel is not used. Defaults to False.

Whether to reject based on annotations. If True (default), epochs overlapping with segments whose description begins with 'bad' are rejected. If False, no rejection based on annotations is performed.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data epoched around ECG R wave peaks.

If you already have a list of R-peak times, or want to compute R-peaks outside MNE-Python using a different algorithm, the recommended approach is to call the Epochs constructor directly, with your R-peaks formatted as an events array (here we also demonstrate the relevant default values):

Overview of artifact detection

Repairing artifacts with ICA

Repairing artifacts with SSP

mne.preprocessing.cortical_signal_suppression

mne.preprocessing.create_eog_epochs

---

## mne.preprocessing.create_eog_epochs#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.create_eog_epochs.html

**Contents:**
- mne.preprocessing.create_eog_epochs#
- Examples using mne.preprocessing.create_eog_epochs#

Conveniently generate epochs around EOG artifact events.

Filter the EOG data channel.

Find the peaks of eyeblinks in the EOG data using mne.preprocessing.find_eog_events().

Create Epochs around the eyeblinks.

The name of the channel(s) to use for EOG peak detection. If a string, can be an arbitrary channel. This doesn‚Äôt have to be a channel of eog type; it could, for example, also be an ordinary EEG channel that was placed close to the eyes, like Fp1 or Fp2.

Multiple channel names can be passed as a list of strings.

If None (default), use the channel(s) in raw with type eog.

The index to assign to found events.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Start time before event.

End time after event.

Low pass frequency to apply to the EOG channel while finding events.

High pass frequency to apply to the EOG channel while finding events.

Rejection parameters based on peak-to-peak amplitude. Valid keys are ‚Äògrad‚Äô | ‚Äòmag‚Äô | ‚Äòeeg‚Äô | ‚Äòeog‚Äô | ‚Äòecg‚Äô. If reject is None then no rejection is done. Example:

Rejection parameters based on flatness of signal. Valid keys are ‚Äògrad‚Äô | ‚Äòmag‚Äô | ‚Äòeeg‚Äô | ‚Äòeog‚Äô | ‚Äòecg‚Äô, and values are floats that set the minimum acceptable peak-to-peak amplitude. If flat is None then no rejection is done.

The time interval to apply rescaling / baseline correction. If None do not apply it. If baseline is (a, b) the interval is between ‚Äúa (s)‚Äù and ‚Äúb (s)‚Äù. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) all the time interval is used. If None, no correction is applied.

Preload epochs or not.

Whether to reject based on annotations. If True (default), epochs overlapping with segments whose description begins with 'bad' are rejected. If False, no rejection based on annotations is performed.

Threshold to trigger EOG event.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data epoched around EOG events.

Filtering is only applied to the EOG channel while finding events. The resulting eog_epochs will have no filtering applied (i.e., have the same filter properties as the input raw instance).

From raw data to dSPM on SPM Faces dataset

Getting started with mne.Report

Overview of artifact detection

Repairing artifacts with regression

Repairing artifacts with ICA

Repairing artifacts with SSP

mne.preprocessing.create_ecg_epochs

mne.preprocessing.find_bad_channels_lof

---

## mne.preprocessing.EOGRegression#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.EOGRegression.html

**Contents:**
- mne.preprocessing.EOGRegression#
- Examples using mne.preprocessing.EOGRegression#

Remove EOG artifact signals from other channels by regression.

Employs linear regression to remove signals captured by some channels, typically EOG, as described in [1]. You can also choose to fit the regression coefficients on evoked blink/saccade data and then apply them to continuous data, as described in [2].

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

List of channels to exclude from the regression, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù). Specify 'bads' (the default) to exclude all channels marked as bad.

Channel picks to use as predictor/explanatory variables capturing the artifact of interest (default is ‚Äúeog‚Äù).

Whether to automatically apply SSP projection vectors before fitting and applying the regression. Default is True.

The regression coefficients. Only available after fitting.

Channel information corresponding to the regression weights. Only available after fitting.

Channels to perform the regression on.

Channels to exclude from the regression.

The channels designated as containing the artifacts of interest.

Whether projections will be applied before performing the regression.

Apply the regression coefficients to data.

Fit EOG regression coefficients.

plot([ch_type, sensors, show_names, mask, ...])

Plot the regression weights of a fitted EOGRegression model.

save(fname[, overwrite])

Save the regression model to an HDF5 file.

Gabriele Gratton, Michael G. H Coles, and Emanuel Donchin. A new method for off-line removal of ocular artifact. Electroencephalography and Clinical Neurophysiology, 55(4):468‚Äì484, 1983. doi:10.1016/0013-4694(83)90135-9.

R. J. Croft and R. J. Barry. Removal of ocular artifact from the EEG: a review. Clinical Neurophysiology, 30(1):5‚Äì19, 2000. doi:10.1016/S0987-7053(00)00055-1.

Apply the regression coefficients to data.

The data on which to apply the regression.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

A version of the data with the artifact channels regressed out.

Only works after .fit() has been used.

Examples using apply:

Reduce EOG artifacts through regression

Repairing artifacts with regression

Preprocessing optically pumped magnetometer (OPM) MEG data

Fit EOG regression coefficients.

The data on which the EOG regression weights should be fitted.

The fitted EOGRegression object. The regression coefficients are available as the .coef_ and .intercept_ attributes.

If your data contains EEG channels, make sure to apply the desired reference (see mne.set_eeg_reference()) before performing EOG regression.

Preprocessing optically pumped magnetometer (OPM) MEG data

Plot the regression weights of a fitted EOGRegression model.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel(s) to highlight with a distinct plotting style. Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of times provided (unless times is None). Default is None.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

Figure with a topomap subplot for each channel type.

Reduce EOG artifacts through regression

Repairing artifacts with regression

Save the regression model to an HDF5 file.

The file to write the regression weights to. Should end in .h5.

If True (default False), overwrite the destination file if it exists.

Reduce EOG artifacts through regression

Repairing artifacts with regression

Preprocessing optically pumped magnetometer (OPM) MEG data

mne.preprocessing.Xdawn

mne.preprocessing.annotate_amplitude

---

## mne.preprocessing.equalize_bads#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.equalize_bads.html

**Contents:**
- mne.preprocessing.equalize_bads#

Interpolate or mark bads consistently for a list of instances.

Once called on a list of instances, the instances can be concatenated as they will have the same list of bad channels.

The list of instances (Evoked, Epochs or Raw) to consider for interpolation. Each instance should have marked channels.

A float between 0 and 1 (default) that specifies the fraction of time a channel should be good to be eventually interpolated for certain instances. For example if 0.5, a channel which is good at least half of the time will be interpolated in the instances where it is marked as bad. If 1 then channels will never be interpolated and if 0 all bad channels will be systematically interpolated.

If True then the returned instances will be copies.

The list of instances, with the same channel(s) marked as bad in all of them, possibly with some formerly bad channels interpolated.

mne.preprocessing.interpolate_bridged_electrodes

mne.preprocessing.maxwell_filter

---

## mne.preprocessing.eyetracking.Calibration#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.eyetracking.Calibration.html

**Contents:**
- mne.preprocessing.eyetracking.Calibration#
- Examples using mne.preprocessing.eyetracking.Calibration#

Eye-tracking calibration info.

This data structure behaves like a dictionary. It contains information regarding a calibration that was conducted during an eye-tracking recording.

When possible, a Calibration instance should be created with a helper function, such as read_eyelink_calibration().

The onset of the calibration in seconds. If the calibration was performed before the recording started, the the onset can be negative.

A string, which is the model of the eye-tracking calibration that was applied. For example 'H3' for a horizontal only 3-point calibration, or 'HV3' for a horizontal and vertical 3-point calibration.

The eye that was calibrated. For example, 'left', or 'right'.

The average error in degrees between the calibration positions and the actual gaze position.

The maximum error in degrees that occurred between the calibration positions and the actual gaze position.

The x and y coordinates of the calibration points.

The error in degrees between the calibration position and the actual gaze position for each calibration point.

The x and y coordinates of the actual gaze position for each calibration point.

The width and height (in meters) of the screen that the eyetracking data was collected with. For example (.531, .298) for a monitor with a display area of 531 x 298 mm.

The distance (in meters) from the participant‚Äôs eyes to the screen.

The resolution (in pixels) of the screen that the eyetracking data was collected with. For example, (1920, 1080) for a 1920x1080 resolution display.

True if the dictionary has the specified key, else False.

Implement iter(self).

fromkeys(iterable[, value])

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

plot([show_offsets, axes, show])

Visualize calibration.

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

setdefault(key[, default])

Insert key with a value of default if key is not in the dictionary.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

True if the dictionary has the specified key, else False.

Implement iter(self).

The copied Calibration.

Create a new dictionary with keys from iterable and values set to value.

Return the value for key if key is in the dictionary, else default.

Visualize calibration.

Whether to display the offset (in visual degrees) of each calibration point or not. Defaults to True.

Axes to draw the calibration positions to. If None (default), a new axes will be created.

Whether to show the figure or not. Defaults to True.

The resulting figure object for the calibration plot.

Importing Data from Eyetracking devices

Working with eye tracker data in MNE-Python

If the key is not found, return the default if given; otherwise, raise a KeyError.

Remove and return a (key, value) pair as a 2-tuple.

Pairs are returned in LIFO (last-in, first-out) order. Raises KeyError if the dict is empty.

Insert key with a value of default if key is not in the dictionary.

Return the value for key if key is in the dictionary, else default.

If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]

Plotting eye-tracking heatmaps in MNE-Python

Importing Data from Eyetracking devices

Working with eye tracker data in MNE-Python

mne.preprocessing.ieeg.warp_montage

mne.preprocessing.eyetracking.read_eyelink_calibration

---

## mne.preprocessing.eyetracking.convert_units#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.eyetracking.convert_units.html

**Contents:**
- mne.preprocessing.eyetracking.convert_units#
- Examples using mne.preprocessing.eyetracking.convert_units#

Convert Eyegaze data from pixels to radians of visual angle or vice versa.

Currently, depending on the units (pixels or radians), eyegaze channels may not be reported correctly in visualization functions like mne.io.Raw.plot(). They will be shown correctly in mne.viz.eyetracking.plot_gaze(). See #11879 for more information.

There are important considerations to keep in mind when using this function, see the Notes section below.

The Raw, Epochs, or Evoked instance with eyegaze channels.

Instance of Calibration, containing information about the screen size (in meters), viewing distance (in meters), and the screen resolution (in pixels).

Must be either "radians" or "pixels", indicating the desired unit.

The Raw, Epochs, or Evoked instance, modified in place.

There are at least two important considerations to keep in mind when using this function:

Converting between on-screen pixels and visual angle is not a linear transformation. If the visual angle subtends less than approximately .44 radians (25 degrees), the conversion could be considered to be approximately linear. However, as the visual angle increases, the conversion becomes increasingly non-linear. This may lead to unexpected results after converting between pixels and visual angle.

This function assumes that the head is fixed in place and aligned with the center of the screen, such that gaze to the center of the screen results in a visual angle of 0 radians.

Plotting eye-tracking heatmaps in MNE-Python

Importing Data from Eyetracking devices

Working with eye tracker data in MNE-Python

mne.preprocessing.eyetracking.set_channel_types_eyetrack

mne.preprocessing.eyetracking.get_screen_visual_angle

---

## mne.preprocessing.eyetracking.get_screen_visual_angle#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.eyetracking.get_screen_visual_angle.html

**Contents:**
- mne.preprocessing.eyetracking.get_screen_visual_angle#

Calculate the radians of visual angle that the participant screen subtends.

An instance of Calibration. Must have valid values for "screen_size" and "screen_distance" keys.

The visual angle of the monitor width and height, respectively.

mne.preprocessing.eyetracking.convert_units

mne.preprocessing.eyetracking.interpolate_blinks

---

## mne.preprocessing.eyetracking.interpolate_blinks#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.eyetracking.interpolate_blinks.html

**Contents:**
- mne.preprocessing.eyetracking.interpolate_blinks#
- Examples using mne.preprocessing.eyetracking.interpolate_blinks#

Interpolate eyetracking signals during blinks.

This function uses the timing of blink annotations to estimate missing data. Missing values are then interpolated linearly. Operates in place.

The raw data with at least one 'pupil' or 'eyegaze' channel.

The time in seconds before and after a blink to consider invalid and include in the segment to be interpolated over. Default is 0.05 seconds (50 ms). If array-like, the first element is the time before the blink and the second element is the time after the blink to consider invalid, for example, (0.025, .1).

The description of annotations to interpolate over. If a list, the data within all annotations that match any of the strings in the list will be interpolated over. If a match starts with 'BAD_', that part will be removed from the annotation description after interpolation. Defaults to 'BAD_blink'.

If False, only apply interpolation to 'pupil channels'. If True, interpolate over 'eyegaze' channels as well. Defaults to False, because eye position can change in unpredictable ways during blinks.

Returns the modified instance.

Plotting eye-tracking heatmaps in MNE-Python

Working with eye tracker data in MNE-Python

mne.preprocessing.eyetracking.get_screen_visual_angle

mne.add_reference_channels

---

## mne.preprocessing.eyetracking.read_eyelink_calibration#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.eyetracking.read_eyelink_calibration.html

**Contents:**
- mne.preprocessing.eyetracking.read_eyelink_calibration#
- Examples using mne.preprocessing.eyetracking.read_eyelink_calibration#

Return info on calibrations collected in an eyelink file.

Path to the eyelink file (.asc).

The width and height (in meters) of the screen that the eyetracking data was collected with. For example (.531, .298) for a monitor with a display area of 531 x 298 mm. Defaults to None.

The distance (in meters) from the participant‚Äôs eyes to the screen. Defaults to None.

The resolution (in pixels) of the screen that the eyetracking data was collected with. For example, (1920, 1080) for a 1920x1080 resolution display. Defaults to None.

A list of Calibration instances, one for each eye of every calibration that was performed during the recording session.

Plotting eye-tracking heatmaps in MNE-Python

Importing Data from Eyetracking devices

Working with eye tracker data in MNE-Python

mne.preprocessing.eyetracking.Calibration

mne.preprocessing.eyetracking.set_channel_types_eyetrack

---

## mne.preprocessing.eyetracking.set_channel_types_eyetrack#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.eyetracking.set_channel_types_eyetrack.html

**Contents:**
- mne.preprocessing.eyetracking.set_channel_types_eyetrack#
- Examples using mne.preprocessing.eyetracking.set_channel_types_eyetrack#

Define sensor type for eyetrack channels.

This function can set all eye tracking specific information: channel type, unit, eye (and x/y component; only for gaze channels)

Supported channel types: 'eyegaze' and 'pupil'

Supported units: 'au', 'px', 'deg', 'rad' (for eyegaze) 'au', 'mm', 'm' (for pupil)

A dictionary mapping a channel to a list/tuple including channel type, unit, eye, [and x/y component] (all as str), e.g., {'l_x': ('eyegaze', 'deg', 'left', 'x')} or {'r_pupil': ('pupil', 'au', 'right')}.

The instance, modified in place.

inst.set_channel_types() to 'eyegaze' or 'pupil' works as well, but cannot correctly set unit, eye and x/y component.

Data will be stored in SI units: if your data comes in deg (visual angle) it will be converted to rad, if it is in mm it will be converted to m.

Importing Data from Eyetracking devices

mne.preprocessing.eyetracking.read_eyelink_calibration

mne.preprocessing.eyetracking.convert_units

---

## mne.preprocessing.find_bad_channels_lof#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.find_bad_channels_lof.html

**Contents:**
- mne.preprocessing.find_bad_channels_lof#

Find bad channels using Local Outlier Factor (LOF) algorithm.

Number of neighbors defining the local neighborhood (default is 20). Smaller values will lead to higher LOF scores.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Metric to use for distance computation. Default is ‚Äúeuclidean‚Äù, see sklearn.metrics.pairwise.distance_metrics() for details.

Threshold to define outliers. Theoretical threshold ranges anywhere between 1.0 and any positive integer. Default: 1.5 It is recommended to consider this as an hyperparameter to optimize.

If True, return a dictionary with LOF scores for each evaluated channel. Default is False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of bad M/EEG channels that were automatically detected.

Only returned when return_scores is True. It contains the LOF outlier score for each channel in picks.

See [1] and [2] for background on choosing threshold.

Velu Prabhakar Kumaravel, Marco Buiatti, Eugenio Parise, and Elisabetta Farella. Adaptable and robust EEG bad channel detection using local outlier factor (LOF). Sensors, 22(19):7314, September 2022. URL: https://doi.org/10.3390/s22197314, doi:10.3390/s22197314.

Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng, and J√∂rg Sander. Lof: identifying density-based local outliers. SIGMOD Rec., 29(2):93‚Äì104, may 2000. URL: https://doi.org/10.1145/335191.335388, doi:10.1145/335191.335388.

mne.preprocessing.create_eog_epochs

mne.preprocessing.find_bad_channels_maxwell

---

## mne.preprocessing.find_bad_channels_maxwell#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.find_bad_channels_maxwell.html

**Contents:**
- mne.preprocessing.find_bad_channels_maxwell#
- Examples using mne.preprocessing.find_bad_channels_maxwell#

Find bad channels using Maxwell filtering.

Detection limit for noisy segments (default is 7.). Smaller values will find more bad channels at increased risk of including good ones. This value can be interpreted as the standard score of differences between the original and Maxwell-filtered data. See the Notes section for details.

This setting only concerns noisy channel detection. The limit for flat channel detection currently cannot be controlled by the user. Flat channel detection is always run before noisy channel detection.

Duration of the segments into which to slice the data for processing, in seconds. Default is 5.

Minimum number of times a channel must show up as bad in a chunk. Default is 5.

If True, return a dictionary with scoring information for each evaluated segment of the data. Default is False.

This feature is experimental and may change in a future version of MNE-Python without prior notice. Please report any problems and enhancement proposals to the developers.

Origin of internal and external multipolar moment space in meters. The default is 'auto', which means (0., 0., 0.) when coord_frame='meg', and a head-digitization-based origin fit using fit_sphere_to_headshape() when coord_frame='head'. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually.

Order of internal component of spherical expansion.

Order of external component of spherical expansion.

Path to the '.dat' file with fine calibration coefficients. File can have 1D or 3D gradiometer imbalance correction. This file is machine/site-specific.

Path to the FIF file with cross-talk correction information.

The coordinate frame that the origin is specified in, either 'meg' or 'head'. For empty-room recordings that do not have a head<->meg transform info['dev_head_t'], the MEG coordinate frame should be used.

Basis regularization type, must be "in" or None. "in" is the same algorithm as the -regularize in option in MaxFilter‚Ñ¢.

If True, do not include reference channels in compensation. This option should be True for KIT files, since Maxwell filtering with reference channels is not currently supported.

How to deal with ill-conditioned SSS matrices. Can be "error" (default), "warning", "info", or "ignore".

If array, movement compensation will be performed. The array should be of shape (N, 10), holding the position parameters as returned by e.g. read_head_pos.

The magenetometer scale-factor used to bring the magnetometers to approximately the same order of magnitude as the gradiometers (default 100.), as they have different units (T vs T/m). Can be 'auto' to use the reciprocal of the physical distance between the gradiometer pickup loops (e.g., 0.0168 m yields 59.5 for VectorView).

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default ('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list.

The cutoff frequency (in Hz) of the low-pass filter that will be applied before processing the data. This defaults to 40., which should provide similar results to MaxFilter. If you do not wish to apply a filter, set this to None.

The empty-room projection vectors used to extend the external SSS basis (i.e., use eSSS).

Interpolation to use between adjacent time points in movement compensation. Can be ‚Äúzero‚Äù (used by MaxFilter), ‚Äúlinear‚Äù, or ‚Äúhann‚Äù (default in 1.11).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of bad MEG channels that were automatically detected as being noisy among the good MEG channels.

List of MEG channels that were detected as being flat in at least min_count segments.

A dictionary with information produced by the scoring algorithms. Only returned when return_scores is True. It contains the following keys:

The names of the MEG channels. Their order corresponds to the order of rows in the scores and limits arrays.

The types of the MEG channels in ch_names ('mag', 'grad').

The inclusive window boundaries (start and stop; in seconds) used to calculate the scores.

The scores for testing whether MEG channels are flat. These values correspond to the standard deviation of a segment. See the Notes section for details.

The score thresholds (in standard deviation) above which a segment was classified as ‚Äúflat‚Äù.

The scores for testing whether MEG channels are noisy. These values correspond to the standard score of a segment. See the Notes section for details.

The score thresholds (in standard scores) above which a segment was classified as ‚Äúnoisy‚Äù.

The scores and limits for channels marked as bad in the input data will be set to np.nan.

All arguments after raw, limit, duration, min_count, and return_scores are the same as maxwell_filter(), except that the following are not allowed in this function because they are unused: st_duration, st_correlation, destination, st_fixed, and st_only.

This algorithm, for a given chunk of data:

Runs SSS on the data, without removing external components.

Excludes channels as flat that have had low variability (standard deviation < 0.01 fT or fT/cm in a 30 ms window) in the given or any previous chunk.

For each channel \(k\), computes the range or peak-to-peak \(d_k\) of the difference between the reconstructed and original data.

Computes the average \(\mu_d\) and standard deviation \(\sigma_d\) of the differences (after scaling magnetometer data to roughly match the scale of the gradiometer data using mag_scale).

Marks channels as bad for the chunk when \(d_k > \mu_d + \textrm{limit} \times \sigma_d\). Note that this expression can be easily transformed into \((d_k - \mu_d) / \sigma_d > \textrm{limit}\), which is equivalent to \(z(d_k) > \textrm{limit}\), with \(z(d_k)\) being the standard or z-score of the difference.

Data are processed in chunks of the given duration, and channels that are bad for at least min_count chunks are returned.

Channels marked as flat in step 2 are excluded from all subsequent steps of noisy channel detection.

This algorithm gives results similar to, but not identical with, MaxFilter. Differences arise because MaxFilter processes on a buffer-by-buffer basis (using buffer-size-dependent downsampling logic), uses different filtering characteristics, and possibly other factors. Channels that are near the limit for a given min_count are particularly susceptible to being different between the two implementations.

Signal-space separation (SSS) and Maxwell filtering

mne.preprocessing.find_bad_channels_lof

mne.preprocessing.find_ecg_events

---

## mne.preprocessing.find_ecg_events#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.find_ecg_events.html

**Contents:**
- mne.preprocessing.find_ecg_events#
- Examples using mne.preprocessing.find_ecg_events#

Find ECG events by localizing the R wave peaks.

The index to assign to found ECG events.

The name of the channel to use for ECG peak detection. If None (default), ECG channel is used if present. If None and no ECG channel is present, a synthetic ECG channel is created from the cross-channel average. This synthetic channel can only be created from MEG channels.

Start ECG detection after tstart seconds. Useful when the beginning of the run is noisy.

Low pass frequency to apply to the ECG channel while finding events.

High pass frequency to apply to the ECG channel while finding events.

Between 0 and 1. qrs detection threshold. Can also be ‚Äúauto‚Äù to automatically choose the threshold that generates a reasonable number of heartbeats (40-160 beats / min).

Number of taps to use for filtering.

Return the ECG data. This is especially useful if no ECG channel is present in the input data, so one will be synthesized (only works if MEG channels are present in the data). Defaults to False.

Whether to omit bad segments from the data before fitting. If True (default), annotated segments whose description begins with 'bad' are omitted. If False, no rejection based on annotations is performed.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The events corresponding to the peaks of the R waves.

Index of channel used.

The estimated average pulse. If no ECG events could be found, this will be zero.

The ECG data of the synthesized ECG channel, if any. This will only be returned if return_ecg=True was passed.

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Overview of artifact detection

Repairing artifacts with SSP

mne.preprocessing.find_bad_channels_maxwell

mne.preprocessing.find_eog_events

---

## mne.preprocessing.find_eog_events#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.find_eog_events.html

**Contents:**
- mne.preprocessing.find_eog_events#
- Examples using mne.preprocessing.find_eog_events#

Locate EOG artifacts.

To control true-positive and true-negative detection rates, you may adjust the thresh parameter.

The index to assign to found events.

Low cut-off frequency to apply to the EOG channel in Hz.

High cut-off frequency to apply to the EOG channel in Hz.

Number of taps to use for filtering.

The name of the channel(s) to use for EOG peak detection. If a string, can be an arbitrary channel. This doesn‚Äôt have to be a channel of eog type; it could, for example, also be an ordinary EEG channel that was placed close to the eyes, like Fp1 or Fp2.

Multiple channel names can be passed as a list of strings.

If None (default), use the channel(s) in raw with type eog.

Start detection after tstart seconds.

Whether to omit data that is annotated as bad.

Threshold to trigger the detection of an EOG event. This controls the thresholding of the underlying peak-finding algorithm. Larger values mean that fewer peaks (i.e., fewer EOG events) will be detected. If None, use the default of (max(eog) - min(eog)) / 4, with eog being the filtered EOG signal.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Show EOG artifact timing

Rejecting bad data spans and breaks

mne.preprocessing.find_ecg_events

mne.preprocessing.fix_stim_artifact

---

## mne.preprocessing.fix_stim_artifact#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.fix_stim_artifact.html

**Contents:**
- mne.preprocessing.fix_stim_artifact#
- Examples using mne.preprocessing.fix_stim_artifact#

Eliminate stimulation‚Äôs artifacts from instance.

This function operates in-place, consider passing inst.copy() if this is not desired.

The list of events. Required only when inst is Raw.

The id of the events generating the stimulation artifacts. If None, read all events. Required only when inst is Raw.

Start time of the interpolation window in seconds.

End time of the interpolation window in seconds.

The baseline to use when mode='constant', in which case it must be non-None.

Way to fill the artifacted time interval.

Does linear interpolation.

Applies a (1 - hanning) window.

Uses baseline average. baseline parameter must be provided.

Changed in version 1.8: Added the "constant" mode.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Instance with modified data.

Brainstorm raw (median nerve) dataset

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

mne.preprocessing.find_eog_events

mne.preprocessing.ica_find_ecg_events

---

## mne.preprocessing.ICA#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.ICA.html

**Contents:**
- mne.preprocessing.ICA#
- Examples using mne.preprocessing.ICA#

Data decomposition using Independent Component Analysis (ICA).

This object estimates independent components from mne.io.Raw, mne.Epochs, or mne.Evoked objects. Components can optionally be removed (for artifact repair) prior to signal reconstruction.

ICA is sensitive to low-frequency drifts and therefore requires the data to be high-pass filtered prior to fitting. Typically, a cutoff frequency of 1 Hz is recommended.

Number of principal components (from the pre-whitening PCA step) that are passed to the ICA algorithm during fitting:

Must be greater than 1 and less than or equal to the number of channels.

Will select the smallest number of components required to explain the cumulative variance of the data greater than n_components. Consider this hypothetical example: we have 3 components, the first explaining 70%, the second 20%, and the third the remaining 10% of the variance. Passing 0.8 here (corresponding to 80% of explained variance) would yield the first two components, explaining 90% of the variance: only by using both components the requested threshold of 80% explained variance can be exceeded. The third component, on the other hand, would be excluded.

0.999999 will be used. This is done to avoid numerical stability problems when whitening, particularly when working with rank-deficient data.

Defaults to None. The actual number used when executing the ICA.fit() method will be stored in the attribute n_components_ (note the trailing underscore).

Changed in version 0.22: For a float, the number of components will account for greater than the given variance level instead of less than or equal to it. The default (None) will also take into account the rank deficiency of the data.

Noise covariance used for pre-whitening. If None (default), channels are scaled to unit variance (‚Äúz-standardized‚Äù) as a group by channel type prior to the whitening by PCA.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

The ICA method to use in the fit method. Use the fit_params argument to set additional parameters. Specifically, if you want Extended Infomax, set method='infomax' and fit_params=dict(extended=True) (this also works for method='picard'). Defaults to 'fastica'. For reference, see [1][2][3][4].

Additional parameters passed to the ICA estimator as specified by method. Allowed entries are determined by the various algorithm implementations: see FastICA, picard(), infomax().

Maximum number of iterations during fit. If 'auto', it will set maximum iterations to 1000 for 'fastica' and to 500 for 'infomax' or 'picard'. The actual number of iterations it took ICA.fit() to complete will be stored in the n_iter_ attribute.

Allow ICA on MEG reference channels. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Which data type was used for the fit.

Channel names resulting from initial picking.

If fit, the actual number of PCA components used for ICA decomposition.

If fit, array used to pre-whiten the data prior to PCA.

If fit, the PCA components.

If fit, the mean vector used to center the data before doing the PCA.

If fit, the variance explained by each PCA component.

If fit, the whitened mixing matrix to go back from ICA space to PCA space. It is, in combination with the pca_components_, used by ICA.apply() and ICA.get_components() to re-mix/project a subset of the ICA components into the observed channel space. The former method also removes the pre-whitening (z-scaling) and the de-meaning.

If fit, the whitened matrix to go from PCA space to ICA space. Used, in combination with the pca_components_, by the methods ICA.get_sources() and ICA.apply() to unmix the observed data.

List or np.array of sources indices to exclude when re-mixing the data in the ICA.apply() method, i.e. artifactual ICA components. The components identified manually and by the various automatic artifact detection methods should be (manually) appended (e.g. ica.exclude.extend(eog_inds)). (There is also an exclude parameter in the ICA.apply() method.) To scrap all marked components, set this attribute to an empty list.

The mne.Info object with information about the sensors and methods of measurement.

The number of samples used on fit.

A dictionary of independent component indices, grouped by types of independent components. This attribute is set by some of the artifact detection functions.

If fit, the number of iterations required to complete ICA.

__contains__(ch_type)

Check channel type membership.

apply(inst[, include, exclude, ...])

Remove selected components from the signal.

find_bads_ecg(inst[, ch_name, threshold, ...])

Detect ECG related components.

find_bads_eog(inst[, ch_name, threshold, ...])

Detect EOG related components using correlation.

find_bads_muscle(inst[, threshold, start, ...])

Detect muscle-related components.

find_bads_ref(inst[, ch_name, threshold, ...])

Detect MEG reference related components using correlation.

fit(inst[, picks, start, stop, decim, ...])

Run the ICA decomposition on raw data.

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

Get ICA topomap for components as numpy arrays.

get_explained_variance_ratio(inst, *[, ...])

Get the proportion of data variance explained by ICA components.

get_sources(inst[, add_channels, start, stop])

Estimate sources given the unmixing matrix.

plot_components([picks, ch_type, inst, ...])

Project mixing matrix on interpolated sensor topography.

plot_overlay(inst[, exclude, picks, start, ...])

Overlay of raw and cleaned signals given the unmixing matrix.

plot_properties(inst[, picks, axes, dB, ...])

Display component properties.

plot_scores(scores[, exclude, labels, ...])

Plot scores related to detected components.

plot_sources(inst[, picks, start, stop, ...])

Plot estimated latent sources given the unmixing matrix.

save(fname, *[, overwrite, verbose])

Store ICA solution into a fiff file.

score_sources(inst[, target, score_func, ...])

Assign score to components based on statistic or metric.

Changed in version 0.23: Version 0.23 introduced the max_iter='auto' settings for maximum iterations. With version 0.24 'auto' will be the new default, replacing the current max_iter=200.

Changed in version 0.23: Warn if Epochs were baseline-corrected.

If you intend to fit ICA on Epochs, it is recommended to high-pass filter, but not baseline correct the data for good ICA performance. A warning will be emitted otherwise.

A trailing _ in an attribute name signifies that the attribute was added to the object during fitting, consistent with standard scikit-learn practice.

ICA fit() in MNE proceeds in two steps:

Whitening the data by means of a pre-whitening step (using noise_cov if provided, or the standard deviation of each channel type) and then principal component analysis (PCA).

Passing the n_components largest-variance components to the ICA algorithm to obtain the unmixing matrix (and by pseudoinversion, the mixing matrix).

Unmixes the data with the unmixing_matrix_.

Includes ICA components based on ica.include and ica.exclude.

Re-mixes the data with mixing_matrix_.

Restores any data not passed to the ICA algorithm, i.e., the PCA components between n_components and n_pca_components.

n_pca_components determines how many PCA components will be kept when reconstructing the data when calling apply(). This parameter can be used for dimensionality reduction of the data, or dealing with low-rank data (such as those with projections, or MEG data processed by SSS). It is important to remove any numerically-zero-variance components in the data, otherwise numerical instability causes problems when computing the mixing matrix. Alternatively, using n_components as a float will also avoid numerical stability problems.

The n_components parameter determines how many components out of the n_channels PCA components the ICA algorithm will actually fit. This is not typically used for EEG data, but for MEG data, it‚Äôs common to use n_components < n_channels. For example, full-rank 306-channel MEG data might use n_components=40 to find (and later exclude) only large, dominating artifacts in the data, but still reconstruct the data using all 306 PCA components. Setting n_pca_components=40, on the other hand, would actually reduce the rank of the reconstructed data to 40, which is typically undesirable.

If you are migrating from EEGLAB and intend to reduce dimensionality via PCA, similarly to EEGLAB‚Äôs runica(..., 'pca', n) functionality, pass n_components=n during initialization and then n_pca_components=n during apply(). The resulting reconstructed data after apply() will have rank n.

Commonly used for reasons of i) computational efficiency and ii) additional noise reduction, it is a matter of current debate whether pre-ICA dimensionality reduction could decrease the reliability and stability of the ICA, at least for EEG data and especially during preprocessing [5]. (But see also [6] for a possibly confounding effect of the different whitening/sphering methods used in this paper (ZCA vs. PCA).) On the other hand, for rank-deficient data such as EEG data after average reference or interpolation, it is recommended to reduce the dimensionality (by 1 for average reference and 1 for each interpolated channel) for optimal ICA performance (see the EEGLAB wiki).

Caveat! If supplying a noise covariance, keep track of the projections available in the cov or in the raw object. For example, if you are interested in EOG or ECG artifacts, EOG and ECG projections should be temporally removed before fitting ICA, for example:

Methods currently implemented are FastICA (default), Infomax, and Picard. Standard Infomax can be quite sensitive to differences in floating point arithmetic. Extended Infomax seems to be more stable in this respect, enhancing reproducibility and stability of results; use Extended Infomax via method='infomax', fit_params=dict(extended=True). Allowed entries in fit_params are determined by the various algorithm implementations: see FastICA, picard(), infomax().

Picard can be used to solve the same problems as FastICA, Infomax, and extended Infomax, but typically converges faster than either of those methods. To make use of Picard‚Äôs speed while still obtaining the same solution as with other algorithms, you need to specify method='picard' and fit_params as a dictionary with the following combination of keys:

dict(ortho=False, extended=False) for Infomax

dict(ortho=False, extended=True) for extended Infomax

dict(ortho=True, extended=True) for FastICA

Reducing the tolerance (set in fit_params) speeds up estimation at the cost of consistency of the obtained results. It is difficult to directly compare tolerance levels between Infomax and Picard, but for Picard and FastICA a good rule of thumb is tol_fastica == tol_picard ** 2.

Aapo Hyv√§rinen. Fast and robust fixed-point algorithms for independent component analysis. IEEE Transactions on Neural Networks, 10(3):626‚Äì634, 1999. doi:10.1109/72.761722.

Anthony J. Bell and Terrence J. Sejnowski. An information-maximization approach to blind separation and blind deconvolution. Neural Computation, 7(6):1129‚Äì1159, 1995. doi:10.1162/neco.1995.7.6.1129.

Te-Won Lee, Mark Girolami, and Terrence J. Sejnowski. Independent component analysis using an extended infomax algorithm for mixed subgaussian and supergaussian sources. Neural Computation, 11(2):417‚Äì441, 1999. doi:10.1162/089976699300016719.

Pierre Ablin, Jean-Francois Cardoso, and Alexandre Gramfort. Faster Independent Component Analysis by preconditioning with hessian approximations. IEEE Transactions on Signal Processing, 66(15):4040‚Äì4049, 2018. doi:10.1109/TSP.2018.2844203.

Fiorenzo Artoni, Arnaud Delorme, and Scott Makeig. Applying dimension reduction to EEG data by Principal Component Analysis reduces the quality of its subsequent Independent Component decomposition. NeuroImage, 175:176‚Äì187, 2018. doi:10.1016/j.neuroimage.2018.03.016.

Jair Montoya-Mart√≠nez, Jean-Fran√ßois Cardoso, and Alexandre Gramfort. Caveats with stochastic gradient and maximum likelihood based ICA for EEG. In Petr Tichavsk√Ω, Massoud Babaie-Zadeh, Olivier J.J. Michel, and Nad√®ge Thirion-Moreau, editors, Latent Variable Analysis and Signal Separation, number 10169 in Lecture Notes in Computer Science, pages 279‚Äì289. Springer International Publishing, Cham, 2017. doi:10.1007/978-3-319-53547-0_27.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Remove selected components from the signal.

Given the unmixing matrix, transform the data, zero out all excluded components, and inverse-transform the data. This procedure will reconstruct M/EEG signals from which the dynamics described by the excluded components is subtracted.

The data to be processed (i.e., cleaned). It will be modified in-place.

The indices referring to columns in the ummixing matrix. The components to be kept. If None (default), all components will be included (minus those defined in ica.exclude and the exclude parameter, see below).

The indices referring to columns in the ummixing matrix. The components to be zeroed out. If None (default) or an empty list, only components from ica.exclude will be excluded. Else, the union of exclude and ica.exclude will be excluded.

The number of PCA components to be kept, either absolute (int) or fraction of the explained variance (float). If None (default), the ica.n_pca_components from initialization will be used in 0.22; in 0.23 all components will be used.

First sample to include. If float, data will be interpreted as time in seconds. If None, data will be used from the first sample.

Last sample to not include. If float, data will be interpreted as time in seconds. If None, data will be used to the last sample.

How to handle baseline-corrected epochs or evoked data. Can be 'raise' to raise an error, 'warn' (default) to emit a warning, 'ignore' to ignore, or ‚Äúreapply‚Äù to reapply the baseline after applying ICA.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Applying ICA may introduce a DC shift. If you pass baseline-corrected Epochs or Evoked data, the baseline period of the cleaned data may not be of zero mean anymore. If you require baseline-corrected data, apply baseline correction again after cleaning via ICA. A warning will be emitted to remind you of this fact if you pass baseline-corrected data.

Changed in version 0.23: Warn if instance was baseline-corrected.

Examples using apply:

From raw data to dSPM on SPM Faces dataset

Find MEG reference channel artifacts

Removing muscle ICA components

Overview of MEG/EEG analysis with MNE-Python

Repairing artifacts with ICA

The current gradient compensation grade.

Find MEG reference channel artifacts

Detect ECG related components.

Cross-trial phase statistics [7] or Pearson correlation can be used for detection.

If no ECG channel is available, an artificial ECG channel will be created based on cross-channel averaging of "mag" or "grad" channels. If neither of these channel types are available in inst, artificial ECG channel creation is impossible.

Object to compute sources from.

The name of the channel to use for ECG peak detection. If None (default), ECG channel is used if present. If None and no ECG channel is present, a synthetic ECG channel is created from the cross-channel average. This synthetic channel can only be created from MEG channels.

Value above which a feature is classified as outlier. See Notes.

Changed in version 0.21.

First sample to include. If float, data will be interpreted as time in seconds. If None, data will be used from the first sample. When working with Epochs or Evoked objects, must be float or None.

Last sample to not include. If float, data will be interpreted as time in seconds. If None, data will be used to the last sample. When working with Epochs or Evoked objects, must be float or None.

The method used for detection. If 'ctps', cross-trial phase statistics [7] are used to detect ECG-related components. See Notes.

Whether to omit bad segments from the data before fitting. If True (default), annotated segments whose description begins with 'bad' are omitted. If False, no rejection based on annotations is performed.

Which method to use for finding outliers among the components:

'zscore' (default) is the iterative z-scoring method. This method computes the z-score of the component‚Äôs scores and masks the components with a z-score above threshold. This process is repeated until no supra-threshold component remains.

'correlation' is an absolute raw correlation threshold ranging from 0 to 1.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The indices of ECG-related components.

If method is ‚Äòctps‚Äô, the normalized Kuiper index scores. If method is ‚Äòcorrelation‚Äô, the correlation scores.

The threshold, method, and measure parameters interact in the following ways:

If method='ctps', threshold refers to the significance value of a Kuiper statistic, and threshold='auto' will compute the threshold automatically based on the sampling frequency.

If method='correlation' and measure='correlation', threshold refers to the Pearson correlation value, and threshold='auto' sets the threshold to 0.9.

If method='correlation' and measure='zscore', threshold refers to the z-score value (i.e., standard deviations) used in the iterative z-scoring method, and threshold='auto' sets the threshold to 3.0.

J√ºrgen Dammers, Michael Schiek, Frank Boers, Carmen Silex, Mikhail Zvyagintsev, Uwe Pietrzyk, and Klaus Mathiak. Integration of amplitude and phase statistics for complete artifact removal in independent components of neuromagnetic recordings. IEEE Transactions on Biomedical Engineering, 55(10):2353‚Äì2362, 2008. doi:10.1109/TBME.2008.926677.

Examples using find_bads_ecg:

Repairing artifacts with ICA

Detect EOG related components using correlation.

Detection is based on Pearson correlation between the filtered data and the filtered EOG channel. Thresholding is based on adaptive z-scoring. The above threshold components will be masked and the z-score will be recomputed until no supra-threshold component remains.

Object to compute sources from.

The name of the channel to use for EOG peak detection. The argument is mandatory if the dataset contains no EOG channels.

Value above which a feature is classified as outlier.

If measure is 'zscore', defines the threshold on the z-score used in the iterative z-scoring method.

If measure is 'correlation', defines the absolute threshold on the correlation between 0 and 1.

If 'auto', defaults to 3.0 if measure is 'zscore' and 0.9 if measure is 'correlation'.

First sample to include. If float, data will be interpreted as time in seconds. If None, data will be used from the first sample.

Last sample to not include. If float, data will be interpreted as time in seconds. If None, data will be used to the last sample.

Whether to omit bad segments from the data before fitting. If True (default), annotated segments whose description begins with 'bad' are omitted. If False, no rejection based on annotations is performed.

Which method to use for finding outliers among the components:

'zscore' (default) is the iterative z-scoring method. This method computes the z-score of the component‚Äôs scores and masks the components with a z-score above threshold. This process is repeated until no supra-threshold component remains.

'correlation' is an absolute raw correlation threshold ranging from 0 to 1.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The indices of EOG related components, sorted by score.

The correlation scores.

Examples using find_bads_eog:

From raw data to dSPM on SPM Faces dataset

Getting started with mne.Report

Repairing artifacts with ICA

Detect muscle-related components.

Detection is based on [8] which uses data from a subject who has been temporarily paralyzed [9]. The criteria are threefold:

Positive log-log spectral slope from 7 to 45 Hz

Peripheral component power (farthest away from the vertex)

A single focal point measured by low spatial smoothness

The threshold is relative to the slope, focal point and smoothness of a typical muscle-related ICA component. Note the high frequency of the power spectral density slope was 75 Hz in the reference but has been modified to 45 Hz as a default based on the criteria being more accurate in practice.

If inst is supplied without sensor positions, only the first criterion (slope) is applied.

Object to compute sources from.

Value above which a component should be marked as muscle-related, relative to a typical muscle component.

First sample to include. If float, data will be interpreted as time in seconds. If None, data will be used from the first sample.

Last sample to not include. If float, data will be interpreted as time in seconds. If None, data will be used to the last sample.

Low frequency for muscle-related power.

High frequency for muscle-related power.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The indices of muscle-related components, sorted by score.

The correlation scores.

Examples using find_bads_muscle:

Removing muscle ICA components

Detect MEG reference related components using correlation.

Object to compute sources from. Should contain at least one channel i.e. component derived from MEG reference channels.

Which MEG reference components to use. If None, then all channels that begin with REF_ICA.

Value above which a feature is classified as outlier.

If measure is 'zscore', defines the threshold on the z-score used in the iterative z-scoring method.

If measure is 'correlation', defines the absolute threshold on the correlation between 0 and 1.

If 'auto', defaults to 3.0 if measure is 'zscore' and 0.9 if measure is 'correlation'.

If method is 'together', the iterative z-score method is always used.

First sample to include. If float, data will be interpreted as time in seconds. If None, data will be used from the first sample.

Last sample to not include. If float, data will be interpreted as time in seconds. If None, data will be used to the last sample.

Whether to omit bad segments from the data before fitting. If True (default), annotated segments whose description begins with 'bad' are omitted. If False, no rejection based on annotations is performed.

Method to use to identify reference channel related components. Defaults to 'together'. See notes.

Which method to use for finding outliers among the components:

'zscore' (default) is the iterative z-scoring method. This method computes the z-score of the component‚Äôs scores and masks the components with a z-score above threshold. This process is repeated until no supra-threshold component remains.

'correlation' is an absolute raw correlation threshold ranging from 0 to 1.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The indices of MEG reference related components, sorted by score.

The correlation scores.

ICA decomposition on MEG reference channels is used to assess external magnetic noise and remove it from the MEG. Two methods are supported:

With the 'together' method, only one ICA fit is used, which encompasses both MEG and reference channels together. Components which have particularly strong weights on the reference channels may be thresholded and marked for removal.

With 'separate' selected components from a separate ICA decomposition on the reference channels are used as a ground truth for identifying bad components in an ICA fit done on MEG channels only. The logic here is similar to an EOG/ECG, with reference components replacing the EOG/ECG channels. Recommended procedure is to perform ICA separately on reference channels, extract them using get_sources(), and then append them to the inst using add_channels(), preferably with the prefix REF_ICA so that they can be automatically detected.

With 'together', thresholding is based on adaptative z-scoring.

If measure is 'zscore', thresholding is based on adaptative z-scoring.

If measure is 'correlation', threshold defines the absolute threshold on the correlation between 0 and 1.

Validation and further documentation for this technique can be found in [10].

Dhani Dharmaprani, Hoang K. Nguyen, Trent W. Lewis, Dylan DeLosAngeles, John O. Willoughby, and Kenneth J. Pope. A comparison of independent component analysis algorithms and measures to discriminate between EEG and artifact components. In 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), 825‚Äì828. Orlando, FL, USA, 2016. IEEE. doi:10.1109/EMBC.2016.7590828.

Emma M. Whitham, Kenneth J. Pope, Sean P. Fitzgibbon, Trent Lewis, C. Richard Clark, Stephen Loveless, Marita Broberg, Angus Wallace, Dylan DeLosAngeles, Peter Lillie, Andrew Hardy, Rik Fronsko, Alyson Pulbrook, and John O. Willoughby. Scalp electrical recording during paralysis: quantitative evidence that EEG frequencies above 20 Hz are contaminated by EMG. Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology, 118(8):1877‚Äì1888, 2007. doi:10.1016/j.clinph.2007.04.027.

Jeff Hanna, Cora Kim, and Nadia M√ºller-Voggel. External noise removed from magnetoencephalographic signal using independent component analysis of reference channels. Journal of Neuroscience Methods, 2020. doi:10.1016/j.jneumeth.2020.108592.

Examples using find_bads_ref:

Find MEG reference channel artifacts

Run the ICA decomposition on raw data.

Caveat! If supplying a noise covariance keep track of the projections available in the cov, the raw or the epochs object. For example, if you are interested in EOG or ECG artifacts, EOG and ECG projections should be temporally removed before fitting the ICA.

The data to be decomposed.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided. This selection remains throughout the initialized ICA solution.

First and last sample to include. If float, data will be interpreted as time in seconds. If None, data will be used from the first sample and to the last sample, respectively.

These parameters only have an effect if inst is Raw data.

Increment for selecting only each n-th sampling point. If None, all samples between start and stop (inclusive) are used.

Rejection parameters based on peak-to-peak amplitude (PTP) in the continuous data. Signal periods exceeding the thresholds in reject or less than the thresholds in flat will be removed before fitting the ICA.

These parameters only have an effect if inst is Raw data. For Epochs, perform PTP rejection via drop_bad().

Valid keys are all channel types present in the data. Values must be integers or floats.

If None, no PTP-based rejection will be performed. Example:

Length of data chunks for artifact rejection in seconds.

This parameter only has an effect if inst is Raw data.

Whether to omit bad segments from the data before fitting. If True (default), annotated segments whose description begins with 'bad' are omitted. If False, no rejection based on annotations is performed.

Has no effect if inst is not a mne.io.Raw object.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Returns the modified instance.

From raw data to dSPM on SPM Faces dataset

Find MEG reference channel artifacts

Removing muscle ICA components

Overview of MEG/EEG analysis with MNE-Python

Getting started with mne.Report

Repairing artifacts with ICA

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get ICA topomap for components as numpy arrays.

The ICA components (maps).

Examples using get_components:

Repairing artifacts with ICA

Get the proportion of data variance explained by ICA components.

The component(s) for which to do the calculation. If more than one component is specified, explained variance will be calculated jointly across all supplied components. If None (default), uses all available components.

The channel type(s) to include in the calculation. If None, all available channel types will be used.

The fraction of variance in inst that can be explained by the ICA components, calculated separately for each channel type. Dictionary keys are the channel types, and corresponding explained variance ratios are the values.

A value similar to EEGLAB‚Äôs pvaf (percent variance accounted for) will be calculated for the specified component(s).

Since ICA components cannot be assumed to be aligned orthogonally, the sum of the proportion of variance explained by all components may not be equal to 1. In certain situations, the proportion of variance explained by a component may even be negative.

Examples using get_explained_variance_ratio:

Repairing artifacts with ICA

Estimate sources given the unmixing matrix.

This method will return the sources in the container format passed. Typical usecases:

pass Raw object to use raw.plot for ICA sources

pass Epochs object to compute trial-based statistics in ICA space

pass Evoked object to investigate time-locking in ICA space

Object to compute sources from and to represent sources in.

Additional channels to be added. Useful to e.g. compare sources with some reference. Defaults to None.

First sample to include. If float, data will be interpreted as time in seconds. If None, the entire data will be used.

Last sample to not include. If float, data will be interpreted as time in seconds. If None, the entire data will be used.

The ICA sources time series.

Examples using get_sources:

Find MEG reference channel artifacts

Project mixing matrix on interpolated sensor topography.

Indices of the independent components (ICs) to visualize. If an integer, represents the index of the IC to pick. Multiple ICs can be selected using a list of int or a slice. The indices are 0-indexed, so picks=1 will pick the second IC: ICA001. None will pick all independent components in the order fitted.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

To be able to see component properties after clicking on component topomap you need to pass relevant data - instances of Raw or Epochs (for example the data that ICA was trained on). This takes effect only when running matplotlib in interactive mode.

Whether to plot standard deviation in ERP/ERF and spectrum plots. Defaults to True, which plots one standard deviation above/below. If set to float allows to control how many standard deviations are plotted. For example 2.5 will plot 2.5 standard deviation above/below.

Allows to specify rejection parameters used to drop epochs (or segments if continuous signal is passed as inst). If None, no rejection is applied. The default is ‚Äòauto‚Äô, which applies the rejection parameters used when fitting the ICA object.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The subplot(s) to plot to. Either a single Axes or an iterable of Axes if more than one subplot is needed. The number of subplots must match the number of selected components. If None, new figures will be created with the number of subplots per figure controlled by nrows and ncols.

The title of the generated figure. If None (default) and axes=None, a default title of ‚ÄúICA Components‚Äù will be used.

The number of rows and columns of topographies to plot. If both nrows and ncols are 'auto', will plot up to 20 components in a 5√ó4 grid, and return multiple figures if more than 20 components are requested. If one is 'auto' and the other a scalar, a single figure is generated. If scalars are provided for both arguments, will plot up to nrows*ncols components in a grid and return multiple figures as needed. Default is nrows='auto', ncols='auto'.

Show the figure if True.

Dictionary of arguments to pass to plot_epochs_image() in interactive mode. Ignored if inst is not supplied. If None, nothing is passed. Defaults to None.

Dictionary of arguments to pass to compute_psd() in interactive mode. Ignored if inst is not supplied. If None, nothing is passed. Defaults to None.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure object(s).

When run in interactive mode, plot_ica_components allows to reject components by clicking on their title label. The state of each component is indicated by its label color (gray: rejected; black: retained). It is also possible to open component properties by clicking on the component topomap (this option is only available when the inst argument is supplied).

Examples using plot_components:

From raw data to dSPM on SPM Faces dataset

Repairing artifacts with ICA

Overlay of raw and cleaned signals given the unmixing matrix.

This method helps visualizing signal quality and artifact rejection.

The signal to plot. If Raw, the raw data per channel type is displayed before and after cleaning. A second panel with the RMS for MEG sensors and the GFP for EEG sensors is displayed. If Evoked, butterfly traces for signals before and after cleaning will be superimposed.

The components marked for exclusion. If None (default), the components listed in ICA.exclude will be used.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels that were included during fitting.

The first and last time point (in seconds) of the data to plot. If inst is a Raw object, start=None and stop=None will be translated into start=0. and stop=3., respectively. For Evoked, None refers to the beginning and end of the evoked signal.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

The number of PCA components to be kept, either absolute (int) or fraction of the explained variance (float). If None (default), the ica.n_pca_components from initialization will be used in 0.22; in 0.23 all components will be used.

How to handle baseline-corrected epochs or evoked data. Can be 'raise' to raise an error, 'warn' (default) to emit a warning, 'ignore' to ignore, or ‚Äúreapply‚Äù to reapply the baseline after applying ICA.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Examples using plot_overlay:

From raw data to dSPM on SPM Faces dataset

Removing muscle ICA components

Repairing artifacts with ICA

Display component properties.

Properties include the topography, epochs image, ERP/ERF, power spectrum, and epoch variance.

The data to use in plotting properties.

You can interactively cycle through topographic maps for different channel types by pressing T.

Indices of the independent components (ICs) to visualize. If an integer, represents the index of the IC to pick. Multiple ICs can be selected using a list of int or a slice. The indices are 0-indexed, so picks=1 will pick the second IC: ICA001. None will pick the first 5 components.

List of five matplotlib axes to use in plotting: [topomap_axis, image_axis, erp_axis, spectrum_axis, variance_axis]. If None a new figure with relevant axes is created. Defaults to None.

Whether to plot spectrum in dB. Defaults to True.

Whether to plot standard deviation/confidence intervals in ERP/ERF and spectrum plots. Defaults to True, which plots one standard deviation above/below for the spectrum. If set to float allows to control how many standard deviations are plotted for the spectrum. For example 2.5 will plot 2.5 standard deviation above/below. For the ERP/ERF, by default, plot the 95 percent parametric confidence interval is calculated. To change this, use ci in ts_args in image_args (see below).

Whether to use a logarithmic frequency axis to plot the spectrum. Defaults to False.

You can interactively toggle this setting by pressing L.

Dictionary of arguments to plot_topomap. If None, doesn‚Äôt pass any additional arguments. Defaults to None.

Dictionary of arguments to plot_epochs_image. If None, doesn‚Äôt pass any additional arguments. Defaults to None.

Dictionary of arguments to compute_psd(). If None, doesn‚Äôt pass any additional arguments. Defaults to None.

Allows to control size of the figure. If None, the figure size defaults to [7., 6.].

Allows to specify rejection parameters used to drop epochs (or segments if continuous signal is passed as inst). If None, no rejection is applied. The default is ‚Äòauto‚Äô, which applies the rejection parameters used when fitting the ICA object.

Whether to omit bad segments from the data before fitting. If True (default), annotated segments whose description begins with 'bad' are omitted. If False, no rejection based on annotations is performed.

Has no effect if inst is not a mne.io.Raw object.

Can be ‚Äúpower‚Äù for power spectral density (PSD; default), ‚Äúamplitude‚Äù for amplitude spectrum density (ASD).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

List of matplotlib figures.

Examples using plot_properties:

Find MEG reference channel artifacts

Removing muscle ICA components

Overview of MEG/EEG analysis with MNE-Python

Repairing artifacts with ICA

Plot scores related to detected components.

Use this function to asses how well your score describes outlier sources and how well you were detecting them.

Scores based on arbitrary metric to characterize ICA components.

The components marked for exclusion. If None (default), ICA.exclude will be used.

The labels to consider for the axes tests. Defaults to None. If list, should match the outer shape of scores. If ‚Äòecg‚Äô or ‚Äòeog‚Äô, the labels_ attributes will be looked up. Note that ‚Äò/‚Äô is used internally for sublabels specifying ECG and EOG channels.

Draw horizontal line to e.g. visualize rejection threshold.

The figure size. If None it gets set automatically.

Scores are plotted in a grid. This parameter controls how many to plot side by side before starting a new row. By default, a number will be chosen to make the grid as square as possible.

Examples using plot_scores:

From raw data to dSPM on SPM Faces dataset

Find MEG reference channel artifacts

Removing muscle ICA components

Repairing artifacts with ICA

Plot estimated latent sources given the unmixing matrix.

plot evolution of latent sources over time based on (Raw input)

plot latent source around event related time windows (Epochs input)

plot time-locking in ICA space (Evoked input)

The object to plot the sources from.

Indices of the independent components (ICs) to visualize. If an integer, represents the index of the IC to pick. Multiple ICs can be selected using a list of int or a slice. The indices are 0-indexed, so picks=1 will pick the second IC: ICA001. None will pick all independent components in the order fitted.

If inst is a Raw or an Evoked object, the first and last time point (in seconds) of the data to plot. If inst is a Raw object, start=None and stop=None will be translated into start=0. and stop=3., respectively. For Evoked, None refers to the beginning and end of the evoked signal. If inst is an Epochs object, specifies the index of the first and last epoch to show.

The window title. If None a default is provided.

Whether to halt program execution until the figure is closed. Useful for interactive selection of components in raw and epoch plotter. For evoked, this parameter has no effect. Defaults to False.

If True, show time axis relative to the raw.first_samp.

Whether to show scrollbars when the plot is initialized. Can be toggled after initialization by pressing z (‚Äúzen mode‚Äù) while the plot window is focused. Default is True.

Style of time labels on the horizontal axis. If 'float', labels will be number of seconds from the start of the recording. If 'clock', labels will show ‚Äúclock time‚Äù (hours/minutes/seconds) inferred from raw.info['meas_date']. Default is 'float'.

Whether to load all data (not just the visible portion) into RAM and apply preprocessing (e.g., projectors) to the full data array in a separate processor thread, instead of window-by-window during scrolling. The default None uses the MNE_BROWSER_PRECOMPUTE variable, which defaults to 'auto'. 'auto' compares available RAM space to the expected size of the precomputed data, and precomputes only if enough RAM is available. This is only used with the Qt backend.

Changed in version 1.0: Support for the MNE_BROWSER_PRECOMPUTE config variable.

Whether to use OpenGL when rendering the plot (requires pyopengl). May increase performance, but effect is dependent on system CPU and graphics hardware. Only works if using the Qt backend. Default is None, which will use False unless the user configuration variable MNE_BROWSER_USE_OPENGL is set to 'true', see mne.set_config().

A regex pattern applied to each annotation‚Äôs label. Matching labels remain visible, non-matching labels are hidden.

Dictionary of arguments to pass to compute_psd() in interactive mode. Ignored if inst is not supplied. If None, nothing is passed. Defaults to None.

Can be ‚Äúauto‚Äù, ‚Äúlight‚Äù, or ‚Äúdark‚Äù or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_BROWSER_THEME will be used, defaulting to ‚Äúauto‚Äù if it‚Äôs not found. Only supported by the 'qt' backend.

Can be ‚Äúchannels‚Äù, ‚Äúempty‚Äù, or ‚Äúhidden‚Äù to set the overview bar mode for the 'qt' backend. If None (default), the config option MNE_BROWSER_OVERVIEW_MODE will be used, defaulting to ‚Äúchannels‚Äù if it‚Äôs not found.

If True (default), a splash screen is shown during the application startup. Only applicable to the qt backend.

For raw and epoch instances, it is possible to select components for exclusion by clicking on the line. The selected components are added to ica.exclude on close.

MNE-Python provides two different backends for browsing plots (i.e., raw.plot(), epochs.plot(), and ica.plot_sources()). One is based on matplotlib, and the other is based on PyQtGraph. You can set the backend temporarily with the context manager mne.viz.use_browser_backend(), you can set it for the duration of a Python session using mne.viz.set_browser_backend(), and you can set the default for your computer via mne.set_config('MNE_BROWSER_BACKEND', 'matplotlib') (or 'qt').

For the PyQtGraph backend to run in IPython with block=False you must run the magic command %gui qt5 first.

To report issues with the PyQtGraph backend, please use the issues of mne-qt-browser.

Examples using plot_sources:

Removing muscle ICA components

Repairing artifacts with ICA

Store ICA solution into a fiff file.

The absolute path of the file name to save the ICA solution into. The file name should end with -ica.fif or -ica.fif.gz.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Repairing artifacts with ICA

Assign score to components based on statistic or metric.

The object to reconstruct the sources from.

Signal to which the sources shall be compared. It has to be of the same shape as the sources. If str, a routine will try to find a matching channel name. If None, a score function expecting only one input-array argument must be used, for instance, scipy.stats.skew (default).

Callable taking as arguments either two input arrays (e.g. Pearson correlation) or one input array (e. g. skewness) and returns a float. For convenience the most common score_funcs are available via string labels: Currently, all distance metrics from scipy.spatial and All functions from scipy.stats taking compatible input arguments are supported. These function have been modified to support iteration over the rows of a 2D array.

First sample to include. If float, data will be interpreted as time in seconds. If None, data will be used from the first sample.

Last sample to not include. If float, data will be interpreted as time in seconds. If None, data will be used to the last sample.

Whether to omit bad segments from the data before fitting. If True (default), annotated segments whose description begins with 'bad' are omitted. If False, no rejection based on annotations is performed.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Scores for each source as returned from score_func.

From raw data to dSPM on SPM Faces dataset

Find MEG reference channel artifacts

Compare the different ICA algorithms in MNE

Removing muscle ICA components

Overview of MEG/EEG analysis with MNE-Python

Getting started with mne.Report

Repairing artifacts with ICA

mne.channels.combine_channels

mne.preprocessing.Xdawn

---

## mne.preprocessing.ica_find_ecg_events#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.ica_find_ecg_events.html

**Contents:**
- mne.preprocessing.ica_find_ecg_events#

Find ECG peaks from one selected ICA source.

Raw object to draw sources from.

ICA source resembling ECG to find peaks from.

The index to assign to found events.

Start detection after tstart seconds. Useful when beginning of run is noisy.

Between 0 and 1. qrs detection threshold. Can also be ‚Äúauto‚Äù to automatically choose the threshold that generates a reasonable number of heartbeats (40-160 beats / min).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Name of channel used.

Estimated average pulse.

mne.preprocessing.fix_stim_artifact

mne.preprocessing.ica_find_eog_events

---

## mne.preprocessing.ica_find_eog_events#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.ica_find_eog_events.html

**Contents:**
- mne.preprocessing.ica_find_eog_events#

Locate EOG artifacts from one selected ICA source.

ICA source resembling EOG to find peaks from.

The index to assign to found events.

Low cut-off frequency in Hz.

High cut-off frequency in Hz.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

mne.preprocessing.ica_find_ecg_events

mne.preprocessing.infomax

---

## mne.preprocessing.ieeg.make_montage_volume#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.ieeg.make_montage_volume.html

**Contents:**
- mne.preprocessing.ieeg.make_montage_volume#

Make a volume from intracranial electrode contact locations.

Find areas of the input volume with intensity greater than a threshold surrounding local extrema near the channel location. Monotonicity from the peak is enforced to prevent channels bleeding into each other.

The montage object containing the channels.

Path to a volumetric scan (e.g. CT) of the subject. Can be in any format readable by nibabel. Can also be a nibabel image object. Local extrema (max or min) should be nearby montage channel locations.

The threshold relative to the peak to determine the size of the sensors on the volume.

The number of voxels away from the channel location to look in the image. This will depend on the accuracy of the channel locations, the default (one voxel in all directions) will work only with localizations that are that accurate.

The maximum number of voxels for each channel.

Whether to hypointensities in the volume as channel locations. Default False uses hyperintensities.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

An image in Freesurfer surface RAS space with voxel values corresponding to the index of the channel. The background is 0s and this index starts at 1.

mne.preprocessing.ieeg.project_sensors_onto_brain

mne.preprocessing.ieeg.warp_montage

---

## mne.preprocessing.ieeg.project_sensors_onto_brain#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.ieeg.project_sensors_onto_brain.html

**Contents:**
- mne.preprocessing.ieeg.project_sensors_onto_brain#

Project sensors onto the brain surface.

The mne.Info object with information about the sensors and methods of measurement.

If str, the path to the head<->MRI transform *-trans.fif file produced during coregistration. Can also be 'fsaverage' to use the built-in fsaverage transformation.

The FreeSurfer subject name.

The path to the directory containing the FreeSurfer subjects reconstructions. If None, defaults to the SUBJECTS_DIR environment variable.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick only ecog channels.

The number of neighbors to use to compute the normal vectors for the projection. Must be 2 or greater. More neighbors makes a normal vector with greater averaging which preserves the grid structure. Fewer neighbors has less averaging which better preserves contours in the grid.

If True, return a new instance of info, if False info is modified in place.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The mne.Info object with information about the sensors and methods of measurement.

This is useful in ECoG analysis for compensating for ‚Äúbrain shift‚Äù or shrinking of the brain away from the skull due to changes in pressure during the craniotomy.

To use the brain surface, a BEM model must be created e.g. using mne watershed_bem using the T1 or mne flash_bem using a FLASH scan.

mne.preprocessing.nirs.temporal_derivative_distribution_repair

mne.preprocessing.ieeg.make_montage_volume

---

## mne.preprocessing.ieeg.warp_montage#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.ieeg.warp_montage.html

**Contents:**
- mne.preprocessing.ieeg.warp_montage#

Warp a montage to a template with image volumes using SDR.

This is likely only applicable for channels inside the brain (intracranial electrodes).

The montage object containing the channels.

The image to morph (‚Äúfrom‚Äù volume).

The image to align with (‚Äúto‚Äù volume).

The affine that registers one volume to another.

The class that applies the the symmetric diffeomorphic registration (SDR) morph.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified montage object containing the channels.

mne.preprocessing.ieeg.make_montage_volume

mne.preprocessing.eyetracking.Calibration

---

## mne.preprocessing.infomax#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.infomax.html

**Contents:**
- mne.preprocessing.infomax#

Run (extended) Infomax ICA decomposition on raw data.

The whitened data to unmix.

The initialized unmixing matrix. Defaults to None, which means the identity matrix is used.

This quantity indicates the relative size of the change in weights. Defaults to 0.01 / log(n_features ** 2).

Smaller learning rates will slow down the ICA procedure.

The block size of randomly chosen data segments. Defaults to floor(sqrt(n_times / 3.)).

The change at which to stop iteration. Defaults to 1e-12.

The angle (in degrees) at which the learning rate will be reduced. Defaults to 60.0.

The factor by which the learning rate will be reduced once anneal_deg is exceeded: l_rate *= anneal_step. Defaults to 0.9.

Whether to use the extended Infomax algorithm or not. Defaults to True.

The number of subgaussian components. Only considered for extended Infomax. Defaults to 1.

The window size for kurtosis estimation. Only considered for extended Infomax. Defaults to 6000.

Only considered for extended Infomax. If positive, denotes the number of blocks after which to recompute the kurtosis, which is used to estimate the signs of the sources. In this case, the number of sub-gaussian sources is automatically determined. If negative, the number of sub-gaussian sources to be used is fixed and equal to n_subgauss. In this case, the kurtosis is not estimated. Defaults to 1.

The maximum number of iterations. Defaults to 200.

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

The maximum difference allowed between two successive estimations of the unmixing matrix. Defaults to 10000.

The factor by which the learning rate will be reduced if the difference between two successive estimations of the unmixing matrix exceededs blowup: l_rate *= blowup_fac. Defaults to 0.5.

The maximum number of allowed steps in which the angle between two successive estimations of the unmixing matrix is less than anneal_deg. If None, this parameter is not taken into account to stop the iterations. Defaults to 20.

This quantity indicates if the bias should be computed. Defaults to True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Whether to return the number of iterations performed. Defaults to False.

The linear unmixing operator.

The number of iterations. Only returned if return_max_iter=True.

A. J. Bell, T. J. Sejnowski. An information-maximization approach to blind separation and blind deconvolution. Neural Computation, 7(6), 1129-1159, 1995.

T. W. Lee, M. Girolami, T. J. Sejnowski. Independent component analysis using an extended infomax algorithm for mixed subgaussian and supergaussian sources. Neural Computation, 11(2), 417-441, 1999.

mne.preprocessing.ica_find_eog_events

mne.preprocessing.interpolate_bridged_electrodes

---

## mne.preprocessing.interpolate_bridged_electrodes#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.interpolate_bridged_electrodes.html

**Contents:**
- mne.preprocessing.interpolate_bridged_electrodes#
- Examples using mne.preprocessing.interpolate_bridged_electrodes#

Interpolate bridged electrode pairs.

Because bridged electrodes contain brain signal, it‚Äôs just that the signal is spatially smeared between the two electrodes, we can make a virtual channel midway between the bridged pairs and use that to aid in interpolation rather than completely discarding the data from the two channels.

The data object with channels that are to be interpolated.

The indices of channels marked as bridged with each bridged pair stored as a tuple.

The maximum number of electrodes that can be bridged together (included) and interpolated. Above this number, an error will be raised.

The modified data object.

Identify EEG Electrodes Bridged by too much Gel

mne.preprocessing.infomax

mne.preprocessing.equalize_bads

---

## mne.preprocessing.maxwell_filter#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.maxwell_filter.html

**Contents:**
- mne.preprocessing.maxwell_filter#
- Examples using mne.preprocessing.maxwell_filter#

Maxwell filter data using multipole moments.

It is critical to mark bad channels in raw.info['bads'] prior to processing in order to prevent artifact spreading. Manual inspection and use of find_bad_channels_maxwell() is recommended.

Origin of internal and external multipolar moment space in meters. The default is 'auto', which means (0., 0., 0.) when coord_frame='meg', and a head-digitization-based origin fit using fit_sphere_to_headshape() when coord_frame='head'. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually.

Order of internal component of spherical expansion.

Order of external component of spherical expansion.

Path to the '.dat' file with fine calibration coefficients. File can have 1D or 3D gradiometer imbalance correction. This file is machine/site-specific.

Path to the FIF file with cross-talk correction information.

If not None, apply spatiotemporal SSS with specified buffer duration (in seconds). MaxFilter‚Ñ¢‚Äôs default is 10.0 seconds in v2.2. Spatiotemporal SSS acts as implicitly as a high-pass filter where the cut-off frequency is 1/st_duration Hz. For this (and other) reasons, longer buffers are generally better as long as your system can handle the higher memory usage. To ensure that each window is processed identically, choose a buffer length that divides evenly into your data. Any data at the trailing edge that doesn‚Äôt fit evenly into a whole buffer window will be lumped into the previous buffer.

Correlation limit between inner and outer subspaces used to reject overlapping intersecting inner/outer signals during spatiotemporal SSS.

The coordinate frame that the origin is specified in, either 'meg' or 'head'. For empty-room recordings that do not have a head<->meg transform info['dev_head_t'], the MEG coordinate frame should be used.

The destination location for the head. Can be:

Will not change the head position.

A MEG device<->head transformation, e.g. info["dev_head_t"].

A 3-element array giving the coordinates to translate to (with no rotations). For example, destination=(0, 0, 0.04) would translate the bases as --trans default would in MaxFilter‚Ñ¢ (i.e., to the default head location).

A path to a FIF file containing the destination MEG device<->head transformation.

Basis regularization type, must be "in" or None. "in" is the same algorithm as the -regularize in option in MaxFilter‚Ñ¢.

If True, do not include reference channels in compensation. This option should be True for KIT files, since Maxwell filtering with reference channels is not currently supported.

How to deal with ill-conditioned SSS matrices. Can be "error" (default), "warning", "info", or "ignore".

If array, movement compensation will be performed. The array should be of shape (N, 10), holding the position parameters as returned by e.g. read_head_pos.

If True (default), do tSSS using the median head position during the st_duration window. This is the default behavior of MaxFilter and has been most extensively tested.

If True, only tSSS (temporal) projection of MEG data will be performed on the output data. The non-tSSS parameters (e.g., int_order, calibration, head_pos, etc.) will still be used to form the SSS bases used to calculate temporal projectors, but the output MEG data will only have temporal projections performed. Noise reduction from SSS basis multiplication, cross-talk cancellation, movement compensation, and so forth will not be applied to the data. This is useful, for example, when evoked movement compensation will be performed with average_movements().

The magenetometer scale-factor used to bring the magnetometers to approximately the same order of magnitude as the gradiometers (default 100.), as they have different units (T vs T/m). Can be 'auto' to use the reciprocal of the physical distance between the gradiometer pickup loops (e.g., 0.0168 m yields 59.5 for VectorView).

If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default ('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list.

The empty-room projection vectors used to extend the external SSS basis (i.e., use eSSS).

If True (default in 1.11), tSSS processing will use a constant overlap-add method. If False, then non-overlapping windows will be used.

Interpolation to use between adjacent time points in movement compensation. Can be ‚Äúzero‚Äù (used by MaxFilter), ‚Äúlinear‚Äù, or ‚Äúhann‚Äù (default in 1.11).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The raw data with Maxwell filtering applied.

Some of this code was adapted and relicensed (with BSD form) with permission from Jussi Nurminen. These algorithms are based on work from [1] and [2]. It will likely use multiple CPU cores, see the FAQ for more information.

Maxwell filtering in MNE is not designed or certified for clinical use.

Compared to the MEGIN MaxFilter‚Ñ¢ 2.2.11 software, the MNE Maxwell filtering routines currently provide the following features:

Maxwell filtering software shielding

Bad channel reconstruction

Cross-talk cancellation

Fine calibration correction (1D)

Fine calibration correction (3D)

Spatio-temporal SSS (tSSS)

Coordinate frame translation

Regularization using information theory

Movement compensation (raw)

Movement compensation (epochs)

Double floating point precision

Seamless processing of split (-1.fif) and concatenated files

Automatic bad channel detection (find_bad_channels_maxwell())

Head position estimation (compute_head_pos())

Overlap-add processing for spatio-temporal projections

Smooth interpolation in movement compensation

Certified for clinical use

Extended external basis (eSSS)

Epoch-based movement compensation is described in [1].

Use of Maxwell filtering routines with non-Neuromag systems is currently experimental. Worse results for non-Neuromag systems are expected due to (at least):

Missing fine-calibration and cross-talk cancellation data for other systems.

Processing with reference sensors has not been vetted.

Regularization of components may not work well for all systems.

Coil integration has not been optimized using Abramowitz/Stegun definitions.

Various Maxwell filtering algorithm components are covered by patents owned by MEGIN. These patents include, but may not be limited to:

US2006031038 (Signal Space Separation)

US6876196 (Head position determination)

WO2005067789 (DC fields)

WO2005078467 (MaxShield)

WO2006114473 (Temporal Signal Space Separation)

These patents likely preclude the use of Maxwell filtering code in commercial applications. Consult a lawyer if necessary.

Currently, in order to perform Maxwell filtering, the raw data must not have any projectors applied. During Maxwell filtering, the spatial structure of the data is modified, so projectors are discarded (unless in st_only=True mode).

Samu Taulu and Matti Kajola. Presentation of electromagnetic multichannel data: the signal space separation method. Journal of Applied Physics, 97(12):124905, 2005. doi:10.1063/1.1935742.

Samu Taulu and Juha Simola. Spatiotemporal signal space separation method for rejecting nearby interference in MEG measurements. Physics in Medicine and Biology, 51(7):1759‚Äì1768, 2006. doi:10.1088/0031-9155/51/7/008.

Maxwell filter data with movement compensation

Brainstorm CTF phantom dataset tutorial

Extracting and visualizing subject head movement

Signal-space separation (SSS) and Maxwell filtering

mne.preprocessing.equalize_bads

mne.preprocessing.maxwell_filter_prepare_emptyroom

---

## mne.preprocessing.maxwell_filter_prepare_emptyroom#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.maxwell_filter_prepare_emptyroom.html

**Contents:**
- mne.preprocessing.maxwell_filter_prepare_emptyroom#

Prepare an empty-room recording for Maxwell filtering.

Empty-room data by default lacks certain properties that are required to ensure running maxwell_filter() will process the empty-room recording the same way as the experimental data. This function preconditions an empty-room raw data instance accordingly so it can be used for Maxwell filtering. Please see the Notes section for details.

The empty-room recording. It will not be modified.

The experimental recording, typically this will be the reference run used for Maxwell filtering.

How to populate the list of bad channel names to be injected into the empty-room recording. If 'from_raw' (default) the list of bad channels will be overwritten with that of raw. If 'union', will use the union of bad channels in raw and raw_er. Note that this may lead to additional bad channels in the empty-room in comparison to the experimental recording. If 'keep', don‚Äôt alter the existing list of bad channels.

Non-MEG channels are silently dropped from the list of bads.

Whether to copy the annotations over from raw (default), use the union of the annotations, or to keep them unchanged.

Whether to transfer the measurement date from raw or to keep it as is (default). If you intend to manually transfer annotations from raw after running this function, you should set this to 'from_raw'.

Whether to emit warnings when cropping or omitting annotations. Unlike raw.set_annotations, the default here is False, as empty-room recordings are often shorter than raw.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A copy of the passed empty-room recording, ready for Maxwell filtering.

Compile the list of bad channels according to the bads parameter.

Inject the device-to-head transformation matrix from the experimental recording into the empty-room recording.

Set the following properties of the empty-room recording to match the experimental recording:

Montage (required for the fiducials defining the head coordinate frame)

raw.first_time and raw.first_samp

Adjust annotations according to the annotations parameter.

Adjust the measurement date according to the meas_date parameter.

Note that in case of dual MEG/EEG acquisition, EEG channels should not be included in the empty room recording. If provided, they will be ignored.

mne.preprocessing.maxwell_filter

mne.preprocessing.oversampled_temporal_projection

---

## mne.preprocessing.nirs.beer_lambert_law#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.nirs.beer_lambert_law.html

**Contents:**
- mne.preprocessing.nirs.beer_lambert_law#
- Examples using mne.preprocessing.nirs.beer_lambert_law#

Convert NIRS optical density data to haemoglobin concentration.

The optical density data.

The partial pathlength factors for each wavelength.

Changed in version 1.7: Support for different factors for the two wavelengths.

The modified raw instance.

Preprocessing functional near-infrared spectroscopy (fNIRS) data

mne.preprocessing.nirs.optical_density

mne.preprocessing.nirs.source_detector_distances

---

## mne.preprocessing.nirs.optical_density#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.nirs.optical_density.html

**Contents:**
- mne.preprocessing.nirs.optical_density#
- Examples using mne.preprocessing.nirs.optical_density#

Convert NIRS raw data to optical density.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified raw instance.

Visualise NIRS artifact correction methods

Preprocessing functional near-infrared spectroscopy (fNIRS) data

mne.preprocessing.apply_pca_obs

mne.preprocessing.nirs.beer_lambert_law

---

## mne.preprocessing.nirs.scalp_coupling_index#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.nirs.scalp_coupling_index.html

**Contents:**
- mne.preprocessing.nirs.scalp_coupling_index#
- Examples using mne.preprocessing.nirs.scalp_coupling_index#

Calculate scalp coupling index.

This function calculates the scalp coupling index [1]. This is a measure of the quality of the connection between the optode and the scalp.

For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.

For FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.

Width of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be ‚Äúauto‚Äù (default) to use a multiple of l_freq:

Only used for method='fir'.

Width of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be ‚Äúauto‚Äù (default in 0.14) to use a multiple of h_freq:

Only used for method='fir'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Array containing scalp coupling index for each channel.

Luca Pollonini, Cristen Olds, Homer Abaya, Heather Bortfeld, Michael S Beauchamp, and John S Oghalai. Auditory cortex activation to natural speech and simulated cochlear implant speech measured with functional near-infrared spectroscopy. Hearing Research, 309:84‚Äì93, 2014. doi:10.1016/j.heares.2013.11.007.

Preprocessing functional near-infrared spectroscopy (fNIRS) data

mne.preprocessing.nirs.short_channels

mne.preprocessing.nirs.temporal_derivative_distribution_repair

---

## mne.preprocessing.nirs.short_channels#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.nirs.short_channels.html

**Contents:**
- mne.preprocessing.nirs.short_channels#

Determine which NIRS channels are short.

Channels with a source to detector distance of less than threshold are reported as short. The default threshold is 0.01 m.

The mne.Info object with information about the sensors and methods of measurement.

The threshold distance for what is considered short in meters.

Array indicating which channels are short. Of shape equal to number of channels.

mne.preprocessing.nirs.source_detector_distances

mne.preprocessing.nirs.scalp_coupling_index

---

## mne.preprocessing.nirs.source_detector_distances#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.nirs.source_detector_distances.html

**Contents:**
- mne.preprocessing.nirs.source_detector_distances#
- Examples using mne.preprocessing.nirs.source_detector_distances#

Determine the distance between NIRS source and detectors.

The mne.Info object with information about the sensors and methods of measurement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Array containing distances in meters. Of shape equal to number of channels, or shape of picks if supplied.

Preprocessing functional near-infrared spectroscopy (fNIRS) data

mne.preprocessing.nirs.beer_lambert_law

mne.preprocessing.nirs.short_channels

---

## mne.preprocessing.nirs.temporal_derivative_distribution_repair#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.nirs.temporal_derivative_distribution_repair.html

**Contents:**
- mne.preprocessing.nirs.temporal_derivative_distribution_repair#
- Examples using mne.preprocessing.nirs.temporal_derivative_distribution_repair#

Apply temporal derivative distribution repair to data.

Applies temporal derivative distribution repair (TDDR) to data [1]. This approach removes baseline shift and spike artifacts without the need for any user-supplied parameters.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Data with TDDR applied.

TDDR was initially designed to be used on optical density fNIRS data but has been enabled to be applied on hemoglobin concentration fNIRS data as well in MNE. We recommend applying the algorithm to optical density fNIRS data as intended by the original author wherever possible.

There is a shorter alias mne.preprocessing.nirs.tddr that can be used instead of this function (e.g. if line length is an issue).

Frank A Fishburn, Ruth S Ludlum, Chandan J Vaidya, and Andrei V Medvedev. Temporal derivative distribution repair (tddr): a motion correction method for fNIRS. NeuroImage, 184:171‚Äì179, 2019. doi:10.1016/j.neuroimage.2018.09.025.

Visualise NIRS artifact correction methods

mne.preprocessing.nirs.scalp_coupling_index

mne.preprocessing.ieeg.project_sensors_onto_brain

---

## mne.preprocessing.oversampled_temporal_projection#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.oversampled_temporal_projection.html

**Contents:**
- mne.preprocessing.oversampled_temporal_projection#
- Examples using mne.preprocessing.oversampled_temporal_projection#

Denoise MEG channels using leave-one-out temporal projection.

The window duration (in seconds; default 10.) to use. Can also be ‚Äúmin‚Äù to use as short a window as possible.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

This algorithm is computationally expensive, and can be several times slower than realtime for conventional M/EEG datasets. It uses a leave-one-out procedure with parallel temporal projection to remove individual sensor noise under the assumption that sampled fields (e.g., MEG and EEG) are oversampled by the sensor array [1].

OTP can improve sensor noise levels (especially under visual inspection) and repair some bad channels. This noise reduction is known to interact with tSSS such that increasing the st_correlation value will likely be necessary.

Channels marked as bad will not be used to reconstruct good channels, but good channels will be used to process the bad channels. Depending on the type of noise present in the bad channels, this might make them usable again.

Use of this algorithm is covered by a provisional patent.

Eric Larson and Samu Taulu. Reducing sensor noise in MEG and EEG recordings using oversampled temporal projection. IEEE Transactions on Biomedical Engineering, 65(5):1002‚Äì1013, 2018. doi:10.1109/TBME.2017.2734641.

Plot sensor denoising using oversampled temporal projection

mne.preprocessing.maxwell_filter_prepare_emptyroom

mne.preprocessing.peak_finder

---

## mne.preprocessing.peak_finder#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.peak_finder.html

**Contents:**
- mne.preprocessing.peak_finder#

Noise-tolerant fast peak-finding algorithm.

A real vector from the maxima will be found (required).

The amount above surrounding data for a peak to be identified. Larger values mean the algorithm is more selective in finding peaks. If None, use the default of (max(x0) - min(x0)) / 4.

1 if maxima are desired, -1 if minima are desired (default = maxima, 1).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The indices of the identified peaks in x0.

The magnitude of the identified peaks.

If repeated values are found the first is identified as the peak. Conversion from initial Matlab code from: Nathanael C. Yoder (ncyoder@purdue.edu)

mne.preprocessing.oversampled_temporal_projection

mne.preprocessing.read_ica

---

## mne.preprocessing.read_eog_regression#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.read_eog_regression.html

**Contents:**
- mne.preprocessing.read_eog_regression#

Read an EOG regression model from an HDF5 file.

The file to read the regression model from. Should end in .h5.

The regression model read from the file.

mne.preprocessing.read_ica

mne.preprocessing.realign_raw

---

## mne.preprocessing.read_fine_calibration#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.read_fine_calibration.html

**Contents:**
- mne.preprocessing.read_fine_calibration#

Read fine calibration information from a .dat file.

The fine calibration typically includes improved sensor locations, calibration coefficients, and gradiometer imbalance information.

Fine calibration information. Key-value pairs are:

List of str of the channel names.

Coil location and orientation parameters.

For magnetometers, the calibration coefficients. For gradiometers, one or three imbalance parameters.

mne.preprocessing.read_ica_eeglab

mne.preprocessing.write_fine_calibration

---

## mne.preprocessing.read_ica#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.read_ica.html

**Contents:**
- mne.preprocessing.read_ica#
- Examples using mne.preprocessing.read_ica#

Restore ICA solution from fif file.

Absolute path to fif file containing ICA matrices. The file name should end with -ica.fif or -ica.fif.gz.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Repairing artifacts with ICA

mne.preprocessing.peak_finder

mne.preprocessing.read_eog_regression

---

## mne.preprocessing.read_ica_eeglab#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.read_ica_eeglab.html

**Contents:**
- mne.preprocessing.read_ica_eeglab#

Load ICA information saved in an EEGLAB .set file.

Complete path to a .set EEGLAB file that contains an ICA object.

Units that channel positions are represented in. Defaults to ‚Äúmm‚Äù (millimeters), but can be any prefix + ‚Äúm‚Äù combination (including just ‚Äúm‚Äù for meters).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

An ICA object based on the information contained in the input file.

mne.preprocessing.corrmap

mne.preprocessing.read_fine_calibration

---

## mne.preprocessing.realign_raw#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.realign_raw.html

**Contents:**
- mne.preprocessing.realign_raw#
- Examples using mne.preprocessing.realign_raw#

Realign two simultaneous recordings.

Due to clock drift, recordings at a given same sample rate made by two separate devices simultaneously can become out of sync over time. This function uses event times captured by both acquisition devices to resample other to match raw.

The first raw instance.

The second raw instance. It will be resampled to match raw.

The times of shared events in raw relative to raw.times[0] (0). Typically these could be events on some TTL channel such as:

The times of shared events in other relative to other.times[0].

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

This function operates inplace. It will:

Estimate the zero-order (start offset) and first-order (clock drift) correction.

Crop the start of raw or other, depending on which started recording first.

Resample other to match raw based on the clock drift.

Realign the onsets and durations in other.annotations.

Crop the end of raw or other, depending on which stopped recording first (and the clock drift rate).

This function is primarily designed to work on recordings made at the same sample rate, but it can also operate on recordings made at different sample rates to resample and deal with clock drift simultaneously.

Working with eye tracker data in MNE-Python

mne.preprocessing.read_eog_regression

mne.preprocessing.regress_artifact

---

## mne.preprocessing.regress_artifact#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.regress_artifact.html

**Contents:**
- mne.preprocessing.regress_artifact#
- Examples using mne.preprocessing.regress_artifact#

Remove artifacts using regression based on reference channels.

The instance to process.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

List of channels to exclude from the regression, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù). Specify 'bads' (the default) to exclude all channels marked as bad.

Channel picks to use as predictor/explanatory variables capturing the artifact of interest (default is ‚Äúeog‚Äù).

The regression coefficients to use. If None (default), they will be estimated from the data.

Whether to automatically apply SSP projection vectors before performing the regression. Default is True.

If True (default), copy the instance before modifying it.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The betas used during regression.

To implement the method outlined in [1], remove the evoked response from epochs before estimating the regression coefficients, then apply those regression coefficients to the original data in two calls like (here for a single-condition epochs only):

Gabriele Gratton, Michael G. H Coles, and Emanuel Donchin. A new method for off-line removal of ocular artifact. Electroencephalography and Clinical Neurophysiology, 55(4):468‚Äì484, 1983. doi:10.1016/0013-4694(83)90135-9.

KIT phantom dataset tutorial

mne.preprocessing.realign_raw

mne.preprocessing.corrmap

---

## mne.preprocessing.write_fine_calibration#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.write_fine_calibration.html

**Contents:**
- mne.preprocessing.write_fine_calibration#

Write fine calibration information to a .dat file.

The filename to write out.

Fine calibration information.

mne.preprocessing.read_fine_calibration

mne.preprocessing.apply_pca_obs

---

## mne.preprocessing.Xdawn#

**URL:** https://mne.tools/stable/generated/mne.preprocessing.Xdawn.html

**Contents:**
- mne.preprocessing.Xdawn#
- Examples using mne.preprocessing.Xdawn#

Implementation of the Xdawn Algorithm.

Xdawn [1][2] is a spatial filtering method designed to improve the signal to signal + noise ratio (SSNR) of the ERP responses. Xdawn was originally designed for P300 evoked potential by enhancing the target response with respect to the non-target response. This implementation is a generalization to any type of ERP.

The number of components to decompose the signals.

(default None). The signal covariance used for whitening of the data. if None, the covariance is estimated from the epochs signal.

Compute the independent evoked responses per condition, while correcting for event overlaps if any. If ‚Äòauto‚Äô, then overlapp_correction = True if the events do overlap.

If not None (same as 'empirical', default), allow regularization for covariance estimation. If float, shrinkage is used (0 <= shrinkage <= 1). For str options, reg will be passed as method to mne.compute_covariance().

If fit, the Xdawn components used to decompose the data for each event type, else empty. For each event type, the filters are in the rows of the corresponding array.

If fit, the Xdawn patterns used to restore the signals for each event type, else empty.

If fit, the evoked response for each event type.

Whether overlap correction was applied.

apply(inst[, event_id, include, exclude])

Remove selected components from the signal.

Fit Xdawn from epochs.

fit_transform(X[, y])

Fit to data, then transform it.

get_metadata_routing()

Get metadata routing of this object.

Get parameters for this estimator.

Not implemented, see Xdawn.apply() instead.

set_fit_request(*[, epochs])

Configure whether metadata should be requested to be passed to the fit method.

set_output(*[, transform])

Set output container.

Set the parameters of this estimator.

set_transform_request(*[, inst])

Configure whether metadata should be requested to be passed to the transform method.

Apply Xdawn dim reduction.

Bertrand Rivet, Antoine Souloumiac, Virginie Attina, and Guillaume Gibert. xDAWN algorithm to enhance evoked potentials: application to brain‚Äìcomputer interface. IEEE Transactions on Biomedical Engineering, 56(8):2035‚Äì2043, 2009. doi:10.1109/TBME.2009.2012869.

Bertrand Rivet, Hubert Cecotti, Antoine Souloumiac, Emmanuel Maby, and J√©r√©mie Mattout. Theoretical analysis of xDAWN algorithm: application to an efficient sensor selection in a P300 BCI. In Proceedings of EUSIPCO-2011, 1382‚Äì1386. Barcelona, 2011. IEEE. URL: https://ieeexplore.ieee.org/document/7073970.

Remove selected components from the signal.

Given the unmixing matrix, transform data, zero out components, and inverse transform the data. This procedure will reconstruct the signals from which the dynamics described by the excluded components is subtracted.

The data to be processed.

The kind of event to apply. if None, a dict of inst will be return one for each type of event xdawn has been fitted.

The indices referring to columns in the ummixing matrix. The components to be kept. If None, the first n_components (as defined in the Xdawn constructor) will be kept.

The indices referring to columns in the ummixing matrix. The components to be zeroed out. If None, all the components except the first n_components will be exclude.

A dict of instance (from the same type as inst input) for each event type in event_id.

Examples using apply:

Fit Xdawn from epochs.

An instance of Epoch on which Xdawn filters will be fitted.

If None, used epochs.events[:, 2].

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Not implemented, see Xdawn.apply() instead.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config()). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Metadata routing for epochs parameter in fit.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

‚Äúdefault‚Äù: Default output format of a transformer

‚Äúpandas‚Äù: DataFrame output

‚Äúpolars‚Äù: Polars output

None: Transform configuration is unchanged

New in v1.4: ‚Äúpolars‚Äù option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it‚Äôs possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config()). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Metadata routing for inst parameter in transform.

Apply Xdawn dim reduction.

Data on which Xdawn filters will be applied.

Spatially filtered signals.

mne.preprocessing.ICA

mne.preprocessing.EOGRegression

---

## mne.read_epochs#

**URL:** https://mne.tools/stable/generated/mne.read_epochs.html

**Contents:**
- mne.read_epochs#
- Examples using mne.read_epochs#

Read epochs from a fif file.

The epochs to load. If a filename, should end with -epo.fif or -epo.fif.gz. If a file-like object, preloading must be used.

Apply SSP projection vectors. If proj is ‚Äòdelayed‚Äô and reject is not None the single epochs will be projected before the rejection decision, but used in unprojected state if they are kept. This way deciding which projection vectors are good can be postponed to the evoked stage without resulting in lower epoch counts and without producing results different from early SSP application given comparable parameters. Note that in this case baselining, detrending and temporal decimation will be postponed. If proj is False no projections will be applied which is the recommended value if SSPs are not used for cleaning the data.

If True, read all epochs from disk immediately. If False, epochs will be read on demand.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Analysing continuous features with binning and regression in sensor space

The Epochs data structure: discontinuous data

Working with Epoch metadata

Visualising statistical significance thresholds on EEG data

---

## mne.read_epochs_eeglab#

**URL:** https://mne.tools/stable/generated/mne.read_epochs_eeglab.html

**Contents:**
- mne.read_epochs_eeglab#

Reader function for EEGLAB epochs files.

Path to the .set file. If the data is stored in a separate .fdt file, it is expected to be in the same folder as the .set file.

Path to events file. If array, it is the events typically returned by the read_events function. If some events don‚Äôt match the events of interest as specified by event_id, they will be marked as ‚ÄòIGNORED‚Äô in the drop log. If None, it is constructed from the EEGLAB (.set) file with each unique event encoded with a different integer.

The id of the event to consider. If dict, the keys can later be used to access associated events. Example:

If int, a dict will be created with the id as string. If a list, all events with the IDs specified in the list are used. If None, the event_id is constructed from the EEGLAB (.set) file with each descriptions copied from eventtype.

Names or indices of channels that should be designated EOG channels. If ‚Äòauto‚Äô, the channel names containing EOG or EYE are used. Defaults to empty tuple.

If your set file contains non-ascii characters, sometimes reading it may fail and give rise to error message stating that ‚Äúbuffer is too small‚Äù. uint16_codec allows to specify what codec (for example: ‚Äòlatin1‚Äô or ‚Äòutf-8‚Äô) should be used when reading character arrays and can therefore help you solve this problem.

Units that channel positions are represented in. Defaults to ‚Äúmm‚Äù (millimeters), but can be any prefix + ‚Äúm‚Äù combination (including just ‚Äúm‚Äù for meters).

Changed in version 1.6: Support for 'auto' was added and is the new default.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Documentation of attributes and methods.

mne.read_epochs_fieldtrip

---

## mne.read_epochs_fieldtrip#

**URL:** https://mne.tools/stable/generated/mne.read_epochs_fieldtrip.html

**Contents:**
- mne.read_epochs_fieldtrip#

Load epoched data from a FieldTrip preprocessing structure.

This function expects to find epoched data in the structure data_name is pointing at.

Only epochs with the same amount of channels and samples are supported!

FieldTrip does not normally store the original information concerning channel location, orientation, type etc. It is therefore highly recommended to provide the info field. This can be obtained by reading the original raw data file with MNE functions (without preload). The returned object contains the necessary info field.

Path and filename of the .mat file containing the data.

The info dict of the raw data file corresponding to the data to import. If this is set to None, limited information is extracted from the FieldTrip structure.

Name of heading dict/ variable name under which the data was originally saved in MATLAB.

Column of the trialinfo matrix to use for the event codes.

An EpochsArray containing the loaded data.

mne.read_epochs_eeglab

---

## mne.read_epochs_kit#

**URL:** https://mne.tools/stable/generated/mne.read_epochs_kit.html

**Contents:**
- mne.read_epochs_kit#

Reader function for Ricoh/KIT epochs files.

Path to the SQD file.

The array of events. The first column contains the event time in samples, with first_samp included. The third column contains the event id. If a path, must yield a .txt file containing the events. If some events don‚Äôt match the events of interest as specified by event_id, they will be marked as IGNORED in the drop log.

The id of the events to consider. If dict, the keys can later be used to access associated events. Example: dict(auditory=1, visual=3). If int, a dict will be created with the id as string. If a list of int, all events with the IDs specified in the list are used. If a str or list of str, events must be None to use annotations and then the IDs must be the name(s) of the annotations to use. If None, all events will be used and a dict is created with string integer names corresponding to the event id integers.

Marker points representing the location of the marker coils with respect to the MEG sensors, or path to a marker file. If list, all of the markers will be averaged together.

Digitizer points representing the location of the fiducials and the marker coils with respect to the digitized head shape, or path to a file containing these points.

Digitizer head shape points, or path to head shape file. If more than 10,000 points are in the head shape, they are automatically decimated.

Force reading old data that is not officially supported. Alternatively, read and re-save the data with the KIT MEG Laboratory application.

If True, standardize MEG and EEG channel names to be 'MEG ###' and 'EEG ###'. If False (default), native channel names in the file will be used when possible.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Documentation of attributes and methods.

mne.read_epochs_eeglab

---

## mne.read_evokeds#

**URL:** https://mne.tools/stable/generated/mne.read_evokeds.html

**Contents:**
- mne.read_evokeds#
- Examples using mne.read_evokeds#

Read evoked dataset(s).

The filename, which should end with -ave.fif or -ave.fif.gz.

The index or list of indices of the evoked dataset to read. FIF files can contain multiple datasets. If None, all datasets are returned as a list.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Correction is applied to each channel individually in the following way:

Calculate the mean signal of the baseline period.

Subtract this mean from the entire Evoked.

If None (default), do not apply baseline correction.

Note that if the read Evoked objects have already been baseline-corrected, the data retrieved from disk will always be baseline-corrected (in fact, only the baseline-corrected version of the data will be saved, so there is no way to undo this procedure). Only after the data has been loaded, a custom (additional) baseline correction may be optionally applied by passing a tuple here. Passing None will not remove an existing baseline correction, but merely omit the optional, additional baseline correction.

Either 'average' or 'standard_error', the type of data to read.

If False, available projectors won‚Äôt be applied to the data.

If True, allow loading of data that has been recorded with internal active compensation (MaxShield). Data recorded with MaxShield should generally not be loaded directly, but should first be processed using SSS/tSSS to remove the compensation signals that may also affect brain activity. Can also be "yes" to load without eliciting a warning.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The evoked dataset(s); one Evoked if condition is an integer or string; or a list of Evoked if condition is None or a list.

Changed in version 0.23: If the read Evoked objects had been baseline-corrected before saving, this will be reflected in their baseline attribute after reading.

Compute MNE-dSPM inverse solution on evoked data in volume source space

Source localization with a custom inverse solver

Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method

Generate a functional label from source estimates

Extracting the time series of activations in a label

Compute sparse inverse solution with mixed norm: MxNE and irMxNE

Compute MNE inverse solution on evoked data with a mixed source space

Morph volumetric source estimate

Plot point-spread functions (PSFs) and cross-talk functions (CTFs)

Plot point-spread functions (PSFs) for a volume

Compute Rap-Music on evoked data

Compute spatial resolution metrics in source space

Compute spatial resolution metrics to compare MEG with EEG+MEG

Estimate data SNR using an inverse

Computing source space SNR

Compute MxNE with time-frequency sparse prior

Compute Trap-Music on evoked data

Plotting the full vector-valued MNE solution

Interpolate bad channels for MEG/EEG channels

Interpolate EEG data to any montage

Shifting time-scale in evoked data

Remap MEG channel types

Plotting with mne.viz.Brain

Plotting topographic arrowmaps of evoked data

Plotting topographic maps of evoked data

Plot the MNE brain and helmet

The Evoked data structure: evoked/averaged data

Visualizing Evoked data

Getting started with mne.Report

Source localization with equivalent current dipole (ECD) fit

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Visualize source time courses (stcs)

Make figures more publication ready

Using the event system to link figures

---

## mne.read_evokeds_mff#

**URL:** https://mne.tools/stable/generated/mne.read_evokeds_mff.html

**Contents:**
- mne.read_evokeds_mff#

Read averaged MFF file as EvokedArray or list of EvokedArray.

File path to averaged MFF file. Should end in .mff.

The index (indices) or category (categories) from which to read in data. Averaged MFF files can contain separate averages for different categories. These can be indexed by the block number or the category name. If condition is a list or None, a list of EvokedArray objects is returned.

Channel naming convention for EEG channels. Defaults to ‚ÄòE%d‚Äô (resulting in channel names ‚ÄòE1‚Äô, ‚ÄòE2‚Äô, ‚ÄòE3‚Äô‚Ä¶).

The time interval to apply baseline correction. If None do not apply it. If baseline is (a, b) the interval is between ‚Äúa (s)‚Äù and ‚Äúb (s)‚Äù. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) all the time interval is used. Correction is applied by computing mean of the baseline period and subtracting it from the data. The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The evoked dataset(s); one EvokedArray if condition is int or str, or list of EvokedArray if condition is None or list.

If fname has file extension other than ‚Äò.mff‚Äô.

If the MFF file specified by fname is not averaged.

If no categories.xml file in MFF directory specified by fname.

mne.read_evoked_fieldtrip

mne.read_freesurfer_lut

---

## mne.read_evoked_besa#

**URL:** https://mne.tools/stable/generated/mne.read_evoked_besa.html

**Contents:**
- mne.read_evoked_besa#

Reader function for BESA .avr or .mul files.

When a .elp sidecar file is present, it will be used to determine electrode information.

Path to the .avr or .mul file.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The evoked data in the .avr or .mul file.

mne.read_evoked_fieldtrip

---

## mne.read_evoked_fieldtrip#

**URL:** https://mne.tools/stable/generated/mne.read_evoked_fieldtrip.html

**Contents:**
- mne.read_evoked_fieldtrip#

Load evoked data from a FieldTrip timelocked structure.

This function expects to find timelocked data in the structure data_name is pointing at.

FieldTrip does not normally store the original information concerning channel location, orientation, type etc. It is therefore highly recommended to provide the info field. This can be obtained by reading the original raw data file with MNE functions (without preload). The returned object contains the necessary info field.

Path and filename of the .mat file containing the data.

The info dict of the raw data file corresponding to the data to import. If this is set to None, limited information is extracted from the FieldTrip structure.

Comment on dataset. Can be the condition.

Name of heading dict/ variable name under which the data was originally saved in MATLAB.

An EvokedArray containing the loaded data.

---

## mne.simulation.simulate_evoked#

**URL:** https://mne.tools/stable/generated/mne.simulation.simulate_evoked.html

**Contents:**
- mne.simulation.simulate_evoked#
- Examples using mne.simulation.simulate_evoked#

Generate noisy evoked data.

No projections from info will be present in the output evoked. You can use e.g. evoked.add_proj or evoked.set_eeg_reference to add them afterward as necessary.

The source time courses.

The mne.Info object with information about the sensors and methods of measurement. Used to generate the evoked.

The noise covariance. If None, no noise is added.

Number of averaged epochs (defaults to 30).

IIR filter coefficients (denominator) e.g. [1, -1, 0.2].

A seed for the NumPy random number generator (RNG). If None (default), the seed will be obtained from the operating system (see RandomState for details), meaning it will most likely produce different output every time this function or method is run. To achieve reproducible results, pass a value here to explicitly initialize the RNG with a defined state.

Whether to use cortical patch statistics to define normal orientations for surfaces (default True).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The simulated evoked data.

To make the equivalence between snr and nave, when the snr is given instead of nave:

where actual_snr is the snr to the generated noise before scaling.

Cortical Signal Suppression (CSS) for removal of cortical signals

Generate simulated evoked data

Source localization with equivalent current dipole (ECD) fit

Corrupt known signal with point spread

mne.simulation.add_noise

mne.simulation.simulate_raw

---

## mne.time_frequency.AverageTFR#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.AverageTFR.html

**Contents:**
- mne.time_frequency.AverageTFR#
- Examples using mne.time_frequency.AverageTFR#

Data object for spectrotemporal representations of averaged data.

The preferred means of creating AverageTFR objects is via the instance methods mne.Epochs.compute_tfr() and mne.Evoked.compute_tfr(), or via mne.time_frequency.EpochsTFR.average(). Direct class instantiation is discouraged.

The data from which to compute the time-frequency representation. Passing a dict will create the AverageTFR using the __setstate__ interface and is not recommended for typical use cases.

The frequencies in Hz.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [1]. None (the default) only works when using __setstate__ and will raise an error otherwise.

The frequencies at which to compute the power estimates. Must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

Comment on the data, e.g., the experimental condition(s)averaged.Default is None which is replaced with inst.comment (for Evoked instances) or a comma-separated string representation of the keys in inst.event_id (for Epochs instances).

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet() and tfr_array_multitaper() for additional details.

Start and end of the baseline period (in seconds).

Comment on the data, e.g., the experimental condition(s) averaged.

The frequencies at which power estimates were computed.

The mne.Info object with information about the sensors and methods of measurement.

The method used to compute the time-frequency power estimates.

The number of epochs that were averaged to yield the result. This may reflect epochs averaged before time-frequency analysis (as in epochs.average(...).compute_tfr(...)) or after time-frequency analysis (as in epochs.compute_tfr(...).average(...)).

Sampling frequency of the data.

The weights used for each taper in the time-frequency estimates.

Add two TFR instances.

__contains__(ch_type)

Check channel type membership.

Multiply a TFR instance by a scalar.

Subtract two TFR instances.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

apply_baseline(baseline[, mode, verbose])

Baseline correct the data.

Return copy of the TFR instance.

crop([tmin, tmax, fmin, fmax, include_tmax])

Crop data to a given time interval in place.

decimate(decim[, offset, verbose])

Decimate the time-series data.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, tmin, ...])

Get time-frequency data in NumPy array format.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, exclude, tmin, tmax, fmin, ...])

Plot TFRs as two-dimensional time-frequency images.

plot_joint(*[, timefreqs, picks, exclude, ...])

Plot TFRs as a two-dimensional image with topomap highlights.

plot_topo([picks, baseline, mode, tmin, ...])

Plot a TFR image for each channel in a sensor layout arrangement.

plot_topomap([tmin, tmax, fmin, fmax, ...])

Plot topographic maps of specific time-frequency intervals of TFR data.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save time-frequency data to disk (in HDF5 format).

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, long_format, ...])

Export data in tabular structure as a pandas DataFrame.

The old API (prior to version 1.7) was:

That API is still available via AverageTFRArray for cases where the data are precomputed or do not originate from MNE-Python objects. The preferred new API uses instance methods:

The new API also supports AverageTFR instantiation from a dict, but this is primarily for save/load and internal purposes, and wraps __setstate__. During the transition from the old to the new API, it may be expedient to use AverageTFRArray as a ‚Äúquick-fix‚Äù approach to updating scripts under active development.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371‚Äì1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Add two TFR instances.

The TFR instance to add. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Multiply a TFR instance by a scalar.

The number to multiply by.

A new TFR instance, of the same type as self.

Subtract two TFR instances.

The TFR instance to subtract. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Baseline correct the data.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Start and end of the baseline period (in seconds).

The current gradient compensation grade.

Return copy of the TFR instance.

A copy of the object.

Crop data to a given time interval in place.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Lowest frequency of selection in Hz.

Highest frequency of selection in Hz.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The modified instance.

The time-frequency-resolved power estimates.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / ‚Äúdecimation‚Äù refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [2], p. 172; which cites [3]):

‚Äú‚Ä¶ a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).‚Äù

Hence ‚Äúdecimation‚Äù in MNE is what is considered ‚Äúcompression‚Äù in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

The frequencies at which power estimates were computed.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get time-frequency data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Whether to return the time values for the requested time range. Default is False.

Whether to return the frequency bin values for the requested frequency range. Default is False.

Whether to return the taper numbers. Default is False.

The requested data in a NumPy array.

The time values for the requested data range. Only returned if return_times is True.

The frequency values for the requested data range. Only returned if return_freqs is True.

The taper numbers. Only returned if return_tapers is True. Will be None if a taper dimension is not present in the data.

Returns a copy of the underlying data (not a view).

The method used to compute the time-frequency power estimates.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot TFRs as two-dimensional time-frequency images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

How to aggregate across channels. If None, plot one figure per selected channel. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to None.

Changed in version 1.3: Added support for callable.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Whether to add a colorbar to the plot. Default is True.

Title for the plot. If "auto", will use the channel name (if combine is None) or state the number and method of combined channels used to generate the plot. If None, no title is shown. Default is None.

An array of boolean values, of the same shape as the data. Data that corresponds to False entries in the mask are plotted differently, as determined by mask_style, mask_alpha, and mask_cmap. Useful for, e.g., highlighting areas of statistical significance.

How to distinguish the masked/unmasked regions of the plot. If "contour", a line is drawn around the areas where the mask is True. If "mask", areas where the mask is False will be (partially) transparent, as determined by mask_alpha. If "both", both a contour and transparency are used. Default is None, which is silently ignored if mask is None and is interpreted like "both" otherwise.

Colormap to use for masked areas of the plot. If a str, must be a valid Matplotlib colormap name. If None, cmap is used for both masked and unmasked areas. Ignored if mask is None. Default is 'Greys'.

Relative opacity of the masked region versus the unmasked region, given as a float between 0 and 1 (i.e., 0 means masked areas are not visible at all). Defaults to 0.1.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of picks. If combine is not None, axes must either be an instance of Axes, or a list of length 1. Default is None.

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of figures containing the time-frequency power.

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Overview of MEG/EEG analysis with MNE-Python

Frequency and time-frequency sensor analysis

Plot TFRs as a two-dimensional image with topomap highlights.

The time-frequency point(s) for which topomaps will be plotted. See Notes.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any). Default is an empty tuple which includes all channels.

How to aggregate across channels. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to "mean".

Changed in version 1.3: Added support for callable.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. To specify the colormap separately for the topomap annotations, see topomap_args. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

Whether to add a colorbar to the plot (for the topomap annotations). Not compatible with user-defined axes. Default is True.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

Keyword arguments to pass to mne.viz.plot_topomap(). axes and show are ignored. If times is not in this dict, automatic peak detection is used. Beyond that, if None, no customizable arguments will be passed. Defaults to None (i.e., an empty dict).

Keyword arguments to pass to mne.time_frequency.AverageTFR.plot(). axes and show are ignored. Defaults to None (i.e., and empty dict).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

timefreqs has three different modes: tuples, dicts, and auto. For (list of) tuple(s) mode, each tuple defines a pair (time, frequency) in s and Hz on the TFR plot. For example, to look at 10 Hz activity 1 second into the epoch and 3 Hz activity 300 ms into the epoch,

If provided as a dictionary, (time, frequency) tuples are keys and (time_window, frequency_window) tuples are the values ‚Äî indicating the width of the windows (centered on the time and frequency indicated by the key) to be averaged over. For example,

would translate into a window that spans 0.95 to 1.05 seconds and 9 to 11 Hz. If None, a single topomap will be plotted at the absolute peak across the time-frequency representation.

Examples using plot_joint:

Frequency and time-frequency sensor analysis

Plot a TFR image for each channel in a sensor layout arrangement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

Lower and upper bounds of the colormap, in the same units as the data. If vmin and vmax are both None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0). If only one of vmin, vmax is None, will use min(data) or max(data), respectively.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

The title of the generated figure. If None (default), no title is displayed.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

Whether to add a colorbar to the plot. Default is True.

Scaling factor for adjusting the relative size of the layout on the canvas.

Show the figure if True.

Matplotlib border style to be used for each sensor plot.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

Examples using plot_topo:

Frequency and time-frequency sensor analysis

Plot topographic maps of specific time-frequency intervals of TFR data.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The time interval to apply rescaling / baseline correction. If None do not apply it. If baseline is (a, b) the interval is between ‚Äúa (s)‚Äù and ‚Äúb (s)‚Äù. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) the whole time interval is used.

Perform baseline correction by

subtracting the mean baseline power (‚Äòmean‚Äô)

dividing by the mean baseline power (‚Äòratio‚Äô)

dividing by the mean baseline power and taking the log (‚Äòlogratio‚Äô)

subtracting the mean baseline power followed by dividing by the mean baseline power (‚Äòpercent‚Äô)

subtracting the mean baseline power and dividing by the standard deviation of the baseline power (‚Äòzscore‚Äô)

dividing by the mean baseline power, taking the log, and dividing by the standard deviation of the baseline power (‚Äòzlogratio‚Äô)

If None no baseline correction is applied.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created. Default is None.

Show the figure if True.

The figure containing the topography.

Examples using plot_topomap:

Frequency and time-frequency sensor analysis

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save time-frequency data to disk (in HDF5 format).

Path of file to save to, which should end with -tfr.h5 or -tfr.hdf5.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Sampling frequency of the data.

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

The time points present in the data (in seconds).

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, additional columns 'time', 'freq', 'taper', 'epoch', and 'condition' (epoch event description) are added, unless index is not None (in which case the columns specified in index will be used to form the DataFrame‚Äôs index instead). 'epoch', and 'condition' are not supported for AverageTFR. 'taper' is only supported when a taper dimensions is present, such as for complex or phase multitaper data.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). If a list of two or more string values, a pandas.MultiIndex will be created. Valid string values are 'time', 'freq', 'taper', 'epoch', and 'condition' for EpochsTFR and 'time', 'freq', and 'taper' for AverageTFR. Defaults to None.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point, channel, epoch number, and condition. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

The weights used for each taper in the time-frequency estimates.

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Compute and visualize ERDS maps

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Overview of MEG/EEG analysis with MNE-Python

Frequency and time-frequency sensor analysis

mne.time_frequency.AverageTFRArray

---

## mne.time_frequency.BaseTFR#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.BaseTFR.html

**Contents:**
- mne.time_frequency.BaseTFR#
- Examples using mne.time_frequency.BaseTFR#

Base class for RawTFR, EpochsTFR, and AverageTFR (for type checking only).

This class should not be instantiated directly; it is provided in the public API only for type-checking purposes (e.g., isinstance(my_obj, BaseTFR)). To create TFR objects, use the .compute_tfr() methods on Raw, Epochs, or Evoked, or use the constructors listed below under ‚ÄúSee Also‚Äù.

The data from which to compute the time-frequency representation.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [1]. None (the default) only works when using __setstate__ and will raise an error otherwise.

The frequencies at which to compute the power estimates. Must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Whether to omit bad spans of data before spectrotemporal power estimation. If True, spans with annotations whose description begins with bad will be represented with np.nan in the time-frequency representation.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet() and tfr_array_multitaper() for additional details.

Start and end of the baseline period (in seconds).

The current gradient compensation grade.

The time-frequency-resolved power estimates.

The frequencies at which power estimates were computed.

The method used to compute the time-frequency power estimates.

Sampling frequency of the data.

The time points present in the data (in seconds).

The weights used for each taper in the time-frequency estimates.

Add two TFR instances.

__contains__(ch_type)

Check channel type membership.

Multiply a TFR instance by a scalar.

Subtract two TFR instances.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

apply_baseline(baseline[, mode, verbose])

Baseline correct the data.

Return copy of the TFR instance.

crop([tmin, tmax, fmin, fmax, include_tmax])

Crop data to a given time interval in place.

decimate(decim[, offset, verbose])

Decimate the time-series data.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, tmin, ...])

Get time-frequency data in NumPy array format.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, exclude, tmin, tmax, fmin, ...])

Plot TFRs as two-dimensional time-frequency images.

plot_joint(*[, timefreqs, picks, exclude, ...])

Plot TFRs as a two-dimensional image with topomap highlights.

plot_topo([picks, baseline, mode, tmin, ...])

Plot a TFR image for each channel in a sensor layout arrangement.

plot_topomap([tmin, tmax, fmin, fmax, ...])

Plot topographic maps of specific time-frequency intervals of TFR data.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save time-frequency data to disk (in HDF5 format).

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, long_format, ...])

Export data in tabular structure as a pandas DataFrame.

Add two TFR instances.

The TFR instance to add. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Multiply a TFR instance by a scalar.

The number to multiply by.

A new TFR instance, of the same type as self.

Subtract two TFR instances.

The TFR instance to subtract. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Baseline correct the data.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Examples using apply_baseline:

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

Start and end of the baseline period (in seconds).

The current gradient compensation grade.

Return copy of the TFR instance.

A copy of the object.

Crop data to a given time interval in place.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Lowest frequency of selection in Hz.

Highest frequency of selection in Hz.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The modified instance.

Compute source level time-frequency timecourses using a DICS beamformer

Compute and visualize ERDS maps

Non-parametric 1 sample cluster statistic on single trial power

The time-frequency-resolved power estimates.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / ‚Äúdecimation‚Äù refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [2], p. 172; which cites [3]):

‚Äú‚Ä¶ a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).‚Äù

Hence ‚Äúdecimation‚Äù in MNE is what is considered ‚Äúcompression‚Äù in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371‚Äì1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

The frequencies at which power estimates were computed.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get time-frequency data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Whether to return the time values for the requested time range. Default is False.

Whether to return the frequency bin values for the requested frequency range. Default is False.

Whether to return the taper numbers. Default is False.

The requested data in a NumPy array.

The time values for the requested data range. Only returned if return_times is True.

The frequency values for the requested data range. Only returned if return_freqs is True.

The taper numbers. Only returned if return_tapers is True. Will be None if a taper dimension is not present in the data.

Returns a copy of the underlying data (not a view).

The method used to compute the time-frequency power estimates.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot TFRs as two-dimensional time-frequency images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

How to aggregate across channels. If None, plot one figure per selected channel. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to None.

Changed in version 1.3: Added support for callable.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Whether to add a colorbar to the plot. Default is True.

Title for the plot. If "auto", will use the channel name (if combine is None) or state the number and method of combined channels used to generate the plot. If None, no title is shown. Default is None.

An array of boolean values, of the same shape as the data. Data that corresponds to False entries in the mask are plotted differently, as determined by mask_style, mask_alpha, and mask_cmap. Useful for, e.g., highlighting areas of statistical significance.

How to distinguish the masked/unmasked regions of the plot. If "contour", a line is drawn around the areas where the mask is True. If "mask", areas where the mask is False will be (partially) transparent, as determined by mask_alpha. If "both", both a contour and transparency are used. Default is None, which is silently ignored if mask is None and is interpreted like "both" otherwise.

Colormap to use for masked areas of the plot. If a str, must be a valid Matplotlib colormap name. If None, cmap is used for both masked and unmasked areas. Ignored if mask is None. Default is 'Greys'.

Relative opacity of the masked region versus the unmasked region, given as a float between 0 and 1 (i.e., 0 means masked areas are not visible at all). Defaults to 0.1.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of picks. If combine is not None, axes must either be an instance of Axes, or a list of length 1. Default is None.

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of figures containing the time-frequency power.

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Overview of MEG/EEG analysis with MNE-Python

Frequency and time-frequency sensor analysis

Plot TFRs as a two-dimensional image with topomap highlights.

The time-frequency point(s) for which topomaps will be plotted. See Notes.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any). Default is an empty tuple which includes all channels.

How to aggregate across channels. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to "mean".

Changed in version 1.3: Added support for callable.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. To specify the colormap separately for the topomap annotations, see topomap_args. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

Whether to add a colorbar to the plot (for the topomap annotations). Not compatible with user-defined axes. Default is True.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

Keyword arguments to pass to mne.viz.plot_topomap(). axes and show are ignored. If times is not in this dict, automatic peak detection is used. Beyond that, if None, no customizable arguments will be passed. Defaults to None (i.e., an empty dict).

Keyword arguments to pass to mne.time_frequency.AverageTFR.plot(). axes and show are ignored. Defaults to None (i.e., and empty dict).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

timefreqs has three different modes: tuples, dicts, and auto. For (list of) tuple(s) mode, each tuple defines a pair (time, frequency) in s and Hz on the TFR plot. For example, to look at 10 Hz activity 1 second into the epoch and 3 Hz activity 300 ms into the epoch,

If provided as a dictionary, (time, frequency) tuples are keys and (time_window, frequency_window) tuples are the values ‚Äî indicating the width of the windows (centered on the time and frequency indicated by the key) to be averaged over. For example,

would translate into a window that spans 0.95 to 1.05 seconds and 9 to 11 Hz. If None, a single topomap will be plotted at the absolute peak across the time-frequency representation.

Examples using plot_joint:

Frequency and time-frequency sensor analysis

Plot a TFR image for each channel in a sensor layout arrangement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

Lower and upper bounds of the colormap, in the same units as the data. If vmin and vmax are both None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0). If only one of vmin, vmax is None, will use min(data) or max(data), respectively.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

The title of the generated figure. If None (default), no title is displayed.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

Whether to add a colorbar to the plot. Default is True.

Scaling factor for adjusting the relative size of the layout on the canvas.

Show the figure if True.

Matplotlib border style to be used for each sensor plot.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

Examples using plot_topo:

Frequency and time-frequency sensor analysis

Plot topographic maps of specific time-frequency intervals of TFR data.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The time interval to apply rescaling / baseline correction. If None do not apply it. If baseline is (a, b) the interval is between ‚Äúa (s)‚Äù and ‚Äúb (s)‚Äù. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) the whole time interval is used.

Perform baseline correction by

subtracting the mean baseline power (‚Äòmean‚Äô)

dividing by the mean baseline power (‚Äòratio‚Äô)

dividing by the mean baseline power and taking the log (‚Äòlogratio‚Äô)

subtracting the mean baseline power followed by dividing by the mean baseline power (‚Äòpercent‚Äô)

subtracting the mean baseline power and dividing by the standard deviation of the baseline power (‚Äòzscore‚Äô)

dividing by the mean baseline power, taking the log, and dividing by the standard deviation of the baseline power (‚Äòzlogratio‚Äô)

If None no baseline correction is applied.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created. Default is None.

Show the figure if True.

The figure containing the topography.

Examples using plot_topomap:

Frequency and time-frequency sensor analysis

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save time-frequency data to disk (in HDF5 format).

Path of file to save to, which should end with -tfr.h5 or -tfr.hdf5.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Sampling frequency of the data.

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

The time points present in the data (in seconds).

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, additional columns 'time', 'freq', 'taper', 'epoch', and 'condition' (epoch event description) are added, unless index is not None (in which case the columns specified in index will be used to form the DataFrame‚Äôs index instead). 'epoch', and 'condition' are not supported for AverageTFR. 'taper' is only supported when a taper dimensions is present, such as for complex or phase multitaper data.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). If a list of two or more string values, a pandas.MultiIndex will be created. Valid string values are 'time', 'freq', 'taper', 'epoch', and 'condition' for EpochsTFR and 'time', 'freq', and 'taper' for AverageTFR. Defaults to None.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point, channel, epoch number, and condition. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Examples using to_data_frame:

Compute and visualize ERDS maps

The weights used for each taper in the time-frequency estimates.

Decoding in time-frequency space using Common Spatial Patterns (CSP)

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

mne.time_frequency.AverageTFRArray

mne.time_frequency.EpochsTFR

---

## mne.time_frequency.EpochsSpectrumArray#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.EpochsSpectrumArray.html

**Contents:**
- mne.time_frequency.EpochsSpectrumArray#
- Examples using mne.time_frequency.EpochsSpectrumArray#

Data object for precomputed epoched spectral data (in NumPy array format).

The spectra for each channel in each epoch.

The mne.Info object with information about the sensors and methods of measurement.

The frequencies in Hz.

The identity and timing of experimental events, around which the epochs were created. See events for more information.Events that don‚Äôt match the events of interest as specified by event_id will be marked as IGNORED in the drop log.

The id of the events to consider. If dict, the keys can later be used to access associated events. Example: dict(auditory=1, visual=3). If int, a dict will be created with the id as string. If a list of int, all events with the IDs specified in the list are used. If a str or list of str, events must be None to use annotations and then the IDs must be the name(s) of the annotations to use. If None, all events will be used and a dict is created with string integer names corresponding to the event id integers.

The name of the dimensions in the data, in the order they occur. Must contain 'channel' and 'freq'; if data are unaggregated estimates, also include either a 'segment' (e.g., Welch-like algorithms) or 'taper' (e.g., multitaper algorithms) dimension. If including 'taper', you should also pass a weights parameter.

Weights for the 'taper' dimension, if present (see dim_names).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The current gradient compensation grade.

__contains__(ch_type)

Check channel type membership.

Subselect epochs from an EpochsSpectrum.

Facilitate iteration over epochs.

Return the number of epochs.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

Average the spectra across epochs.

Return copy of the Spectrum instance.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, ...])

Get spectrum data in NumPy array format.

next([return_event_id])

Iterate over epoch data.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot(*[, picks, average, dB, amplitude, ...])

Plot power or amplitude spectra.

plot_topo(*[, dB, layout, color, ...])

Plot power spectral density, separately for each channel.

plot_topomap([bands, ch_type, normalize, ...])

Plot scalp topography of PSD for chosen frequency bands.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save spectrum data to disk (in HDF5 format).

to_data_frame([picks, index, copy, ...])

Export data in tabular structure as a pandas DataFrame.

Get the spectrum units for each channel type.

If the data passed in is real-valued, it is assumed to represent spectral power (not amplitude, phase, etc), and downstream methods (such as plot()) assume power data. If you pass in real-valued data that is not power, axis labels will be incorrect.

If the data passed in is complex-valued, it is assumed to represent Fourier coefficients. Downstream plotting methods will treat the data as such, attempting to convert this to power before visualisation. If you pass in complex-valued data that is not Fourier coefficients, axis labels will be incorrect.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Subselect epochs from an EpochsSpectrum.

Access options are the same as for Epochs objects, see the docstring of mne.Epochs.__getitem__() for explanation.

Facilitate iteration over epochs.

This method resets the object iteration state to the first epoch.

This enables the use of this Python pattern:

Where epoch is given by successive outputs of mne.Epochs.next().

Return the number of epochs.

The number of remaining epochs.

This function only works if bad epochs have been dropped.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Average the spectra across epochs.

How to aggregate spectra across epochs. If callable, must take a NumPy array of shape (n_epochs, n_channels, n_freqs) and return an array of shape (n_channels, n_freqs). Default is 'mean'.

The aggregated spectrum object.

The current gradient compensation grade.

Return copy of the Spectrum instance.

A copy of the object.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get spectrum data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

Whether to return the frequency bin values for the requested frequency range. Default is False.

The requested data in a NumPy array.

The frequency values for the requested range. Only returned if return_freqs is True.

Iterate over epoch data.

If True, return both the epoch data and an event_id.

The event id. Only returned if return_event_id is True.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (‚ïé) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (‚ãÆ). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Changed in version 1.5: In version 1.5, the default behavior changed so that all data channels (not just ‚Äúgood‚Äù data channels) are shown by default.

Whether to average across channels before plotting. If True, interactive plotting of scalp topography is disabled, and parameters ci and ci_alpha control the style of the confidence band around the mean. Default is False.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz), or 20 √ó log‚ÇÅ‚ÇÄ(spectral amplitude/‚àöHz) if amplitude=True.

Whether to plot an amplitude spectrum (True) or power spectrum (False).

Changed in version 1.8: In version 1.8, the default changed to amplitude=False.

Scale of the frequency axis. Default is 'linear'.

Type of confidence band drawn around the mean when average=True. If 'sd' the band spans ¬±1 standard deviation across channels. If 'range' the band spans the range across channels at each frequency. If a float, it indicates the (bootstrapped) confidence interval to display, and must satisfy 0 < ci <= 100. If None, no band is drawn. Default is sd.

Opacity of the confidence band. Must satisfy 0 <= ci_alpha <= 1. Default is 0.3.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Opacity of the spectrum line(s). If float, must satisfy 0 <= alpha <= 1. If None, opacity will be 1 when average=True and 0.1 when average=False. Default is None.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

Changed in version 1.5: In version 1.5, the default behavior changed from exclude='bads' to exclude=().

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

Figure with spectra plotted in separate subplots for each channel type.

Plot power spectral density, separately for each channel.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‚Äò%0.3f‚Äô if dB=False and ‚Äò%0.1f‚Äô if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

Figure showing one scalp topography per frequency band.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save spectrum data to disk (in HDF5 format).

Path of file to save to.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, an additional column ‚Äúfreq‚Äù is added, unless index='freq' (in which case frequency values form the DataFrame‚Äôs index).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If a str, a pandas.Index will be used (see Notes). If a list of two or more string values, a pandas.MultiIndex will be used. Defaults to None.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of frequency and channel. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Valid values for index depend on whether the Spectrum was created from continuous data (Raw, Evoked) or discontinuous data (Epochs). For continuous data, only None or 'freq' is supported. For discontinuous data, additional valid values are 'epoch' and 'condition', or a list comprising some of the valid string values (e.g., ['freq', 'epoch']).

Get the spectrum units for each channel type.

Whether to format the unit strings as LaTeX. Default is False.

Mapping from channel type to a string representation of the units for that channel type.

Creating MNE-Python data structures from scratch

mne.time_frequency.EpochsSpectrum

mne.time_frequency.combine_spectrum

---

## mne.time_frequency.EpochsSpectrum#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.EpochsSpectrum.html

**Contents:**
- mne.time_frequency.EpochsSpectrum#
- Examples using mne.time_frequency.EpochsSpectrum#

Data object for spectral representations of epoched data.

The preferred means of creating Spectrum objects from Epochs is via the instance method mne.Epochs.compute_psd(). Direct class instantiation is not supported.

The data from which to compute the frequency spectrum.

Spectral estimation method. 'welch' uses Welch‚Äôs method [1], 'multitaper' uses DPSS tapers [2].

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

Whether to apply SSP projection vectors before spectral estimation. Default is False.

If True, the mean is subtracted from each segment before computing its spectrum.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details. Note that for Welch method if n_fft is unspecified its default will be the smaller of 2048 or the number of available time samples (taking into account tmin and tmax), not 256 as in psd_array_welch().

Frequencies at which the amplitude, power, or fourier coefficients have been computed.

The mne.Info object with information about the sensors and methods of measurement.

The method used to compute the spectrum.

The weights for each taper. Only present if spectra computed with method='multitaper' and output='complex'.

__contains__(ch_type)

Check channel type membership.

Subselect epochs from an EpochsSpectrum.

Facilitate iteration over epochs.

Return the number of epochs.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

Average the spectra across epochs.

Return copy of the Spectrum instance.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, ...])

Get spectrum data in NumPy array format.

next([return_event_id])

Iterate over epoch data.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot(*[, picks, average, dB, amplitude, ...])

Plot power or amplitude spectra.

plot_topo(*[, dB, layout, color, ...])

Plot power spectral density, separately for each channel.

plot_topomap([bands, ch_type, normalize, ...])

Plot scalp topography of PSD for chosen frequency bands.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save spectrum data to disk (in HDF5 format).

to_data_frame([picks, index, copy, ...])

Export data in tabular structure as a pandas DataFrame.

Get the spectrum units for each channel type.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70‚Äì73, 1967. doi:10.1109/TAU.1967.1161901.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371‚Äì1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Subselect epochs from an EpochsSpectrum.

Access options are the same as for Epochs objects, see the docstring of mne.Epochs.__getitem__() for explanation.

Facilitate iteration over epochs.

This method resets the object iteration state to the first epoch.

This enables the use of this Python pattern:

Where epoch is given by successive outputs of mne.Epochs.next().

Return the number of epochs.

The number of remaining epochs.

This function only works if bad epochs have been dropped.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Average the spectra across epochs.

How to aggregate spectra across epochs. If callable, must take a NumPy array of shape (n_epochs, n_channels, n_freqs) and return an array of shape (n_channels, n_freqs). Default is 'mean'.

The aggregated spectrum object.

Examples using average:

Frequency and time-frequency sensor analysis

The current gradient compensation grade.

Return copy of the Spectrum instance.

A copy of the object.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get spectrum data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

Whether to return the frequency bin values for the requested frequency range. Default is False.

The requested data in a NumPy array.

The frequency values for the requested range. Only returned if return_freqs is True.

Examples using get_data:

Sleep stage classification from polysomnography (PSG) data

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

Iterate over epoch data.

If True, return both the epoch data and an event_id.

The event id. Only returned if return_event_id is True.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot power or amplitude spectra.

Separate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (‚ïé) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (‚ãÆ). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Changed in version 1.5: In version 1.5, the default behavior changed so that all data channels (not just ‚Äúgood‚Äù data channels) are shown by default.

Whether to average across channels before plotting. If True, interactive plotting of scalp topography is disabled, and parameters ci and ci_alpha control the style of the confidence band around the mean. Default is False.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz), or 20 √ó log‚ÇÅ‚ÇÄ(spectral amplitude/‚àöHz) if amplitude=True.

Whether to plot an amplitude spectrum (True) or power spectrum (False).

Changed in version 1.8: In version 1.8, the default changed to amplitude=False.

Scale of the frequency axis. Default is 'linear'.

Type of confidence band drawn around the mean when average=True. If 'sd' the band spans ¬±1 standard deviation across channels. If 'range' the band spans the range across channels at each frequency. If a float, it indicates the (bootstrapped) confidence interval to display, and must satisfy 0 < ci <= 100. If None, no band is drawn. Default is sd.

Opacity of the confidence band. Must satisfy 0 <= ci_alpha <= 1. Default is 0.3.

A matplotlib-compatible color to use. Has no effect when spatial_colors=True.

Opacity of the spectrum line(s). If float, must satisfy 0 <= alpha <= 1. If None, opacity will be 1 when average=True and 0.1 when average=False. Default is None.

Whether to color spectrum lines by channel location. Ignored if average=True.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

Changed in version 1.5: In version 1.5, the default behavior changed from exclude='bads' to exclude=().

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

Figure with spectra plotted in separate subplots for each channel type.

Sleep stage classification from polysomnography (PSG) data

Visualizing epoched data

Plot power spectral density, separately for each channel.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz).

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

A matplotlib-compatible color to use for the curves. Defaults to white.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A matplotlib-compatible color to use for the axis background. Defaults to black.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.

Whether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.

Show the figure if True.

Figure distributing one image per channel across sensor topography.

Plot scalp topography of PSD for chosen frequency bands.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‚Äò%0.3f‚Äô if dB=False and ‚Äò%0.1f‚Äô if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

Figure showing one scalp topography per frequency band.

Examples using plot_topomap:

Visualizing epoched data

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save spectrum data to disk (in HDF5 format).

Path of file to save to.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, an additional column ‚Äúfreq‚Äù is added, unless index='freq' (in which case frequency values form the DataFrame‚Äôs index).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If a str, a pandas.Index will be used (see Notes). If a list of two or more string values, a pandas.MultiIndex will be used. Defaults to None.

If True, data will be copied. Otherwise data may be modified in place. Defaults to True.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of frequency and channel. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Valid values for index depend on whether the Spectrum was created from continuous data (Raw, Evoked) or discontinuous data (Epochs). For continuous data, only None or 'freq' is supported. For discontinuous data, additional valid values are 'epoch' and 'condition', or a list comprising some of the valid string values (e.g., ['freq', 'epoch']).

Get the spectrum units for each channel type.

Whether to format the unit strings as LaTeX. Default is False.

Mapping from channel type to a string representation of the units for that channel type.

Sleep stage classification from polysomnography (PSG) data

Visualizing epoched data

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency and time-frequency sensor analysis

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

mne.time_frequency.SpectrumArray

mne.time_frequency.EpochsSpectrumArray

---

## mne.time_frequency.EpochsTFRArray#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.EpochsTFRArray.html

**Contents:**
- mne.time_frequency.EpochsTFRArray#
- Examples using mne.time_frequency.EpochsTFRArray#

Data object for precomputed spectrotemporal representations of epoched data.

The mne.Info object with information about the sensors and methods of measurement.

The time values in seconds.

The frequencies in Hz.

Comment on the data, e.g., the experimental condition(s).

Comment on the method used to compute the data, e.g., "hilbert". Default is None.

The identity and timing of experimental events, around which the epochs were created. See events for more information.If None, all integer event codes are set to 1 (i.e., all epochs are assumed to be of the same type) and their corresponding sample numbers are set as arbitrary, equally spaced sample numbers with a step size of len(times).

Mapping from condition descriptions (strings) to integer event codes.If None, all events in events will be included, and the event_id attribute will be a dict mapping a string version of each integer event ID to the corresponding integer.

Iterable of indices of selected epochs. If None, will be automatically generated, corresponding to all non-zero events.

Tuple of tuple of strings indicating which epochs have been marked to be ignored.

A pandas.DataFrame specifying metadata about each epoch. If not None, len(metadata) must equal len(events). For save/load compatibility, the DataFrame may only contain str, int, float, and bool values. If not None, then pandas-style queries may be used to select subsets of data, see mne.Epochs.__getitem__(). When the EpochsTFR object is subsetted, the metadata is subsetted accordingly, and the row indices will be modified to match EpochsTFR.selection.

The weights for each taper. Must be provided if data has a taper dimension, such as for complex or phase multitaper data.

Start and end of the baseline period (in seconds).

Comment on the data, e.g., the experimental condition(s).

Tuple of tuple of strings indicating which epochs have been marked to be ignored.

Mapping from condition descriptions (strings) to integer event codes.

The frequencies at which power estimates were computed.

The mne.Info object with information about the sensors and methods of measurement.

The method used to compute the time-frequency power estimates.

Array of indices of selected epochs (i.e., epochs that were not rejected, dropped, or ignored).

Sampling frequency of the data.

The weights used for each taper in the time-frequency estimates.

Add two TFR instances.

__contains__(ch_type)

Check channel type membership.

Subselect epochs from an EpochsTFR.

Facilitate iteration over epochs.

Return the number of epochs.

Multiply a TFR instance by a scalar.

Subtract two TFR instances.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

apply_baseline(baseline[, mode, verbose])

Baseline correct the data.

average([method, dim, copy])

Aggregate the EpochsTFR across epochs, frequencies, or times.

Return copy of the TFR instance.

crop([tmin, tmax, fmin, fmax, include_tmax])

Crop data to a given time interval in place.

decimate(decim[, offset, verbose])

Decimate the time-series data.

drop(indices[, reason, verbose])

Drop epochs based on indices or boolean mask.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, tmin, ...])

Get time-frequency data in NumPy array format.

Iterate over EpochsTFR to yield a sequence of AverageTFR objects.

next([return_event_id])

Iterate over epoch data.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, exclude, tmin, tmax, fmin, ...])

Plot TFRs as two-dimensional time-frequency images.

plot_joint(*[, timefreqs, picks, exclude, ...])

Plot TFRs as a two-dimensional image with topomap highlights.

plot_topo([picks, baseline, mode, tmin, ...])

Plot a TFR image for each channel in a sensor layout arrangement.

plot_topomap([tmin, tmax, fmin, fmax, ...])

Plot topographic maps of specific time-frequency intervals of TFR data.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save time-frequency data to disk (in HDF5 format).

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, long_format, ...])

Export data in tabular structure as a pandas DataFrame.

Add two TFR instances.

The TFR instance to add. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Subselect epochs from an EpochsTFR.

Access options are the same as for Epochs objects, see the docstring Notes section of mne.Epochs.__getitem__() for explanation.

The selected time-frequency data. Shape will be (n_epochs, n_channels, n_freqs, n_times) for Morlet, Stockwell, and aggregated (output='power') multitaper methods, or (n_epochs, n_channels, n_tapers, n_freqs, n_times) for unaggregated (output='complex') multitaper method.

Facilitate iteration over epochs.

This method resets the object iteration state to the first epoch.

This enables the use of this Python pattern:

Where epoch is given by successive outputs of mne.Epochs.next().

Return the number of epochs.

The number of remaining epochs.

This function only works if bad epochs have been dropped.

Multiply a TFR instance by a scalar.

The number to multiply by.

A new TFR instance, of the same type as self.

Subtract two TFR instances.

The TFR instance to subtract. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Baseline correct the data.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Aggregate the EpochsTFR across epochs, frequencies, or times.

How to aggregate the data across the given dim. If callable, must take a NumPy array of shape (n_epochs, n_channels, n_freqs, n_times) and return an array with one fewer dimensions (which dimension is collapsed depends on the value of dim). Default is "mean".

The dimension along which to combine the data.

Whether to return a copy of the modified instance, or modify in place. Ignored when dim="epochs" or "times" because those options return different types (AverageTFR and EpochsSpectrum, respectively).

The aggregated TFR object.

Passing in np.median is considered unsafe for complex data; pass the string "median" instead to compute the marginal median (i.e. the median of the real and imaginary components separately). See discussion here:

Averaging is not supported for data containing a taper dimension.

Start and end of the baseline period (in seconds).

The current gradient compensation grade.

Return copy of the TFR instance.

A copy of the object.

Crop data to a given time interval in place.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Lowest frequency of selection in Hz.

Highest frequency of selection in Hz.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The modified instance.

The time-frequency-resolved power estimates.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / ‚Äúdecimation‚Äù refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [1], p. 172; which cites [2]):

‚Äú‚Ä¶ a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).‚Äù

Hence ‚Äúdecimation‚Äù in MNE is what is considered ‚Äúcompression‚Äù in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Drop epochs based on indices or boolean mask.

The indices refer to the current set of undropped epochs rather than the complete set of dropped and undropped epochs. They are therefore not necessarily consistent with any external indices (e.g., behavioral logs). To drop epochs based on external criteria, do not use the preload=True flag when constructing an Epochs object, and call this method before calling the mne.Epochs.drop_bad() or mne.Epochs.load_data() methods.

Set epochs to remove by specifying indices to remove or a boolean mask to apply (where True values get removed). Events are correspondingly modified.

Reason for dropping the epochs (‚ÄòECG‚Äô, ‚Äòtimeout‚Äô, ‚Äòblink‚Äô etc). Default: ‚ÄòUSER‚Äô.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs with indices dropped. Operates in-place.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

The frequencies at which power estimates were computed.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get time-frequency data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Whether to return the time values for the requested time range. Default is False.

Whether to return the frequency bin values for the requested frequency range. Default is False.

Whether to return the taper numbers. Default is False.

The requested data in a NumPy array.

The time values for the requested data range. Only returned if return_times is True.

The frequency values for the requested data range. Only returned if return_freqs is True.

The taper numbers. Only returned if return_tapers is True. Will be None if a taper dimension is not present in the data.

Returns a copy of the underlying data (not a view).

Iterate over EpochsTFR to yield a sequence of AverageTFR objects.

The AverageTFR objects will each contain a single epoch (i.e., no averaging is performed). This method resets the EpochTFR instance‚Äôs iteration state to the first epoch.

Whether to yield copies of the data and measurement info, or views/pointers.

The method used to compute the time-frequency power estimates.

Iterate over epoch data.

If True, return both the epoch data and an event_id.

The event id. Only returned if return_event_id is True.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot TFRs as two-dimensional time-frequency images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

How to aggregate across channels. If None, plot one figure per selected channel. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to None.

Changed in version 1.3: Added support for callable.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Whether to add a colorbar to the plot. Default is True.

Title for the plot. If "auto", will use the channel name (if combine is None) or state the number and method of combined channels used to generate the plot. If None, no title is shown. Default is None.

An array of boolean values, of the same shape as the data. Data that corresponds to False entries in the mask are plotted differently, as determined by mask_style, mask_alpha, and mask_cmap. Useful for, e.g., highlighting areas of statistical significance.

How to distinguish the masked/unmasked regions of the plot. If "contour", a line is drawn around the areas where the mask is True. If "mask", areas where the mask is False will be (partially) transparent, as determined by mask_alpha. If "both", both a contour and transparency are used. Default is None, which is silently ignored if mask is None and is interpreted like "both" otherwise.

Colormap to use for masked areas of the plot. If a str, must be a valid Matplotlib colormap name. If None, cmap is used for both masked and unmasked areas. Ignored if mask is None. Default is 'Greys'.

Relative opacity of the masked region versus the unmasked region, given as a float between 0 and 1 (i.e., 0 means masked areas are not visible at all). Defaults to 0.1.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of picks. If combine is not None, axes must either be an instance of Axes, or a list of length 1. Default is None.

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of figures containing the time-frequency power.

Plot TFRs as a two-dimensional image with topomap highlights.

The time-frequency point(s) for which topomaps will be plotted. See Notes.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any). Default is an empty tuple which includes all channels.

How to aggregate across channels. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to "mean".

Changed in version 1.3: Added support for callable.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. To specify the colormap separately for the topomap annotations, see topomap_args. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

Whether to add a colorbar to the plot (for the topomap annotations). Not compatible with user-defined axes. Default is True.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

Keyword arguments to pass to mne.viz.plot_topomap(). axes and show are ignored. If times is not in this dict, automatic peak detection is used. Beyond that, if None, no customizable arguments will be passed. Defaults to None (i.e., an empty dict).

Keyword arguments to pass to mne.time_frequency.AverageTFR.plot(). axes and show are ignored. Defaults to None (i.e., and empty dict).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

timefreqs has three different modes: tuples, dicts, and auto. For (list of) tuple(s) mode, each tuple defines a pair (time, frequency) in s and Hz on the TFR plot. For example, to look at 10 Hz activity 1 second into the epoch and 3 Hz activity 300 ms into the epoch,

If provided as a dictionary, (time, frequency) tuples are keys and (time_window, frequency_window) tuples are the values ‚Äî indicating the width of the windows (centered on the time and frequency indicated by the key) to be averaged over. For example,

would translate into a window that spans 0.95 to 1.05 seconds and 9 to 11 Hz. If None, a single topomap will be plotted at the absolute peak across the time-frequency representation.

Plot a TFR image for each channel in a sensor layout arrangement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

Lower and upper bounds of the colormap, in the same units as the data. If vmin and vmax are both None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0). If only one of vmin, vmax is None, will use min(data) or max(data), respectively.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

The title of the generated figure. If None (default), no title is displayed.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

Whether to add a colorbar to the plot. Default is True.

Scaling factor for adjusting the relative size of the layout on the canvas.

Show the figure if True.

Matplotlib border style to be used for each sensor plot.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

Plot topographic maps of specific time-frequency intervals of TFR data.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The time interval to apply rescaling / baseline correction. If None do not apply it. If baseline is (a, b) the interval is between ‚Äúa (s)‚Äù and ‚Äúb (s)‚Äù. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) the whole time interval is used.

Perform baseline correction by

subtracting the mean baseline power (‚Äòmean‚Äô)

dividing by the mean baseline power (‚Äòratio‚Äô)

dividing by the mean baseline power and taking the log (‚Äòlogratio‚Äô)

subtracting the mean baseline power followed by dividing by the mean baseline power (‚Äòpercent‚Äô)

subtracting the mean baseline power and dividing by the standard deviation of the baseline power (‚Äòzscore‚Äô)

dividing by the mean baseline power, taking the log, and dividing by the standard deviation of the baseline power (‚Äòzlogratio‚Äô)

If None no baseline correction is applied.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created. Default is None.

Show the figure if True.

The figure containing the topography.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save time-frequency data to disk (in HDF5 format).

Path of file to save to, which should end with -tfr.h5 or -tfr.hdf5.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Sampling frequency of the data.

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

The time points present in the data (in seconds).

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, additional columns 'time', 'freq', 'taper', 'epoch', and 'condition' (epoch event description) are added, unless index is not None (in which case the columns specified in index will be used to form the DataFrame‚Äôs index instead). 'epoch', and 'condition' are not supported for AverageTFR. 'taper' is only supported when a taper dimensions is present, such as for complex or phase multitaper data.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). If a list of two or more string values, a pandas.MultiIndex will be created. Valid string values are 'time', 'freq', 'taper', 'epoch', and 'condition' for EpochsTFR and 'time', 'freq', and 'taper' for AverageTFR. Defaults to None.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point, channel, epoch number, and condition. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

The weights used for each taper in the time-frequency estimates.

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

mne.time_frequency.EpochsTFR

mne.time_frequency.RawTFR

---

## mne.time_frequency.EpochsTFR#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.EpochsTFR.html

**Contents:**
- mne.time_frequency.EpochsTFR#
- Examples using mne.time_frequency.EpochsTFR#

Data object for spectrotemporal representations of epoched data.

The preferred means of creating EpochsTFR objects from Epochs objects is via the instance method compute_tfr(). To create an EpochsTFR object from pre-computed data (i.e., a NumPy array) use EpochsTFRArray.

The data from which to compute the time-frequency representation.

The frequencies at which to compute the power estimates. If method='stockwell' this must be a length 2 iterable specifying lowest and highest frequencies, or 'auto' (to use all available frequencies). For other methods, must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.

Spectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers [1], and 'stockwell' uses the S-transform [2][3][4][5]. None (the default) only works when using __setstate__ and will raise an error otherwise.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to apply SSP projection vectors before spectral estimation. Default is False.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Additional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet() and tfr_array_multitaper() for additional details.

Start and end of the baseline period (in seconds).

Comment on the data, e.g., the experimental condition(s).

Tuple of tuple of strings indicating which epochs have been marked to be ignored.

Mapping from condition descriptions (strings) to integer event codes.

The frequencies at which power estimates were computed.

The mne.Info object with information about the sensors and methods of measurement.

The method used to compute the time-frequency power estimates.

Array of indices of selected epochs (i.e., epochs that were not rejected, dropped, or ignored).

Sampling frequency of the data.

The weights used for each taper in the time-frequency estimates.

Add two TFR instances.

__contains__(ch_type)

Check channel type membership.

Subselect epochs from an EpochsTFR.

Facilitate iteration over epochs.

Return the number of epochs.

Multiply a TFR instance by a scalar.

Subtract two TFR instances.

add_channels(add_list[, force_update_info])

Append new channels from other MNE objects to the instance.

add_reference_channels(ref_channels)

Add reference channels to data that consists of all zeros.

apply_baseline(baseline[, mode, verbose])

Baseline correct the data.

average([method, dim, copy])

Aggregate the EpochsTFR across epochs, frequencies, or times.

Return copy of the TFR instance.

crop([tmin, tmax, fmin, fmax, include_tmax])

Crop data to a given time interval in place.

decimate(decim[, offset, verbose])

Decimate the time-series data.

drop(indices[, reason, verbose])

Drop epochs based on indices or boolean mask.

drop_channels(ch_names[, on_missing])

get_channel_types([picks, unique, only_data_chs])

Get a list of channel type for each channel.

get_data([picks, exclude, fmin, fmax, tmin, ...])

Get time-frequency data in NumPy array format.

Iterate over EpochsTFR to yield a sequence of AverageTFR objects.

next([return_event_id])

Iterate over epoch data.

pick(picks[, exclude, verbose])

Pick a subset of channels.

pick_channels(ch_names[, ordered, verbose])

pick_types([meg, eeg, stim, eog, ecg, emg, ...])

plot([picks, exclude, tmin, tmax, fmin, ...])

Plot TFRs as two-dimensional time-frequency images.

plot_joint(*[, timefreqs, picks, exclude, ...])

Plot TFRs as a two-dimensional image with topomap highlights.

plot_topo([picks, baseline, mode, tmin, ...])

Plot a TFR image for each channel in a sensor layout arrangement.

plot_topomap([tmin, tmax, fmin, fmax, ...])

Plot topographic maps of specific time-frequency intervals of TFR data.

reorder_channels(ch_names)

save(fname, *[, overwrite, verbose])

Save time-frequency data to disk (in HDF5 format).

shift_time(tshift[, relative])

Shift time scale in epoched or evoked data.

time_as_index(times[, use_rounding])

Convert time to indices.

to_data_frame([picks, index, long_format, ...])

Export data in tabular structure as a pandas DataFrame.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371‚Äì1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

R. G. Stockwell. Why use the S-transform? In Luigi Rodino, Bert-Wolfgang Schulze, and M. W. Wong, editors, Pseudo-Differential Operators: Partial Differential Equations and Time-Frequency Analysis, number 52 in Fields Institute Communications, pages 279‚Äì309. American Mathematical Society, Providence, RI, 2007. doi:10.1090/fic/052.

Ali Moukadem, Zied Bouguila, Djaffar Ould Abdeslam, and Alain Dieterlen. Stockwell transform optimization applied on the detection of split in heart sounds. In Proceedings of EUSIPCO-2014, 2015‚Äì2019. Lisbon, 2014. IEEE. URL: https://ieeexplore.ieee.org/document/6952743.

Katherine L. Wheat, Piers L. Cornelissen, Stephen J. Frost, and Peter C. Hansen. During visual word recognition, phonology is accessed within 100 ms and may be mediated by a speech production code: evidence from magnetoencephalography. Journal of Neuroscience, 30(15):5229‚Äì5233, 2010. doi:10.1523/JNEUROSCI.4448-09.2010.

Kevin A. Jones, Bernice Porjesz, David Chorlian, Madhavi Rangaswamy, Chella Kamarajan, Ajayan Padmanabhapillai, Arthur Stimus, and Henri Begleiter. S-transform time-frequency analysis of P300 reveals deficits in individuals diagnosed with alcoholism. Clinical Neurophysiology, 117(10):2128‚Äì2143, 2006. doi:10.1016/j.clinph.2006.02.028.

Add two TFR instances.

The TFR instance to add. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Check channel type membership.

Channel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.

Whether or not the instance contains the given channel type.

Channel type membership can be tested as:

Subselect epochs from an EpochsTFR.

Access options are the same as for Epochs objects, see the docstring Notes section of mne.Epochs.__getitem__() for explanation.

The selected time-frequency data. Shape will be (n_epochs, n_channels, n_freqs, n_times) for Morlet, Stockwell, and aggregated (output='power') multitaper methods, or (n_epochs, n_channels, n_tapers, n_freqs, n_times) for unaggregated (output='complex') multitaper method.

Facilitate iteration over epochs.

This method resets the object iteration state to the first epoch.

This enables the use of this Python pattern:

Where epoch is given by successive outputs of mne.Epochs.next().

Return the number of epochs.

The number of remaining epochs.

This function only works if bad epochs have been dropped.

Multiply a TFR instance by a scalar.

The number to multiply by.

A new TFR instance, of the same type as self.

Subtract two TFR instances.

The TFR instance to subtract. Must have the same type as self, and matching .times and .freqs attributes.

A new TFR instance, of the same type as self.

Append new channels from other MNE objects to the instance.

A list of MNE objects to append to the current instance. The channels contained in the other instances are appended to the channels of the current instance. Therefore, all other instances must be of the same type as the current object. See notes on how to add data coming from an array.

If True, force the info for objects to be appended to match the values of the current instance. This should generally only be used when adding stim channels for which important metadata won‚Äôt be overwritten.

The modified instance.

If self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.

This function expects an MNE object to be appended (e.g. Raw, Epochs, Evoked). If you simply want to add a channel based on values of an np.ndarray, you need to create a RawArray. See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_

Add reference channels to data that consists of all zeros.

Adds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.

Name of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.

The modified instance.

Baseline correct the data.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Examples using apply_baseline:

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

Aggregate the EpochsTFR across epochs, frequencies, or times.

How to aggregate the data across the given dim. If callable, must take a NumPy array of shape (n_epochs, n_channels, n_freqs, n_times) and return an array with one fewer dimensions (which dimension is collapsed depends on the value of dim). Default is "mean".

The dimension along which to combine the data.

Whether to return a copy of the modified instance, or modify in place. Ignored when dim="epochs" or "times" because those options return different types (AverageTFR and EpochsSpectrum, respectively).

The aggregated TFR object.

Passing in np.median is considered unsafe for complex data; pass the string "median" instead to compute the marginal median (i.e. the median of the real and imaginary components separately). See discussion here:

Averaging is not supported for data containing a taper dimension.

Examples using average:

Compute and visualize ERDS maps

Start and end of the baseline period (in seconds).

The current gradient compensation grade.

Return copy of the TFR instance.

A copy of the object.

Crop data to a given time interval in place.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Lowest frequency of selection in Hz.

Highest frequency of selection in Hz.

If True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).

The modified instance.

Compute source level time-frequency timecourses using a DICS beamformer

Compute and visualize ERDS maps

Non-parametric 1 sample cluster statistic on single trial power

The time-frequency-resolved power estimates.

Decimate the time-series data.

Factor by which to subsample the data.

Low-pass filtering is not performed, this simply selects every Nth sample (where N is the value passed to decim), i.e., it compresses the signal (see Notes). If the data are not properly filtered, aliasing artifacts may occur. See Resampling and decimating data for more information.

Apply an offset to where the decimation starts relative to the sample corresponding to t=0. The offset is in samples at the current sampling rate.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The decimated object.

For historical reasons, decim / ‚Äúdecimation‚Äù refers to simply subselecting samples from a given signal. This contrasts with the broader signal processing literature, where decimation is defined as (quoting [6], p. 172; which cites [7]):

‚Äú‚Ä¶ a general system for downsampling by a factor of M is the one shown in Figure 4.23. Such a system is called a decimator, and downsampling by lowpass filtering followed by compression [i.e, subselecting samples] has been termed decimation (Crochiere and Rabiner, 1983).‚Äù

Hence ‚Äúdecimation‚Äù in MNE is what is considered ‚Äúcompression‚Äù in the signal processing community.

Decimation can be done multiple times. For example, inst.decimate(2).decimate(2) will be the same as inst.decimate(4).

If decim is 1, this method does not copy the underlying data.

Alan V. Oppenheim, Ronald W. Schafer, and John R. Buck. Discrete-Time Signal Processing. Prentice Hall, Upper Saddle River, NJ, 2 edition edition, 1999. ISBN 978-0-13-754920-7.

Ronald E. Crochiere and Lawrence R. Rabiner. Multirate Digital Signal Processing. Pearson, Englewood Cliffs, NJ, 1 edition edition, 1983. ISBN 978-0-13-605162-6.

Drop epochs based on indices or boolean mask.

The indices refer to the current set of undropped epochs rather than the complete set of dropped and undropped epochs. They are therefore not necessarily consistent with any external indices (e.g., behavioral logs). To drop epochs based on external criteria, do not use the preload=True flag when constructing an Epochs object, and call this method before calling the mne.Epochs.drop_bad() or mne.Epochs.load_data() methods.

Set epochs to remove by specifying indices to remove or a boolean mask to apply (where True values get removed). Events are correspondingly modified.

Reason for dropping the epochs (‚ÄòECG‚Äô, ‚Äòtimeout‚Äô, ‚Äòblink‚Äô etc). Default: ‚ÄòUSER‚Äô.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The epochs with indices dropped. Operates in-place.

Iterable (e.g. list) of channel name(s) or channel name to remove.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.

The modified instance.

The frequencies at which power estimates were computed.

Get a list of channel type for each channel.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Whether to return only unique channel types. Default is False.

Whether to ignore non-data channels. Default is False.

Get time-frequency data in NumPy array format.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Whether to return the time values for the requested time range. Default is False.

Whether to return the frequency bin values for the requested frequency range. Default is False.

Whether to return the taper numbers. Default is False.

The requested data in a NumPy array.

The time values for the requested data range. Only returned if return_times is True.

The frequency values for the requested data range. Only returned if return_freqs is True.

The taper numbers. Only returned if return_tapers is True. Will be None if a taper dimension is not present in the data.

Returns a copy of the underlying data (not a view).

Iterate over EpochsTFR to yield a sequence of AverageTFR objects.

The AverageTFR objects will each contain a single epoch (i.e., no averaging is performed). This method resets the EpochTFR instance‚Äôs iteration state to the first epoch.

Whether to yield copies of the data and measurement info, or views/pointers.

The method used to compute the time-frequency power estimates.

Iterate over epoch data.

If True, return both the epoch data and an event_id.

The event id. Only returned if return_event_id is True.

Pick a subset of channels.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Set of channels to exclude, only used when picking based on types (e.g., exclude=‚Äùbads‚Äù when picks=‚Äùmeg‚Äù).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

LEGACY: New code should use inst.pick(‚Ä¶).

The list of channels to select.

If True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.

Changed in version 1.7: The default changed from False in 1.6 to True in 1.7.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

If ordered is False, the channel names given via ch_names are assumed to be a set, that is, their order does not matter. In that case, the original order of the channels in the data is preserved. Apart from using ordered=True, you may also use reorder_channels to set channel order, if necessary.

LEGACY: New code should use inst.pick(‚Ä¶).

Pick some channels by type and names.

If True include MEG channels. If string it can be ‚Äòmag‚Äô, ‚Äògrad‚Äô, ‚Äòplanar1‚Äô or ‚Äòplanar2‚Äô to select only magnetometers, all gradiometers, or a specific type of gradiometer.

If True include EEG channels.

If True include stimulus channels.

If True include EOG channels.

If True include ECG channels.

If True include EMG channels.

If True include CTF / 4D reference channels. If ‚Äòauto‚Äô, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.

If True include miscellaneous analog channels.

If True include respiratory channels.

If True include continuous HPI coil channels.

Flux excitation channel used to be a stimulus channel.

Internal Active Shielding data (maybe on Triux only).

System status channel information (on Triux systems only).

Stereotactic EEG channels.

Dipole time course channels.

Dipole goodness of fit channels.

Electrocorticography channels.

Functional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‚Äòhbo‚Äô (to include channels measuring oxyhemoglobin) or ‚Äòhbr‚Äô (to include channels measuring deoxyhemoglobin).

Deep brain stimulation channels.

Temperature channels.

Galvanic skin response channels.

Eyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‚Äòeyegaze‚Äô (to include eye position channels) or ‚Äòpupil‚Äô (to include pupil-size channels).

List of additional channels to include. If empty do not include any.

List of channels to exclude. If ‚Äòbads‚Äô (default), exclude channels in info['bads'].

Restrict sensor channels (MEG, EEG, etc.) to this list of channel names.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The modified instance.

Plot TFRs as two-dimensional time-frequency images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude from being drawn. If 'bads', channels in spectrum.info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any).

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

How to aggregate across channels. If None, plot one figure per selected channel. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to None.

Changed in version 1.3: Added support for callable.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Whether to add a colorbar to the plot. Default is True.

Title for the plot. If "auto", will use the channel name (if combine is None) or state the number and method of combined channels used to generate the plot. If None, no title is shown. Default is None.

An array of boolean values, of the same shape as the data. Data that corresponds to False entries in the mask are plotted differently, as determined by mask_style, mask_alpha, and mask_cmap. Useful for, e.g., highlighting areas of statistical significance.

How to distinguish the masked/unmasked regions of the plot. If "contour", a line is drawn around the areas where the mask is True. If "mask", areas where the mask is False will be (partially) transparent, as determined by mask_alpha. If "both", both a contour and transparency are used. Default is None, which is silently ignored if mask is None and is interpreted like "both" otherwise.

Colormap to use for masked areas of the plot. If a str, must be a valid Matplotlib colormap name. If None, cmap is used for both masked and unmasked areas. Ignored if mask is None. Default is 'Greys'.

Relative opacity of the masked region versus the unmasked region, given as a float between 0 and 1 (i.e., 0 means masked areas are not visible at all). Defaults to 0.1.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of picks. If combine is not None, axes must either be an instance of Axes, or a list of length 1. Default is None.

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A list of figures containing the time-frequency power.

Plot TFRs as a two-dimensional image with topomap highlights.

The time-frequency point(s) for which topomaps will be plotted. See Notes.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including ‚Äúbad‚Äù channels, if any). Default is an empty tuple which includes all channels.

How to aggregate across channels. If a string, "mean" uses numpy.mean(), "rms" computes the root-mean-square. If callable(), it must operate on an array of shape (n_channels, n_freqs, n_times) and return an array of shape (n_freqs, n_times). Defaults to "mean".

Changed in version 1.3: Added support for callable.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. To specify the colormap separately for the topomap annotations, see topomap_args. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

Whether to add a colorbar to the plot (for the topomap annotations). Not compatible with user-defined axes. Default is True.

The title of the generated figure. If None (default), no title is displayed.

Show the figure if True.

Keyword arguments to pass to mne.viz.plot_topomap(). axes and show are ignored. If times is not in this dict, automatic peak detection is used. Beyond that, if None, no customizable arguments will be passed. Defaults to None (i.e., an empty dict).

Keyword arguments to pass to mne.time_frequency.AverageTFR.plot(). axes and show are ignored. Defaults to None (i.e., and empty dict).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

timefreqs has three different modes: tuples, dicts, and auto. For (list of) tuple(s) mode, each tuple defines a pair (time, frequency) in s and Hz on the TFR plot. For example, to look at 10 Hz activity 1 second into the epoch and 3 Hz activity 300 ms into the epoch,

If provided as a dictionary, (time, frequency) tuples are keys and (time_window, frequency_window) tuples are the values ‚Äî indicating the width of the windows (centered on the time and frequency indicated by the key) to be averaged over. For example,

would translate into a window that spans 0.95 to 1.05 seconds and 9 to 11 Hz. If None, a single topomap will be plotted at the absolute peak across the time-frequency representation.

Plot a TFR image for each channel in a sensor layout arrangement.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

The time interval to consider as ‚Äúbaseline‚Äù when applying baseline correction. If None, do not apply baseline correction. If a tuple (a, b), the interval is between a and b (in seconds), including the endpoints. If a is None, the beginning of the data is used; and if b is None, it is set to the end of the data. If (None, None), the entire time interval is used.

The baseline (a, b) includes both endpoints, i.e. all timepoints t such that a <= t <= b.

How baseline is computed is determined by the mode parameter.

Perform baseline correction by

subtracting the mean of baseline values (‚Äòmean‚Äô) (default)

dividing by the mean of baseline values (‚Äòratio‚Äô)

dividing by the mean of baseline values and taking the log (‚Äòlogratio‚Äô)

subtracting the mean of baseline values followed by dividing by the mean of baseline values (‚Äòpercent‚Äô)

subtracting the mean of baseline values and dividing by the standard deviation of baseline values (‚Äòzscore‚Äô)

dividing by the mean of baseline values, taking the log, and dividing by the standard deviation of log baseline values (‚Äòzlogratio‚Äô)

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is None which is equivalent to fmin=0, fmax=np.inf (spans all frequencies present in the data).

Lower and upper bounds of the colormap, in the same units as the data. If vmin and vmax are both None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0). If only one of vmin, vmax is None, will use min(data) or max(data), respectively.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).

The Colormap to use. If a str, must be a valid Matplotlib colormap name. Default is "RdBu_r".

The title of the generated figure. If None (default), no title is displayed.

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(data).

Whether to add a colorbar to the plot. Default is True.

Scaling factor for adjusting the relative size of the layout on the canvas.

Show the figure if True.

Matplotlib border style to be used for each sensor plot.

A matplotlib-compatible color to use for the figure background. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

The scale of the y (frequency) axis. ‚Äòlinear‚Äô gives linear y axis, ‚Äòlog‚Äô gives log-spaced y axis and ‚Äòauto‚Äô detects if frequencies are log-spaced and if so sets the y axis to ‚Äòlog‚Äô. Default is ‚Äòauto‚Äô.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure containing the topography.

Plot topographic maps of specific time-frequency intervals of TFR data.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

The lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The time interval to apply rescaling / baseline correction. If None do not apply it. If baseline is (a, b) the interval is between ‚Äúa (s)‚Äù and ‚Äúb (s)‚Äù. If a is None the beginning of the data is used and if b is None then b is set to the end of the interval. If baseline is equal to (None, None) the whole time interval is used.

Perform baseline correction by

subtracting the mean baseline power (‚Äòmean‚Äô)

dividing by the mean baseline power (‚Äòratio‚Äô)

dividing by the mean baseline power and taking the log (‚Äòlogratio‚Äô)

subtracting the mean baseline power followed by dividing by the mean baseline power (‚Äòpercent‚Äô)

subtracting the mean baseline power and dividing by the standard deviation of the baseline power (‚Äòzscore‚Äô)

dividing by the mean baseline power, taking the log, and dividing by the standard deviation of the baseline power (‚Äòzlogratio‚Äô)

If None no baseline correction is applied.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. If both entries are None, the bounds are set at (min(data), max(data)). Providing None for just one entry will set the corresponding boundary at the min/max of the data. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created. Default is None.

Show the figure if True.

The figure containing the topography.

The desired channel order.

The modified instance.

Channel names must be unique. Channels that are not in ch_names are dropped.

Save time-frequency data to disk (in HDF5 format).

Path of file to save to, which should end with -tfr.h5 or -tfr.hdf5.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Sampling frequency of the data.

Shift time scale in epoched or evoked data.

The (absolute or relative) time shift in seconds. If relative is True, positive tshift increases the time value associated with each sample, while negative tshift decreases it.

If True, increase or decrease time values by tshift seconds. Otherwise, shift the time values such that the time of the first sample equals tshift.

The modified instance.

This method allows you to shift the time values associated with each data sample by an arbitrary amount. It does not resample the signal or change the data values in any way.

Convert time to indices.

List of numbers or a number representing points in time.

If True, use rounding (instead of truncation) when converting times to indices. This can help avoid non-unique indices.

Indices corresponding to the times supplied.

The time points present in the data (in seconds).

Export data in tabular structure as a pandas DataFrame.

Channels are converted to columns in the DataFrame. By default, additional columns 'time', 'freq', 'taper', 'epoch', and 'condition' (epoch event description) are added, unless index is not None (in which case the columns specified in index will be used to form the DataFrame‚Äôs index instead). 'epoch', and 'condition' are not supported for AverageTFR. 'taper' is only supported when a taper dimensions is present, such as for complex or phase multitaper data.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Kind of index to use for the DataFrame. If None, a sequential integer index (pandas.RangeIndex) will be used. If 'time', a pandas.Index or pandas.TimedeltaIndex will be used (depending on the value of time_format). If a list of two or more string values, a pandas.MultiIndex will be created. Valid string values are 'time', 'freq', 'taper', 'epoch', and 'condition' for EpochsTFR and 'time', 'freq', and 'taper' for AverageTFR. Defaults to None.

If True, the DataFrame is returned in long format where each row is one observation of the signal at a unique combination of time point, channel, epoch number, and condition. For convenience, a ch_type column is added to facilitate subsetting the resulting DataFrame. Defaults to False.

Desired time format. If None, no conversion is applied, and time values remain as float values in seconds. If 'ms', time values will be rounded to the nearest millisecond and converted to integers. If 'timedelta', time values will be converted to pandas.Timedelta values. Default is None unless specified otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

A dataframe suitable for usage with other statistical/plotting/analysis packages.

Examples using to_data_frame:

Compute and visualize ERDS maps

The weights used for each taper in the time-frequency estimates.

Compute source level time-frequency timecourses using a DICS beamformer

Compute and visualize ERDS maps

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

mne.time_frequency.BaseTFR

mne.time_frequency.EpochsTFRArray

---

## mne.time_frequency.tfr_array_multitaper#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.tfr_array_multitaper.html

**Contents:**
- mne.time_frequency.tfr_array_multitaper#

Compute Time-Frequency Representation (TFR) using DPSS tapers.

Same computation as tfr_multitaper, but operates on NumPy arrays instead of Epochs or Evoked objects.

Sampling frequency of the data in Hz.

The frequencies in Hz.

Number of cycles in the wavelet, either a fixed number or one per frequency. The number of cycles n_cycles and the frequencies of interest freqs define the temporal window length. See notes for additional information about the relationship between those arguments and about time and frequency smoothing.

If True, make sure the wavelets have a mean of zero. Defaults to True.

Product between the temporal window length (in seconds) and the full frequency bandwidth (in Hz). This product can be seen as the surface of the window on the time/frequency plane and controls the frequency bandwidth (thus the frequency resolution) and the number of good tapers. See notes for additional information.

Use the FFT for convolutions or not. Defaults to True.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

'complex' : single trial per taper complex values.

'power' : single trial power.

'phase' : single trial per taper phase.

'avg_power' : average of single trial power.

'itc' : inter-trial coherence.

'avg_power_itc' : average of single trial power and inter-trial coherence across trials.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. The parallelization is implemented across channels.

If True, return the taper weights. Only applies if output='complex' or 'phase'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Time frequency transform of data.

if output in ('complex',' 'phase'), array of shape (n_epochs, n_chans, n_tapers, n_freqs, n_times)

if output is 'power', array of shape (n_epochs, n_chans, n_freqs, n_times)

else, array of shape (n_chans, n_freqs, n_times)

If output is 'avg_power_itc', the real values in out contain the average power and the imaginary values contain the inter-trial coherence: \(out = power_{avg} + i * ITC\).

The taper weights. Only returned if output='complex' or 'phase' and return_weights=True.

In spectrotemporal analysis (as with traditional fourier methods), the temporal and spectral resolution are interrelated: longer temporal windows allow more precise frequency estimates; shorter temporal windows ‚Äúsmear‚Äù frequency estimates while providing more precise timing information.

Time-frequency representations are computed using a sliding temporal window. Either the temporal window has a fixed length independent of frequency, or the temporal window decreases in length with increased frequency.

Figure: Time and frequency smoothing. (a) For a fixed length temporal window the time and frequency smoothing remains fixed. (b) For temporal windows that decrease with frequency, the temporal smoothing decreases and the frequency smoothing increases with frequency. Source: FieldTrip tutorial: Time-frequency analysis using Hanning window, multitapers and wavelets.

In MNE-Python, the multitaper temporal window length is defined by the arguments freqs and n_cycles, respectively defining the frequencies of interest and the number of cycles: \(T = \frac{\mathtt{n\_cycles}}{\mathtt{freqs}}\)

A fixed number of cycles for all frequencies will yield a temporal window which decreases with frequency. For example, freqs=np.arange(1, 6, 2) and n_cycles=2 yields T=array([2., 0.7, 0.4]).

To use a temporal window with fixed length, the number of cycles has to be defined based on the frequency. For example, freqs=np.arange(1, 6, 2) and n_cycles=freqs / 2 yields T=array([0.5, 0.5, 0.5]).

In MNE-Python‚Äôs multitaper functions, the frequency bandwidth is additionally affected by the parameter time_bandwidth. The n_cycles parameter determines the temporal window length based on the frequencies of interest: \(T = \frac{\mathtt{n\_cycles}}{\mathtt{freqs}}\). The time_bandwidth parameter defines the ‚Äútime-bandwidth product‚Äù, which is the product of the temporal window length (in seconds) and the frequency bandwidth (in Hz). Thus once n_cycles has been set, frequency bandwidth is determined by \(\frac{\mathrm{time~bandwidth}}{\mathrm{time~window}}\), and thus passing a larger time_bandwidth value will increase the frequency bandwidth (thereby decreasing the frequency resolution).

The increased frequency bandwidth is reached by averaging spectral estimates obtained from multiple tapers. Thus, time_bandwidth also determines the number of tapers used. MNE-Python uses only ‚Äúgood‚Äù tapers (tapers with minimal leakage from far-away frequencies); the number of good tapers is floor(time_bandwidth - 1). This means there is another trade-off at play, between frequency resolution and the variance reduction that multitaper analysis provides. Striving for finer frequency resolution (by setting time_bandwidth low) means fewer tapers will be used, which undermines what is unique about multitaper methods ‚Äî namely their ability to improve accuracy / reduce noise in the power estimates by using several (orthogonal) tapers.

In tfr_array_multitaper and tfr_multitaper, time_bandwidth defines the product of the temporal window length with the full frequency bandwidth For example, a full bandwidth of 4 Hz at a frequency of interest of 10 Hz will ‚Äúsmear‚Äù the frequency estimate between 8 Hz and 12 Hz.

This is not the case for psd_array_multitaper where the argument bandwidth defines the half frequency bandwidth. In the example above, the half-frequency bandwidth is 2 Hz.

mne.time_frequency.tfr_array_morlet

mne.time_frequency.tfr_array_stockwell

---

## mne.time_frequency.tfr_morlet#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.tfr_morlet.html

**Contents:**
- mne.time_frequency.tfr_morlet#
- Examples using mne.time_frequency.tfr_morlet#

LEGACY: New code should use .compute_tfr(method=‚Äùmorlet‚Äù).

Compute Time-Frequency Representation (TFR) using Morlet wavelets.

Same computation as tfr_array_morlet, but operates on Epochs or Evoked objects instead of NumPy arrays.

The epochs or evoked object.

The frequencies in Hz.

Number of cycles in the wavelet, either a fixed number or one per frequency. The number of cycles n_cycles and the frequencies of interest freqs define the temporal window length. See notes for additional information about the relationship between those arguments and about time and frequency smoothing.

The fft based convolution or not.

Return inter-trial coherence (ITC) as well as averaged power. Must be False for evoked data.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

The indices of the channels to decompose. If None, all available good data channels are decomposed.

Make sure the wavelet has a mean of zero.

If False return an EpochsTFR containing separate TFRs for each epoch. If True return an AverageTFR containing the average of all TFRs across epochs.

Using average=True is functionally equivalent to using average=False followed by EpochsTFR.average(), but is more memory efficient.

Can be "power" (default) or "complex". If "complex", then average must be False.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The averaged or single-trial power.

The inter-trial coherence (ITC). Only returned if return_itc is True.

The Morlet wavelets follow the formulation in Tallon-Baudry et al.[1].

In spectrotemporal analysis (as with traditional fourier methods), the temporal and spectral resolution are interrelated: longer temporal windows allow more precise frequency estimates; shorter temporal windows ‚Äúsmear‚Äù frequency estimates while providing more precise timing information.

Time-frequency representations are computed using a sliding temporal window. Either the temporal window has a fixed length independent of frequency, or the temporal window decreases in length with increased frequency.

Figure: Time and frequency smoothing. (a) For a fixed length temporal window the time and frequency smoothing remains fixed. (b) For temporal windows that decrease with frequency, the temporal smoothing decreases and the frequency smoothing increases with frequency. Source: FieldTrip tutorial: Time-frequency analysis using Hanning window, multitapers and wavelets.

In MNE-Python, the length of the Morlet wavelet is affected by the arguments freqs and n_cycles, which define the frequencies of interest and the number of cycles, respectively. For the time-frequency representation, the length of the wavelet is defined such that both tails of the wavelet extend five standard deviations from the midpoint of its Gaussian envelope and that there is a sample at time zero.

The length of the wavelet is thus \(10\times\mathtt{sfreq}\cdot\sigma-1\), which is equal to \(\frac{5}{\pi} \cdot \frac{\mathtt{n\_cycles} \cdot \mathtt{sfreq}}{\mathtt{freqs}} - 1\), where \(\sigma = \frac{\mathtt{n\_cycles}}{2\pi f}\) corresponds to the standard deviation of the wavelet‚Äôs Gaussian envelope. Note that the length of the wavelet must not exceed the length of your signal.

For more information on the Morlet wavelet, see mne.time_frequency.morlet().

See mne.time_frequency.morlet() for more information about the Morlet wavelet.

Catherine Tallon-Baudry, Olivier Bertrand, Claude Delpuech, and Jacques Pernier. Oscillatory Gamma-Band (30‚Äì70 Hz) Activity Induced by a Visual Search Task in Humans. Journal of Neuroscience, pages 722‚Äì734, 1997. doi:10.1523/JNEUROSCI.17-02-00722.1997.

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

mne.time_frequency.fit_iir_model_raw

mne.time_frequency.tfr_multitaper

---

## mne.time_frequency.tfr_multitaper#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.tfr_multitaper.html

**Contents:**
- mne.time_frequency.tfr_multitaper#
- Examples using mne.time_frequency.tfr_multitaper#

LEGACY: New code should use .compute_tfr(method=‚Äùmultitaper‚Äù).

Compute Time-Frequency Representation (TFR) using DPSS tapers.

Same computation as tfr_array_multitaper(), but operates on Epochs or Evoked objects instead of NumPy arrays.

The epochs or evoked object.

The frequencies in Hz.

Number of cycles in the wavelet, either a fixed number or one per frequency. The number of cycles n_cycles and the frequencies of interest freqs define the temporal window length. See notes for additional information about the relationship between those arguments and about time and frequency smoothing.

Product between the temporal window length (in seconds) and the full frequency bandwidth (in Hz). This product can be seen as the surface of the window on the time/frequency plane and controls the frequency bandwidth (thus the frequency resolution) and the number of good tapers. See notes for additional information.

The fft based convolution or not.

Return inter-trial coherence (ITC) as well as averaged (or single-trial) power.

Decimation factor, applied after time-frequency decomposition.

if int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).

if slice, returns tfr[..., decim] (keep only the specified slice along the time axis).

Decimation is done after convolutions and may create aliasing artifacts.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

If False return an EpochsTFR containing separate TFRs for each epoch. If True return an AverageTFR containing the average of all TFRs across epochs.

Using average=True is functionally equivalent to using average=False followed by EpochsTFR.average(), but is more memory efficient.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The averaged or single-trial power.

The inter-trial coherence (ITC). Only returned if return_itc is True.

In spectrotemporal analysis (as with traditional fourier methods), the temporal and spectral resolution are interrelated: longer temporal windows allow more precise frequency estimates; shorter temporal windows ‚Äúsmear‚Äù frequency estimates while providing more precise timing information.

Time-frequency representations are computed using a sliding temporal window. Either the temporal window has a fixed length independent of frequency, or the temporal window decreases in length with increased frequency.

Figure: Time and frequency smoothing. (a) For a fixed length temporal window the time and frequency smoothing remains fixed. (b) For temporal windows that decrease with frequency, the temporal smoothing decreases and the frequency smoothing increases with frequency. Source: FieldTrip tutorial: Time-frequency analysis using Hanning window, multitapers and wavelets.

In MNE-Python, the multitaper temporal window length is defined by the arguments freqs and n_cycles, respectively defining the frequencies of interest and the number of cycles: \(T = \frac{\mathtt{n\_cycles}}{\mathtt{freqs}}\)

A fixed number of cycles for all frequencies will yield a temporal window which decreases with frequency. For example, freqs=np.arange(1, 6, 2) and n_cycles=2 yields T=array([2., 0.7, 0.4]).

To use a temporal window with fixed length, the number of cycles has to be defined based on the frequency. For example, freqs=np.arange(1, 6, 2) and n_cycles=freqs / 2 yields T=array([0.5, 0.5, 0.5]).

In MNE-Python‚Äôs multitaper functions, the frequency bandwidth is additionally affected by the parameter time_bandwidth. The n_cycles parameter determines the temporal window length based on the frequencies of interest: \(T = \frac{\mathtt{n\_cycles}}{\mathtt{freqs}}\). The time_bandwidth parameter defines the ‚Äútime-bandwidth product‚Äù, which is the product of the temporal window length (in seconds) and the frequency bandwidth (in Hz). Thus once n_cycles has been set, frequency bandwidth is determined by \(\frac{\mathrm{time~bandwidth}}{\mathrm{time~window}}\), and thus passing a larger time_bandwidth value will increase the frequency bandwidth (thereby decreasing the frequency resolution).

The increased frequency bandwidth is reached by averaging spectral estimates obtained from multiple tapers. Thus, time_bandwidth also determines the number of tapers used. MNE-Python uses only ‚Äúgood‚Äù tapers (tapers with minimal leakage from far-away frequencies); the number of good tapers is floor(time_bandwidth - 1). This means there is another trade-off at play, between frequency resolution and the variance reduction that multitaper analysis provides. Striving for finer frequency resolution (by setting time_bandwidth low) means fewer tapers will be used, which undermines what is unique about multitaper methods ‚Äî namely their ability to improve accuracy / reduce noise in the power estimates by using several (orthogonal) tapers.

In tfr_array_multitaper and tfr_multitaper, time_bandwidth defines the product of the temporal window length with the full frequency bandwidth For example, a full bandwidth of 4 Hz at a frequency of interest of 10 Hz will ‚Äúsmear‚Äù the frequency estimate between 8 Hz and 12 Hz.

This is not the case for psd_array_multitaper where the argument bandwidth defines the half frequency bandwidth. In the example above, the half-frequency bandwidth is 2 Hz.

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

mne.time_frequency.tfr_morlet

mne.time_frequency.tfr_stockwell

---

## mne.time_frequency.tfr_stockwell#

**URL:** https://mne.tools/stable/generated/mne.time_frequency.tfr_stockwell.html

**Contents:**
- mne.time_frequency.tfr_stockwell#
- Examples using mne.time_frequency.tfr_stockwell#

LEGACY: New code should use .compute_tfr(method=‚Äùstockwell‚Äù, freqs=‚Äùauto‚Äù).

Compute Time-Frequency Representation (TFR) using Stockwell Transform.

Same computation as tfr_array_stockwell, but operates on Epochs objects instead of NumPy arrays.

See [1][2][3][4] for more information.

The epochs or evoked object.

The minimum frequency to include. If None defaults to the minimum fft frequency greater than zero.

The maximum frequency to include. If None defaults to the maximum fft.

The length of the windows used for FFT. If None, it defaults to the next power of 2 larger than the signal length.

The width of the Gaussian window. If < 1, increased temporal resolution, if > 1, increased frequency resolution. Defaults to 1. (classical S-Transform).

The decimation factor on the time axis. To reduce memory usage.

Return intertrial coherence (ITC) as well as averaged power.

The number of jobs to run in parallel (over channels).

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The intertrial coherence. Only returned if return_itc is True.

R. G. Stockwell. Why use the S-transform? In Luigi Rodino, Bert-Wolfgang Schulze, and M. W. Wong, editors, Pseudo-Differential Operators: Partial Differential Equations and Time-Frequency Analysis, number 52 in Fields Institute Communications, pages 279‚Äì309. American Mathematical Society, Providence, RI, 2007. doi:10.1090/fic/052.

Ali Moukadem, Zied Bouguila, Djaffar Ould Abdeslam, and Alain Dieterlen. Stockwell transform optimization applied on the detection of split in heart sounds. In Proceedings of EUSIPCO-2014, 2015‚Äì2019. Lisbon, 2014. IEEE. URL: https://ieeexplore.ieee.org/document/6952743.

Katherine L. Wheat, Piers L. Cornelissen, Stephen J. Frost, and Peter C. Hansen. During visual word recognition, phonology is accessed within 100 ms and may be mediated by a speech production code: evidence from magnetoencephalography. Journal of Neuroscience, 30(15):5229‚Äì5233, 2010. doi:10.1523/JNEUROSCI.4448-09.2010.

Kevin A. Jones, Bernice Porjesz, David Chorlian, Madhavi Rangaswamy, Chella Kamarajan, Ajayan Padmanabhapillai, Arthur Stimus, and Henri Begleiter. S-transform time-frequency analysis of P300 reveals deficits in individuals diagnosed with alcoholism. Clinical Neurophysiology, 117(10):2128‚Äì2143, 2006. doi:10.1016/j.clinph.2006.02.028.

Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)

mne.time_frequency.tfr_multitaper

mne.time_frequency.read_tfrs

---

## mne.viz.EvokedField#

**URL:** https://mne.tools/stable/generated/mne.viz.EvokedField.html

**Contents:**
- mne.viz.EvokedField#
- Examples using mne.viz.EvokedField#

Plot MEG/EEG fields on head surface and helmet in 3D.

The surface mapping information obtained with make_field_map.

The time point at which the field map shall be displayed. If None, the average peak latency (across sensor types) is used.

How to print info about the time instant visualized.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

If None (default), a new figure will be created, otherwise it will plot into the given figure.

Maximum intensity. Can be a dictionary with two entries "eeg" and "meg" to specify separate values for EEG and MEG fields respectively. Can be None to use the maximum value of the data.

New in v1.4: vmax can be a dictionary to specify separate values for EEG and MEG fields.

The number of contours.

Whether to draw the field density as an overlay on top of the helmet/head surface. Defaults to True.

Opacity of the meshes (between 0 and 1). Can be a dictionary with two entries "eeg" and "meg" to specify separate values for EEG and MEG fields respectively. Can be None to use 1.0 when a single field map is shown, or dict(eeg=1.0, meg=0.5) when both field maps are shown.

Interpolation method (scipy.interpolate.interp1d parameter). Must be one of 'linear', 'nearest', 'zero', 'slinear', 'quadratic' or 'cubic'.

How interactions with the scene via an input device (e.g., mouse or trackpad) modify the camera position. If 'terrain', one axis is fixed, enabling ‚Äúturntable-style‚Äù rotations. If 'trackball', movement along all axes is possible, which provides more freedom of movement, but you may incidentally perform unintentional rotations along some axes. Defaults to 'terrain'.

Display time viewer GUI. Can also be "auto", which will mean True if there is more than one time point and False otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

set_contours(n_contours)

Adjust the number of contour lines to use when drawing the fieldlines.

Set the time to display (in seconds).

set_vmax(vmax[, kind])

Change the color range of the density maps.

The figure will publish and subscribe to the following UI events:

Contours, kind="field_strength_meg" | "field_strength_eeg"

ColormapRange, kind="field_strength_meg" | "field_strength_eeg"

Adjust the number of contour lines to use when drawing the fieldlines.

The number of contour lines to use.

Set the time to display (in seconds).

The time to show, in seconds.

Change the color range of the density maps.

The new maximum value of the color range.

Which field map to apply the new color range to.

Visualizing Evoked data

Using the event system to link figures

mne.viz.ClickableImage

---

## mne.viz.plot_compare_evokeds#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_compare_evokeds.html

**Contents:**
- mne.viz.plot_compare_evokeds#
- Examples using mne.viz.plot_compare_evokeds#

Plot evoked time courses for one or more conditions and/or channels.

If a single Evoked instance, it is plotted as a time series. If a list of Evokeds, the contents are plotted with their .comment attributes used as condition labels. If no comment is set, the index of the respective Evoked the list will be used instead, starting with 1 for the first Evoked. If a dict whose values are Evoked objects, the contents are plotted as single time series each and the keys are used as labels. If a [dict/list] of lists, the unweighted mean is plotted as a time series and the parametric confidence interval is plotted as a shaded area. All instances must have the same shape - channel numbers, time points etc. If dict, keys must be of type str.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

If picks is None or a (collection of) data channel types, the global field power will be plotted for all data channels. Otherwise, picks will be averaged.

If multiple channel types are selected, one figure will be returned for each channel type.

If the selected channels are gradiometers, the signal from corresponding (gradiometer) pairs will be combined.

Colors to use when plotting the ERP/F lines and confidence bands. If cmap is not None, colors must be a list or dict of ints or floats indicating steps or percentiles (respectively) along the colormap. If cmap is None, list elements or dict values of colors must be ints or valid matplotlib colors; lists are cycled through sequentially, while dicts must have keys matching the keys or conditions of an evokeds dict (see Notes for details). If None, the current matplotlib color cycle is used. Defaults to None.

Styles to use when plotting the ERP/F lines. If a list or dict, elements must be valid matplotlib linestyles. Lists are cycled through sequentially; dictionaries must have keys matching the keys or conditions of an evokeds dict (see Notes for details). If None, all lines will be solid. Defaults to None.

Dictionary of styles to use when plotting ERP/F lines. Keys must match keys or conditions of evokeds, and values must be a dict of legal inputs to matplotlib.pyplot.plot(). Those values will be passed as parameters to the line plot call of the corresponding condition, overriding defaults (e.g., styles={"Aud/L": {"linewidth": 3}} will set the linewidth for ‚ÄúAud/L‚Äù to 3). As with colors and linestyles, keys matching conditions in /-separated evokeds keys are supported (see Notes for details).

Colormap from which to draw color values when plotting the ERP/F lines and confidence bands. If not None, ints or floats in the colors parameter are mapped to steps or percentiles (respectively) along the colormap. If cmap is a str, it will be passed to matplotlib.colormaps; if cmap is a tuple, its first element will be used as a string to label the colorbar, and its second element will be passed to matplotlib.colormaps (unless it is already an instance of Colormap).

Changed in version 0.19: Support for passing Colormap instances.

A list in seconds at which to plot dashed vertical lines. If "auto" and the supplied data includes 0, it is set to [0.] and a vertical bar is plotted at time 0. If an empty list is passed, no vertical lines are plotted.

Confidence band around each ERP/F time series. If False or None no confidence band is drawn. If float, ci must be between 0 and 1, and will set the threshold for a bootstrap (single plot)/parametric (when axes=='topo') estimation of the confidence band; True is equivalent to setting a threshold of 0.95 (i.e., the 95% confidence band is drawn). If a callable, it must take a single array (n_observations √ó n_times) as input and return upper and lower confidence margins (2 √ó n_times). Defaults to True.

Whether to shorten the y-axis spine. If 'auto', the spine is truncated at the minimum and maximum ticks. If True, it is truncated at the multiple of 0.25 nearest to half the maximum absolute value of the data. If truncate_xaxis=False, only the far bound of the y-axis will be truncated. Defaults to 'auto'.

Whether to shorten the x-axis spine. If True, the spine is truncated at the minimum and maximum ticks. If truncate_yaxis=False, only the far bound of the x-axis will be truncated. Defaults to True.

Y-axis limits for plots (after scaling has been applied). dict keys should match channel types; valid keys are for instance eeg, mag, grad, misc, csd, .. (example: ylim=dict(eeg=[-20, 20])). If None, the y-axis limits will be set automatically by matplotlib. Defaults to None.

Whether to plot negative values upward (as is sometimes done for ERPs out of tradition). Defaults to False.

Whether to display an inset showing sensor locations on a head outline. If int or str, indicates position of the inset (see mpl_toolkits.axes_grid1.inset_locator.inset_axes()). If None, treated as True if there is only one channel in picks. If True, location is upper or lower right corner, depending on data values. Defaults to None.

Whether to show a legend for the colors/linestyles of the conditions plotted. If int or str, indicates position of the legend (see mpl_toolkits.axes_grid1.inset_locator.inset_axes()). If True, equivalent to 'upper left'. Defaults to True.

Whether to separate color and linestyle in the legend. If None, a separate linestyle legend will still be shown if cmap is specified. Defaults to None.

Axes object to plot into. If plotting multiple channel types (or multiple channels when combine=None), axes should be a list of appropriate length containing Axes objects. If 'topo', a new Figure is created with one axis for each channel, in a topographical layout. If None, a new Figure is created for each channel type. Defaults to None.

Title printed above the plot. If None, a title will be automatically generated based on channel name(s) or type(s) and the value of the combine parameter. Defaults to None.

Whether to show the figure. Defaults to True.

How to aggregate across channels. If None, channels are combined by computing GFP/RMS, unless picks is a single channel (not channel type) or axes="topo", in which cases no combining is performed. If a string, "mean" uses numpy.mean(), "median" computes the marginal median, "std" uses numpy.std(), and "gfp" computes global field power for EEG channels and RMS amplitude for MEG channels. If callable(), it must operate on an array of shape (n_evokeds, n_channels, n_times) and return an array of shape (n_evokeds, n_times). For example:

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The units for the time axis, can be ‚Äús‚Äù (default) or ‚Äúms‚Äù.

A list of the figure(s) generated.

If the parameters styles, colors, or linestyles are passed as dicts, then evokeds must also be a dict, and the keys of the plot-style parameters must either match the keys of evokeds, or match a /-separated partial key (‚Äúcondition‚Äù) of evokeds. For example, if evokeds has keys ‚ÄúAud/L‚Äù, ‚ÄúAud/R‚Äù, ‚ÄúVis/L‚Äù, and ‚ÄúVis/R‚Äù, then linestyles=dict(L='--', R='-') will plot both Aud/L and Vis/L conditions with dashed lines and both Aud/R and Vis/R conditions with solid lines. Similarly, colors=dict(Aud='r', Vis='b') will plot Aud/L and Aud/R conditions red and Vis/L and Vis/R conditions blue.

Color specification depends on whether a colormap has been provided in the cmap parameter. The following table summarizes how the colors parameter is interpreted:

matplotlib default color cycle; unique color for each condition

list or dict of integers

matplotlib default color cycle; lowest integer mapped to first cycle color; conditions with same integer get same color; unspecified conditions are ‚Äúgray‚Äù

list or dict of floats

list or dict of hexadecimal color strings

the specified hex colors; unspecified conditions are ‚Äúgray‚Äù

string or instance of matplotlib Colormap

equally spaced colors on the colormap; unique color for each condition

list or dict of integers

equally spaced colors on the colormap; lowest integer mapped to first cycle color; conditions with same integer get same color

list or dict of floats

floats mapped to corresponding colormap values

list or dict of hexadecimal color strings

Single trial linear regression analysis with the LIMO dataset

Analysing continuous features with binning and regression in sensor space

Regression-based baseline correction

Visualizing epoched data

Working with Epoch metadata

Auto-generating Epochs metadata

Visualizing Evoked data

EEG analysis - Event-Related Potentials (ERPs)

Overview of MEG/EEG analysis with MNE-Python

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Spatiotemporal permutation F-test on full sensor data

mne.viz.plot_ideal_filter

mne.viz.plot_ica_sources

---

## mne.viz.plot_epochs#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_epochs.html

**Contents:**
- mne.viz.plot_epochs#

Bad epochs can be marked with a left click on top of the epoch. Bad channels can be selected by clicking the channel name on the left side of the main axes. Calling this function drops all the selected bad epochs as well as bad epochs marked beforehand with rejection parameters.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Scaling factors for the traces. If a dictionary where any value is 'auto', the scaling factor is set to match the 99.5th percentile of the respective data. If 'auto', all scalings (for all channel types) are set to 'auto'. If any values are 'auto' and the data is not preloaded, a subset up to 100 MB will be loaded. If None, defaults to:

A particular scaling value s corresponds to half of the visualized signal range around zero (i.e. from 0 to +s or from 0 to -s). For example, the default scaling of 20e-6 (20¬µV) for EEG signals means that the visualized range will be 40 ¬µV (20 ¬µV in the positive direction and 20 ¬µV in the negative direction).

The number of epochs per view. Defaults to 20.

The number of channels per view. Defaults to 20.

The title of the window. If None, the event names (from epochs.event_id) will be displayed. Defaults to None.

Events to show with vertical bars. You can use plot_events as a legend for the colors. By default, the coloring scheme is the same. True plots epochs.events. Defaults to False (do not plot events).

If the epochs have been resampled, the events no longer align with the data.

Changed in version 1.6: Passing events=None was disallowed. The new equivalent is events=False.

Color(s) to use for events. To show all events in the same color, pass any matplotlib-compatible color. To color events differently, pass a dict that maps event names or integer event numbers to colors (must include entries for all events, or include a ‚Äúfallback‚Äù entry with key -1). If None, colors are chosen from the current Matplotlib color cycle. Defaults to None.

Order in which to plot channel types.

Show figure if True. Defaults to True.

Whether to halt program execution until the figure is closed. Useful for rejecting bad trials on the fly by clicking on an epoch. Defaults to False.

Amount to decimate the data during display for speed purposes. You should only decimate if the data are sufficiently low-passed, otherwise aliasing can occur. The ‚Äòauto‚Äô mode (default) uses the decimation that results in a sampling rate at least three times larger than info['lowpass'] (e.g., a 40 Hz lowpass will result in at least a 120 Hz displayed sample rate).

Noise covariance used to whiten the data while plotting. Whitened data channels are scaled by scalings['whitened'], and their channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().

Whether to directly call the butterfly view.

Whether to show scrollbars when the plot is initialized. Can be toggled after initialization by pressing z (‚Äúzen mode‚Äù) while the plot window is focused. Default is True.

Whether to show scale bars when the plot is initialized. Can be toggled after initialization by pressing s while the plot window is focused. Default is True.

Colors to use for individual epochs. If None, use default colors.

Determines to label the event markers on the plot. If True, uses epochs.event_id. If False, uses integer event codes instead of IDs. If a dict is passed, uses its keys as event labels on the plot for entries whose values are integer codes for events being drawn. Ignored if events=False.

How to group channels. 'type' groups by channel type, 'original' plots in the order of ch_names, 'selection' uses Elekta‚Äôs channel groupings (only works for Neuromag data), 'position' groups the channels by the positions of the sensors. 'selection' and 'position' modes allow custom selections by using a lasso selector on the topomap. In butterfly mode, 'type' and 'original' group the channels by type, whereas 'selection' and 'position' use regional grouping. 'type' and 'original' modes are ignored when order is not None. Defaults to 'type'.

Whether to load all data (not just the visible portion) into RAM and apply preprocessing (e.g., projectors) to the full data array in a separate processor thread, instead of window-by-window during scrolling. The default None uses the MNE_BROWSER_PRECOMPUTE variable, which defaults to 'auto'. 'auto' compares available RAM space to the expected size of the precomputed data, and precomputes only if enough RAM is available. This is only used with the Qt backend.

Changed in version 1.0: Support for the MNE_BROWSER_PRECOMPUTE config variable.

Whether to use OpenGL when rendering the plot (requires pyopengl). May increase performance, but effect is dependent on system CPU and graphics hardware. Only works if using the Qt backend. Default is None, which will use False unless the user configuration variable MNE_BROWSER_USE_OPENGL is set to 'true', see mne.set_config().

Can be ‚Äúauto‚Äù, ‚Äúlight‚Äù, or ‚Äúdark‚Äù or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_BROWSER_THEME will be used, defaulting to ‚Äúauto‚Äù if it‚Äôs not found. Only supported by the 'qt' backend.

Can be ‚Äúchannels‚Äù, ‚Äúempty‚Äù, or ‚Äúhidden‚Äù to set the overview bar mode for the 'qt' backend. If None (default), the config option MNE_BROWSER_OVERVIEW_MODE will be used, defaulting to ‚Äúchannels‚Äù if it‚Äôs not found.

If True (default), a splash screen is shown during the application startup. Only applicable to the qt backend.

The arrow keys (up/down/left/right) can be used to navigate between channels and epochs and the scaling can be adjusted with - and + (or =) keys, but this depends on the backend matplotlib is configured to use (e.g., mpl.use(TkAgg) should work). Full screen mode can be toggled with f11 key. The amount of epochs and channels per view can be adjusted with home/end and page down/page up keys. h key plots a histogram of peak-to-peak values along with the used rejection thresholds. Butterfly plot can be toggled with b key. Left mouse click adds a vertical line to the plot. Click ‚Äòhelp‚Äô button at bottom left corner of the plotter to view all the options.

MNE-Python provides two different backends for browsing plots (i.e., raw.plot(), epochs.plot(), and ica.plot_sources()). One is based on matplotlib, and the other is based on PyQtGraph. You can set the backend temporarily with the context manager mne.viz.use_browser_backend(), you can set it for the duration of a Python session using mne.viz.set_browser_backend(), and you can set the default for your computer via mne.set_config('MNE_BROWSER_BACKEND', 'matplotlib') (or 'qt').

For the PyQtGraph backend to run in IPython with block=False you must run the magic command %gui qt5 first.

To report issues with the PyQtGraph backend, please use the issues of mne-qt-browser.

mne.viz.plot_drop_log

mne.viz.plot_epochs_psd_topomap

---

## mne.viz.plot_epochs_image#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_epochs_image.html

**Contents:**
- mne.viz.plot_epochs_image#
- Examples using mne.viz.plot_epochs_image#

Plot Event Related Potential / Fields image.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick good data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided. picks interacts with group_by and combine to determine the number of figures generated; see Notes.

The standard deviation of a Gaussian smoothing window applied along the epochs axis of the image. If 0, no smoothing is applied. Defaults to 0.

The min value in the image (and the ER[P/F]). The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers. If vmin is None and multiple plots are returned, the limit is equalized within channel types. Hint: to specify the lower limit of the data, use vmin=lambda data: data.min().

The max value in the image (and the ER[P/F]). The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers. If vmin is None and multiple plots are returned, the limit is equalized within channel types.

Display or not a colorbar.

If not None, order is used to reorder the epochs along the y-axis of the image. If it is an array of int, its length should match the number of good epochs. If it is a callable it should accept two positional parameters (times and data, where data.shape == (len(good_epochs), len(times))) and return an array of indices that will sort data along its first axis.

The units of the channel types used for axes labels. If None, defaults to units=dict(eeg='¬µV', grad='fT/cm', mag='fT').

The scalings of the channel types to be applied for plotting. If None, defaults to scalings=dict(eeg=1e6, grad=1e13, mag=1e15, eog=1e6).

Colormap. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the scale. Up and down arrows can be used to change the colormap. If ‚Äòinteractive‚Äô, translates to (‚ÄòRdBu_r‚Äô, True). If None, ‚ÄúRdBu_r‚Äù is used, unless the data is all positive, in which case ‚ÄúReds‚Äù is used.

Figure instance to draw the image to. Figure must contain the correct number of axes for drawing the epochs image, the evoked response, and a colorbar (depending on values of evoked and colorbar). If None a new figure is created. Defaults to None.

List of Axes objects in which to draw the image, evoked response, and colorbar (in that order). Length of list must be 1, 2, or 3 (depending on values of colorbar and evoked parameters). If a dict, each entry must be a list of Axes objects with the same constraints as above. If both axes and group_by are dicts, their keys must match. Providing non-None values for both fig and axes results in an error. Defaults to None.

Times (in seconds) at which to draw a line on the corresponding row of the image (e.g., a reaction time associated with each epoch). Note that overlay_times should be ordered to correspond with the Epochs object (i.e., overlay_times[0] corresponds to epochs[0], etc).

How to aggregate across channels. If None, channels are combined by computing GFP/RMS, unless group_by is also None and picks is a list of specific channels (not channel types), in which case no combining is performed and each channel gets its own figure. If a string, "mean" uses numpy.mean(), "median" computes the marginal median, "std" uses numpy.std(), and "gfp" computes global field power for EEG channels and RMS amplitude for MEG channels. If callable(), it must operate on an array of shape (n_epochs, n_channels, n_times) and return an array of shape (n_epochs, n_times). For example:

See Notes for further details. Defaults to None.

Specifies which channels are aggregated into a single figure, with aggregation method determined by the combine parameter. If not None, one Figure is made per dict entry; the dict key will be used as the figure title and the dict values must be lists of picks (either channel names or integer indices of epochs.ch_names). For example:

Note that within a dict entry all channels must have the same type. group_by interacts with picks and combine to determine the number of figures generated; see Notes. Defaults to None.

Draw the ER[P/F] below the image or not.

Arguments passed to a call to plot_compare_evokeds to style the evoked plot below the image. Defaults to an empty dictionary, meaning plot_compare_evokeds will be called with default parameters.

If str, will be plotted as figure title. Otherwise, the title will indicate channel(s) or channel type being plotted. Defaults to None.

Whether to clear the axes before plotting (if fig or axes are provided). Defaults to False.

One figure per channel, channel type, or group, depending on values of picks, group_by, and combine. See Notes.

You can control how channels are aggregated into one figure or plotted in separate figures through a combination of the picks, group_by, and combine parameters. If group_by is a dict, the result is one Figure per dictionary key (for any valid values of picks and combine). If group_by is None, the number and content of the figures generated depends on the values of picks and combine, as summarized in this table:

None, int, list of int, ch_name, list of ch_names, ch_type, list of ch_types

None, string, or callable

1 figure per dict key

None, ch_type, list of ch_types

None, string, or callable

int, ch_name, list of int, list of ch_names

Visualize channel over epochs as an image

mne.viz.plot_ica_overlay

---

## mne.viz.plot_epochs_psd_topomap#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_epochs_psd_topomap.html

**Contents:**
- mne.viz.plot_epochs_psd_topomap#

LEGACY: New code should use Epochs.compute_psd().plot_topomap().

Plot the topomap of the power spectral density across epochs.

The frequencies or frequency ranges to plot. If a dict, keys will be used as subplot titles and values should be either a single frequency (e.g., {'presentation rate': 6.5}) or a length-two sequence of lower and upper frequency band edges (e.g., {'theta': (4, 8)}). If a single frequency is provided, the plot will show the frequency bin that is closest to the requested value. If None (the default), expands to:

For backwards compatibility, tuples of length 2 or 3 are also accepted, where the last element of the tuple is the subplot title and the other entries are frequency values (a single value or band edges). New code should use dict or None.

Changed in version 1.2: Allow passing a dict and discourage passing tuples.

First and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).

Whether to apply SSP projection vectors before spectral estimation. Default is False.

The bandwidth of the multi taper windowing function in Hz. The default value is a window half-bandwidth of 4 Hz.

Use adaptive weights to combine the tapered spectra into PSD (slow, use n_jobs >> 1 to speed up computation).

Only use tapers with more than 90% spectral concentration within bandwidth.

Normalization strategy. If ‚Äúfull‚Äù, the PSD will be normalized by the sampling rate as well as the length of the signal (as in Nitime). Default is 'length'.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the mean for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

If True, each band will be divided by the total power. Defaults to False.

The function used to aggregate over frequencies. Defaults to numpy.sum() if normalize=True, else numpy.mean().

Whether to plot on a decibel scale. If True, plots 10 √ó log‚ÇÅ‚ÇÄ(spectral_power/Hz), following the application of agg_fun. Ignored if normalize=True.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

Labels for the sensors. If a list, labels should correspond to the order of channels in data. If None (default), no channel names are plotted.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details. If 'auto', is equivalent to ‚Äò%0.3f‚Äô if dB=False and ‚Äò%0.1f‚Äô if dB=True. Defaults to 'auto'.

The units to use for the colorbar label. Ignored if colorbar=False. If None the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the length of bands. Default is None.

Show the figure if True.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure showing one scalp topography per frequency band.

---

## mne.viz.plot_evoked#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_evoked.html

**Contents:**
- mne.viz.plot_evoked#

Plot evoked data using butterfly plots.

Left click to a line shows the channel name. Selecting an area by clicking and holding left mouse button plots a topographic map of the painted area.

If bad channels are not excluded they are shown in red.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channels names to exclude from being shown. If 'bads', the bad channels are excluded.

Scale plot with channel (SI) unit.

Y-axis limits for plots (after scaling has been applied). dict keys should match channel types; valid keys are for instance eeg, mag, grad, misc, csd, .. (example: ylim=dict(eeg=[-20, 20])). If None, the y-axis limits will be set automatically by matplotlib. Defaults to None.

Limits for the X-axis of the plots.

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown. If 'reconstruct', projection vectors will be applied and then M/EEG data will be reconstructed via field mapping to reduce the signal bias caused by projection.

Changed in version 0.21: Support for ‚Äòreconstruct‚Äô was added.

The values at which to show an horizontal line.

The units of the channel types used for axes labels. If None, defaults to dict(eeg='¬µV', grad='fT/cm', mag='fT').

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

The titles associated with the channels. If None, defaults to dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers').

The axes to plot to. If list, the list must be a list of Axes of the same length as the number of channel types. If instance of Axes, there must be only one channel type plotted.

Plot the global field power (GFP) or the root mean square (RMS) of the data. For MEG data, this will plot the RMS. For EEG, it plots GFP, i.e. the standard deviation of the signal across channels. The GFP is equivalent to the RMS of an average-referenced signal.

Plot GFP or RMS (for EEG and MEG, respectively) and traces for all channels.

Plot GFP or RMS (for EEG and MEG, respectively), and omit the traces for individual channels.

The color of the GFP/RMS trace will be green if spatial_colors=False, and black otherwise.

Changed in version 0.23: Plot GFP for EEG instead of RMS. Label RMS traces correctly as such.

The title to put at the top of the figure.

If True, the lines are color coded by mapping physical sensor coordinates into color values. Spatially similar channels will have similar colors. Bad channels will be dotted. If False, the good channels are plotted black and bad channels red. If 'auto', uses True if channel locations are present, and False if channel locations are missing or if the data contains only a single channel. Defaults to 'auto'.

Which channels to put in the front or back. Only matters if spatial_colors is used. If str, must be std or unsorted (defaults to unsorted). If std, data with the lowest standard deviation (weakest effects) will be put in front so that they are not obscured by those with stronger effects. If unsorted, channels are z-sorted as in the evoked instance. If callable, must take one argument: a numpy array of the same dimensionality as the evoked raw data; and return a list of unique integers corresponding to the number of channels.

Whether to use interactive features. If True (default), it is possible to paint an area to draw topomaps. When False, the interactive features are disabled. Disabling interactive features reduces memory consumption and is useful when using axes parameter to draw multiaxes figures.

Noise covariance used to whiten the data while plotting. Whitened data channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().

The units for the time axis, can be ‚Äús‚Äù (default) or ‚Äúms‚Äù.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Segments of the data to highlight by means of a light-yellow background color. Can be used to put visual emphasis on certain time periods. The time periods must be specified as array-like objects in the form of (t_start, t_end) in the unit given by the time_unit parameter. Multiple time periods can be specified by passing an array-like object of individual time periods (e.g., for 3 time periods, the shape of the passed object would be (3, 2). If None, no highlighting is applied.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Figure containing the butterfly plots.

mne.viz.plot_evoked_image

---

## mne.viz.plot_evoked_field#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_evoked_field.html

**Contents:**
- mne.viz.plot_evoked_field#
- Examples using mne.viz.plot_evoked_field#

Plot MEG/EEG fields on head surface and helmet in 3D.

The surface mapping information obtained with make_field_map.

The time point at which the field map shall be displayed. If None, the average peak latency (across sensor types) is used.

How to print info about the time instant visualized.

The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‚Äòunset‚Äô that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.

If None (default), a new figure will be created, otherwise it will plot into the given figure.

New in v1.4: fig can also be a Brain figure.

Maximum intensity. Can be a dictionary with two entries "eeg" and "meg" to specify separate values for EEG and MEG fields respectively. Can be None to use the maximum value of the data.

New in v1.4: vmax can be a dictionary to specify separate values for EEG and MEG fields.

The number of contours.

Whether to draw the field density as an overlay on top of the helmet/head surface. Defaults to True.

Opacity of the meshes (between 0 and 1). Can be a dictionary with two entries "eeg" and "meg" to specify separate values for EEG and MEG fields respectively. Can be None to use 1.0 when a single field map is shown, or dict(eeg=1.0, meg=0.5) when both field maps are shown.

Interpolation method (scipy.interpolate.interp1d parameter). Must be one of 'linear', 'nearest', 'zero', 'slinear', 'quadratic' or 'cubic'.

How interactions with the scene via an input device (e.g., mouse or trackpad) modify the camera position. If 'terrain', one axis is fixed, enabling ‚Äúturntable-style‚Äù rotations. If 'trackball', movement along all axes is possible, which provides more freedom of movement, but you may incidentally perform unintentional rotations along some axes. Defaults to 'terrain'.

Display time viewer GUI. Can also be "auto", which will mean True if there is more than one time point and False otherwise.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Without the time viewer active, the figure is returned. With the time viewer active, an object is returned that can be used to control different aspects of the figure.

Using the event system to link figures

mne.viz.plot_evoked_joint

mne.viz.plot_evoked_white

---

## mne.viz.plot_evoked_image#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_evoked_image.html

**Contents:**
- mne.viz.plot_evoked_image#
- Examples using mne.viz.plot_evoked_image#

Plot evoked data as images.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided. This parameter can also be used to set the order the channels are shown in, as the channel image is sorted by the order of picks.

Channels names to exclude from being shown. If ‚Äòbads‚Äô, the bad channels are excluded.

Scale plot with channel (SI) unit.

Color limits for plots (after scaling has been applied). e.g. clim = dict(eeg=[-20, 20]). Valid keys are eeg, mag, grad, misc. If None, the clim parameter for each channel equals the pyplot default.

If true SSP projections are applied before display. If ‚Äòinteractive‚Äô, a check box for reversible selection of SSP projection vectors will be shown.

The units of the channel types used for axes labels. If None, defaults to dict(eeg='¬µV', grad='fT/cm', mag='fT').

The scalings of the channel types to be applied for plotting. If None,` defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

The titles associated with the channels. If None, defaults to dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers').

The axes to plot to. If list, the list must be a list of Axes of the same length as the number of channel types. If instance of Axes, there must be only one channel type plotted. If group_by is a dict, this cannot be a list, but it can be a dict of lists of axes, with the keys matching those of group_by. In that case, the provided axes will be used for the corresponding groups. Defaults to None.

Colormap. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the scale. Up and down arrows can be used to change the colormap. If ‚Äòinteractive‚Äô, translates to ('RdBu_r', True). Defaults to 'RdBu_r'.

If True, plot a colorbar. Defaults to True.

An array of booleans of the same shape as the data. Entries of the data that correspond to False in the mask are masked (see do_mask below). Useful for, e.g., masking for statistical significance.

If mask is not None: if ‚Äòcontour‚Äô, a contour line is drawn around the masked areas (True in mask). If ‚Äòmask‚Äô, entries not True in mask are shown transparently. If ‚Äòboth‚Äô, both a contour and transparency are used. If None, defaults to ‚Äòboth‚Äô if mask is not None, and is ignored otherwise.

The colormap chosen for masked parts of the image (see below), if mask is not None. If None, cmap is reused. Defaults to Greys. Not interactive. Otherwise, as cmap.

A float between 0 and 1. If mask is not None, this sets the alpha level (degree of transparency) for the masked-out segments. I.e., if 0, masked-out segments are not visible at all. Defaults to .25.

The units for the time axis, can be ‚Äúms‚Äù or ‚Äús‚Äù (default).

Determines if channel names should be plotted on the y axis. If False, no names are shown. If True, ticks are set automatically by matplotlib and the corresponding channel names are shown. If ‚Äúall‚Äù, all channel names are shown. If ‚Äúauto‚Äù, is set to False if picks is None, to True if picks contains 25 or more entries, or to ‚Äúall‚Äù if picks contains fewer than 25 entries.

If a dict, the values must be picks, and axes must also be a dict with matching keys, or None. If axes is None, one figure and one axis will be created for each entry in group_by.Then, for each entry, the picked channels will be plotted to the corresponding axis. If titles are None, keys will become plot titles. This is useful for e.g. ROIs. Each entry must contain only one channel type. For example:

If None, all picked channels are plotted to the same axis.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

Figure containing the images.

Analysing continuous features with binning and regression in sensor space

mne.viz.plot_evoked_topo

---

## mne.viz.plot_evoked_joint#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_evoked_joint.html

**Contents:**
- mne.viz.plot_evoked_joint#

Plot evoked data as butterfly plot and add topomaps for time points.

Axes to plot in can be passed by the user through ts_args or topomap_args. In that case both ts_args and topomap_args axes have to be used. Be aware that when the axes are provided, their position may be slightly modified.

The time point(s) to plot. If "auto", 5 evenly spaced topographies between the first and last time instant will be shown. If "peaks", finds time points automatically by checking for 3 local maxima in Global Field Power. Defaults to "peaks".

The title. If None, suppress printing channel type title. If an empty string, a default title is created. Defaults to ‚Äò‚Äô. If custom axes are passed make sure to set title=None, otherwise some of your axes may be removed during placement of the title axis.

Channels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.

Channels names to exclude from being shown. If 'bads', the bad channels are excluded. Defaults to 'bads'.

Show figure if True. Defaults to True.

A dict of kwargs that are forwarded to mne.Evoked.plot() to style the butterfly plot. If they are not in this dict, the following defaults are passed: spatial_colors=True, zorder='std'. show and exclude are illegal. If None, no customizable arguments will be passed. Defaults to None.

A dict of kwargs that are forwarded to mne.Evoked.plot_topomap() to style the topomaps. If it is not in this dict, outlines='head' will be passed. show, times, colorbar are illegal. If None, no customizable arguments will be passed. Defaults to None.

The figure object containing the plot. If evoked has multiple channel types, a list of figures, one for each channel type, is returned.

mne.viz.plot_evoked_topomap

mne.viz.plot_evoked_field

---

## mne.viz.plot_evoked_topomap#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_evoked_topomap.html

**Contents:**
- mne.viz.plot_evoked_topomap#

Plot topographic maps of specific time points of evoked data.

The time point(s) to plot. If ‚Äúauto‚Äù, the number of axes determines the amount of time point(s). If axes is also None, at most 10 topographies will be shown with a regular time spacing between the first and last time instant. If ‚Äúpeaks‚Äù, finds time points automatically by checking for local maxima in global field power. If ‚Äúinteractive‚Äù, the time can be set interactively at run-time by using a slider.

The time window (in seconds) around a given time point to be used for averaging. For example, 0.2 would translate into a time window that starts 0.1 s before and ends 0.1 s after the given time point. If the time window exceeds the duration of the data, it will be clipped. Different time windows (one per time point) can be provided by passing an array-like object (e.g., [0.1, 0.2, 0.3]). If None (default), no averaging will take place.

Changed in version 1.1: Support for array-like input.

The channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None the first available channel type from order shown above is used. Defaults to None.

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown. If 'reconstruct', projection vectors will be applied and then M/EEG data will be reconstructed via field mapping to reduce the signal bias caused by projection.

Changed in version 0.21: Support for ‚Äòreconstruct‚Äô was added.

Whether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.

If True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‚ÄòMEG ‚Äò from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.

Array indicating channel-time combinations to highlight with a distinct plotting style (useful for, e.g. marking which channels at which times a statistical test of the data reaches significance). Array elements set to True will be plotted with the parameters given in mask_params. Defaults to None, equivalent to an array of all False elements.

Additional plotting parameters for plotting significant sensors. Default (None) equals:

The number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in ¬µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.

The outlines to be drawn. If ‚Äòhead‚Äô, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‚Äòmask_pos‚Äô will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‚Äòhead‚Äô.

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

The image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.

Extrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.

Extrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.

Extrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.

Changed in version 0.21:

The default was changed to 'local' for MEG sensors.

'local' was changed to use a convex hull mask

'head' was changed to extrapolate out to the clipping circle.

Value to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.

The resolution of the topomap image (number of pixels along each side).

Side length of each subplot in inches.

Colormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.

Interactive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.

Lower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.

If both entries are None, the bounds are set at ¬± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim="joint", will compute the colormap limits jointly across all topomaps of the same channel type (instead of separately for each topomap), using the min/max of the data for that channel type. Defaults to (None, None).

How to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.

Plot a colorbar in the rightmost column of the figure.

Formatting string for colorbar tick labels. See Format Specification Mini-Language for details.

The units to use for the colorbar label. Ignored if colorbar=False. If None and scalings=None the unit is automatically determined, otherwise the label will be ‚ÄúAU‚Äù indicating arbitrary units. Default is None.

The axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of times provided (unless times is None). Default is None.

The units for the time axis, can be ‚Äúms‚Äù or ‚Äús‚Äù (default).

String format for topomap values. Defaults (None) to ‚Äú%01d ms‚Äù if time_unit='ms', ‚Äú%0.3f s‚Äù if time_unit='s', and ‚Äú%g‚Äù otherwise. Can be an empty string to omit the time label.

The number of rows and columns of topographies to plot. If either nrows or ncols is 'auto', the necessary number will be inferred. Defaults to nrows=1, ncols='auto'. Ignored when times == ‚Äòinteractive‚Äô.

Show the figure if True.

When existing axes are provided and colorbar=True, note that the colorbar scale will only accurately reflect topomaps that are generated in the same call as the colorbar. Note also that the colorbar will not be resized automatically when axes are provided; use Matplotlib‚Äôs axes.set_position() method or gridspec interface to adjust the colorbar size yourself.

The defaults for contours and vlim are handled as follows:

When neither vlim nor a list of contours is passed, MNE sets vlim at ¬± the maximum absolute value of the data and then chooses contours within those bounds.

When vlim but not a list of contours is passed, MNE chooses contours to be within the vlim.

When a list of contours but not vlim is passed, MNE chooses vlim to encompass the contours and the maximum absolute value of the data.

When both a list of contours and vlim are passed, MNE uses them as-is.

When time=="interactive", the figure will publish and subscribe to the following UI events:

TimeChange whenever a new time is selected.

mne.viz.plot_evoked_topo

mne.viz.plot_evoked_joint

---

## mne.viz.plot_evoked_topo#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_evoked_topo.html

**Contents:**
- mne.viz.plot_evoked_topo#
- Examples using mne.viz.plot_evoked_topo#

Plot 2D topography of evoked responses.

Clicking on the plot of an individual sensor opens a new figure showing the evoked response for the selected sensor.

The evoked response to plot.

Layout instance specifying sensor positions (does not need to be specified for Neuromag data). If possible, the correct layout is inferred from the data.

Scaling factor for adjusting the relative size of the layout on the canvas.

Everything matplotlib accepts to specify colors. If not list-like, the color specified will be repeated. If None, colors are automatically drawn.

Matplotlib borders style to be used for each sensor plot.

Y-axis limits for plots (after scaling has been applied). dict keys should match channel types; valid keys are for instance eeg, mag, grad, misc, csd, .. (example: ylim=dict(eeg=[-20, 20])). If None, the y-axis limits will be set automatically by matplotlib. Defaults to None.

The scalings of the channel types to be applied for plotting. If None,` defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

If true SSP projections are applied before display. If 'interactive', a check box for reversible selection of SSP projection vectors will be shown.

The values at which to show a vertical line.

A background image for the figure. This must work with a call to plt.imshow. Defaults to None.

Whether to use RMS value of gradiometer pairs. Only works for Neuromag data. Defaults to False.

If True, create a legend based on evoked.comment. If False, disable the legend. Otherwise, the legend is created and the parameter value is passed as the location parameter to the matplotlib legend call. It can be an integer (e.g. 0 corresponds to upper right corner of the plot), a string (e.g. 'upper right'), or a tuple (x, y coordinates of the lower left corner of the legend in the axes coordinate system). See matplotlib documentation for more details.

Axes to plot into. If None, axes will be created.

Background color. Typically 'k' (black) or 'w' (white; default).

Noise covariance used to whiten the data while plotting. Whitened data channel names are shown in italic. Can be a string to load a covariance from disk.

Channels names to exclude from the plot. If 'bads', the bad channels are excluded. By default, exclude is set to 'bads'.

Whether to enable the lasso-selection tool to enable the user to select channels. The selected channels will be available in fig.lasso.selection.

Channels names to exclude from the plot. If 'bads', the bad channels are excluded. By default, exclude is set to 'bads'.

Images of evoked responses at sensor locations.

Compare evoked responses for different conditions

Visualizing Evoked data

Preprocessing functional near-infrared spectroscopy (fNIRS) data

mne.viz.plot_evoked_image

mne.viz.plot_evoked_topomap

---

## mne.viz.plot_evoked_white#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_evoked_white.html

**Contents:**
- mne.viz.plot_evoked_white#
- Examples using mne.viz.plot_evoked_white#

Plot whitened evoked response.

Plots the whitened evoked response and the whitened GFP as described in [1]. This function is especially useful for investigating noise covariance properties to determine if data are properly whitened (e.g., achieving expected values in line with model assumptions, see Notes below).

The noise covariance. Can be a string to load a covariance from disk.

This controls the rank computation that can be read from the measurement info or estimated from the data. When a noise covariance is used for whitening, this should reflect the rank of that covariance, otherwise amplification of noise components can occur in whitening (e.g., often during source localization).

The rank will be estimated from the data after proper scaling of different channel types.

The rank is inferred from info. If data have been processed with Maxwell filtering, the Maxwell filtering header is used. Otherwise, the channel counts themselves are used. In both cases, the number of projectors is subtracted from the (effective) number of channels in the data. For example, if Maxwell filtering reduces the rank to 68, with two projectors the returned value will be 66.

The rank is assumed to be full, i.e. equal to the number of good channels. If a Covariance is passed, this can make sense if it has been (possibly improperly) regularized without taking into account the true data rank.

Calculate the rank only for a subset of channel types, and explicitly specify the rank for the remaining channel types. This can be extremely useful if you already know the rank of (part of) your data, for instance in case you have calculated it earlier.

This parameter must be a dictionary whose keys correspond to channel types in the data (e.g. 'meg', 'mag', 'grad', 'eeg'), and whose values are integers representing the respective ranks. For example, {'mag': 90, 'eeg': 45} will assume a rank of 90 and 45 for magnetometer data and EEG data, respectively.

The ranks for all channel types present in the data, but not specified in the dictionary will be estimated empirically. That is, if you passed a dataset containing magnetometer, gradiometer, and EEG data together with the dictionary from the previous example, only the gradiometer rank would be determined, while the specified magnetometer and EEG ranks would be taken for granted.

The units for the time axis, can be ‚Äúms‚Äù or ‚Äús‚Äù (default).

The sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. Can also be a str, in which case:

'auto': the sphere is fit to external digitization points first, and to external + EEG digitization points if the former fails.

'eeglab': the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz').

'extra': the sphere is fit to external digitization points.

'eeg': the sphere is fit to EEG digitization points.

'cardinal': the sphere is fit to cardinal digitization points.

'hpi': the sphere is fit to HPI coil digitization points.

Can also be a list of str, in which case the sphere is fit to the specified digitization points, which can be any combination of 'extra', 'eeg', 'cardinal', and 'hpi', as specified above. None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.

Changed in version 1.1: Added 'eeglab' option.

Changed in version 1.11: Added 'extra', 'eeg', 'cardinal', 'hpi' and list of str options.

List of axes to plot into.

If True, the lines are color coded by mapping physical sensor coordinates into color values. Spatially similar channels will have similar colors. Bad channels will be dotted. If False, the good channels are plotted black and bad channels red. If 'auto', uses True if channel locations are present, and False if channel locations are missing or if the data contains only a single channel. Defaults to 'auto'.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

The figure object containing the plot.

If baseline signals match the assumption of Gaussian white noise, values should be centered at 0, and be within 2 standard deviations (¬±1.96) for 95% of the time points. For the global field power (GFP), we expect it to fluctuate around a value of 1.

If one single covariance object is passed, the GFP panel (bottom) will depict different sensor types. If multiple covariance objects are passed as a list, the left column will display the whitened evoked responses for each channel based on the whitener from the noise covariance that has the highest log-likelihood. The left column will depict the whitened GFPs based on each estimator separately for each sensor type. Instead of numbers of channels the GFP display shows the estimated rank. Note. The rank estimation will be printed by the logger (if verbose=True) for each noise covariance estimator that is passed.

Engemann D. and Gramfort A. (2015) Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals, vol. 108, 328-342, NeuroImage.

Brainstorm Elekta phantom dataset tutorial

mne.viz.plot_evoked_field

---

## mne.viz.plot_ica_sources#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_ica_sources.html

**Contents:**
- mne.viz.plot_ica_sources#

Plot estimated latent sources given the unmixing matrix.

plot evolution of latent sources over time based on (Raw input)

plot latent source around event related time windows (Epochs input)

plot time-locking in ICA space (Evoked input)

The object to plot the sources from.

Indices of the independent components (ICs) to visualize. If an integer, represents the index of the IC to pick. Multiple ICs can be selected using a list of int or a slice. The indices are 0-indexed, so picks=1 will pick the second IC: ICA001. None will pick all independent components in the order fitted.

If inst is a Raw or an Evoked object, the first and last time point (in seconds) of the data to plot. If inst is a Raw object, start=None and stop=None will be translated into start=0. and stop=3., respectively. For Evoked, None refers to the beginning and end of the evoked signal. If inst is an Epochs object, specifies the index of the first and last epoch to show.

The window title. If None a default is provided.

Whether to halt program execution until the figure is closed. Useful for interactive selection of components in raw and epoch plotter. For evoked, this parameter has no effect. Defaults to False.

If True, show time axis relative to the raw.first_samp.

Whether to show scrollbars when the plot is initialized. Can be toggled after initialization by pressing z (‚Äúzen mode‚Äù) while the plot window is focused. Default is True.

Style of time labels on the horizontal axis. If 'float', labels will be number of seconds from the start of the recording. If 'clock', labels will show ‚Äúclock time‚Äù (hours/minutes/seconds) inferred from raw.info['meas_date']. Default is 'float'.

Whether to load all data (not just the visible portion) into RAM and apply preprocessing (e.g., projectors) to the full data array in a separate processor thread, instead of window-by-window during scrolling. The default None uses the MNE_BROWSER_PRECOMPUTE variable, which defaults to 'auto'. 'auto' compares available RAM space to the expected size of the precomputed data, and precomputes only if enough RAM is available. This is only used with the Qt backend.

Changed in version 1.0: Support for the MNE_BROWSER_PRECOMPUTE config variable.

Whether to use OpenGL when rendering the plot (requires pyopengl). May increase performance, but effect is dependent on system CPU and graphics hardware. Only works if using the Qt backend. Default is None, which will use False unless the user configuration variable MNE_BROWSER_USE_OPENGL is set to 'true', see mne.set_config().

A regex pattern applied to each annotation‚Äôs label. Matching labels remain visible, non-matching labels are hidden.

Dictionary of arguments to pass to compute_psd() in interactive mode. Ignored if inst is not supplied. If None, nothing is passed. Defaults to None.

Can be ‚Äúauto‚Äù, ‚Äúlight‚Äù, or ‚Äúdark‚Äù or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_BROWSER_THEME will be used, defaulting to ‚Äúauto‚Äù if it‚Äôs not found. Only supported by the 'qt' backend.

Can be ‚Äúchannels‚Äù, ‚Äúempty‚Äù, or ‚Äúhidden‚Äù to set the overview bar mode for the 'qt' backend. If None (default), the config option MNE_BROWSER_OVERVIEW_MODE will be used, defaulting to ‚Äúchannels‚Äù if it‚Äôs not found.

If True (default), a splash screen is shown during the application startup. Only applicable to the qt backend.

For raw and epoch instances, it is possible to select components for exclusion by clicking on the line. The selected components are added to ica.exclude on close.

MNE-Python provides two different backends for browsing plots (i.e., raw.plot(), epochs.plot(), and ica.plot_sources()). One is based on matplotlib, and the other is based on PyQtGraph. You can set the backend temporarily with the context manager mne.viz.use_browser_backend(), you can set it for the duration of a Python session using mne.viz.set_browser_backend(), and you can set the default for your computer via mne.set_config('MNE_BROWSER_BACKEND', 'matplotlib') (or 'qt').

For the PyQtGraph backend to run in IPython with block=False you must run the magic command %gui qt5 first.

To report issues with the PyQtGraph backend, please use the issues of mne-qt-browser.

mne.viz.plot_compare_evokeds

mne.viz.plot_ica_components

---

## mne.viz.plot_projs_joint#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_projs_joint.html

**Contents:**
- mne.viz.plot_projs_joint#
- Examples using mne.viz.plot_projs_joint#

Plot projectors and evoked jointly.

The projectors to plot.

The data to plot. Typically this is the evoked instance created from averaging the epochs used to create the projection.

Channels to show alongside the projected time courses. Typically these are the ground-truth channels for an artifact (e.g., 'eog' or 'ecg'). Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values 'all' to pick all channels, or 'data' to pick data channels. None (default) will pick no channels.

Keyword arguments to pass to mne.viz.plot_projs_topomap().

Show the figure if True.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

This function creates a figure with three columns:

The left shows the evoked data traces before (black) and after (green) projection.

The center shows the topomaps associated with each of the projectors.

The right again shows the data traces (black), but this time with:

The data projected onto each projector with a single normalization factor (solid lines). This is useful for seeing the relative power in each projection vector.

The data projected onto each projector with individual normalization factors (dashed lines). This is useful for visualizing each time course regardless of its power.

Additional data traces from picks_trace (solid yellow lines). This is useful for visualizing the ‚Äúground truth‚Äù of the time course, e.g. the measured EOG or ECG channel time courses.

Repairing artifacts with SSP

mne.viz.plot_projs_topomap

---

## mne.viz.plot_topo_image_epochs#

**URL:** https://mne.tools/stable/generated/mne.viz.plot_topo_image_epochs.html

**Contents:**
- mne.viz.plot_topo_image_epochs#

Plot Event Related Potential / Fields image on topographies.

System specific sensor positions.

The standard deviation of the Gaussian smoothing to apply along the epoch axis to apply in the image. If 0., no smoothing is applied.

The min value in the image. The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers.

The max value in the image. The unit is ¬µV for EEG channels, fT for magnetometers and fT/cm for gradiometers.

Whether to display a colorbar or not. If None a colorbar will be shown only if all channels are of the same type. Defaults to None.

If not None, order is used to reorder the epochs on the y-axis of the image. If it‚Äôs an array of int it should be of length the number of good epochs. If it‚Äôs a callable the arguments passed are the times vector and the data as 2d array (data.shape[1] == len(times)).

Colors to be mapped to the values.

Scaling factor for adjusting the relative size of the layout on the canvas.

The scalings of the channel types to be applied for plotting. If None, defaults to dict(eeg=1e6, grad=1e13, mag=1e15).

Matplotlib borders style to be used for each sensor plot.

The figure face color. Defaults to black.

A background image for the figure. This must be a valid input to matplotlib.pyplot.imshow(). Defaults to None.

The color of tick labels in the colorbar. Defaults to white.

Whether to enable the lasso-selection tool to enable the user to select channels. The selected channels will be available in fig.lasso.selection.

Whether to show the figure. Defaults to True.

Figure distributing one image per channel across sensor topography.

In an interactive Python session, this plot will be interactive; clicking on a channel image will pop open a larger view of the image; this image will always have a colorbar even when the topo plot does not (because it shows multiple sensor types).

mne.viz.plot_tfr_topomap

---

## mne.write_evokeds#

**URL:** https://mne.tools/stable/generated/mne.write_evokeds.html

**Contents:**
- mne.write_evokeds#

Write an evoked dataset to a file.

The file name, which should end with -ave.fif or -ave.fif.gz.

The evoked dataset, or list of evoked datasets, to save in one file. Note that the measurement info from the first evoked instance is used, so be sure that information matches.

Can be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when the device-to-head transformation differs between instances.

If True (default False), overwrite the destination file if it exists.

Control verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.

Changed in version 0.23: Information on baseline correction will be stored with each individual Evoked object, and will be restored when reading the data again via mne.read_evokeds.

mne.write_forward_solution

---

## Modifying data in-place#

**URL:** https://mne.tools/stable/auto_tutorials/intro/15_inplace.html

**Contents:**
- Modifying data in-place#
- Signal processing#
- Channel picking#
- The copy parameter#
- Summary#

Go to the end to download the full example code.

Many of MNE-Python‚Äôs data objects (Raw, Epochs, Evoked, etc) have methods that modify the data in-place (either optionally or obligatorily). This can be advantageous when working with large datasets because it reduces the amount of computer memory needed to perform the computations. However, it can lead to unexpected results if you‚Äôre not aware that it‚Äôs happening. This tutorial provides a few examples of in-place processing, and how and when to avoid it.

As usual we‚Äôll start by importing the modules we need and loading some example data:

Most MNE-Python data objects have built-in methods for filtering, including high-, low-, and band-pass filters (filter), band-stop filters (notch_filter), Hilbert transforms (apply_hilbert), and even arbitrary or user-defined functions (apply_function). These typically always modify data in-place, so if we want to preserve the unprocessed data for comparison, we must first make a copy of it. For example:

Another group of methods where data is modified in-place are the channel-picking methods. For example:

Note also that when picking only EEG channels, projectors that affected only the magnetometers were dropped, since there are no longer any magnetometer channels.

Above we saw an example of using the copy method to facilitate comparing data before and after processing. This is not needed when using certain MNE-Python functions, because they have a function parameter where you can specify copy=True (return a modified copy of the data) or copy=False (operate in-place). For example, mne.set_eeg_reference is one such function; notice that here we plot original_raw after the rereferencing has been done, but original_raw is unaffected because we specified copy=True:

Another example is the picking function mne.pick_info, which operates on mne.Info dictionaries rather than on data objects. See The Info data structure for details.

Generally speaking, you should expect that methods of data objects will operate in-place, and functions that take a data object as a parameter will operate on a copy of the data (unless the function has a copy parameter and it defaults to False or you specify copy=False). During the exploratory phase of your analysis, where you might want to try out the effects of different data cleaning approaches, you should get used to patterns like raw.copy().filter(...).plot() or raw.copy().apply_proj().compute_psd().plot() if you want to avoid having to re-load data and repeat earlier steps each time you change a computation (see the In-place operation section for more info on method chaining).

Total running time of the script: (0 minutes 5.080 seconds)

Download Jupyter notebook: 15_inplace.ipynb

Download Python source code: 15_inplace.py

Download zipped: 15_inplace.zip

Gallery generated by Sphinx-Gallery

Overview of MEG/EEG analysis with MNE-Python

Parsing events from raw data

---

## Most-used classes#

**URL:** https://mne.tools/stable/api/most_used_classes.html

**Contents:**
- Most-used classes#

io.Raw(fname[, allow_maxshield, preload, ...])

Raw data in FIF format.

Epochs(raw[, events, event_id, tmin, tmax, ...])

Epochs extracted from a Raw instance.

Evoked(fname[, condition, proj, kind, ...])

Info(*args, **kwargs)

Measurement information.

---

## Non-parametric 1 sample cluster statistic on single trial power#

**URL:** https://mne.tools/stable/auto_tutorials/stats-sensor-space/40_cluster_1samp_time_freq.html

**Contents:**
- Non-parametric 1 sample cluster statistic on single trial power#
- Set parameters#
- Define adjacency for statistics#
- Compute statistic#
- View time-frequency plots#

Go to the end to download the full example code.

This script shows how to estimate significant clusters in time-frequency power estimates. It uses a non-parametric statistical procedure based on permutations and cluster level statistics.

The procedure consists of:

compute single trial power estimates

baseline line correct the power estimates (power ratios)

compute stats to see if ratio deviates from 1.

Here, the unit of observation is epochs from a specific study subject. However, the same logic applies when the unit of observation is a number of study subjects each of whom contribute their own averaged data (i.e., an average of their epochs). This would then be considered an analysis at the ‚Äú2nd level‚Äù.

For more information on cluster-based permutation testing in MNE-Python, see also: Spatiotemporal permutation F-test on full sensor data.

To perform a cluster-based permutation test, we need a suitable definition for the adjacency of sensors, time points, and frequency bins. The adjacency matrix will be used to form clusters.

We first compute the sensor adjacency, and then combine that with a ‚Äúlattice‚Äù adjacency for the time-frequency plane, which assumes that elements at index ‚ÄúN‚Äù are adjacent to elements at indices ‚ÄúN + 1‚Äù and ‚ÄúN - 1‚Äù (forming a ‚Äúgrid‚Äù on the time-frequency plane).

For forming clusters, we need to specify a critical test statistic threshold. Only data bins exceeding this threshold will be used to form clusters.

Here, we use a t-test and can make use of Scipy‚Äôs percent point function of the t distribution to get a t-value that corresponds to a specific alpha level for significance. This threshold is often called the ‚Äúcluster forming threshold‚Äù.

The choice of the threshold is more or less arbitrary. Choosing a t-value corresponding to p=0.05, p=0.01, or p=0.001 may often provide a good starting point. Depending on the specific dataset you are working with, you may need to adjust the threshold.

We now visualize the observed clusters that are statistically significant under our permutation distribution.

Talking about ‚Äúsignificant clusters‚Äù can be convenient, but you must be aware of all associated caveats! For example, it is invalid to interpret the cluster p value as being spatially or temporally specific. A cluster with sufficiently low (for example < 0.05) p value at specific location does not allow you to say that the significant effect is at that particular location. The p value only tells you about the probability of obtaining similar or stronger/larger cluster anywhere in the data if there were no differences between the compared conditions. So it only allows you to draw conclusions about the differences in the data ‚Äúin general‚Äù, not at specific locations. See the comprehensive FieldTrip tutorial for more information. FieldTrip tutorial for more information.

Total running time of the script: (0 minutes 10.891 seconds)

Download Jupyter notebook: 40_cluster_1samp_time_freq.ipynb

Download Python source code: 40_cluster_1samp_time_freq.py

Download zipped: 40_cluster_1samp_time_freq.zip

Gallery generated by Sphinx-Gallery

Visualising statistical significance thresholds on EEG data

Non-parametric between conditions cluster statistic on single trial power

---

## Non-parametric between conditions cluster statistic on single trial power#

**URL:** https://mne.tools/stable/auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html

**Contents:**
- Non-parametric between conditions cluster statistic on single trial power#
- Compute statistic#
- View time-frequency plots#

Go to the end to download the full example code.

This script shows how to compare clusters in time-frequency power estimates between conditions. It uses a non-parametric statistical procedure based on permutations and cluster level statistics.

The procedure consists of:

extracting epochs for 2 conditions

compute single trial power estimates

baseline line correct the power estimates (power ratios)

compute stats to see if the power estimates are significantly different between conditions.

Factor to downsample the temporal dimension of the TFR computed by tfr_morlet. Decimation occurs after frequency decomposition and can be used to reduce memory usage (and possibly comptuational time of downstream operations such as nonparametric statistics) if you don‚Äôt need high spectrotemporal resolution.

Total running time of the script: (0 minutes 1.606 seconds)

Download Jupyter notebook: 50_cluster_between_time_freq.ipynb

Download Python source code: 50_cluster_between_time_freq.py

Download zipped: 50_cluster_between_time_freq.zip

Gallery generated by Sphinx-Gallery

Non-parametric 1 sample cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

---

## Overview of artifact detection#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/10_preprocessing_overview.html

**Contents:**
- Overview of artifact detection#
- What are artifacts?#
- What to do about artifacts#
- Artifact detection#
  - Low-frequency drifts#
  - Power line noise#
  - Heartbeat artifacts (ECG)#
  - Ocular artifacts (EOG)#
- Summary#

Go to the end to download the full example code.

This tutorial covers the basics of artifact detection, and introduces the artifact detection tools available in MNE-Python.

We begin as always by importing the necessary Python modules and loading some example data:

Artifacts are parts of the recorded signal that arise from sources other than the source of interest (i.e., neuronal activity in the brain). As such, artifacts are a form of interference or noise relative to the signal of interest. There are many possible causes of such interference, for example:

Persistent oscillations centered around the AC power line frequency (typically 50 or 60 Hz)

Brief signal jumps due to building vibration (such as a door slamming)

Electromagnetic field noise from nearby elevators, cell phones, the geomagnetic field, etc.

Electromagnetic interference from stimulus presentation (such as EEG sensors picking up the field generated by unshielded headphones)

Continuous oscillations at specific frequencies used by head position indicator (HPI) coils

Random high-amplitude fluctuations (or alternatively, constant zero signal) in a single channel due to sensor malfunction (e.g., in surface electrodes, poor scalp contact)

Periodic QRS-like signal patterns (especially in magnetometer channels) due to electrical activity of the heart

Short step-like deflections (especially in frontal EEG channels) due to eye movements

Large transient deflections (especially in frontal EEG channels) due to blinking

Brief bursts of high frequency fluctuations across several channels due to the muscular activity during swallowing

There are also some cases where signals from within the brain can be considered artifactual. For example, if a researcher is primarily interested in the sensory response to a stimulus, but the experimental paradigm involves a behavioral response (such as button press), the neural activity associated with the planning and executing the button press could be considered an artifact relative to signal of interest (i.e., the evoked sensory response).

Artifacts of the same genesis may appear different in recordings made by different EEG or MEG systems, due to differences in sensor design (e.g., passive vs. active EEG electrodes; axial vs. planar gradiometers, etc).

There are 3 basic options when faced with artifacts in your recordings:

Ignore the artifact and carry on with analysis

Exclude the corrupted portion of the data and analyze the remaining data

Repair the artifact by suppressing artifactual part of the recording while (hopefully) leaving the signal of interest intact

There are many different approaches to repairing artifacts, and MNE-Python includes a variety of tools for artifact repair, including digital filtering, independent components analysis (ICA), Maxwell filtering / signal-space separation (SSS), and signal-space projection (SSP). Separate tutorials demonstrate each of these techniques for artifact repair. Many of the artifact repair techniques work on both continuous (raw) data and on data that has already been epoched (though not necessarily equally well); some can be applied to memory-mapped data while others require the data to be copied into RAM. Of course, before you can choose any of these strategies you must first detect the artifacts, which is the topic of the next section.

MNE-Python includes a few tools for automated detection of certain artifacts (such as heartbeats and blinks), but of course you can always visually inspect your data to identify and annotate artifacts as well.

We saw in the introductory tutorial that the example data includes SSP projectors, so before we look at artifacts let‚Äôs set aside the projectors in a separate variable and then remove them from the Raw object using the del_proj() method, so that we can inspect our data in it‚Äôs original, raw state:

Low-frequency drifts are most readily detected by visual inspection using the basic plot() method, though it is helpful to plot a relatively long time span and to disable channel-wise DC shift correction. Here we plot 60 seconds and show all the magnetometer channels:

Low-frequency drifts are readily removed by high-pass filtering at a fairly low cutoff frequency (the wavelength of the drifts seen above is probably around 20 seconds, so in this case a cutoff of 0.1 Hz would probably suppress most of the drift).

Power line artifacts are easiest to see on plots of the spectrum, so we‚Äôll use compute_psd() to illustrate.

Here we see narrow frequency peaks at 60, 120, 180, and 240 Hz ‚Äî the power line frequency of the USA (where the sample data was recorded) and its 2nd, 3rd, and 4th harmonics. Other peaks (around 25 to 30 Hz, and the second harmonic of those) are probably related to the heartbeat, which is more easily seen in the time domain using a dedicated heartbeat detection function as described in the next section.

MNE-Python includes a dedicated function find_ecg_events() in the mne.preprocessing submodule, for detecting heartbeat artifacts from either dedicated ECG channels or from magnetometers (if no ECG channel is present). Additionally, the function create_ecg_epochs() will call find_ecg_events() under the hood, and use the resulting events array to extract epochs centered around the detected heartbeat artifacts. Here we create those epochs, then show an image plot of the detected ECG artifacts along with the average ERF across artifacts. We‚Äôll show all three channel types, even though EEG channels are less strongly affected by heartbeat artifacts:

The horizontal streaks in the magnetometer image plot reflect the fact that the heartbeat artifacts are superimposed on low-frequency drifts like the one we saw in an earlier section; to avoid this you could pass baseline=(-0.5, -0.2) in the call to create_ecg_epochs(). You can also get a quick look at the ECG-related field pattern across sensors by averaging the ECG epochs together via the average() method, and then using the mne.Evoked.plot_topomap() method:

Here again we can visualize the spatial pattern of the associated field at various times relative to the peak of the EOG response:

Or, we can get an ERP/F plot with plot() or a combined scalp field maps and ERP/F plot with plot_joint(). Here we‚Äôve specified the times for scalp field maps manually, but if not provided they will be chosen automatically based on peaks in the signal:

Similar to the ECG detection and epoching methods described above, MNE-Python also includes functions for detecting and extracting ocular artifacts: find_eog_events() and create_eog_epochs(). Once again we‚Äôll use the higher-level convenience function that automatically finds the artifacts and extracts them in to an Epochs object in one step. Unlike the heartbeat artifacts seen above, ocular artifacts are usually most prominent in the EEG channels, but we‚Äôll still show all three channel types. We‚Äôll use the baseline parameter this time too; note that there are many fewer blinks than heartbeats, which makes the image plots appear somewhat blocky:

Familiarizing yourself with typical artifact patterns and magnitudes is a crucial first step in assessing the efficacy of later attempts to repair those artifacts. A good rule of thumb is that the artifact amplitudes should be orders of magnitude larger than your signal of interest ‚Äî and there should be several occurrences of such events ‚Äî in order to find signal decompositions that effectively estimate and repair the artifacts.

Several other tutorials in this section illustrate the various tools for artifact repair, and discuss the pros and cons of each technique, for example:

Repairing artifacts with SSP

Repairing artifacts with ICA

Signal-space separation (SSS) and Maxwell filtering

There are also tutorials on general-purpose preprocessing steps such as filtering and resampling and excluding bad channels or spans of data.

Total running time of the script: (0 minutes 22.386 seconds)

Download Jupyter notebook: 10_preprocessing_overview.ipynb

Download Python source code: 10_preprocessing_overview.py

Download zipped: 10_preprocessing_overview.zip

Gallery generated by Sphinx-Gallery

Handling bad channels

---

## Overview of MEG/EEG analysis with MNE-Python#

**URL:** https://mne.tools/stable/auto_tutorials/intro/10_overview.html

**Contents:**
- Overview of MEG/EEG analysis with MNE-Python#
- Loading data#
- Preprocessing#
- Detecting experimental events#
- Epoching continuous data#
- Time-frequency analysis#
- Estimating evoked responses#
- Inverse modeling#

Go to the end to download the full example code.

This tutorial covers the basic EEG/MEG pipeline for event-related analysis: loading data, epoching, averaging, plotting, and estimating cortical activity from sensor data. It introduces the core MNE-Python data structures Raw, Epochs, Evoked, and SourceEstimate, and covers a lot of ground fairly quickly (at the expense of depth). Subsequent tutorials address each of these topics in greater detail.

We begin by importing the necessary Python modules:

MNE-Python data structures are based around the FIF file format from Neuromag, but there are reader functions for a wide variety of other data formats. MNE-Python also has interfaces to a variety of publicly available datasets, which MNE-Python can download and manage for you.

We‚Äôll start this tutorial by loading one of the example datasets (called ‚ÄúSample‚Äù), which contains EEG and MEG data from one subject performing an audiovisual experiment, along with structural MRI scans for that subject. The mne.datasets.sample.data_path function will automatically download the dataset if it isn‚Äôt found in one of the expected locations, then return the directory path to the dataset (see the documentation of data_path for a list of places it checks before downloading). Note also that for this tutorial to run smoothly on our servers, we‚Äôre using a filtered and downsampled version of the data (sample_audvis_filt-0-40_raw.fif), but an unfiltered version (sample_audvis_raw.fif) is also included in the sample dataset and could be substituted here when running the tutorial locally.

By default, read_raw_fif displays some information about the file it‚Äôs loading; for example, here it tells us that there are four ‚Äúprojection items‚Äù in the file along with the recorded data; those are SSP projectors calculated to remove environmental noise from the MEG signals, plus a projector to mean-reference the EEG channels; these are discussed in the tutorial Background on projectors and projections. In addition to the information displayed during loading, you can get a glimpse of the basic details of a Raw object by printing it; even more is available by printing its info attribute (a dictionary-like object that is preserved across Raw, Epochs, and Evoked objects). The info data structure keeps track of channel locations, applied filters, projectors, etc. Notice especially the chs entry, showing that MNE-Python detects different sensor types and handles each appropriately. See The Info data structure for more on the Info class.

Raw objects also have several built-in plotting methods; here we show the power spectral density (PSD) for each sensor type with compute_psd, as well as a plot of the raw sensor traces with plot. In the PSD plot, we‚Äôll only plot frequencies below 50 Hz (since our data are low-pass filtered at 40 Hz). In interactive Python sessions, plot is interactive and allows scrolling, scaling, bad channel marking, annotations, projector toggling, etc.

MNE-Python supports a variety of preprocessing approaches and techniques (maxwell filtering, signal-space projection, independent components analysis, filtering, downsampling, etc); see the full list of capabilities in the mne.preprocessing and mne.filter submodules. Here we‚Äôll clean up our data by performing independent components analysis (ICA); for brevity we‚Äôll skip the steps that helped us determined which components best capture the artifacts (see Repairing artifacts with ICA for a detailed walk-through of that process).

Once we‚Äôre confident about which component(s) we want to remove, we pass them as the exclude parameter and then apply the ICA to the raw signal. The apply method requires the raw data to be loaded into memory (by default it‚Äôs only read from disk as-needed), so we‚Äôll use load_data first. We‚Äôll also make a copy of the Raw object so we can compare the signal before and after artifact removal side-by-side:

The sample dataset includes several ‚ÄúSTIM‚Äù channels that recorded electrical signals sent from the stimulus delivery computer (as brief DC shifts / squarewave pulses). These pulses (often called ‚Äútriggers‚Äù) are used in this dataset to mark experimental events: stimulus onset, stimulus type, and participant response (button press). The individual STIM channels are combined onto a single channel, in such a way that voltage levels on that channel can be unambiguously decoded as a particular event type. On older Neuromag systems (such as that used to record the sample data) this summation channel was called STI 014, so we can pass that channel name to the mne.find_events function to recover the timing and identity of the stimulus events.

The resulting events array is an ordinary 3-column NumPy array, with sample number in the first column and integer event ID in the last column; the middle column is usually ignored. Rather than keeping track of integer event IDs, we can provide an event dictionary that maps the integer IDs to experimental conditions or events. In this dataset, the mapping looks like this:

auditory stimulus (tone) to the left ear

auditory stimulus (tone) to the right ear

visual stimulus (checkerboard) to the left visual field

visual stimulus (checkerboard) to the right visual field

smiley face (catch trial)

Event dictionaries like this one are used when extracting epochs from continuous data; the / character in the dictionary keys allows pooling across conditions by requesting partial condition descriptors (i.e., requesting 'auditory' will select all epochs with Event IDs 1 and 2; requesting 'left' will select all epochs with Event IDs 1 and 3). An example of this is shown in the next section. There is also a convenient plot_events function for visualizing the distribution of events across the duration of the recording (to make sure event detection worked as expected). Here we will also make use of the Info attribute to get the sampling frequency of the recording (so our x-axis will be in seconds instead of in samples).

For paradigms that are not event-related (e.g., analysis of resting-state data), you can extract regularly spaced (possibly overlapping) spans of data by creating events using mne.make_fixed_length_events and then proceeding with epoching as described in the next section.

The Raw object and the events array are the bare minimum needed to create an Epochs object, which we create with the Epochs class constructor. Here we‚Äôll also specify some data quality constraints: we‚Äôll reject any epoch where peak-to-peak signal amplitude is beyond reasonable limits for that channel type. This is done with a rejection dictionary; you may include or omit thresholds for any of the channel types present in your data. The values given here are reasonable for this particular dataset, but may need to be adapted for different hardware or recording conditions. For a more automated approach, consider using the autoreject package.

We‚Äôll also pass the event dictionary as the event_id parameter (so we can work with easy-to-pool event labels instead of the integer event IDs), and specify tmin and tmax (the time relative to each event at which to start and end each epoch). As mentioned above, by default Raw and Epochs data aren‚Äôt loaded into memory (they‚Äôre accessed from disk only when needed), but here we‚Äôll force loading into memory using the preload=True parameter so that we can see the results of the rejection criteria being applied:

Next we‚Äôll pool across left/right stimulus presentations so we can compare auditory versus visual responses. To avoid biasing our signals to the left or right, we‚Äôll use equalize_event_counts first to randomly sample epochs from each condition to match the number of epochs present in the condition with the fewest good epochs.

Like Raw objects, Epochs objects also have a number of built-in plotting methods. One is plot_image, which shows each epoch as one row of an image map, with color representing signal magnitude; the average evoked response and the sensor location are shown below the image:

Both Raw and Epochs objects have get_data methods that return the underlying data as a NumPy array. Both methods have a picks parameter for subselecting which channel(s) to return; raw.get_data() has additional parameters for restricting the time domain. The resulting matrices have dimension (n_channels, n_times) for Raw and (n_epochs, n_channels, n_times) for Epochs.

The mne.time_frequency submodule provides implementations of several algorithms to compute time-frequency representations, power spectral density, and cross-spectral density. Here, for example, we‚Äôll compute for the auditory epochs the induced power at different frequencies and times, using Morlet wavelets. On this dataset the result is not especially informative (it just shows the evoked ‚Äúauditory N100‚Äù response); see here for a more extended example on a dataset with richer frequency content.

Now that we have our conditions in aud_epochs and vis_epochs, we can get an estimate of evoked responses to auditory versus visual stimuli by averaging together the epochs in each condition. This is as simple as calling the average method on the Epochs object, and then using a function from the mne.viz module to compare the global field power for each sensor type of the two Evoked objects:

We can also get a more detailed view of each Evoked object using other plotting methods such as plot_joint or plot_topomap. Here we‚Äôll examine just the EEG channels, and see the classic auditory evoked N100-P200 pattern over dorso-frontal electrodes, then plot scalp topographies at some additional arbitrary times:

Evoked objects can also be combined to show contrasts between conditions, using the mne.combine_evoked function. A simple difference can be generated by passing weights=[1, -1]. We‚Äôll then plot the difference wave at each sensor using plot_topo:

Finally, we can estimate the origins of the evoked activity by projecting the sensor data into this subject‚Äôs source space (a set of points either on the cortical surface or within the cortical volume of that subject, as estimated by structural MRI scans). MNE-Python supports lots of ways of doing this (dynamic statistical parametric mapping, dipole fitting, beamformers, etc.); here we‚Äôll use minimum-norm estimation (MNE) to generate a continuous map of activation constrained to the cortical surface. MNE uses a linear inverse operator to project EEG+MEG sensor measurements into the source space. The inverse operator is computed from the forward solution for this subject and an estimate of the covariance of sensor measurements. For this tutorial we‚Äôll skip those computational steps and load a pre-computed inverse operator from disk (it‚Äôs included with the sample data). Because this ‚Äúinverse problem‚Äù is underdetermined (there is no unique solution), here we further constrain the solution by providing a regularization parameter specifying the relative smoothness of the current estimates in terms of a signal-to-noise ratio (where ‚Äúnoise‚Äù here is akin to baseline activity level across all of cortex).

Finally, in order to plot the source estimate on the subject‚Äôs cortical surface we‚Äôll also need the path to the sample subject‚Äôs structural MRI files (the subjects_dir):

The remaining tutorials have much more detail on each of these topics (as well as many other capabilities of MNE-Python not mentioned here: connectivity analysis, encoding/decoding models, lots more visualization options, etc). Read on to learn more!

Total running time of the script: (0 minutes 40.302 seconds)

Download Jupyter notebook: 10_overview.ipynb

Download Python source code: 10_overview.py

Download zipped: 10_overview.zip

Gallery generated by Sphinx-Gallery

Introductory tutorials

Modifying data in-place

---

## Parsing events from raw data#

**URL:** https://mne.tools/stable/auto_tutorials/intro/20_events_from_raw.html

**Contents:**
- Parsing events from raw data#
- The Events and Annotations data structures#
- What is a STIM channel?#
- Converting a STIM channel signal to an Events array#
- Reading embedded events as Annotations#
- Converting between Events arrays and Annotations objects#
- Making multiple events per annotation#

Go to the end to download the full example code.

This tutorial describes how to read experimental events from raw recordings, and how to convert between the two different representations of events within MNE-Python (Events arrays and Annotations objects).

In the introductory tutorial we saw an example of reading experimental events from a ‚ÄúSTIM‚Äù channel; here we‚Äôll discuss events and annotations more broadly, give more detailed information about reading from STIM channels, and give an example of reading events that are in a marker file or included in the data file as an embedded array. The tutorials Working with events and Annotating continuous data discuss how to plot, combine, load, save, and export events and Annotations (respectively), and the latter tutorial also covers interactive annotation of Raw objects.

We‚Äôll begin by loading the Python modules we need, and loading the same example data we used in the introductory tutorial, but to save memory we‚Äôll crop the Raw object to just 60 seconds before loading it into RAM:

Generally speaking, both the Events and Annotations data structures serve the same purpose: they provide a mapping between times during an EEG/MEG recording and a description of what happened at those times. In other words, they associate a when with a what. The main differences are:

Units: the Events data structure represents the when in terms of samples, whereas the Annotations data structure represents the when in seconds.

Limits on the description: the Events data structure represents the what as an integer ‚ÄúEvent ID‚Äù code, whereas the Annotations data structure represents the what as a string.

How duration is encoded: Events in an Event array do not have a duration (though it is possible to represent duration with pairs of onset/offset events within an Events array), whereas each element of an Annotations object necessarily includes a duration (though the duration can be zero if an instantaneous event is desired).

Internal representation: Events are stored as an ordinary NumPy array, whereas Annotations is a list-like class defined in MNE-Python.

A stim channel (short for ‚Äústimulus channel‚Äù) is a channel that does not receive signals from an EEG, MEG, or other sensor. Instead, STIM channels record voltages (usually short, rectangular DC pulses of fixed magnitudes sent from the experiment-controlling computer) that are time-locked to experimental events, such as the onset of a stimulus or a button-press response by the subject (those pulses are sometimes called TTL pulses, event pulses, trigger signals, or just ‚Äútriggers‚Äù). In other cases, these pulses may not be strictly time-locked to an experimental event, but instead may occur in between trials to indicate the type of stimulus (or experimental condition) that is about to occur on the upcoming trial.

The DC pulses may be all on one STIM channel (in which case different experimental events or trial types are encoded as different voltage magnitudes), or they may be spread across several channels, in which case the channel(s) on which the pulse(s) occur can be used to encode different events or conditions. Even on systems with multiple STIM channels, there is often one channel that records a weighted sum of the other STIM channels, in such a way that voltage levels on that channel can be unambiguously decoded as particular event types. On older Neuromag systems (such as that used to record the sample data) this ‚Äúsummation channel‚Äù was typically STI 014; on newer systems it is more commonly STI101. You can see the STIM channels in the raw data file here:

You can see that STI 014 (the summation channel) contains pulses of different magnitudes whereas pulses on other channels have consistent magnitudes. You can also see that every time there is a pulse on one of the other STIM channels, there is a corresponding pulse on STI 014.

If your data has events recorded on a STIM channel, you can convert them into an events array using find_events. The sample number of the onset (or offset) of each pulse is recorded as the event time, the pulse magnitudes are converted into integers, and these pairs of sample numbers plus integer codes are stored in NumPy arrays (usually called ‚Äúthe events array‚Äù or just ‚Äúthe events‚Äù). In its simplest form, the function requires only the Raw object, and the name of the channel(s) from which to read events:

The middle column of the Events array

MNE-Python events are actually three values: in between the sample number and the integer event code is a value indicating what the event code was on the immediately preceding sample. In practice, that value is almost always 0, but it can be used to detect the endpoint of an event whose duration is longer than one sample. See the documentation of find_events for more details.

If you don‚Äôt provide the name of a STIM channel, find_events will first look for MNE-Python config variables for variables MNE_STIM_CHANNEL, MNE_STIM_CHANNEL_1, etc. If those are not found, channels STI 014 and STI101 are tried, followed by the first channel with type ‚ÄúSTIM‚Äù present in raw.ch_names. If you regularly work with data from several different MEG systems with different STIM channel names, setting the MNE_STIM_CHANNEL config variable may not be very useful, but for researchers whose data is all from a single system it can be a time-saver to configure that variable once and then forget about it.

find_events has several options, including options for aligning events to the onset or offset of the STIM channel pulses, setting the minimum pulse duration, and handling of consecutive pulses (with no return to zero between them). For example, you can effectively encode event duration by passing output='step' to find_events; see the documentation of find_events for details. More information on working with events arrays (including how to plot, combine, load, and save event arrays) can be found in the tutorial Working with events.

Some EEG/MEG systems generate files where events are stored in a separate data array rather than as pulses on one or more STIM channels. For example, the EEGLAB format stores events as a collection of arrays in the .set file. When reading those files, MNE-Python will automatically convert the stored events into an Annotations object and store it as the annotations attribute of the Raw object:

The core data within an Annotations object is accessible through three of its attributes: onset, duration, and description. Here we can see that there were 154 events stored in the EEGLAB file, they all had a duration of zero seconds, there were two different types of events, and the first event occurred about 1 second after the recording began:

More information on working with Annotations objects, including how to add annotations to Raw objects interactively, and how to plot, concatenate, load, save, and export Annotations objects can be found in the tutorial Annotating continuous data.

Once your experimental events are read into MNE-Python (as either an Events array or an Annotations object), you can easily convert between the two formats as needed. You might do this because, e.g., an Events array is needed for epoching continuous data, or because you want to take advantage of the ‚Äúannotation-aware‚Äù capability of some functions, which automatically omit spans of data if they overlap with certain annotations.

To convert an Annotations object to an Events array, use the function mne.events_from_annotations on the Raw file containing the annotations. This function will assign an integer Event ID to each unique element of raw.annotations.description, and will return the mapping of descriptions to integer Event IDs along with the derived Event array. By default, one event will be created at the onset of each annotation; this can be modified via the chunk_duration parameter of events_from_annotations to create equally spaced events within each annotation span (see Making multiple events per annotation, below, or see Making equally-spaced Events arrays for direct creation of an Events array of equally-spaced events).

If you want to control which integers are mapped to each unique description value, you can pass a dict specifying the mapping as the event_id parameter of events_from_annotations; this dict will be returned unmodified as the event_dict.

Note that this event_dict can be used when creating Epochs from Raw objects, as demonstrated in the tutorial The Epochs data structure: discontinuous data.

To make the opposite conversion (from an Events array to an Annotations object), you can create a mapping from integer Event ID to string descriptions, use annotations_from_events to construct the Annotations object, and call the set_annotations method to add the annotations to the Raw object.

Because the sample data was recorded on a Neuromag system (where sample numbering starts when the acquisition system is initiated, not when the recording is initiated), we also need to pass in the orig_time parameter so that the onsets are properly aligned relative to the start of recording:

Now, the annotations will appear automatically when plotting the raw data, and will be color-coded by their label value:

As mentioned above, you can generate equally-spaced events from an Annotations object using the chunk_duration parameter of events_from_annotations. For example, suppose we have an annotation in our Raw object indicating when the subject was in REM sleep, and we want to perform a resting-state analysis on those spans of data. We can create an Events array with a series of equally-spaced events within each ‚ÄúREM‚Äù span, and then use those events to generate (potentially overlapping) epochs that we can analyze further.

Now we can check that our events indeed fall in the ranges 5-21 seconds and 41-52 seconds, and are ~1.5 seconds apart (modulo some jitter due to the sampling frequency). Here are the event times rounded to the nearest millisecond:

Other examples of resting-state analysis can be found in the online documentation for make_fixed_length_events.

Total running time of the script: (0 minutes 4.570 seconds)

Download Jupyter notebook: 20_events_from_raw.ipynb

Download Python source code: 20_events_from_raw.py

Download zipped: 20_events_from_raw.zip

Gallery generated by Sphinx-Gallery

Modifying data in-place

The Info data structure

---

## Permutation F-test on sensor data with 1D cluster level#

**URL:** https://mne.tools/stable/auto_examples/stats/cluster_stats_evoked.html

**Contents:**
- Permutation F-test on sensor data with 1D cluster level#

Go to the end to download the full example code.

One tests if the evoked response is significantly different between conditions. Multiple comparison problem is addressed with cluster level permutation test.

Read epochs for the channel of interest

Download Jupyter notebook: cluster_stats_evoked.ipynb

Download Python source code: cluster_stats_evoked.py

Download zipped: cluster_stats_evoked.zip

Gallery generated by Sphinx-Gallery

FDR correction on T-test on sensor data

---

## Permutation t-test on source data with spatio-temporal clustering#

**URL:** https://mne.tools/stable/auto_tutorials/stats-source-space/20_cluster_1samp_spatiotemporal.html

**Contents:**
- Permutation t-test on source data with spatio-temporal clustering#
- Set parameters#
- Read epochs for all channels, removing a bad one#
- Transform to source space#
- Transform to common cortical space#
- Find adjacency matrix#
- Compute statistic#
- Selecting ‚Äúsignificant‚Äù clusters#
- Visualize the clusters#

Go to the end to download the full example code.

This example tests if the evoked response is significantly different between two conditions across subjects. Here just for demonstration purposes we simulate data from multiple subjects using one subject‚Äôs data. The multiple comparisons problem is addressed with a cluster-level permutation test across space and time.

Normally you would read in estimates across several subjects and morph them to the same cortical space (e.g., fsaverage). For example purposes, we will simulate this by just having each ‚Äúsubject‚Äù have the same response (just noisy in source space) here.

Note that for 6 subjects with a two-sided statistical test, the minimum significance under a permutation test is only p = 1/(2 ** 6) = 0.015, which is large.

It‚Äôs a good idea to spatially smooth the data, and for visualization purposes, let‚Äôs morph these to fsaverage, which is a grade 5 source space with vertices 0:10242 for each hemisphere. Usually you‚Äôd have to morph each subject‚Äôs data separately (and you might want to use morph_data instead), but here since all estimates are on ‚Äòsample‚Äô we can use one morph matrix for all the heavy lifting.

Finally, we want to compare the overall activity levels in each condition, the diff is taken along the last axis (condition). The negative sign makes it so condition1 > condition2 shows up as ‚Äúred blobs‚Äù (instead of blue).

For cluster-based permutation testing, we must define adjacency relations that govern which points can become members of the same cluster. While these relations are rather obvious for dimensions such as time or frequency they require a bit more work for spatial dimension such as channels or source vertices.

Here, to use an algorithm optimized for spatio-temporal clustering, we just pass the spatial adjacency matrix (instead of spatio-temporal). But note that clustering still takes place along the temporal dimension and can be controlled via the max_step parameter in mne.stats.spatio_temporal_cluster_1samp_test().

If we wanted to specify an adjacency matrix for both space and time explicitly we would have to use mne.stats.combine_adjacency(), however for the present case, this is not needed.

After performing the cluster-based permutationt test, you may wish to select the observed clusters that can be considered statistically significant under the permutation distribution. This can easily be done using the code snippet below.

However, it is crucial to be aware that a statistically significant observed cluster does not directly translate into statistical significance of the channels, time points, frequency bins, etc. that form the cluster!

For more information, see the FieldTrip tutorial.

Total running time of the script: (0 minutes 10.019 seconds)

Download Jupyter notebook: 20_cluster_1samp_spatiotemporal.ipynb

Download Python source code: 20_cluster_1samp_spatiotemporal.py

Download zipped: 20_cluster_1samp_spatiotemporal.zip

Gallery generated by Sphinx-Gallery

Statistical analysis of source estimates

2 samples permutation test on source data with spatio-temporal clustering

---

## Plotting EEG sensors on the scalp#

**URL:** https://mne.tools/stable/auto_examples/visualization/eeg_on_scalp.html

**Contents:**
- Plotting EEG sensors on the scalp#

Go to the end to download the full example code.

In this example, digitized EEG sensor locations are shown on the scalp surface.

Total running time of the script: (0 minutes 1.131 seconds)

Download Jupyter notebook: eeg_on_scalp.ipynb

Download Python source code: eeg_on_scalp.py

Download zipped: eeg_on_scalp.zip

Gallery generated by Sphinx-Gallery

Visualize channel over epochs as an image

Plotting topographic arrowmaps of evoked data

---

## Plotting topographic arrowmaps of evoked data#

**URL:** https://mne.tools/stable/auto_examples/visualization/evoked_arrowmap.html

**Contents:**
- Plotting topographic arrowmaps of evoked data#
- References#

Go to the end to download the full example code.

Load evoked data and plot arrowmaps along with the topomap for selected time points. An arrowmap is based upon the Hosaka-Cohen transformation and represents an estimation of the current flow underneath the MEG sensors. They are a poor man‚Äôs MNE.

David Cohen and Hidehiro Hosaka. Part II magnetic field produced by a current dipole. Journal of Electrocardiology, 9(4):409‚Äì417, 1976. doi:10.1016/S0022-0736(76)80041-6.

Plot magnetometer data as an arrowmap along with the topoplot at the time of the maximum sensor space activity:

Plot gradiometer data as an arrowmap along with the topoplot at the time of the maximum sensor space activity:

Since Vectorview 102 system perform sparse spatial sampling of the magnetic field, data from the Vectorview (info_from) can be projected to the high density CTF 272 system (info_to) for visualization

Plot gradiometer data as an arrowmap along with the topoplot at the time of the maximum sensor space activity:

Total running time of the script: (0 minutes 21.245 seconds)

Download Jupyter notebook: evoked_arrowmap.ipynb

Download Python source code: evoked_arrowmap.py

Download zipped: evoked_arrowmap.zip

Gallery generated by Sphinx-Gallery

Plotting EEG sensors on the scalp

Plotting topographic maps of evoked data

---

## Plotting topographic maps of evoked data#

**URL:** https://mne.tools/stable/auto_examples/visualization/evoked_topomap.html

**Contents:**
- Plotting topographic maps of evoked data#
- Basic plot_topomap() options#
- Additional plot_topomap() options#
- More advanced usage#
- Interpolating topomaps#
- Animating the topomap#

Go to the end to download the full example code.

Load evoked data and plot topomaps for selected time points using multiple additional options.

We plot evoked topographies using mne.Evoked.plot_topomap(). The first argument, times allows to specify time instants (in seconds!) for which topographies will be shown. We select timepoints from 50 to 150 ms with a step of 20ms and plot magnetometer data:

If times is set to None at most 10 regularly spaced topographies will be shown:

We can use nrows and ncols parameter to create multiline plots with more timepoints.

Instead of showing topographies at specific time points we can compute averages of 50 ms bins centered on these time points to reduce the noise in the topographies:

We can plot gradiometer data (plots the RMS for each pair of gradiometers)

We can also use a range of various mne.viz.plot_topomap() arguments that control how the topography is drawn. For example:

cmap - to specify the color map

res - to control the resolution of the topographies (lower resolution means faster plotting)

contours to define how many contour lines should be plotted

If you look at the edges of the head circle of a single topomap you‚Äôll see the effect of extrapolation. There are three extrapolation modes:

extrapolate='local' extrapolates only to points close to the sensors.

extrapolate='head' extrapolates out to the head circle.

extrapolate='box' extrapolates to a large box stretching beyond the head circle.

The default value extrapolate='auto' will use 'local' for MEG sensors and 'head' otherwise. Here we show each option:

Now we plot magnetometer data as topomap at a single time point: 100 ms post-stimulus, add channel labels, title and adjust plot margins:

We can also highlight specific channels by adding a mask, to e.g. mark channels exceeding a threshold at a given time:

Or by manually picking the channels to highlight at different times:

We can also look at the effects of interpolating our data. Perhaps, we might have data per channel such as the impedance of each electrode that we don‚Äôt want interpolated, or we just want to visualize the data without interpolation as a sanity check. We can use image_interp='nearest' to prevent any interpolation or image_interp='linear' to do a linear interpolation instead of the default cubic interpolation.

The default cubic interpolation is the smoothest and is great for publications.

The linear interpolation might be helpful in some cases.

The nearest (Voronoi, no interpolation) interpolation is especially helpful for debugging and seeing the values assigned to the topomap unaltered.

Instead of using a still image we can plot magnetometer data as an animation, which animates properly only in matplotlib interactive mode.

Total running time of the script: (0 minutes 23.593 seconds)

Download Jupyter notebook: evoked_topomap.ipynb

Download Python source code: evoked_topomap.py

Download zipped: evoked_topomap.zip

Gallery generated by Sphinx-Gallery

Plotting topographic arrowmaps of evoked data

Whitening evoked data with a noise covariance

---

## Plotting whitened data#

**URL:** https://mne.tools/stable/auto_tutorials/evoked/40_whitened.html

**Contents:**
- Plotting whitened data#
- Raw data with whitening#
- Epochs with whitening#
- Evoked data with whitening#
- Evoked data with scaled whitening#
- Topographic plot with whitening#

Go to the end to download the full example code.

This tutorial demonstrates how to plot whitened evoked data.

Data are whitened for many processes, including dipole fitting, source localization and some decoding algorithms. Viewing whitened data thus gives a different perspective on the data that these algorithms operate on.

Let‚Äôs start by loading some data and computing a signal (spatial) covariance that we‚Äôll consider to be noise.

In the mne.io.Raw.plot() with noise_cov supplied, you can press they ‚Äúw‚Äù key to turn whitening on and off.

The mne.Evoked.plot_white() function takes an additional step of scaling the whitened plots to show how well the assumption of Gaussian noise is satisfied by the data:

Total running time of the script: (0 minutes 25.969 seconds)

Download Jupyter notebook: 40_whitened.ipynb

Download Python source code: 40_whitened.py

Download zipped: 40_whitened.zip

Gallery generated by Sphinx-Gallery

EEG analysis - Event-Related Potentials (ERPs)

Time-frequency analysis

---

## Plot sensor denoising using oversampled temporal projection#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/otp.html

**Contents:**
- Plot sensor denoising using oversampled temporal projection#
- References#

Go to the end to download the full example code.

This demonstrates denoising using the OTP algorithm [1] on data with with sensor artifacts (flux jumps) and random noise.

Plot the phantom data, lowpassed to get rid of high-frequency artifacts. We also crop to a single 10-second segment for speed. Notice that there are two large flux jumps on channel 1522 that could spread to other channels when performing subsequent spatial operations (e.g., Maxwell filtering, SSP, or ICA).

Now we can clean the data with OTP, lowpass, and plot. The flux jumps have been suppressed alongside the random sensor noise.

We can also look at the effect on single-trial phantom localization. See the Brainstorm Elekta phantom dataset tutorial for more information. Here we use a version that does single-trial localization across the 17 trials are in our 10-second window:

Eric Larson and Samu Taulu. Reducing sensor noise in MEG and EEG recordings using oversampled temporal projection. IEEE Transactions on Biomedical Engineering, 65(5):1002‚Äì1013, 2018. doi:10.1109/TBME.2017.2734641.

Total running time of the script: (0 minutes 24.101 seconds)

Download Jupyter notebook: otp.ipynb

Download Python source code: otp.py

Download zipped: otp.zip

Gallery generated by Sphinx-Gallery

Removing muscle ICA components

Shifting time-scale in evoked data

---

## Preprocessing#

**URL:** https://mne.tools/stable/api/preprocessing.html

**Contents:**
- Preprocessing#

Projection(*, data[, desc, kind, active, ...])

Dictionary-like object holding a projection vector.

compute_proj_epochs(epochs[, n_grad, n_mag, ...])

Compute SSP (signal-space projection) vectors on epoched data.

compute_proj_evoked(evoked[, n_grad, n_mag, ...])

Compute SSP (signal-space projection) vectors on evoked data.

compute_proj_raw(raw[, start, stop, ...])

Compute SSP (signal-space projection) vectors on continuous data.

read_proj(fname, *[, verbose])

Read projections from a FIF file.

write_proj(fname, projs, *[, overwrite, verbose])

Write projections to a FIF file.

Module dedicated to manipulation of channels.

Can be used for setting of sensor locations used for processing and plotting.

Layout(box, pos, names, ids, kind)

DigMontage(*[, dig, ch_names])

Montage for digitized electrode and headshape position data.

compute_native_head_t(montage, *[, ...])

Compute the native-to-head transformation for a montage.

fix_mag_coil_types(info[, use_cal])

Fix magnetometer coil types.

read_polhemus_fastscan(fname[, unit, ...])

Read Polhemus FastSCAN digitizer data from a .txt file.

get_builtin_montages(*[, descriptions])

Get a list of all standard montages shipping with MNE-Python.

make_dig_montage([ch_pos, nasion, lpa, rpa, ...])

Make montage from arrays.

read_dig_polhemus_isotrak(fname[, ch_names, ...])

Read Polhemus digitizer data from a file.

read_dig_captrak(fname)

Read electrode locations from CapTrak Brain Products system.

read_dig_curry(fname)

Read electrode locations from Neuroscan Curry files.

Read electrode locations from EGI system.

read_dig_fif(fname, *[, verbose])

Read digitized points from a .fif file.

read_dig_hpts(fname[, unit])

Read historical .hpts MNE-C files.

read_dig_localite(fname[, nasion, lpa, rpa])

Read Localite .csv file.

make_standard_montage(kind[, head_size])

Read a generic (built-in) standard montage that ships with MNE-Python.

read_custom_montage(fname[, head_size, ...])

Read a montage from a file.

transform_to_head(montage)

Transform a DigMontage object into head coordinate.

compute_dev_head_t(montage)

Compute device to head transform from a DigMontage.

read_layout([fname, scale])

Read layout from a file.

find_layout(info[, ch_type, exclude])

Choose a layout based on the channels in the info 'chs' field.

make_eeg_layout(info[, radius, width, ...])

Make a Layout object based on EEG electrode digitization.

make_grid_layout(info[, picks, n_col])

Make a grid Layout object.

find_ch_adjacency(info, ch_type)

Find the adjacency matrix for the given channels.

get_builtin_ch_adjacencies(*[, descriptions])

Get a list of all FieldTrip neighbor definitions shipping with MNE.

read_ch_adjacency(fname[, picks])

Read a channel adjacency ("neighbors") file that ships with MNE.

equalize_channels(instances[, copy, verbose])

Equalize channel picks and ordering across multiple MNE-Python objects.

unify_bad_channels(insts)

Unify bad channels across a list of instances.

rename_channels(info, mapping[, ...])

generate_2d_layout(xy[, w, h, pad, ...])

Generate a custom 2D layout from xy points.

make_1020_channel_selections(info[, ...])

Map hemisphere names to corresponding EEG channel names or indices.

combine_channels(inst, groups[, method, ...])

Combine channels based on specified channel grouping.

Preprocessing with artifact detection, SSP, and ICA.

ICA([n_components, noise_cov, random_state, ...])

Data decomposition using Independent Component Analysis (ICA).

Xdawn([n_components, signal_cov, ...])

Implementation of the Xdawn Algorithm.

EOGRegression([picks, exclude, ...])

Remove EOG artifact signals from other channels by regression.

annotate_amplitude(raw[, peak, flat, ...])

Annotate raw data based on peak-to-peak amplitude.

annotate_break(raw[, events, ...])

Create Annotations for breaks in an ongoing recording.

annotate_movement(raw, pos[, ...])

Detect segments with movement.

annotate_muscle_zscore(raw[, threshold, ...])

Create annotations for segments that likely contain muscle artifacts.

annotate_nan(raw, *[, verbose])

Detect segments with NaN and return a new Annotations instance.

compute_average_dev_head_t(raw, pos, *[, ...])

Get new device to head transform based on good segments.

compute_current_source_density(inst[, ...])

Get the current source density (CSD) transformation.

compute_bridged_electrodes(inst[, ...])

Compute bridged EEG electrodes using the intrinsic Hjorth algorithm.

compute_fine_calibration(raw[, n_imbalance, ...])

Compute fine calibration from empty-room data.

compute_maxwell_basis(info[, origin, ...])

Compute the SSS basis for a given measurement info structure.

compute_proj_ecg(raw[, raw_event, tmin, ...])

Compute SSP (signal-space projection) vectors for ECG artifacts.

compute_proj_eog(raw[, raw_event, tmin, ...])

Compute SSP (signal-space projection) vectors for EOG artifacts.

compute_proj_hfc(info[, order, picks, ...])

Generate projectors to perform homogeneous/harmonic correction to data.

cortical_signal_suppression(evoked[, picks, ...])

Apply cortical signal suppression (CSS) to evoked data.

create_ecg_epochs(raw[, ch_name, event_id, ...])

Conveniently generate epochs around ECG artifact events.

create_eog_epochs(raw[, ch_name, event_id, ...])

Conveniently generate epochs around EOG artifact events.

find_bad_channels_lof(raw[, n_neighbors, ...])

Find bad channels using Local Outlier Factor (LOF) algorithm.

find_bad_channels_maxwell(raw[, limit, ...])

Find bad channels using Maxwell filtering.

find_ecg_events(raw[, event_id, ch_name, ...])

Find ECG events by localizing the R wave peaks.

find_eog_events(raw[, event_id, l_freq, ...])

Locate EOG artifacts.

fix_stim_artifact(inst[, events, event_id, ...])

Eliminate stimulation's artifacts from instance.

ica_find_ecg_events(raw, ecg_source[, ...])

Find ECG peaks from one selected ICA source.

ica_find_eog_events(raw[, eog_source, ...])

Locate EOG artifacts from one selected ICA source.

infomax(data[, weights, l_rate, block, ...])

Run (extended) Infomax ICA decomposition on raw data.

interpolate_bridged_electrodes(inst, bridged_idx)

Interpolate bridged electrode pairs.

equalize_bads(insts[, interp_thresh, copy])

Interpolate or mark bads consistently for a list of instances.

maxwell_filter(raw[, origin, int_order, ...])

Maxwell filter data using multipole moments.

maxwell_filter_prepare_emptyroom(raw_er, *, raw)

Prepare an empty-room recording for Maxwell filtering.

oversampled_temporal_projection(raw[, ...])

Denoise MEG channels using leave-one-out temporal projection.

peak_finder(x0[, thresh, extrema, verbose])

Noise-tolerant fast peak-finding algorithm.

read_ica(fname[, verbose])

Restore ICA solution from fif file.

read_eog_regression(fname)

Read an EOG regression model from an HDF5 file.

realign_raw(raw, other, t_raw, t_other, *[, ...])

Realign two simultaneous recordings.

regress_artifact(inst[, picks, exclude, ...])

Remove artifacts using regression based on reference channels.

corrmap(icas, template[, threshold, label, ...])

Find similar Independent Components across subjects by map similarity.

read_ica_eeglab(fname, *[, montage_units, ...])

Load ICA information saved in an EEGLAB .set file.

read_fine_calibration(fname)

Read fine calibration information from a .dat file.

write_fine_calibration(fname, calibration)

Write fine calibration information to a .dat file.

apply_pca_obs(raw, picks, *, qrs_times[, ...])

Apply the PCA-OBS algorithm to picks of a Raw object.

mne.preprocessing.nirs:

NIRS specific preprocessing functions.

optical_density(raw, *[, verbose])

Convert NIRS raw data to optical density.

beer_lambert_law(raw[, ppf])

Convert NIRS optical density data to haemoglobin concentration.

source_detector_distances(info[, picks])

Determine the distance between NIRS source and detectors.

short_channels(info[, threshold])

Determine which NIRS channels are short.

scalp_coupling_index(raw[, l_freq, h_freq, ...])

Calculate scalp coupling index.

temporal_derivative_distribution_repair(raw, *)

Apply temporal derivative distribution repair to data.

mne.preprocessing.ieeg:

Intracranial EEG specific preprocessing functions.

project_sensors_onto_brain(info, trans, subject)

Project sensors onto the brain surface.

make_montage_volume(montage, base_image[, ...])

Make a volume from intracranial electrode contact locations.

warp_montage(montage, moving, static, ...[, ...])

Warp a montage to a template with image volumes using SDR.

mne.preprocessing.eyetracking:

Eye tracking specific preprocessing functions.

Calibration(*, onset, model, eye, avg_error, ...)

Eye-tracking calibration info.

read_eyelink_calibration(fname[, ...])

Return info on calibrations collected in an eyelink file.

set_channel_types_eyetrack(inst, mapping)

Define sensor type for eyetrack channels.

convert_units(inst, calibration[, to])

Convert Eyegaze data from pixels to radians of visual angle or vice versa.

get_screen_visual_angle(calibration)

Calculate the radians of visual angle that the participant screen subtends.

interpolate_blinks(raw[, buffer, match, ...])

Interpolate eyetracking signals during blinks.

add_reference_channels(inst, ref_channels[, ...])

Add reference channels to data that consists of all zeros.

set_bipolar_reference(inst, anode, cathode)

Re-reference selected channels using a bipolar referencing scheme.

set_eeg_reference(inst[, ref_channels, ...])

Specify which reference to use for EEG data.

IIR and FIR filtering and resampling functions.

construct_iir_filter(iir_params[, f_pass, ...])

Use IIR parameters to get filtering coefficients.

create_filter(data, sfreq, l_freq, h_freq[, ...])

Create a FIR or IIR filter.

estimate_ringing_samples(system[, max_try])

Estimate filter ringing.

filter_data(data, sfreq, l_freq, h_freq[, ...])

Filter a subset of channels.

notch_filter(x, Fs, freqs[, filter_length, ...])

Notch filter for the signal x.

resample(x[, up, down, axis, window, ...])

Functions for fitting head positions with (c)HPI coils.

compute_head_pos can be used to:

Drop coils whose GOF are below gof_limit. If fewer than 3 coils remain, abandon fitting for the chunk.

Fit dev_head_t quaternion (using _fit_chpi_quat_subset), iteratively dropping coils (as long as 3 remain) to find the best GOF (using _fit_chpi_quat).

If fewer than 3 coils meet the dist_limit criteria following projection of the fitted device coil locations into the head frame, abandon fitting for the chunk.

The function filter_chpi uses the same linear model to filter cHPI and (optionally) line frequencies from the data.

compute_chpi_amplitudes(raw[, t_step_min, ...])

Compute time-varying cHPI amplitudes.

compute_chpi_snr(raw[, t_step_min, ...])

Compute time-varying estimates of cHPI SNR.

compute_chpi_locs(info, chpi_amplitudes[, ...])

Compute locations of each cHPI coils over time.

compute_head_pos(info, chpi_locs[, ...])

Compute time-varying head positions.

extract_chpi_locs_ctf(raw[, verbose])

Extract cHPI locations from CTF data.

extract_chpi_locs_kit(raw[, stim_channel, ...])

Extract cHPI locations from KIT data.

filter_chpi(raw[, include_line, t_step, ...])

Remove cHPI and line noise from data.

get_active_chpi(raw, *[, on_missing, verbose])

Determine how many HPI coils were active for a time point.

get_chpi_info(info[, on_missing, verbose])

Retrieve cHPI information from the data.

head_pos_to_trans_rot_t(quats)

Convert Maxfilter-formatted head position quaternions.

Read MaxFilter-formatted head position parameters.

refit_hpi(info, *[, amplitudes, locs, ...])

Refit HPI coil order.

write_head_pos(fname, pos)

Write MaxFilter-formatted head position parameters.

Helpers for various transformations.

Transform(fro, to[, trans])

angle_distance_between_rigid(a[, b, ...])

Compute the angle and distance between two rigid transforms.

Convert a set of quaternions to rotations.

Convert a set of rotations to quaternions.

read_ras_mni_t(subject[, subjects_dir])

Read a subject's RAS to MNI transform.

mne.viz.ui_events.VertexSelect

---

## Preprocessing#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/index.html

**Contents:**
- Preprocessing#

Examples related to data preprocessing (artifact detection / rejection etc.)

Locating micro-scale intracranial electrode contacts

Using contralateral referencing for EEG

Cortical Signal Suppression (CSS) for removal of cortical signals

Define target events based on time lag, plot evoked response

Identify EEG Electrodes Bridged by too much Gel

Transform EEG data using current source density (CSD)

Show EOG artifact timing

Reduce EOG artifacts through regression

Automated epochs metadata generation with variable time windows

Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact

Find MEG reference channel artifacts

Visualise NIRS artifact correction methods

Compare the different ICA algorithms in MNE

Interpolate bad channels for MEG/EEG channels

Interpolate EEG data to any montage

Maxwell filter data with movement compensation

Annotate movement artifacts and reestimate dev_head_t

Annotate muscle artifacts

Removing muscle ICA components

Plot sensor denoising using oversampled temporal projection

Shifting time-scale in evoked data

Remap MEG channel types

Generate simulated source data

Using contralateral referencing for EEG

---

## Preprocessing#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/index.html

**Contents:**
- Preprocessing#

These tutorials cover various preprocessing techniques for continuous data, as well as some diagnostic plotting methods.

Overview of artifact detection

Handling bad channels

Rejecting bad data spans and breaks

Background information on filtering

Filtering and resampling data

Repairing artifacts with regression

Repairing artifacts with ICA

Background on projectors and projections

Repairing artifacts with SSP

Setting the EEG reference

Extracting and visualizing subject head movement

Signal-space separation (SSS) and Maxwell filtering

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Preprocessing optically pumped magnetometer (OPM) MEG data

Working with eye tracker data in MNE-Python

Built-in plotting methods for Raw objects

Overview of artifact detection

---

## Preprocessing functional near-infrared spectroscopy (fNIRS) data#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/70_fnirs_processing.html

**Contents:**
- Preprocessing functional near-infrared spectroscopy (fNIRS) data#
- Providing more meaningful annotation information#
- Viewing location of sensors over brain surface#
- Selecting channels appropriate for detecting neural responses#
- Converting from raw intensity to optical density#
- Evaluating the quality of the data#
- Converting from optical density to haemoglobin#
- Removing heart rate from signal#
- Extract epochs#
- View consistency of responses across trials#

Go to the end to download the full example code.

This tutorial covers how to convert functional near-infrared spectroscopy (fNIRS) data from raw measurements to relative oxyhaemoglobin (HbO) and deoxyhaemoglobin (HbR) concentration, view the average waveform, and topographic representation of the response.

Here we will work with the fNIRS motor data.

First, we attribute more meaningful names to the trigger codes which are stored as annotations. Second, we include information about the duration of each stimulus, which was 5 seconds for all conditions in this experiment. Third, we remove the trigger code 15, which signaled the start and end of the experiment and is not relevant to our analysis.

Here we validate that the location of sources-detector pairs and channels are in the expected locations. Source-detector pairs are shown as lines between the optodes, channels (the mid point of source-detector pairs) are optionally shown as orange dots. Source are optionally shown as red dots and detectors as black.

First we remove channels that are too close together (short channels) to detect a neural response (less than 1 cm distance between optodes). These short channels can be seen in the figure above. To achieve this we pick all the channels that are not considered to be short.

The raw intensity values are then converted to optical density.

At this stage we can quantify the quality of the coupling between the scalp and the optodes using the scalp coupling index. This method looks for the presence of a prominent synchronous signal in the frequency range of cardiac signals across both photodetected signals.

In this example the data is clean and the coupling is good for all channels, so we will not mark any channels as bad based on the scalp coupling index.

In this example we will mark all channels with a SCI less than 0.5 as bad (this dataset is quite clean, so no channels are marked as bad).

At this stage it is appropriate to inspect your data (for instructions on how to use the interactive data visualisation tool see Built-in plotting methods for Raw objects) to ensure that channels with poor scalp coupling have been removed. If your data contains lots of artifacts you may decide to apply artifact reduction techniques as described in Visualise NIRS artifact correction methods.

Next we convert the optical density data to haemoglobin concentration using the modified Beer-Lambert law.

The haemodynamic response has frequency content predominantly below 0.5 Hz. An increase in activity around 1 Hz can be seen in the data that is due to the person‚Äôs heart beat and is unwanted. So we use a low pass filter to remove this. A high pass filter is also included to remove slow drifts in the data.

Now that the signal has been converted to relative haemoglobin concentration, and the unwanted heart rate component has been removed, we can extract epochs related to each of the experimental conditions.

First we extract the events of interest and visualize them to ensure they are correct.

Next we define the range of our epochs, the rejection criteria, baseline correction, and extract the epochs. We visualize the log of which epochs were dropped.

Now we can view the haemodynamic response for our tapping condition. We visualize the response for both the oxy- and deoxyhaemoglobin, and observe the expected peak in HbO at around 6 seconds consistently across trials, and the consistent dip in HbR that is slightly delayed relative to the HbO peak.

We can also view the epoched data for the control condition and observe that it does not show the expected morphology.

Similarly we can view how consistent the response is across the optode pairs that we selected. All the channels in this data are located over the motor cortex, and all channels show a similar pattern in the data.

Next we generate the most common visualisation of fNIRS data: plotting both the HbO and HbR on the same figure to illustrate the relation between the two signals.

Next we view how the topographic activity changes throughout the response.

Finally we generate topo maps for the left and right conditions to view the location of activity. First we visualize the HbO activity.

And we also view the HbR activity for the two conditions.

And we can plot the comparison at a single time point for two conditions.

Lastly, we can also look at the individual waveforms to see what is driving the topographic plot above.

Total running time of the script: (0 minutes 30.938 seconds)

Download Jupyter notebook: 70_fnirs_processing.ipynb

Download Python source code: 70_fnirs_processing.py

Download zipped: 70_fnirs_processing.zip

Gallery generated by Sphinx-Gallery

Signal-space separation (SSS) and Maxwell filtering

Preprocessing optically pumped magnetometer (OPM) MEG data

---

## Preprocessing optically pumped magnetometer (OPM) MEG data#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/80_opm_processing.html

**Contents:**
- Preprocessing optically pumped magnetometer (OPM) MEG data#
- Examining raw data#
- Denoising: Regressing via reference sensors#
- Denoising: Regressing via homogeneous field correction#
- Comparing denoising methods#
- Filtering nuisance signals#
- Generating an evoked response#
- Visualizing coregistration#
- Plotting the inverse#
- References#

Go to the end to download the full example code.

This tutorial covers preprocessing steps that are specific to OPM MEG data. OPMs use a different sensing technology than traditional SQUID MEG systems, which leads to several important differences for analysis:

They are sensitive to DC magnetic fields

Sensor layouts can vary by participant and recording session due to flexible sensor placement

Devices are typically not fixed in place, so the position of the sensors relative to the room (and through the DC fields) can change over time

We will cover some of these considerations here by processing the UCL OPM auditory dataset [1]

First, let‚Äôs look at the raw data, noting that there are large fluctuations in the sub 1 Hz band. In some cases the range of fields a single channel reports is as much as 600 pT across this experiment.

The simplest method for reducing low frequency drift in the data is to use a set of reference sensors away from the scalp, which only sample the ambient fields in the room. An advantage of this method is that no prior knowldge of the locations of the sensors is required. However, it assumes that the reference sensors experience the same interference as scalp recordings.

To do this in our current dataset, we require a bit of housekeeping. There are a set of channels beginning with the name ‚ÄúFlux‚Äù which do not contain any evironmental data, these need to be set to as bad channels. Another channel ‚Äì G2-17-TAN ‚Äì will also be set to bad.

For now we are only interested in removing artefacts seen below 5 Hz, so we initially low-pass filter the good reference channels in this dataset prior to regression

Looking at the processed data, we see there has been a large reduction in the low frequency drift, but there are still periods where the drift has not been entirely removed. The likely cause of this is that the spatial profile of the interference is dynamic, so performing a single regression over the entire experiment is not the most effective approach.

Regression of a reference channel is a start, but in this instance assumes the relatiship between the references and a given sensor on the head as constant. However this becomes less accurate when the reference is not moving but the subject is. An alternative method, Homogeneous Field Correction (HFC) only requires that the sensors on the helmet stationary relative to each other. Which in a well-designed rigid helmet is the case.

Differing denoising methods will have differing levels of performance across different parts of the spectrum. One way to evaluate the performance of a denoising step is to calculate the power spectrum of the dataset before and after processing. We will use metric called the shielding factor to summarise the values. Positive shielding factors indicate a reduction in power, whilst negative means in increase.

We see that reference regression does a good job in reducing low frequency drift up to ~2 Hz, with 20 dB of shielding. But rapidly drops off due to low pass filtering the reference signal at 5 Hz. We also can see that this method is also introducing additional interference at 3 Hz.

HFC improves on the low frequency shielding (up to 32 dB). Also this method is not frequency-specific so we observe broadband interference reduction.

Having regressed much of the high-amplitude, low-frequency interference, we can now look to filtering the remnant nuisance signals. The motivation for filtering after regression (rather than before) is to minimise any filter artefacts generated when removing such high-amplitude interfece (compared to the neural signals we are interested in).

We are going to remove the 50 Hz mains signal with a notch filter, followed by a bandpass filter between 2 and 40 Hz. From here it becomes clear that the variance in our signal has been reduced from 100s of pT to 10s of pT instead.

With the data preprocessed, it is now possible to see an auditory evoked response at the sensor level.

By design, the sensors in this dataset are already in the scanner RAS coordinate frame. We can thus visualize them in the FreeSurfer MRI coordinate frame by computing the transformation between the FreeSurfer MRI coordinate frame and scanner RAS:

Now we can compute a forward and inverse:

Robert A. Seymour, Nicholas Alexander, Stephanie Mellor, George C. O‚ÄôNeill, Tim M. Tierney, Gareth R. Barnes, and Eleanor A. Maguire. Interference suppression techniques for OPM-based MEG: Opportunities and challenges. NeuroImage, 247:118834, February 2022. doi:10.1016/j.neuroimage.2021.118834.

Total running time of the script: (0 minutes 59.202 seconds)

Download Jupyter notebook: 80_opm_processing.ipynb

Download Python source code: 80_opm_processing.py

Download zipped: 80_opm_processing.zip

Gallery generated by Sphinx-Gallery

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Working with eye tracker data in MNE-Python

---

## Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/esg_rm_heart_artefact_pcaobs.html

**Contents:**
- Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact#
- References#

Go to the end to download the full example code.

This script shows an example of how to use an adaptation of PCA-OBS [1]. PCA-OBS was originally designed to remove the ballistocardiographic artefact in simultaneous EEG-fMRI. Here, it has been adapted to remove the delay between the detected R-peak and the ballistocardiographic artefact such that the algorithm can be applied to remove the cardiac artefact in EEG (electroencephalography) and ESG (electrospinography) data. We will illustrate how it works by applying the algorithm to ESG data, where the effect of removal is most pronounced.

See: https://www.biorxiv.org/content/10.1101/2024.09.05.611423v1 for more details on the dataset and application for ESG data.

Download sample subject data from OpenNeuro if you haven‚Äôt already. This will download simultaneous EEG and ESG data from a single run of a single participant after median nerve stimulation of the left wrist.

Define the esg channels (arranged in two patches over the neck and lower back).

Next, we perform minimal preprocessing including removing the stimulation artefact, downsampling and filtering.

Find ECG events and add to the raw structure as event annotations.

Create evoked response around the detected R-peaks before and after cardiac artefact correction.

Compare evoked responses to assess completeness of artefact removal.

R. K. Niazy, C.F. Beckmann, G.D. Iannetti, J. M. Brady, and S. M. Smith. Removal of fmri environment artifacts from eeg data using optimal basis sets. NeuroImage, 28:720‚Äì737, 2005. doi:10.1016/j.neuroimage.2005.06.067.

Total running time of the script: (0 minutes 6.280 seconds)

Download Jupyter notebook: esg_rm_heart_artefact_pcaobs.ipynb

Download Python source code: esg_rm_heart_artefact_pcaobs.py

Download zipped: esg_rm_heart_artefact_pcaobs.zip

Gallery generated by Sphinx-Gallery

Automated epochs metadata generation with variable time windows

Find MEG reference channel artifacts

---

## Reading data for different recording systems#

**URL:** https://mne.tools/stable/auto_tutorials/io/index.html

**Contents:**
- Reading data for different recording systems#

These tutorials cover the basics of loading EEG/MEG data into MNE-Python for various recording devices.

Importing data from MEG devices

Importing data from EEG devices

Importing data from fNIRS devices

Working with CTF data: the Brainstorm auditory dataset

Importing Data from Eyetracking devices

Getting started with mne.Report

Importing data from MEG devices

---

## Reduce EOG artifacts through regression#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/eog_regression.html

**Contents:**
- Reduce EOG artifacts through regression#
- Import packages and load data#
- Perform regression and remove EOG#
- Before/after comparison#

Go to the end to download the full example code.

Reduce artifacts by regressing the EOG channels onto the rest of the channels and then subtracting the EOG signal.

This is a quick example to show the most basic application of the technique. See the tutorial for a more thorough explanation that demonstrates more advanced approaches.

We begin as always by importing the necessary Python modules and loading some data, in this case the MNE sample dataset.

Let‚Äôs compare the signal before and after cleaning with EOG regression. This is best visualized by extracting epochs and plotting the evoked potential.

Total running time of the script: (0 minutes 8.146 seconds)

Download Jupyter notebook: eog_regression.ipynb

Download Python source code: eog_regression.py

Download zipped: eog_regression.zip

Gallery generated by Sphinx-Gallery

Show EOG artifact timing

Automated epochs metadata generation with variable time windows

---

## Regression-based baseline correction#

**URL:** https://mne.tools/stable/auto_tutorials/epochs/15_baseline_regression.html

**Contents:**
- Regression-based baseline correction#
- Load the data#
- Preprocessing#
  - Traditional baselining#
  - Regression-based baselining#
- Plot the baseline regressor#
- Plot the ERPs#
- Plot the scalp topographies and difference waves#
- Examine the interaction term#
- References#

Go to the end to download the full example code.

This tutorial compares traditional baseline correction (adding or subtracting a scalar amount from every timepoint in an epoch) to a regression-based approach to baseline correction (which allows the effect of the baseline period to vary by timepoint). Specifically, this tutorial follows the method introduced by Alday[1].

There are at least two reasons you might consider using regression-based baseline correction:

Unlike traditional baseline correction, the regression-based approach does not assume that the effect of the baseline is equivalent between different experimental conditions. Thus it is safer against introduced bias.

Assuming that pre-trial baseline signal level is mostly determined by slow drifts in the data, the further away (in time) you get from the baseline period, the less likely it is that the signal level is similar in amplitude to the baseline amplitude. Thus using a time-varying baseline correction is less likely to introduce signal distortions / spurious effects in the later spans of long-duration epochs.

One issue that affects both traditional and regression-based baseline correction is the question of what time window to choose as the baseline window.

We‚Äôll start by loading the MNE-Python sample dataset and extracting the experimental events to get trial locations and trial types. Since for this tutorial we‚Äôre only going to look at EEG channels, we can drop the other channel types, to speed things up:

Here we merge visual and auditory events from both hemispheres, and make our event_id dictionary for use during epoching.

Next we‚Äôll define some variables needed to epoch and preprocess the data. We‚Äôll be combining left- and right-side stimuli, so we‚Äôll look at a single central electrode to visualize the difference between auditory and visual trials.

We‚Äôll do some standard preprocessing (a bandpass filter) and then epoch the data. Note that we don‚Äôt baseline correct the epochs (we specify baseline=None); we just minimally clean the data by rejecting channels with very high or low amplitudes. Note also that we operate on a copy of the data so that we can later compare this with traditional baselining.

First let‚Äôs baseline correct the data the traditional way. We average epochs within each condition, and subtract the condition-specific baseline separately for auditory and visual trials.

Now let‚Äôs try out the regression-based baseline correction approach. We‚Äôll use mne.stats.linear_regression(), which needs a design matrix to represent the regression predictors. We‚Äôll use four predictors: one for each experimental condition, one for the effect of baseline, and one that is an interaction between the baseline and one of the conditions (to account for any heterogeneity of the effect of baseline between the two conditions). Here are the first two:

The baseline predictor is a bit trickier to compute: we‚Äôll find the average value within the baseline period separately for each epoch, and use that value as our (trial-level) predictor. Here, since we‚Äôre focused on one particular channel, we‚Äôll use the baseline value in that channel as our predictor, but depending on your research question you may want to do this seaprately for each channel or combine information across channels.

Note that we converted just the predictor (not the epochs data) from Volts to microVolts. This is done for regression-model-fitting purposes (very small values can make model fitting unstable).

Now we can set up the design matrix, stacking the 1-D predictors as rows, then transposing with .T to make them columns. Combining them into one array() will also automatically convert the boolean aud_predictor and vis_predictor into ones and zeros:

Finally we fit the regression model:

The function returns a dictionary of mne.stats.regression.lm objects, which are each a namedtuple() with the various estimated values stored as if it were an Evoked object. Let‚Äôs inspect it:

First let‚Äôs look at the estimated effect of the baseline period. What we care about is the beta values, which tell us how strongly predictive the baseline value is at each timepoint. The model will estimate its effectiveness for every channel but since we used only one channel to form our baseline predictor, let‚Äôs examine how it looks for that channel only. We‚Äôll add a horizontal line at Œ≤=1 to represent traditional baselining, where the effect is assumed to be constant across timepoints:

Unsurprisingly, the trend is that the farther away in time we get from the baseline period, the weaker the predictive value of the baseline amplitude becomes. Put another way, early time points (in this data) should be more strongly baseline-corrected than later time points.

Now let‚Äôs look at the beta values for the two conditions (auditory and visual): these are the coefficients that represent the ‚Äúpure‚Äù influence of the experimental stimuli on the signal, after taking into account the (time-varying!) effect of the baseline. We‚Äôll plot them together, side-by-side with the traditional baseline approach:

They look pretty similar, but there are some subtle differences in how far apart the two conditions are (e.g., around 400-500 ms).

Now let‚Äôs compare the scalp topographies for the traditional and regression-based approach. We‚Äôll do this by computing the difference between conditions:

Before we plot, let‚Äôs make sure we get the same color scale for both figures:

We can see that the regression-based approach shows stronger difference between conditions early on (around 100-150 ms) and weaker differences later (around 250-350 ms, and again around 450 ms). This is also reflected in the difference waves themselves: notice how the regression-based difference wave is further from zero around 150 ms but closer to zero around 250-350 ms.

Finally, let‚Äôs look at the interaction term from the regression model. This tells us whether the effect of the baseline period is different in the visual trials versus its effect in the auditory trials. Here we‚Äôll add a horizontal line at zero, indicating the assumption that there ought to be no difference (i.e., baselines should not be systematically higher in one type of trial, and there should not be a difference in how long the effect of the baseline persists through time in each type of trial).

Indeed, the interaction beta weights are rather small and seem to fluctuate randomly around zero, suggesting that there is no systematic difference in the effect of the baseline on our two trial types.

Phillip M. Alday. How much baseline correction do we need in ERP research? extended GLM model can replace baseline correction while lifting its limits. Psychophysiology, 2019. doi:10.1111/psyp.13451.

Total running time of the script: (0 minutes 6.381 seconds)

Download Jupyter notebook: 15_baseline_regression.ipynb

Download Python source code: 15_baseline_regression.py

Download zipped: 15_baseline_regression.zip

Gallery generated by Sphinx-Gallery

The Epochs data structure: discontinuous data

Visualizing epoched data

---

## Regression on continuous data (rER[P/F])#

**URL:** https://mne.tools/stable/auto_examples/stats/linear_regression_raw.html

**Contents:**
- Regression on continuous data (rER[P/F])#

Go to the end to download the full example code.

This demonstrates how rER[P/F]s - regressing the continuous data - is a generalisation of traditional averaging. If all preprocessing steps are the same, no overlap between epochs exists, and if all predictors are binary, regression is virtually identical to traditional averaging. If overlap exists and/or predictors are continuous, traditional averaging is inapplicable, but regression can estimate effects, including those of continuous predictors.

rERPs are described in Smith and Kutas[1].

Nathaniel J. Smith and Marta Kutas. Regression-based estimation of ERP waveforms: II. Nonlinear effects, overlap correction, and practical considerations: rERPS II. Psychophysiology, 52(2):169‚Äì181, 2015. doi:10.1111/psyp.12320.

Total running time of the script: (0 minutes 2.581 seconds)

Download Jupyter notebook: linear_regression_raw.ipynb

Download Python source code: linear_regression_raw.py

Download zipped: linear_regression_raw.zip

Gallery generated by Sphinx-Gallery

FDR correction on T-test on sensor data

Permutation T-test on sensor data

---

## Rejecting bad data spans and breaks#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/20_rejecting_bad_data.html

**Contents:**
- Rejecting bad data spans and breaks#
- Annotating bad spans of data#
  - The reject_by_annotation parameter#
  - Generating annotations programmatically#
  - Detecting and annotating breaks#
- Rejecting Epochs based on peak-to-peak channel amplitude#
- Rejecting Epochs using callables (functions)#

Go to the end to download the full example code.

This tutorial covers:

manual marking of bad spans of data,

automated rejection of data spans based on signal amplitude, and

automated detection of breaks during an experiment.

We begin as always by importing the necessary Python modules and loading some example data; to save memory we‚Äôll use a pre-filtered and downsampled version of the example data, and we‚Äôll also load an events array to use when converting the continuous data to epochs:

The tutorial Parsing events from raw data describes how Annotations can be read from embedded events in the raw recording file, and Annotating continuous data describes in detail how to interactively annotate a Raw data object. Here, we focus on best practices for annotating bad data spans so that they will be excluded from your analysis pipeline.

In the interactive raw.plot() window, the annotation controls can be opened by pressing a. Here, new annotation labels can be created or existing annotation labels can be selected for use.

You can see that you need to add a description first to start with marking spans (Push the button ‚ÄúAdd Description‚Äù and enter the description). You can use any description you like, but annotations marking spans that should be excluded from the analysis pipeline should all begin with ‚ÄúBAD‚Äù or ‚Äúbad‚Äù (e.g., ‚Äúbad_cough‚Äù, ‚Äúbad-eyes-closed‚Äù, ‚Äúbad door slamming‚Äù, etc). When this practice is followed, many processing steps in MNE-Python will automatically exclude the ‚Äúbad‚Äù-labelled spans of data; this behavior is controlled by a parameter reject_by_annotation that can be found in many MNE-Python functions or class constructors, including:

creation of epoched data from continuous data (mne.Epochs)

many methods of the independent components analysis class (mne.preprocessing.ICA)

functions for finding heartbeat and blink artifacts (find_ecg_events(), find_eog_events())

covariance computations (mne.compute_raw_covariance())

power spectral density computation (mne.io.Raw.compute_psd())

For example, when creating epochs from continuous data, if reject_by_annotation=True the Epochs constructor will drop any epoch that partially or fully overlaps with an annotated span that begins with ‚Äúbad‚Äù.

The Overview of artifact detection tutorial introduced the artifact detection functions find_eog_events() and find_ecg_events() (although that tutorial mostly relied on their higher-level wrappers create_eog_epochs() and create_ecg_epochs()). Here, for demonstration purposes, we make use of the lower-level artifact detection function to get an events array telling us where the blinks are, then automatically add ‚Äúbad_blink‚Äù annotations around them (this is not necessary when using create_eog_epochs(), it is done here just to show how annotations are added non-interactively). We‚Äôll start the annotations 250 ms before the blink and end them 250 ms after it:

Now we can confirm that the annotations are centered on the EOG events. Since blinks are usually easiest to see in the EEG channels, we‚Äôll only plot EEG here:

See the section Creating annotations programmatically for more details on creating annotations programmatically.

Another useful function, albeit not related to artifact detection per se, is mne.preprocessing.annotate_break: It will generate annotations for segments of the data where no existing annotations (or, alternatively: events) can be found. It can therefore be used to automatically detect and mark breaks, e.g. between experimental blocks, when recording continued.

For the sake of this example, let‚Äôs assume an experiment consisting of two blocks, the first one stretching from 30 to 90, and the second from 120 to 180 seconds. We‚Äôll mark these blocks by annotations, and then use mne.preprocessing.annotate_break to detect and annotate any breaks.

We need to take raw.first_time into account, otherwise the onsets will be incorrect!

Now detect break periods. We can control how far the break annotations shall expand toward both ends of each break.

You can see that 3 segments have been annotated as BAD_break:

the first one starting with the beginning of the recording and ending 2 seconds before the beginning of block 1 (due to t_stop_before_next=2),

the second one starting 5 seconds after block 1 has ended, and ending 2 seconds before the beginning of block 2 (t_start_after_previous=5, t_stop_before_next=2),

and the last one starting 5 seconds after block 2 has ended (t_start_after_previous=5) and continuing until the end of the recording.

You can also see that only the block_1 and block_2 annotations were considered in the detection of the break periods ‚Äì the EOG annotations were simply ignored. This is because, by default, annotate_break ignores all annotations starting with 'bad'. You can control this behavior via the ignore parameter.

It is also possible to perform break period detection based on an array of events: simply pass the array via the events parameter. Existing annotations in the raw data will be ignored in this case:

Besides ‚Äúbad‚Äù annotations, the mne.Epochs class constructor has another means of rejecting epochs, based on signal amplitude thresholds for each channel type. In the overview tutorial we saw an example of this: setting maximum acceptable peak-to-peak amplitudes for each channel type in an epoch, using the reject parameter. There is also a related parameter, flat, that can be used to set minimum acceptable peak-to-peak amplitudes for each channel type in an epoch:

The values that are appropriate are dataset- and hardware-dependent, so some trial-and-error may be necessary to find the correct balance between data quality and loss of power due to too many dropped epochs. Here, we‚Äôve set the rejection criteria to be fairly stringent, for illustration purposes.

Two additional parameters, reject_tmin and reject_tmax, are used to set the temporal window in which to calculate peak-to-peak amplitude for the purposes of epoch rejection. These default to the same tmin and tmax of the entire epoch. As one example, if you wanted to only apply the rejection thresholds to the portion of the epoch that occurs before the event marker around which the epoch is created, you could set reject_tmax=0. A summary of the causes of rejected epochs can be generated with the plot_drop_log() method:

Notice that we‚Äôve passed reject_by_annotation=False above, in order to isolate the effects of the rejection thresholds. If we re-run the epoching with reject_by_annotation=True (the default) we see that the rejections due to EEG and EOG channels have disappeared (suggesting that those channel fluctuations were probably blink-related, and were subsumed by rejections based on the ‚Äúbad blink‚Äù label).

More importantly, note that many more epochs are rejected (~12.2% instead of ~2.5%) when rejecting based on the blink labels, underscoring why it is usually desirable to repair artifacts rather than exclude them.

The plot_drop_log() method is a visualization of an Epochs attribute, namely epochs.drop_log, which stores empty lists for retained epochs and lists of strings for dropped epochs, with the strings indicating the reason(s) why the epoch was dropped. For example:

Finally, it should be noted that ‚Äúdropped‚Äù epochs are not necessarily deleted from the Epochs object right away. Above, we forced the dropping to happen when we created the Epochs object by using the preload=True parameter. If we had not done that, the Epochs object would have been memory-mapped (not loaded into RAM), in which case the criteria for dropping epochs are stored, and the actual dropping happens when the Epochs data are finally loaded and used. There are several ways this can get triggered, such as:

explicitly loading the data into RAM with the load_data() method

plotting the data (plot(), plot_image(), etc)

using the average() method to create an Evoked object

You can also trigger dropping with the drop_bad() method; if reject and/or flat criteria have already been provided to the epochs constructor, drop_bad() can be used without arguments to simply delete the epochs already marked for removal (if the epochs have already been dropped, nothing further will happen):

Alternatively, if rejection thresholds were not originally given to the Epochs constructor, they can be passed to drop_bad() later instead; this can also be a way of imposing progressively more stringent rejection criteria:

Sometimes it is useful to reject epochs based criteria other than peak-to-peak amplitudes. For example, we might want to reject epochs based on the maximum or minimum amplitude of a channel. In this case, the mne.Epochs.drop_bad function also accepts callables (functions) in the reject and flat parameters. This allows us to define functions to reject epochs based on our desired criteria.

Let‚Äôs begin by generating Epoch data with large artifacts in one eeg channel in order to demonstrate the versatility of this approach.

As you can see, we have two large artifacts in the first channel. One large spike in amplitude and one large increase in amplitude.

Here, the epoch containing the spike in amplitude was rejected for having a maximum amplitude greater than 1e-2 Volts. Notice the use of the any() function to check if any of the channels exceeded the threshold. We could have also used the all() function to check if all channels exceeded the threshold.

Finally, let‚Äôs try to reject both epochs using a combination of the maximum and median. We‚Äôll define a custom function and use boolean operators to combine the two criteria.

Note that a complementary Python module, the autoreject package, uses machine learning to find optimal rejection criteria, and is designed to integrate smoothly with MNE-Python workflows. This can be a considerable time-saver when working with heterogeneous datasets.

Total running time of the script: (0 minutes 16.193 seconds)

Download Jupyter notebook: 20_rejecting_bad_data.ipynb

Download Python source code: 20_rejecting_bad_data.py

Download zipped: 20_rejecting_bad_data.zip

Gallery generated by Sphinx-Gallery

Handling bad channels

Background information on filtering

---

## Remap MEG channel types#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/virtual_evoked.html

**Contents:**
- Remap MEG channel types#

Go to the end to download the full example code.

In this example, MEG data are remapped from one channel type to another. This is useful to:

visualize combined magnetometers and gradiometers as magnetometers or gradiometers.

run statistics from both magnetometers and gradiometers while working with a single type of channels.

First, let‚Äôs call remap gradiometers to magnometers, and plot the original and remapped topomaps of the magnetometers.

Now, we remap magnometers to gradiometers, and plot the original and remapped topomaps of the gradiometers

Total running time of the script: (0 minutes 7.857 seconds)

Download Jupyter notebook: virtual_evoked.ipynb

Download Python source code: virtual_evoked.py

Download zipped: virtual_evoked.zip

Gallery generated by Sphinx-Gallery

Shifting time-scale in evoked data

---

## Removing muscle ICA components#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/muscle_ica.html

**Contents:**
- Removing muscle ICA components#
- Let‚Äôs now replicate this on the EEGBCI dataset#
- References#

Go to the end to download the full example code.

Gross movements produce widespread high-frequency activity across all channels that is usually not recoverable and so the epoch must be rejected as shown in Annotate muscle artifacts. More ubiquitously than gross movements, muscle artifact is produced during postural maintenance. This is more appropriately removed by ICA otherwise there wouldn‚Äôt be any epochs left! Note that muscle artifacts of this kind are much more pronounced in EEG than they are in MEG.

Remove components with postural muscle artifact using ICA

By inspection, let‚Äôs select out the muscle-artifact components based on [1] manually.

Positive slope of log-log power spectrum between 7 and 75 Hz (here just flat because it‚Äôs not in log-log)

Peripheral focus or dipole/multi-pole foci (the blue and red blobs in the topomap are far from the vertex where the most muscle is)

Single focal point (low spatial smoothness; there is just one focus of the topomap compared to components like the first ones that are more likely neural which spread across the topomap)

The other attribute worth noting is that the time course in mne.preprocessing.ICA.plot_sources() looks like EMG; you can see spikes when each motor unit fires so that the time course looks fuzzy and sometimes has large spikes that are often at regular intervals.

ICA component 13 is a textbook example of what muscle artifact looks like. The focus of the topomap for this component is right on the temporalis muscle near the ears. There is also a minimum in the power spectrum at around 10 Hz, then a maximum at around 25 Hz, generally resulting in a positive slope in log-log units; this is a very typical pattern for muscle artifact.

Finally, let‚Äôs try an automated algorithm to find muscle components and ensure that it gets the same components we did manually.

Dhani Dharmaprani, Hoang K. Nguyen, Trent W. Lewis, Dylan DeLosAngeles, John O. Willoughby, and Kenneth J. Pope. A comparison of independent component analysis algorithms and measures to discriminate between EEG and artifact components. In 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), 825‚Äì828. Orlando, FL, USA, 2016. IEEE. doi:10.1109/EMBC.2016.7590828.

Total running time of the script: (0 minutes 26.074 seconds)

Download Jupyter notebook: muscle_ica.ipynb

Download Python source code: muscle_ica.py

Download zipped: muscle_ica.zip

Gallery generated by Sphinx-Gallery

Annotate muscle artifacts

Plot sensor denoising using oversampled temporal projection

---

## Repairing artifacts with ICA#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/40_artifact_correction_ica.html

**Contents:**
- Repairing artifacts with ICA#
- What is ICA?#
  - ICA in MNE-Python#
- Example: EOG and ECG artifact repair#
  - Visualizing the artifacts#
  - Filtering to remove slow drifts#
  - Fitting ICA#
  - Looking at the ICA solution#
  - Selecting ICA components manually#
  - Using an EOG channel to select ICA components#

Go to the end to download the full example code.

This tutorial covers the basics of independent components analysis (ICA) and shows how ICA can be used for artifact repair; an extended example illustrates repair of ocular and heartbeat artifacts. For conceptual background on ICA, see this scikit-learn tutorial.

We begin as always by importing the necessary Python modules and loading some example data. Because ICA can be computationally intense, we‚Äôll also crop the data to 60 seconds; and to save ourselves from repeatedly typing mne.preprocessing we‚Äôll directly import a few functions and classes from that submodule:

Before applying ICA (or any artifact repair strategy), be sure to observe the artifacts in your data to make sure you choose the right repair tool. Sometimes the right tool is no tool at all ‚Äî if the artifacts are small enough you may not even need to repair them to get good analysis results. See Overview of artifact detection for guidance on detecting and visualizing various types of artifact.

Independent components analysis (ICA) is a technique for estimating independent source signals from a set of recordings in which the source signals were mixed together in unknown ratios. A common example of this is the problem of blind source separation: with 3 musical instruments playing in the same room, and 3 microphones recording the performance (each picking up all 3 instruments, but at varying levels), can you somehow ‚Äúunmix‚Äù the signals recorded by the 3 microphones so that you end up with a separate ‚Äúrecording‚Äù isolating the sound of each instrument?

It is not hard to see how this analogy applies to EEG/MEG analysis: there are many ‚Äúmicrophones‚Äù (sensor channels) simultaneously recording many ‚Äúinstruments‚Äù (blinks, heartbeats, activity in different areas of the brain, muscular activity from jaw clenching or swallowing, etc). As long as these various source signals are statistically independent and non-gaussian, it is usually possible to separate the sources using ICA, and then re-construct the sensor signals after excluding the sources that are unwanted.

ICA and dimensionality reduction

If you want to perform ICA with no dimensionality reduction (other than the number of Independent Components (ICs) given in n_components, and any subsequent exclusion of ICs you specify in ICA.exclude), simply pass n_components.

However, if you do want to reduce dimensionality, consider this example: if you have 300 sensor channels and you set n_components=50 during instantiation and pass n_pca_components=None to apply, then the the first 50 PCs are sent to the ICA algorithm (yielding 50 ICs), and during reconstruction apply will use the 50 ICs plus PCs number 51-300 (the full PCA residual). If instead you specify n_pca_components=120 in apply, it will reconstruct using the 50 ICs plus the first 70 PCs in the PCA residual (numbers 51-120), thus discarding the smallest 180 components.

If you have previously been using EEGLAB‚Äôs runica() and are looking for the equivalent of its 'pca', n option to reduce dimensionality, set n_components=n during initialization and pass n_pca_components=n to apply.

MNE-Python implements three different ICA algorithms: fastica (the default), picard, and infomax. FastICA and Infomax are both in fairly widespread use; Picard is a newer (2017) algorithm that is expected to converge faster than FastICA and Infomax, and is more robust than other algorithms in cases where the sources are not completely independent, which typically happens with real EEG/MEG data. See [1] for more information.

The ICA interface in MNE-Python is similar to the interface in scikit-learn: some general parameters are specified when creating an ICA object, then the ICA object is fit to the data using its fit method. The results of the fitting are added to the ICA object as attributes that end in an underscore (_), such as ica.mixing_matrix_ and ica.unmixing_matrix_. After fitting, the ICA component(s) that you want to remove must be chosen, and the ICA fit must then be applied to the Raw or Epochs object using the ICA object‚Äôs apply method.

As is typically done with ICA, the data are first scaled to unit variance and whitened using principal components analysis (PCA) before performing the ICA decomposition. This is a two-stage process:

To deal with different channel types having different units (e.g., Volts for EEG and Tesla for MEG), data must be pre-whitened. If noise_cov=None (default), all data of a given channel type is scaled by the standard deviation across all channels. If noise_cov is a Covariance, the channels are pre-whitened using the covariance.

The pre-whitened data are then decomposed using PCA.

From the resulting principal components (PCs), the first n_components are then passed to the ICA algorithm if n_components is an integer number. It can also be a float between 0 and 1, specifying the fraction of explained variance that the PCs should capture; the appropriate number of PCs (i.e., just as many PCs as are required to explain the given fraction of total variance) is then passed to the ICA.

After visualizing the Independent Components (ICs) and excluding any that capture artifacts you want to repair, the sensor signal can be reconstructed using the ICA object‚Äôs apply method. By default, signal reconstruction uses all of the ICs (less any ICs listed in ICA.exclude) plus all of the PCs that were not included in the ICA decomposition (i.e., the ‚ÄúPCA residual‚Äù). If you want to reduce the number of components used at the reconstruction stage, it is controlled by the n_pca_components parameter (which will in turn reduce the rank of your data; by default n_pca_components=None resulting in no additional dimensionality reduction). The fitting and reconstruction procedures and the parameters that control dimensionality at various stages are summarized in the diagram below:

Diagram of ICA procedure in MNE-Python

See the Notes section of the ICA documentation for further details. Next we‚Äôll walk through an extended example that illustrates each of these steps in greater detail.

Let‚Äôs begin by visualizing the artifacts that we want to repair. In this dataset they are big enough to see easily in the raw data:

We can get a summary of how the ocular artifact manifests across each channel type using create_eog_epochs like we did in the Overview of artifact detection tutorial:

Now we‚Äôll do the same for the heartbeat artifacts, using create_ecg_epochs:

Before we run the ICA, an important step is filtering the data to remove low-frequency drifts, which can negatively affect the quality of the ICA fit. The slow drifts are problematic because they reduce the independence of the assumed-to-be-independent sources (e.g., during a slow upward drift, the neural, heartbeat, blink, and other muscular sources will all tend to have higher values), making it harder for the algorithm to find an accurate solution. A high-pass filter with 1 Hz cutoff frequency is recommended. However, because filtering is a linear operation, the ICA solution found from the filtered signal can be applied to the unfiltered signal (see [2] for more information), so we‚Äôll keep a copy of the unfiltered Raw object around so we can apply the ICA solution to it later.

Ignoring the time domain

The ICA algorithms implemented in MNE-Python find patterns across channels, but ignore the time domain. This means you can compute ICA on discontinuous Epochs or Evoked objects (not just continuous Raw objects), or only use every Nth sample by passing the decim parameter to ICA.fit().

Now we‚Äôre ready to set up and fit the ICA. Since we know (from observing our raw data) that the EOG and ECG artifacts are fairly strong, we would expect those artifacts to be captured in the first few dimensions of the PCA decomposition that happens before the ICA. Therefore, we probably don‚Äôt need a huge number of components to do a good job of isolating our artifacts (though it is usually preferable to include more components for a more accurate solution). As a first guess, we‚Äôll run ICA with n_components=15 (use only the first 15 PCA components to compute the ICA decomposition) ‚Äî a very small number given that our data has over 300 channels, but with the advantage that it will run quickly and we will able to tell easily whether it worked or not (because we already know what the EOG / ECG artifacts should look like).

ICA fitting is not deterministic (e.g., the components may get a sign flip on different runs, or may not always be returned in the same order), so we‚Äôll also specify a random seed so that we get identical results each time this tutorial is built by our web servers.

Epochs used for fitting ICA should not be baseline-corrected. Because cleaning the data via ICA may introduce DC offsets, we suggest to baseline correct your data after cleaning (and not before), should you require baseline correction.

Some optional parameters that we could have passed to the fit method include decim (to use only every Nth sample in computing the ICs, which can yield a considerable speed-up) and reject (for providing a rejection dictionary for maximum acceptable peak-to-peak amplitudes for each channel type, just like we used when creating epoched data in the Overview of MEG/EEG analysis with MNE-Python tutorial).

Now we can examine the ICs to see what they captured.

Using get_explained_variance_ratio(), we can retrieve the fraction of variance in the original data that is explained by our ICA components in the form of a dictionary:

The values were calculated for all ICA components jointly, but separately for each channel type (here: magnetometers and EEG).

We can also explicitly request for which component(s) and channel type(s) to perform the computation:

plot_sources will show the time series of the ICs. Note that in our call to plot_sources we can use the original, unfiltered Raw object. A helpful tip is that right clicking (or control + click with a trackpad) on the name of the component will bring up a plot of its properties. In this plot, you can also toggle the channel type in the topoplot (if you have multiple channel types) with ‚Äòt‚Äô and whether the spectrum is log-scaled or not with ‚Äòl‚Äô.

Here we can pretty clearly see that the first component (ICA000) captures the EOG signal quite well, and the second component (ICA001) looks a lot like a heartbeat (for more info on visually identifying Independent Components, this EEGLAB tutorial is a good resource). We can also visualize the scalp field distribution of each component using plot_components. These are interpolated based on the values in the ICA mixing matrix:

plot_components (which plots the scalp field topographies for each component) has an optional inst parameter that takes an instance of Raw or Epochs. Passing inst makes the scalp topographies interactive: clicking one will bring up a diagnostic plot_properties window (see below) for that component.

In the plots above it‚Äôs fairly obvious which ICs are capturing our EOG and ECG artifacts, but there are additional ways visualize them anyway just to be sure. First, we can plot an overlay of the original signal against the reconstructed signal with the artifactual ICs excluded, using plot_overlay:

We can also plot some diagnostics of each IC using plot_properties:

In the remaining sections, we‚Äôll look at different ways of choosing which ICs to exclude prior to reconstructing the sensor signals.

Once we‚Äôre certain which components we want to exclude, we can specify that manually by setting the ica.exclude attribute. Similar to marking bad channels, merely setting ica.exclude doesn‚Äôt do anything immediately (it just adds the excluded ICs to a list that will get used later when it‚Äôs needed). Once the exclusions have been set, ICA methods like plot_overlay will exclude those component(s) even if no exclude parameter is passed, and the list of excluded components will be preserved when using mne.preprocessing.ICA.save and mne.preprocessing.read_ica.

Now that the exclusions have been set, we can reconstruct the sensor signals with artifacts removed using the apply method (remember, we‚Äôre applying the ICA solution from the filtered data to the original unfiltered signal). Plotting the original raw data alongside the reconstructed data shows that the heartbeat and blink artifacts are repaired.

It may have seemed easy to review the plots and manually select which ICs to exclude, but when processing dozens or hundreds of subjects this can become a tedious, rate-limiting step in the analysis pipeline. One alternative is to use dedicated EOG or ECG sensors as a ‚Äúpattern‚Äù to check the ICs against, and automatically mark for exclusion any ICs that match the EOG/ECG pattern. Here we‚Äôll use find_bads_eog to automatically find the ICs that best match the EOG signal, then use plot_scores along with our other plotting functions to see which ICs it picked. We‚Äôll start by resetting ica.exclude back to an empty list:

Note that above we used plot_sources() on both the original Raw instance and also on an Evoked instance of the extracted EOG artifacts. This can be another way to confirm that find_bads_eog() has identified the correct components.

If you don‚Äôt have an EOG channel, find_bads_eog has a ch_name parameter that you can use as a proxy for EOG. You can use a single channel, or create a bipolar reference from frontal EEG sensors and use that as virtual EOG channel. This carries a risk however: you must hope that the frontal EEG channels only reflect EOG and not brain dynamics in the prefrontal cortex (or you must not care about those prefrontal signals).

For ECG, it is easier: find_bads_ecg can use cross-channel averaging of magnetometer or gradiometer channels to construct a virtual ECG channel, so if you have MEG channels it is usually not necessary to pass a specific channel name. find_bads_ecg also has two options for its method parameter: 'ctps' (cross-trial phase statistics [3]) and 'correlation' (Pearson correlation between data and ECG channel).

The last of these plots is especially useful: it shows us that the heartbeat artifact is coming through on two ICs, and we‚Äôve only caught one of them. In fact, if we look closely at the output of plot_sources (online, you can right-click ‚Üí ‚Äúview image‚Äù to zoom in), it looks like ICA014 has a weak periodic component that is in-phase with ICA001. It might be worthwhile to re-run the ICA with more components to see if that second heartbeat artifact resolves out a little better:

Much better! Now we‚Äôve captured both ICs that are reflecting the heartbeat artifact (and as a result, we got two diagnostic plots: one for each IC that reflects the heartbeat). This demonstrates the value of checking the results of automated approaches like find_bads_ecg before accepting them.

For EEG, activation of muscles for postural control of the head and neck contaminate the signal as well. This is usually not detected by MEG. For an example showing how to remove these components, see Removing muscle ICA components.

When dealing with multiple subjects, it is also possible to manually select an IC for exclusion on one subject, and then use that component as a template for selecting which ICs to exclude from other subjects‚Äô data, using mne.preprocessing.corrmap [4]. The idea behind corrmap is that the artifact patterns are similar enough across subjects that corresponding ICs can be identified by correlating the ICs from each ICA solution with a common template, and picking the ICs with the highest correlation strength. corrmap takes a list of ICA solutions, and a template parameter that specifies which ICA object and which component within it to use as a template.

Since our sample dataset only contains data from one subject, we‚Äôll use a different dataset with multiple subjects: the EEGBCI dataset [5][6]. The dataset has 109 subjects, we‚Äôll just download one run (a left/right hand movement task) from each of the first 4 subjects:

Now let‚Äôs run corrmap:

The first figure shows the template map, while the second figure shows all the maps that were considered a ‚Äúmatch‚Äù for the template (including the template itself). There is one match for each subject, but it‚Äôs a good idea to also double-check the ICA sources for each subject:

Notice that subjects 2 and 3 each seem to have two ICs that reflect ocular activity (components ICA000 and ICA002), but only one was caught by corrmap. Let‚Äôs try setting the threshold manually:

This time it found 2 ICs for each of subjects 2 and 3 (which is good). At this point we‚Äôll re-run corrmap with parameters label='blink', plot=False to label the ICs from each subject that capture the blink artifacts (without plotting them again).

Notice that the first subject has 3 different labels for the IC at index 0: ‚Äúeog/0/Fpz‚Äù, ‚Äúeog‚Äù, and ‚Äúblink‚Äù. The first two were added by find_bads_eog; the ‚Äúblink‚Äù label was added by the last call to corrmap. Notice also that each subject has at least one IC index labelled ‚Äúblink‚Äù, and subjects 2 and 3 each have two components (0 and 2) labelled ‚Äúblink‚Äù (consistent with the plot of IC sources above). The labels_ attribute of ICA objects can also be manually edited to annotate the ICs with custom labels. They also come in handy when plotting:

As a final note, it is possible to extract ICs numerically using the get_components method of ICA objects. This will return a NumPy array that can be passed to corrmap instead of the tuple of (subject_index, component_index) we passed before, and will yield the same result:

An advantage of using this numerical representation of an IC to capture a particular artifact pattern is that it can be saved and used as a template for future template-matching tasks using corrmap without having to load or recompute the ICA solution that yielded the template originally. Put another way, when the template is a NumPy array, the ICA object containing the template does not need to be in the list of ICAs provided to corrmap.

ICA is now fit to epoched MEG data instead of the raw data. We assume that the non-stationary EOG artifacts have already been removed. The sources matching the ECG are automatically found and displayed.

This example is computationally intensive, so it might take a few minutes to complete.

After reading the data, preprocessing consists of:

MEG channel selection

1-30 Hz band-pass filter

epoching -0.2 to 0.5 seconds with respect to events

rejection based on peak-to-peak amplitude

Note that we don‚Äôt baseline correct the epochs here ‚Äì we‚Äôll do this after cleaning with ICA is completed. Baseline correction before ICA is not recommended by the MNE-Python developers, as it doesn‚Äôt guarantee optimal results.

Fit ICA model using the FastICA algorithm, detect and plot components explaining ECG artifacts.

Plot the properties of the ECG components:

Plot the estimated sources of detected ECG related components:

Pierre Ablin, Jean-Francois Cardoso, and Alexandre Gramfort. Faster Independent Component Analysis by preconditioning with hessian approximations. IEEE Transactions on Signal Processing, 66(15):4040‚Äì4049, 2018. doi:10.1109/TSP.2018.2844203.

Irene Winkler, Stefan Debener, Klaus-Robert M√ºller, and Michael Tangermann. On the influence of high-pass filtering on ICA-based artifact reduction in EEG-ERP. In Proceedings of EMBC-2015, 4101‚Äì4105. Milan, 2015. IEEE. doi:10.1109/EMBC.2015.7319296.

J√ºrgen Dammers, Michael Schiek, Frank Boers, Carmen Silex, Mikhail Zvyagintsev, Uwe Pietrzyk, and Klaus Mathiak. Integration of amplitude and phase statistics for complete artifact removal in independent components of neuromagnetic recordings. IEEE Transactions on Biomedical Engineering, 55(10):2353‚Äì2362, 2008. doi:10.1109/TBME.2008.926677.

Filipa Campos Viola, Jeremy Thorne, Barrie Edmonds, Till Schneider, Tom Eichele, and Stefan Debener. Semi-automatic identification of independent components representing EEG artifact. Clinical Neurophysiology, 120(5):868‚Äì877, 2009. doi:10.1016/j.clinph.2009.01.015.

Gerwin Schalk, Dennis J. McFarland, Thilo Hinterberger, Niels Birbaumer, and Jonathan R. Wolpaw. BCI2000: a general-purpose brain-computer interface (BCI) system. IEEE Transactions on Biomedical Engineering, 51(6):1034‚Äì1043, 2004. doi:10.1109/TBME.2004.827072.

Ary L. Goldberger, Luis A. N. Amaral, Leon Glass, Jeffrey M. Hausdorff, Plamen Ch. Ivanov, Roger G. Mark, Joseph E. Mietus, George B. Moody, Chung-Kang Peng, and H. Eugene Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation, 2000. doi:10.1161/01.CIR.101.23.e215.

Total running time of the script: (0 minutes 53.671 seconds)

Download Jupyter notebook: 40_artifact_correction_ica.ipynb

Download Python source code: 40_artifact_correction_ica.py

Download zipped: 40_artifact_correction_ica.zip

Gallery generated by Sphinx-Gallery

Repairing artifacts with regression

Background on projectors and projections

---

## Repairing artifacts with regression#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/35_artifact_correction_regression.html

**Contents:**
- Repairing artifacts with regression#
- Prepare the data#
- Visualize the original data#
- Compute and apply EOG regression#
- Subtract the evoked response from the epoch data before regression#
- Create EOG evoked before regression#
- Visualize the effect on raw data#
- References#

Go to the end to download the full example code.

This tutorial covers removal of artifacts using regression as in Gratton et al. (1983) [1] and Croft & Barry (2000) [2].

Generally speaking, artifacts that result in time waveforms on the sensors that are accurately reflected by some reference signal can be removed by regression. Blink artifacts captured by bipolar EOG channels provide a good example of this, so we will demonstrate this here.

Although ECG signals are well captured by bipolar ECG electrodes, regression-based removal of ECG artifacts usually does not work very well. This is likely because the heart acts like a rotating dipole, and therefore the ECG channel time waveform recorded from the ECG electrode sites does not reflect the same temporal dynamics that manifest at each MEG channel (obtained by sampling some component of the related magnetic vector field). Other approaches like ICA or SSP will likely work better for ECG.

Furthermore, regression approaches are usually performed in situations where there are few channels available, and removing an entire signal component is undesirable. Hence, most articles on the topic concern EEG and it is unusual to see the technique applied to MEG. For this reason, we will restrict the analysis in this tutorial to EEG data only.

We begin as always by importing the necessary Python modules and loading some data. The MNE-Sample dataset has some clear, large blink artifacts, especially during the presentation of visual stimuli.

Let‚Äôs first look at the Evoked data (average across epochs) without any corrections applied.

We can see there is some EOG activity that is likely bleeding into the EEG evoked response. At around 250ms this becomes especially noticeable. Let‚Äôs apply regression to subtract the EOG signal from the EEG signals to clean it up.

Now, we‚Äôll compare the evoked response before and after we regress out the EOG signal. First, let‚Äôs try plain regression, and then we‚Äôll explore more advanced techniques.

The regression coefficients show the linear relationship between each EEG sensor and the EOG sensor. Note that occipital sensors have a positive relationship, as we set a common-average reference when we loaded the data above.

Now we are ready to use these coefficients to subtract the EOG signal from the EEG signals.

Regressing the EOG signal out of the EEG signals has reduced the peak around 250ms that was partly there because of eye artifacts.

In the MNE-Sample dataset, there are no segments of data that are particularly unstable, so the basic form of regression produces robust coefficients. However, this may not be the case in every dataset, so let‚Äôs explore some variations that may improve the estimation of the regression coefficients.

One potential problem is that the EOG sensor does not only pick up eye artifacts, but also a bit of EEG signal. This means we are prone to overestimating the regression coefficients if the EOG sensors are placed too close to the EEG sensors. However, there is a correction we can apply to alleviate this.

Gratton et al. (1983) [1] suggest computing regression coefficients on epoch data with the evoked response subtracted out. The idea is that the EEG signal components relevant to the study are in the evoked, so by removing them, mostly noise components will be left. Since EOG artifacts are unlikely to be strictly time-locked to the stimulus onset, enough EOG information will likely remain to be able to estimate robust regression coefficients.

We see that we obtain the same regression coefficients, even with the evoked removed from the epochs.

It is advantageous to estimate the regression coefficients on a piece of data with lots of EOG activity. As EOG activity is typically much larger than EEG, the EOG artifacts will dominate the signal and the regression coefficients will reflect mostly the influence of the EOG. To amplify this effect, Croft & Barry (2000) [2] suggest creating epochs based on blink onsets and computing the evoked blink response. The averaging procedure will suppress EEG signals that are not strictly time-locked with the blink response. Ideally, one would create evokeds for both blinks and saccades, and create two separate regression models. However, we will restrict ourselves to just blink epochs, since MNE-Python contains an automated method for creating those.

This is very similar to the approach taken by SSP. The difference is that SSP estimates signal components that are maximally correlated with the artifact and removes any data along that component (thereby reducing the rank of the non-EOG data), whereas the regression approach uses the ongoing EOG signal to determine how much data to remove (thereby not necessarily reducing the rank of the non-EOG data). Generally, SSP tends to err on the side of removing too much data, eliminating artifacts and true brain signals alike, whereas regression will err on the side of not removing enough, leaving some artifact signals still present in the signal.

We see that again, the regression weights have been correctly estimated.

Once we have obtained robust regression weights, we can use them to apply the regression directly to raw, epoched, and evoked data. Here, we will use the regression weights obtained from the blink evoked and apply it to an instance of Raw.

Gabriele Gratton, Michael G. H Coles, and Emanuel Donchin. A new method for off-line removal of ocular artifact. Electroencephalography and Clinical Neurophysiology, 55(4):468‚Äì484, 1983. doi:10.1016/0013-4694(83)90135-9.

R. J. Croft and R. J. Barry. Removal of ocular artifact from the EEG: a review. Clinical Neurophysiology, 30(1):5‚Äì19, 2000. doi:10.1016/S0987-7053(00)00055-1.

Total running time of the script: (0 minutes 12.499 seconds)

Download Jupyter notebook: 35_artifact_correction_regression.ipynb

Download Python source code: 35_artifact_correction_regression.py

Download zipped: 35_artifact_correction_regression.zip

Gallery generated by Sphinx-Gallery

Filtering and resampling data

Repairing artifacts with ICA

---

## Repairing artifacts with SSP#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/50_artifact_correction_ssp.html

**Contents:**
- Repairing artifacts with SSP#
- What is SSP?#
- Example: Environmental noise reduction from empty-room recordings#
  - Visualizing the empty-room noise#
  - Creating the empty-room projectors#
  - Visualizing how projectors affect the signal#
- Example: EOG and ECG artifact repair#
  - Visualizing the artifacts#
  - Repairing ECG artifacts with SSP#
  - Repairing EOG artifacts with SSP#

Go to the end to download the full example code.

This tutorial covers the basics of signal-space projection (SSP) and shows how SSP can be used for artifact repair; extended examples illustrate use of SSP for environmental noise reduction, and for repair of ocular and heartbeat artifacts.

We begin as always by importing the necessary Python modules. To save ourselves from repeatedly typing mne.preprocessing we‚Äôll directly import a handful of functions from that submodule:

Before applying SSP (or any artifact repair strategy), be sure to observe the artifacts in your data to make sure you choose the right repair tool. Sometimes the right tool is no tool at all ‚Äî if the artifacts are small enough you may not even need to repair them to get good analysis results. See Overview of artifact detection for guidance on detecting and visualizing various types of artifact.

Signal-space projection (SSP) [1] is a technique for removing noise from EEG and MEG signals by projecting the signal onto a lower-dimensional subspace. The subspace is chosen by calculating the average pattern across sensors when the noise is present, treating that pattern as a ‚Äúdirection‚Äù in the sensor space, and constructing the subspace to be orthogonal to the noise direction (for a detailed walk-through of projection see Background on projectors and projections).

The most common use of SSP is to remove noise from MEG signals when the noise comes from environmental sources (sources outside the subject‚Äôs body and the MEG system, such as the electromagnetic fields from nearby electrical equipment) and when that noise is stationary (doesn‚Äôt change much over the duration of the recording). However, SSP can also be used to remove biological artifacts such as heartbeat (ECG) and eye movement (EOG) artifacts. Examples of each of these are given below.

The example data was recorded on a Neuromag system, which stores SSP projectors for environmental noise removal in the system configuration (so that reasonably clean raw data can be viewed in real-time during acquisition). For this reason, all the Raw data in the example dataset already includes SSP projectors, which are noted in the output when loading the data:

The example data also includes an ‚Äúempty room‚Äù recording taken the same day as the recording of the subject. This will provide a more accurate estimate of environmental noise than the projectors stored with the system (which are typically generated during annual maintenance and tuning). Since we have this subject-specific empty-room recording, we‚Äôll create our own projectors from it and discard the system-provided SSP projectors (saving them first, for later comparison with the custom ones):

Notice that the empty room recording itself has the system-provided SSP projectors in it ‚Äî we‚Äôll remove those from the empty room file too.

Let‚Äôs take a look at the spectrum of the empty room noise. We can view an individual spectrum for each sensor, or an average (with confidence band) across sensors:

We create the SSP vectors using compute_proj_raw, and control the number of projectors with parameters n_grad and n_mag. Once created, the field pattern of the projectors can be easily visualized with plot_projs_topomap. We include the parameter vlim='joint' so that the colormap is computed jointly for all projectors of a given channel type; this makes it easier to compare their relative smoothness. Note that for the function to know the types of channels in a projector, you must also provide the corresponding Info object:

Notice that the gradiometer-based projectors seem to reflect problems with individual sensor units rather than a global noise source (indeed, planar gradiometers are much less sensitive to distant sources). This is the reason that the system-provided noise projectors are computed only for magnetometers. Comparing the system-provided projectors to the subject-specific ones, we can see they are reasonably similar (though in a different order) and the left-right component seems to have changed polarity.

We could visualize the different effects these have on the data by applying each set of projectors to different copies of the Raw object using apply_proj. However, the plot method has a proj parameter that allows us to temporarily apply projectors while plotting, so we can use this to visualize the difference without needing to copy the data. Because the projectors are so similar, we need to zoom in pretty close on the data to see any differences:

The effect is sometimes easier to see on averaged data. Here we use an interactive feature of mne.Evoked.plot_topomap to turn projectors on and off to see the effect on the data. Of course, the interactivity won‚Äôt work on the tutorial website, but you can download the tutorial and try it locally:

Plotting the ERP/F using evoked.plot() or evoked.plot_joint() with and without projectors applied can also be informative, as can plotting with proj='reconstruct', which can reduce the signal bias introduced by projections (see Visualizing SSP sensor-space bias via signal reconstruction below).

As mentioned in the ICA tutorial, an important first step is visualizing the artifacts you want to repair. Here they are in the raw data:

MNE-Python provides several functions for detecting and removing heartbeats from EEG and MEG data. As we saw in Overview of artifact detection, create_ecg_epochs can be used to both detect and extract heartbeat artifacts into an Epochs object, which can be used to visualize how the heartbeat artifacts manifest across the sensors:

Looks like the EEG channels are pretty spread out; let‚Äôs baseline-correct and plot again:

To compute SSP projectors for the heartbeat artifact, you can use compute_proj_ecg, which takes a Raw object as input and returns the requested number of projectors for magnetometers, gradiometers, and EEG channels (default is two projectors for each channel type). compute_proj_ecg also returns an events array containing the sample numbers corresponding to the peak of the R wave of each detected heartbeat.

The first line of output tells us that compute_proj_ecg found three existing projectors already in the Raw object, and will include those in the list of projectors that it returns (appending the new ECG projectors to the end of the list). If you don‚Äôt want that, you can change that behavior with the boolean no_proj parameter. Since we‚Äôve already run the computation, we can just as easily separate out the ECG projectors by indexing the list of projectors:

Just like with the empty-room projectors, we can visualize the scalp distribution:

Moreover, because these projectors were created using epochs chosen specifically because they contain time-locked artifacts, we can do a joint plot of the projectors and their effect on the time-averaged epochs. This figure has three columns:

The left shows the data traces before (black) and after (green) projection. We can see that the ECG artifact is well suppressed by one projector per channel type.

The center shows the topomaps associated with the projectors, in this case just a single topography for our one projector per channel type.

The right again shows the data traces (black), but this time with those traces also projected onto the first projector for each channel type (red) plus one surrogate ground truth for an ECG channel (MEG 0111).

Since no dedicated ECG sensor channel was detected in the Raw object, by default compute_proj_ecg used the magnetometers to estimate the ECG signal (as stated on the third line of output, above). You can also supply the ch_name parameter to restrict which channel to use for ECG artifact detection; this is most useful when you had an ECG sensor but it is not labeled as such in the Raw file.

The next few lines of the output describe the filter used to isolate ECG events. The default settings are usually adequate, but the filter can be customized via the parameters ecg_l_freq, ecg_h_freq, and filter_length (see the documentation of compute_proj_ecg for details).

Once the ECG events have been identified, compute_proj_ecg will also filter the data channels before extracting epochs around each heartbeat, using the parameter values given in l_freq, h_freq, filter_length, filter_method, and iir_params. Here again, the default parameter values are usually adequate.

By default, the filtered epochs will be averaged together before the projection is computed; this can be controlled with the boolean average parameter. In general this improves the signal-to-noise (where ‚Äúsignal‚Äù here is our artifact!) ratio because the artifact temporal waveform is fairly similar across epochs and well time locked to the detected events.

To get a sense of how the heartbeat affects the signal at each sensor, you can plot the data with and without the ECG projectors:

Finally, note that above we passed reject=None to the compute_proj_ecg function, meaning that all detected ECG epochs would be used when computing the projectors (regardless of signal quality in the data sensors during those epochs). The default behavior is to reject epochs based on signal amplitude: epochs with peak-to-peak amplitudes exceeding 50 ¬µV in EEG channels, 250 ¬µV in EOG channels, 2000 fT/cm in gradiometer channels, or 3000 fT in magnetometer channels. You can change these thresholds by passing a dictionary with keys eeg, eog, mag, and grad (though be sure to pass the threshold values in volts, teslas, or teslas/meter). Generally, it is a good idea to reject such epochs when computing the ECG projectors (since presumably the high-amplitude fluctuations in the channels are noise, not reflective of brain activity); passing reject=None above was done simply to avoid the dozens of extra lines of output (enumerating which sensor(s) were responsible for each rejected epoch) from cluttering up the tutorial.

compute_proj_ecg has a similar parameter flat for specifying the minimum acceptable peak-to-peak amplitude for each channel type.

While compute_proj_ecg conveniently combines several operations into a single function, MNE-Python also provides functions for performing each part of the process. Specifically:

mne.preprocessing.find_ecg_events for detecting heartbeats in a Raw object and returning a corresponding events array

mne.preprocessing.create_ecg_epochs for detecting heartbeats in a Raw object and returning an Epochs object

mne.compute_proj_epochs for creating projector(s) from any Epochs object

See the documentation of each function for further details.

In situations only limited electrodes are available for analysis, removing the cardiac artefact using techniques which rely on the availability of spatial information (such as SSP) may not be possible. In these instances, it may be of use to consider algorithms which require information only regarding heartbeat instances in the time domain, such as mne.preprocessing.apply_pca_obs().

Once again let‚Äôs visualize our artifact before trying to repair it. We‚Äôve seen above the large deflections in frontal EEG channels in the raw data; here is how the ocular artifacts manifests across all the sensors:

Just like we did with the heartbeat artifact, we can compute SSP projectors for the ocular artifact using compute_proj_eog, which again takes a Raw object as input and returns the requested number of projectors for magnetometers, gradiometers, and EEG channels (default is two projectors for each channel type). This time, we‚Äôll pass no_proj parameter (so we get back only the new EOG projectors, not also the existing projectors in the Raw object), and we‚Äôll ignore the events array by assigning it to _ (the conventional way of handling unwanted return elements in Python).

Just like with the empty-room and ECG projectors, we can visualize the scalp distribution:

And we can do a joint image:

And finally, we can make a joint visualization with our EOG evoked. We will also make a bad choice here and select two EOG projectors for EEG and magnetometers, and we will see them show up as noise in the plot. Even though the projected time course (left column) looks perhaps okay, problems show up in the center (topomaps) and right plots (projection of channel data onto the projection vector):

The second magnetometer topomap has a bilateral auditory field pattern.

The uniformly-scaled projected temporal time course (solid lines) show that, while the first projector trace (red) has a large EOG-like amplitude, the second projector trace (blue-green) is much smaller.

The re-normalized projected temporal time courses show that the second PCA trace is very noisy relative to the EOG channel data (yellow).

Now we repeat the plot from above (with empty room and ECG projectors) and compare it to a plot with empty room, ECG, and EOG projectors, to see how well the ocular artifacts have been repaired:

Notice that the small peaks in the first to magnetometer channels (MEG 1411 and MEG 1421) that occur at the same time as the large EEG deflections have also been removed.

In the examples above, we used 3 projectors (all magnetometer) to capture empty room noise, and saw how projectors computed for the gradiometers failed to capture global patterns (and thus we discarded the gradiometer projectors). Then we computed 3 projectors (1 for each channel type) to capture the heartbeat artifact, and 3 more to capture the ocular artifact. How did we choose these numbers? The short answer is ‚Äúbased on experience‚Äù ‚Äî knowing how heartbeat artifacts typically manifest across the sensor array allows us to recognize them when we see them, and recognize when additional projectors are capturing something else other than a heartbeat artifact (and thus may be removing brain signal and should be discarded).

Internally, the reconstruction is performed by effectively using a minimum-norm source localization to a spherical source space with the projections accounted for, and then projecting the source-space data back out to sensor space.

Because SSP performs an orthogonal projection, any spatial component in the data that is not perfectly orthogonal to the SSP spatial direction(s) will have its overall amplitude reduced by the projection operation. In other words, SSP typically introduces some amount of amplitude reduction bias in the sensor space data.

When performing source localization of M/EEG data, these projections are properly taken into account by being applied not just to the M/EEG data but also to the forward solution, and hence SSP should not bias the estimated source amplitudes. However, for sensor space analyses, it can be useful to visualize the extent to which SSP projection has biased the data. This can be explored by using proj='reconstruct' in evoked plotting functions, for example via evoked.plot(), here restricted to just EEG channels for speed:

Note that here the bias in the EEG and magnetometer channels is reduced by the reconstruction. This suggests that the application of SSP has slightly reduced the amplitude of our signals in sensor space, but that it should not bias the amplitudes in source space.

Mikko A. Uusitalo and Risto J. Ilmoniemi. Signal-space projection method for separating MEG or EEG into components. Medical & Biological Engineering & Computing, 35(2):135‚Äì140, 1997. doi:10.1007/BF02534144.

Total running time of the script: (0 minutes 47.936 seconds)

Download Jupyter notebook: 50_artifact_correction_ssp.ipynb

Download Python source code: 50_artifact_correction_ssp.py

Download zipped: 50_artifact_correction_ssp.zip

Gallery generated by Sphinx-Gallery

Background on projectors and projections

Setting the EEG reference

---

## Repeated measures ANOVA on source data with spatio-temporal clustering#

**URL:** https://mne.tools/stable/auto_tutorials/stats-source-space/60_cluster_rmANOVA_spatiotemporal.html

**Contents:**
- Repeated measures ANOVA on source data with spatio-temporal clustering#
- Set parameters#
- Read epochs for all channels, removing a bad one#
- Transform to source space#
- Transform to common cortical space#
- Prepare function for arbitrary contrast#
- Compute clustering statistic#
- Visualize the clusters#

Go to the end to download the full example code.

This example illustrates how to make use of the clustering functions for arbitrary, self-defined contrasts beyond standard t-tests. In this case we will tests if the differences in evoked responses between stimulation modality (visual VS auditory) depend on the stimulus location (left vs right) for a group of subjects (simulated here using one subject‚Äôs data). For this purpose we will compute an interaction effect using a repeated measures ANOVA. The multiple comparisons problem is addressed with a cluster-level permutation test across space and time.

Normally you would read in estimates across several subjects and morph them to the same cortical space (e.g. fsaverage). For example purposes, we will simulate this by just having each ‚Äúsubject‚Äù have the same response (just noisy in source space) here.

We‚Äôll only consider the left hemisphere in this tutorial.

It‚Äôs a good idea to spatially smooth the data, and for visualization purposes, let‚Äôs morph these to fsaverage, which is a grade 5 ICO source space with vertices 0:10242 for each hemisphere. Usually you‚Äôd have to morph each subject‚Äôs data separately, but here since all estimates are on ‚Äòsample‚Äô we can use one morph matrix for all the heavy lifting.

Now we need to prepare the group matrix for the ANOVA statistic. To make the clustering function work correctly with the ANOVA function X needs to be a list of multi-dimensional arrays (one per condition) of shape: samples (subjects) √ó time √ó space.

First we permute dimensions, then split the array into a list of conditions and discard the empty dimension resulting from the split using numpy squeeze.

As our ANOVA function is a multi-purpose tool we need to apply a few modifications to integrate it with the clustering function. This includes reshaping data, setting default arguments and processing the return values. For this reason we‚Äôll write a tiny dummy function.

We will tell the ANOVA how to interpret the data matrix in terms of factors. This is done via the factor levels argument which is a list of the number factor levels for each factor.

Finally we will pick the interaction effect by passing ‚ÄòA:B‚Äô. (this notation is borrowed from the R formula language). As an aside, note that in this particular example, we cannot use the A*B notation which return both the main and the interaction effect. The reason is that the clustering function expects stat_fun to return a 1-D array. To get clusters for both, you must create a loop.

A stat_fun must deal with a variable number of input arguments.

Inside the clustering function each condition will be passed as flattened array, necessitated by the clustering procedure. The ANOVA however expects an input array of dimensions: subjects √ó conditions √ó observations (optional).

The following function catches the list input and swaps the first and the second dimension, and finally calls ANOVA.

For further details on this ANOVA function consider the corresponding time-frequency tutorial.

To use an algorithm optimized for spatio-temporal clustering, we just pass the spatial adjacency matrix (instead of spatio-temporal).

Finally, let‚Äôs investigate interaction effect by reconstructing the time courses:

Total running time of the script: (0 minutes 14.811 seconds)

Download Jupyter notebook: 60_cluster_rmANOVA_spatiotemporal.ipynb

Download Python source code: 60_cluster_rmANOVA_spatiotemporal.py

Download zipped: 60_cluster_rmANOVA_spatiotemporal.zip

Gallery generated by Sphinx-Gallery

2 samples permutation test on source data with spatio-temporal clustering

Machine learning models of neural activity

---

## Segmenting continuous data into epochs#

**URL:** https://mne.tools/stable/auto_tutorials/epochs/index.html

**Contents:**
- Segmenting continuous data into epochs#

These tutorials cover epoched data, and how it differs from working with continuous data.

The Epochs data structure: discontinuous data

Regression-based baseline correction

Visualizing epoched data

Working with Epoch metadata

Auto-generating Epochs metadata

Exporting Epochs to Pandas DataFrames

Divide continuous data into equally-spaced epochs

Working with eye tracker data in MNE-Python

The Epochs data structure: discontinuous data

---

## Setting the EEG reference#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/55_setting_eeg_reference.html

**Contents:**
- Setting the EEG reference#
- Background#
- Setting or changing the reference channel#
- Setting average reference#
- Creating the average reference as a projector#
- Using an infinite reference (REST)#
- Using a bipolar reference#
- EEG reference and source modeling#
- References#

Go to the end to download the full example code.

This tutorial describes how to set or change the EEG reference in MNE-Python.

As usual we‚Äôll start by importing the modules we need, loading some example data, and cropping it to save memory. Since this tutorial deals specifically with EEG, we‚Äôll also restrict the dataset to just a few EEG channels so the plots are easier to see:

EEG measures a voltage (difference in electric potential) between each electrode and a reference electrode. This means that whatever signal is present at the reference electrode is effectively subtracted from all the measurement electrodes. Therefore, an ideal reference signal is one that captures none of the brain-specific fluctuations in electric potential, while capturing all of the environmental noise/interference that is being picked up by the measurement electrodes.

In practice, this means that the reference electrode is often placed in a location on the subject‚Äôs body and close to their head (so that any environmental interference affects the reference and measurement electrodes similarly) but as far away from the neural sources as possible (so that the reference signal doesn‚Äôt pick up brain-based fluctuations). Typical reference locations are the subject‚Äôs earlobe, nose, mastoid process, or collarbone. Each of these has advantages and disadvantages regarding how much brain signal it picks up (e.g., the mastoids pick up a fair amount compared to the others), and regarding the environmental noise it picks up (e.g., earlobe electrodes may shift easily, and have signals more similar to electrodes on the same side of the head).

Even in cases where no electrode is specifically designated as the reference, EEG recording hardware will still treat one of the scalp electrodes as the reference, and the recording software may or may not display it to you (it might appear as a completely flat channel, or the software might subtract out the average of all signals before displaying, making it look like there is no reference).

If you want to recompute your data with a different reference than was used when the raw data were recorded and/or saved, MNE-Python provides the set_eeg_reference() method on Raw objects as well as the mne.add_reference_channels() function. To use an existing channel as the new reference, use the set_eeg_reference() method; you can also designate multiple existing electrodes as reference channels, as is sometimes done with mastoid references:

If a scalp electrode was used as reference but was not saved alongside the raw data (reference channels often aren‚Äôt), you may wish to add it back to the dataset before re-referencing. For example, if your EEG system recorded with channel Fp1 as the reference but did not include Fp1 in the data file, using set_eeg_reference() to set (say) Cz as the new reference will then subtract out the signal at Cz without restoring the signal at Fp1. In this situation, you can add back Fp1 as a flat channel prior to re-referencing using add_reference_channels(). (Since our example data doesn‚Äôt use the 10-20 electrode naming system, the example below adds EEG 999 as the missing reference, then sets the reference to EEG 050.) Here‚Äôs how the data looks in its original state:

By default, add_reference_channels() returns a copy, so we can go back to our original raw object later. If you wanted to alter the existing Raw object in-place you could specify copy=False.

Notice that the new reference (EEG 050) is now flat, while the original reference channel that we added back to the data (EEG 999) has a non-zero signal. Notice also that EEG 053 (which is marked as ‚Äúbad‚Äù in raw.info['bads']) is not affected by the re-referencing.

To set a ‚Äúvirtual reference‚Äù that is the average of all channels, you can use set_eeg_reference() with ref_channels='average'. Just as above, this will not affect any channels marked as ‚Äúbad‚Äù, nor will it include bad channels when computing the average. However, it does modify the Raw object in-place, so we‚Äôll make a copy first, so we can still go back to the unmodified Raw object later:

If using an average reference, it is possible to create the reference as a projector rather than subtracting the reference from the data immediately by specifying projection=True:

Creating the average reference as a projector has a few advantages:

It is possible to turn projectors on or off when plotting, so it is easy to visualize the effect that the average reference has on the data.

If additional channels are marked as ‚Äúbad‚Äù or if a subset of channels are later selected, the projector will be re-computed to take these changes into account (thus guaranteeing that the signal is zero-mean).

If there are other unapplied projectors affecting the EEG channels (such as SSP projectors for removing heartbeat or blink artifacts), EEG re-referencing cannot be performed until those projectors are either applied or removed; adding the EEG reference as a projector is not subject to that constraint. (The reason this wasn‚Äôt a problem when we applied the non-projector average reference to raw_avg_ref above is that the empty-room projectors included in the sample data .fif file were only computed for the magnetometers.)

To use the ‚Äúpoint at infinity‚Äù reference technique described in [1] requires a forward model, which we can create in a few steps. Here we use a fairly large spacing of vertices (pos = 15 mm) to reduce computation time; a 5 mm spacing is more typical for real data analysis:

To create a bipolar reference, you can use set_bipolar_reference() along with the respective channel names for anode and cathode which creates a new virtual channel that takes the difference between two specified channels (anode and cathode) and drops the original channels by default. The new virtual channel will be annotated with the channel info of the anode with location set to (0, 0, 0) and coil type set to EEG_BIPOLAR by default. Here we use a contralateral/transverse bipolar reference between channels EEG 054 and EEG 055 as described in [2] which creates a new virtual channel named EEG 054-EEG 055.

If you plan to perform source modeling (either with EEG or combined EEG/MEG data), it is strongly recommended to use the average-reference-as-projection approach. It is important to use an average reference because using a specific reference sensor (or even an average of a few sensors) spreads the forward model error from the reference sensor(s) into all sensors, effectively amplifying the importance of the reference sensor(s) when computing source estimates. In contrast, using the average of all EEG channels as reference spreads the forward modeling error evenly across channels, so no one channel is weighted more strongly during source estimation. See also this FieldTrip FAQ on average referencing for more information.

The main reason for specifying the average reference as a projector was mentioned in the previous section: an average reference projector adapts if channels are dropped, ensuring that the signal will always be zero-mean when the source modeling is performed. In contrast, applying an average reference by the traditional subtraction method offers no such guarantee.

For these reasons, when performing inverse imaging, MNE-Python will raise a ValueError if there are EEG channels present and something other than an average reference projector strategy has been specified. To ensure correct functioning consider calling set_eeg_reference(projection=True) to add an average reference as a projector.

D. Yao. A method to standardize a reference of scalp EEG recordings to a point at infinity. Physiological Measurement, 22(4):693‚Äì711, 2001. doi:10.1088/0967-3334/22/4/305.

Dezhong Yao, Yun Qin, Shiang Hu, Li Dong, Maria L Bringas Vega, and Pedro A Vald√©s Sosa. Which reference should we use for EEG and ERP practice? Brain topography, 32(4):530‚Äì549, 2019. doi:10.1007/s10548-019-00707-x.

Total running time of the script: (0 minutes 23.227 seconds)

Download Jupyter notebook: 55_setting_eeg_reference.ipynb

Download Python source code: 55_setting_eeg_reference.py

Download zipped: 55_setting_eeg_reference.zip

Gallery generated by Sphinx-Gallery

Repairing artifacts with SSP

Extracting and visualizing subject head movement

---

## Shifting time-scale in evoked data#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/shift_evoked.html

**Contents:**
- Shifting time-scale in evoked data#

Go to the end to download the full example code.

Download Jupyter notebook: shift_evoked.ipynb

Download Python source code: shift_evoked.py

Download zipped: shift_evoked.zip

Gallery generated by Sphinx-Gallery

Plot sensor denoising using oversampled temporal projection

Remap MEG channel types

---

## Show EOG artifact timing#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/eog_artifact_histogram.html

**Contents:**
- Show EOG artifact timing#

Go to the end to download the full example code.

Compute the distribution of timing for EOG artifacts.

Plot EOG artifact distribution

Download Jupyter notebook: eog_artifact_histogram.ipynb

Download Python source code: eog_artifact_histogram.py

Download zipped: eog_artifact_histogram.zip

Gallery generated by Sphinx-Gallery

Transform EEG data using current source density (CSD)

Reduce EOG artifacts through regression

---

## Signal-space separation (SSS) and Maxwell filtering#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/60_maxwell_filtering_sss.html

**Contents:**
- Signal-space separation (SSS) and Maxwell filtering#
- Background on SSS and Maxwell filtering#
- Using SSS and Maxwell filtering in MNE-Python#
- Spatiotemporal SSS (tSSS)#
- Movement compensation#
- Caveats to using SSS / Maxwell filtering#
- References#

Go to the end to download the full example code.

This tutorial covers reducing environmental noise and compensating for head movement with SSS and Maxwell filtering.

As usual, we‚Äôll start by importing the modules we need, loading some example data, and cropping it to save on memory:

Signal-space separation (SSS) [1][2] is a technique based on the physics of electromagnetic fields. SSS separates the measured signal into components attributable to sources inside the measurement volume of the sensor array (the internal components), and components attributable to sources outside the measurement volume (the external components). The internal and external components are linearly independent, so it is possible to simply discard the external components to reduce environmental noise. Maxwell filtering is a related procedure that omits the higher-order components of the internal subspace, which are dominated by sensor noise. Typically, Maxwell filtering and SSS are performed together (in MNE-Python they are implemented together in a single function).

Like SSP, SSS is a form of projection. Whereas SSP empirically determines a noise subspace based on data (empty-room recordings, EOG or ECG activity, etc) and projects the measurements onto a subspace orthogonal to the noise, SSS mathematically constructs the external and internal subspaces from spherical harmonics and reconstructs the sensor signals using only the internal subspace (i.e., does an oblique projection).

Maxwell filtering was originally developed for Elekta Neuromag¬Æ systems, and should be considered experimental for non-Neuromag data. See the Notes section of the maxwell_filter() docstring for details.

The MNE-Python implementation of SSS / Maxwell filtering currently provides the following features:

Basic bad channel detection (find_bad_channels_maxwell())

Bad channel reconstruction

Cross-talk cancellation

Fine calibration correction

Coordinate frame translation

Regularization of internal components using information theory

Raw movement compensation (using head positions estimated by MaxFilter)

cHPI subtraction (see mne.chpi.filter_chpi())

Handling of 3D (in addition to 1D) fine calibration files

Epoch-based movement compensation as described in [1] through mne.epochs.average_movements()

Experimental processing of data from (un-compensated) non-Elekta systems

For optimal use of SSS with data from Elekta Neuromag¬Æ systems, you should provide the path to the fine calibration file (which encodes site-specific information about sensor orientation and calibration) as well as a crosstalk compensation file (which reduces interference between Elekta‚Äôs co-located magnetometer and paired gradiometer sensor units).

Before we perform SSS we‚Äôll look for bad channels ‚Äî MEG 2443 is quite noisy.

It is critical to mark bad channels in raw.info['bads'] before calling maxwell_filter() in order to prevent bad channel noise from spreading.

Let‚Äôs see if we can automatically detect it.

find_bad_channels_maxwell needs to operate on a signal without line noise or cHPI signals. By default, it simply applies a low-pass filter with a cutoff frequency of 40 Hz to the data, which should remove these artifacts. You may also specify a different cutoff by passing the h_freq keyword argument. If you set h_freq=None, no filtering will be applied. This can be useful if your data has already been preconditioned, for example using mne.chpi.filter_chpi(), mne.io.Raw.notch_filter(), or mne.io.Raw.filter().

Now we can update the list of bad channels in the dataset.

We called find_bad_channels_maxwell with the optional keyword argument return_scores=True, causing the function to return a dictionary of all data related to the scoring used to classify channels as noisy or flat. This information can be used to produce diagnostic figures.

In the following, we will generate such visualizations for the automated detection of noisy gradiometer channels.

You can use the very same code as above to produce figures for flat channel detection. Simply replace the word ‚Äúnoisy‚Äù with ‚Äúflat‚Äù, and replace vmin=np.nanmin(limits) with vmax=np.nanmax(limits).

You can see the un-altered scores for each channel and time segment in the left subplots, and thresholded scores ‚Äì those which exceeded a certain limit of noisiness ‚Äì in the right subplots. While the right subplot is entirely white for the magnetometers, we can see a horizontal line extending all the way from left to right for the gradiometers. This line corresponds to channel MEG 2443, which was reported as auto-detected noisy channel in the step above. But we can also see another channel exceeding the limits, apparently in a more transient fashion. It was therefore not detected as bad, because the number of segments in which it exceeded the limits was less than 5, which MNE-Python uses by default.

You can request a different number of segments that must be found to be problematic before find_bad_channels_maxwell reports them as bad. To do this, pass the keyword argument min_count to the function.

Obviously, this algorithm is not perfect. Specifically, on closer inspection of the raw data after looking at the diagnostic plots above, it becomes clear that the channel exceeding the ‚Äúnoise‚Äù limits in some segments without qualifying as ‚Äúbad‚Äù, in fact contains some flux jumps. There were just not enough flux jumps in the recording for our automated procedure to report the channel as bad. So it can still be useful to manually inspect and mark bad channels. The channel in question is MEG 2313. Let‚Äôs mark it as bad:

After that, performing SSS and Maxwell filtering is done with a single call to maxwell_filter(), with the crosstalk and fine calibration filenames provided (if available):

To see the effect, we can plot the data before and after SSS / Maxwell filtering.

Notice that channels marked as ‚Äúbad‚Äù have been effectively repaired by SSS, eliminating the need to perform interpolation. The heartbeat artifact has also been substantially reduced.

The maxwell_filter() function has parameters int_order and ext_order for setting the order of the spherical harmonic expansion of the interior and exterior components; the default values are appropriate for most use cases. Additional parameters include coord_frame and origin for controlling the coordinate frame (‚Äúhead‚Äù or ‚Äúmeg‚Äù) and the origin of the sphere; the defaults are appropriate for most studies that include digitization of the scalp surface / electrodes. See the documentation of maxwell_filter() for details.

An assumption of SSS is that the measurement volume (the spherical shell where the sensors are physically located) is free of electromagnetic sources. The thickness of this source-free measurement shell should be 4-8 cm for SSS to perform optimally. In practice, there may be sources falling within that measurement volume; these can often be mitigated by using Spatiotemporal Signal Space Separation (tSSS) [2]. tSSS works by looking for temporal correlation between components of the internal and external subspaces, and projecting out any components that are common to the internal and external subspaces. The projection is done in an analogous way to SSP, except that the noise vector is computed across time points instead of across sensors.

To use tSSS in MNE-Python, pass a time (in seconds) to the parameter st_duration of maxwell_filter(). This will determine the ‚Äúchunk duration‚Äù over which to compute the temporal projection. The chunk duration effectively acts as a high-pass filter with a cutoff frequency of \(\frac{1}{\mathtt{st\_duration}}~\mathrm{Hz}\); this effective high-pass has an important consequence:

In general, larger values of st_duration are better (provided that your computer has sufficient memory) because larger values of st_duration will have a smaller effect on the signal.

If the chunk duration does not evenly divide your data length, the final (shorter) chunk will be added to the prior chunk before filtering, leading to slightly different effective filtering for the combined chunk (the effective cutoff frequency differing at most by a factor of 2). If you need to ensure identical processing of all analyzed chunks, either:

choose a chunk duration that evenly divides your data length (only recommended if analyzing a single subject or run), or

include at least 2 * st_duration of post-experiment recording time at the end of the Raw object, so that the data you intend to further analyze is guaranteed not to be in the final or penultimate chunks.

Additional parameters affecting tSSS include st_correlation (to set the correlation value above which correlated internal and external components will be projected out) and st_only (to apply only the temporal projection without also performing SSS and Maxwell filtering). See the docstring of maxwell_filter() for details.

If you have information about subject head position relative to the sensors (i.e., continuous head position indicator coils, or cHPI), SSS can take that into account when projecting sensor data onto the internal subspace. In case you are not sure whether you have that information or want to doublecheck, you can use mne.chpi.get_active_chpi() (currently only implemented for neuromag systems).

Head position data can be computed using mne.chpi.compute_chpi_locs() and mne.chpi.compute_head_pos(), or loaded with the mne.chpi.read_head_pos() function. The example data doesn‚Äôt include cHPI, so here we‚Äôll load a .pos file used for testing, just to demonstrate:

The cHPI data file could also be passed as the head_pos parameter of maxwell_filter(). Not only would this account for movement within a given recording session, but also would effectively normalize head position across different measurement sessions and subjects. See here for an extended example of applying movement compensation during Maxwell filtering / SSS. Another option is to apply movement compensation when averaging epochs into an Evoked instance, using the mne.epochs.average_movements() function.

Each of these approaches requires time-varying estimates of head position, which is obtained from MaxFilter using the -headpos and -hp arguments (see the MaxFilter manual for details).

There are patents related to the Maxwell filtering algorithm, which may legally preclude using it in commercial applications. More details are provided in the documentation of maxwell_filter().

SSS works best when both magnetometers and gradiometers are present, and is most effective when gradiometers are planar (due to the need for very accurate sensor geometry and fine calibration information). Thus its performance is dependent on the MEG system used to collect the data.

Samu Taulu and Matti Kajola. Presentation of electromagnetic multichannel data: the signal space separation method. Journal of Applied Physics, 97(12):124905, 2005. doi:10.1063/1.1935742.

Samu Taulu and Juha Simola. Spatiotemporal signal space separation method for rejecting nearby interference in MEG measurements. Physics in Medicine and Biology, 51(7):1759‚Äì1768, 2006. doi:10.1088/0031-9155/51/7/008.

Total running time of the script: (0 minutes 33.234 seconds)

Download Jupyter notebook: 60_maxwell_filtering_sss.ipynb

Download Python source code: 60_maxwell_filtering_sss.py

Download zipped: 60_maxwell_filtering_sss.zip

Gallery generated by Sphinx-Gallery

Extracting and visualizing subject head movement

Preprocessing functional near-infrared spectroscopy (fNIRS) data

---

## Simulation#

**URL:** https://mne.tools/stable/auto_tutorials/simulation/index.html

**Contents:**
- Simulation#

These tutorials describe how to populate MNE-Python data structures with arbitrary data, using the array-based constructors and the simulation submodule.

Creating MNE-Python data structures from scratch

Corrupt known signal with point spread

DICS for power mapping

Sleep stage classification from polysomnography (PSG) data

Creating MNE-Python data structures from scratch

---

## Sleep stage classification from polysomnography (PSG) data#

**URL:** https://mne.tools/stable/auto_tutorials/clinical/60_sleep.html

**Contents:**
- Sleep stage classification from polysomnography (PSG) data#
- Load the data#
  - Read the PSG data and Hypnograms to create a raw object#
  - Extract 30s events from annotations#
  - Create Epochs from the data based on the events found in the annotations#
  - Applying the same steps to the test data from Bob#
- Feature Engineering#
  - Design a scikit-learn transformer from a Python function#
- Multiclass classification workflow using scikit-learn#
  - Further analysis of the data#

Go to the end to download the full example code.

This code is taken from the analysis code used in [1]. If you reuse this code please consider citing this work.

This tutorial explains how to perform a toy polysomnography analysis that answers the following question:

Given two subjects from the Sleep Physionet dataset [2][3], namely Alice and Bob, how well can we predict the sleep stages of Bob from Alice‚Äôs data?

This problem is tackled as supervised multiclass classification task. The aim is to predict the sleep stage from 5 possible stages for each chunk of 30 seconds of data.

Here we download the data of two subjects. The end goal is to obtain epochs and the associated ground truth.

MNE-Python provides us with mne.datasets.sleep_physionet.age.fetch_data() to conveniently download data from the Sleep Physionet dataset [2][3]. Given a list of subjects and records, the fetcher downloads the data and provides us with a pair of files for each subject:

-PSG.edf containing the polysomnography. The raw data from the EEG helmet,

-Hypnogram.edf containing the annotations recorded by an expert.

Combining these two in a mne.io.Raw object will allow us to extract events based on the descriptions of the annotations to obtain the epochs.

The Sleep Physionet dataset is annotated using 8 labels: Wake (W), Stage 1, Stage 2, Stage 3, Stage 4 corresponding to the range from light sleep to deep sleep, REM sleep (R) where REM is the abbreviation for Rapid Eye Movement sleep, movement (M), and Stage (?) for any none scored segment.

We will work only with 5 stages: Wake (W), Stage 1, Stage 2, Stage 3/4, and REM sleep (R). To do so, we use the event_id parameter in mne.events_from_annotations() to select which events are we interested in and we associate an event identifier to each of them.

Moreover, the recordings contain long awake (W) regions before and after each night. To limit the impact of class imbalance, we trim each recording by only keeping 30 minutes of wake time before the first occurrence and 30 minutes after the last occurrence of sleep stages.

Observing the power spectral density (PSD) plot of the epochs grouped by sleeping stage we can see that different sleep stages have different signatures. These signatures remain similar between Alice and Bob‚Äôs data.

The rest of this section we will create EEG features based on relative power in specific frequency bands to capture this difference between the sleep stages in our data.

We will now create a function to extract EEG features based on relative power in specific frequency bands to be able to predict sleep stages from EEG signals.

To answer the question of how well can we predict the sleep stages of Bob from Alice‚Äôs data and avoid as much boilerplate code as possible, we will take advantage of two key features of sckit-learn: Pipeline , and FunctionTransformer.

Scikit-learn pipeline composes an estimator as a sequence of transforms and a final estimator, while the FunctionTransformer converts a python function in an estimator compatible object. In this manner we can create scikit-learn estimator that takes mne.Epochs thanks to eeg_power_band function we just created.

In short, yes. We can predict Bob‚Äôs sleeping stages based on Alice‚Äôs data.

We can check the confusion matrix or the classification report.

Fetch 50 subjects from the Physionet database and run a 5-fold cross-validation leaving each time 10 subjects out in the test set.

Stanislas Chambon, Mathieu N. Galtier, Pierrick J. Arnal, Gilles Wainrib, and Alexandre Gramfort. A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 26(4):758‚Äì769, 2018. doi:10.1109/TNSRE.2018.2813138.

B. Kemp, A. H. Zwinderman, B. Tuk, H. A. C. Kamphuisen, and J. J. L. Obery√©. Analysis of a sleep-dependent neuronal feedback loop: the slow-wave microcontinuity of the EEG. IEEE Transactions on Biomedical Engineering, 47(9):1185‚Äì1194, 2000. doi:10.1109/10.867928.

Ary L. Goldberger, Luis A. N. Amaral, Leon Glass, Jeffrey M. Hausdorff, Plamen Ch. Ivanov, Roger G. Mark, Joseph E. Mietus, George B. Moody, Chung-Kang Peng, and H. Eugene Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation, 2000. doi:10.1161/01.CIR.101.23.e215.

Total running time of the script: (0 minutes 22.882 seconds)

Download Jupyter notebook: 60_sleep.ipynb

Download Python source code: 60_sleep.py

Download zipped: 60_sleep.zip

Gallery generated by Sphinx-Gallery

Working with ECoG data

---

## Source alignment and coordinate frames#

**URL:** https://mne.tools/stable/auto_tutorials/forward/20_source_alignment.html

**Contents:**
- Source alignment and coordinate frames#
- Understanding coordinate frames#
  - Coordinate frame definitions#
  - A bad example#
  - A good example#
- Visualizing the transformations#
  - Example: MRI defacing#
- Defining the head‚ÜîMRI trans using the GUI#
- Alignment without MRI#

Go to the end to download the full example code.

This tutorial shows how to visually assess the spatial alignment of MEG sensor locations, digitized scalp landmark and sensor locations, and MRI volumes. This alignment process is crucial for computing the forward solution, as is understanding the different coordinate frames involved in this process.

Let‚Äôs start out by loading some data.

For M/EEG source imaging, there are three coordinate frames must be brought into alignment using two 3D transformation matrices that define how to rotate and translate points in one coordinate frame to their equivalent locations in another. The three main coordinate frames are:

‚Äúmeg‚Äù: the coordinate frame for the physical locations of MEG sensors

‚Äúmri‚Äù: the coordinate frame for MRI images, and scalp/skull/brain surfaces derived from the MRI images

‚Äúhead‚Äù: the coordinate frame for digitized sensor locations and scalp landmarks (‚Äúfiducials‚Äù)

Each of these are described in more detail in the next section.

A good way to start visualizing these coordinate frames is to use the mne.viz.plot_alignment function, which is used for creating or inspecting the transformations that bring these coordinate frames into alignment, and displaying the resulting alignment of EEG sensors, MEG sensors, brain sources, and conductor models. If you provide subjects_dir and subject parameters, the function automatically loads the subject‚Äôs Freesurfer MRI surfaces. Important for our purposes, passing show_axes=True to plot_alignment will draw the origin of each coordinate frame in a different color, with axes indicated by different sized arrows:

shortest arrow: (R)ight / X

medium arrow: forward / (A)nterior / Y

longest arrow: up / (S)uperior / Z

Note that all three coordinate systems are RAS coordinate frames and hence are also right-handed coordinate systems. Finally, note that the coord_frame parameter sets which coordinate frame the camera should initially be aligned with. Let‚Äôs have a look:

The head coordinate frame is defined through the coordinates of anatomical landmarks on the subject‚Äôs head: usually the Nasion (NAS), and the left and right preauricular points (LPA and RPA). Different MEG manufacturers may have different definitions of the head coordinate frame. A good overview can be seen in the FieldTrip FAQ on coordinate systems.

For Neuromag/Elekta/MEGIN, the head coordinate frame is defined by the intersection of

the line between the LPA (red sphere) and RPA (purple sphere), and

the line perpendicular to this LPA-RPA line one that goes through the Nasion (green sphere).

The axes are oriented as X origin‚ÜíRPA, Y origin‚ÜíNAS, Z origin‚Üíupward (orthogonal to X and Y).

The required 3D coordinates for defining the head coordinate frame (NAS, LPA, RPA) are measured at a stage separate from the MEG data recording. There exist numerous devices to perform such measurements, usually called ‚Äúdigitizers‚Äù. For example, see the devices by the company Polhemus.

The MEG device coordinate frame is defined by the respective MEG manufacturers. All MEG data is acquired with respect to this coordinate frame. To account for the anatomy and position of the subject‚Äôs head, we use so-called head position indicator (HPI) coils. The HPI coils are placed at known locations on the scalp of the subject and emit high-frequency magnetic fields used to coregister the head coordinate frame with the device coordinate frame.

From the Neuromag/Elekta/MEGIN user manual:

The origin of the device coordinate system is located at the center of the posterior spherical section of the helmet with X axis going from left to right and Y axis pointing front. The Z axis is, again normal to the plane with positive direction up.

The HPI coils are shown as magenta spheres. Coregistration happens at the beginning of the recording and the head‚Üîmeg transformation matrix is stored in raw.info['dev_head_t'].

Defined by Freesurfer, the ‚ÄúMRI surface RAS‚Äù coordinate frame has its origin at the center of a 256√ó256√ó256 1mm anisotropic volume (though the center may not correspond to the anatomical center of the subject‚Äôs head).

We typically align the MRI coordinate frame to the head coordinate frame through a rotation and translation matrix, that we refer to in MNE as trans.

Let‚Äôs try using plot_alignment by making trans the identity transform. This (incorrectly!) equates the MRI and head coordinate frames.

Here is the same plot, this time with the trans properly defined (using a precomputed transformation matrix).

Let‚Äôs visualize these coordinate frames using just the scalp surface; this will make it easier to see their relative orientations. To do this we‚Äôll first load the Freesurfer scalp surface, then apply a few different transforms to it. In addition to the three coordinate frames discussed above, we‚Äôll also show the ‚Äúmri_voxel‚Äù coordinate frame. Unlike MRI Surface RAS, ‚Äúmri_voxel‚Äù has its origin in the corner of the volume (the left-most, posterior-most coordinate on the inferior-most MRI slice) instead of at the center of the volume. ‚Äúmri_voxel‚Äù is also not an RAS coordinate system: rather, its XYZ directions are based on the acquisition order of the T1 image slices.

Now that we‚Äôve transformed all the points, let‚Äôs plot them. We‚Äôll use the same colors used by plot_alignment and use green for the ‚Äúmri_voxel‚Äù coordinate frame:

The relative orientations of the coordinate frames can be inferred by observing the direction of the subject‚Äôs nose. Notice also how the origin of the mri_voxel coordinate frame is in the corner of the volume (above, behind, and to the left of the subject), whereas the other three coordinate frames have their origin roughly in the center of the head.

For a real-world example of using these transforms, consider the task of defacing the MRI to preserve subject anonymity. If you know the points in the ‚Äúhead‚Äù coordinate frame (as you might if you‚Äôre basing the defacing on digitized points) you would need to transform them into ‚Äúmri‚Äù or ‚Äúmri_voxel‚Äù in order to apply the blurring or smoothing operations to the MRI surfaces or images. Here‚Äôs what that would look like (we‚Äôll use the nasion landmark as a representative example):

You can try creating the head‚ÜîMRI transform yourself using mne.gui.coregistration().

To set the MRI fiducials, make sure Lock Fiducials is toggled off.

Set the landmarks by clicking the radio button (LPA, Nasion, RPA) and then clicking the corresponding point in the image.

The position of each fiducial used is the center of the octahedron icon.

After doing this for all the landmarks, toggle Lock Fiducials radio button and optionally pressing Save MRI Fid. which will save to a default location in the bem folder of the Freesurfer subject directory.

Then you can load the digitization data from the raw file (Path to info).

Click Fit ICP. This will align the digitization points to the head surface. Sometimes the fitting algorithm doesn‚Äôt find the correct alignment immediately. You can try first fitting using LPA/RPA or fiducials and then align according to the digitization. You can also finetune manually with the controls on the right side of the panel.

Click Save (lower right corner of the panel), set the filename and read it with mne.read_trans().

For more information, see this video:

Coregistration can also be automated as shown in Using an automated approach to coregistration.

The surface alignments above are possible if you have the surfaces available from Freesurfer. mne.viz.plot_alignment() automatically searches for the correct surfaces from the provided subjects_dir. Another option is to use a spherical conductor model. It is passed through bem parameter.

It is also possible to use mne.gui.coregistration() to warp a subject (usually fsaverage) to subject digitization data, see these slides.

Total running time of the script: (0 minutes 55.797 seconds)

Download Jupyter notebook: 20_source_alignment.ipynb

Download Python source code: 20_source_alignment.py

Download zipped: 20_source_alignment.zip

Gallery generated by Sphinx-Gallery

FreeSurfer MRI reconstruction

Using an automated approach to coregistration

---

## Source localization and inverses#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/index.html

**Contents:**
- Source localization and inverses#

These tutorials cover estimation of cortical activity from sensor recordings.

The SourceEstimate data structure

Source localization with equivalent current dipole (ECD) fit

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Source reconstruction using an LCMV beamformer

Visualize source time courses (stcs)

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

Computing a covariance matrix

The SourceEstimate data structure

---

## Source localization with equivalent current dipole (ECD) fit#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/20_dipole_fit.html

**Contents:**
- Source localization with equivalent current dipole (ECD) fit#
- References#

Go to the end to download the full example code.

This shows how to fit a dipole [1] using MNE-Python.

For a comparison of fits between MNE-C and MNE-Python, see this gist.

Let‚Äôs localize the N100m (using MEG only)

We can also plot the result using outlines of the head and brain.

Plot the result in 3D brain with the MRI image using Nilearn In MRI coordinates and in MNI coordinates (template brain)

Calculate and visualise magnetic field predicted by dipole with maximum GOF and compare to the measured data, highlighting the ipsilateral (right) source

Estimate the time course of a single dipole with fixed position and orientation (the one that maximized GOF) over the entire interval

Jukka Sarvas. Basic mathematical and electromagnetic concepts of the biomagnetic inverse problem. Physics in Medicine and Biology, 32(1):11‚Äì22, 1987. doi:10.1088/0031-9155/32/1/004.

Total running time of the script: (0 minutes 31.994 seconds)

Download Jupyter notebook: 20_dipole_fit.ipynb

Download Python source code: 20_dipole_fit.py

Download zipped: 20_dipole_fit.zip

Gallery generated by Sphinx-Gallery

The SourceEstimate data structure

Source localization with MNE, dSPM, sLORETA, and eLORETA

---

## Source localization with MNE, dSPM, sLORETA, and eLORETA#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/30_mne_dspm_loreta.html

**Contents:**
- Source localization with MNE, dSPM, sLORETA, and eLORETA#
- Compute regularized noise covariance#
- Compute the evoked response#
- Inverse modeling: MNE/dSPM on evoked and raw data#
- Compute inverse solution#
- Visualization#

Go to the end to download the full example code.

The aim of this tutorial is to teach you how to compute and apply a linear minimum-norm inverse method on evoked/raw/epochs data.

For more details see Computing a covariance matrix.

Let‚Äôs just use the MEG channels for simplicity.

It‚Äôs also a good idea to look at whitened data:

Here we first read the forward solution. You will likely need to compute one for your own data ‚Äì see Head model and forward computation for information on how to do it.

Next, we make an MEG inverse operator.

You can write the inverse operator to disk with:

We can use this to compute the inverse solution and obtain source time courses:

We can look at different dipole activations:

Examine the original data and the residual after fitting:

Here we use peak getter to move visualization to the time point of the peak and draw a marker at the maximum peak vertex.

There are many other ways to visualize and work with source data, see for example:

Visualize source time courses (stcs)

Morph surface source estimate

Morph volumetric source estimate

Plotting the full vector-valued MNE solution

The role of dipole orientations in distributed source localization

Computing various MNE solutions

examples using apply_inverse.

Total running time of the script: (0 minutes 42.121 seconds)

Download Jupyter notebook: 30_mne_dspm_loreta.ipynb

Download Python source code: 30_mne_dspm_loreta.py

Download zipped: 30_mne_dspm_loreta.zip

Gallery generated by Sphinx-Gallery

Source localization with equivalent current dipole (ECD) fit

The role of dipole orientations in distributed source localization

---

## Source reconstruction using an LCMV beamformer#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/50_beamformer_lcmv.html

**Contents:**
- Source reconstruction using an LCMV beamformer#
- Introduction to beamformers#
- Data processing#
- Computing the covariance matrices#
- The forward model#
- Handling depth bias#
- Compute the spatial filter#
- Apply the spatial filter#
- Visualize the reconstructed source activity#
  - On MRI slices (orthoview; 2D)#

Go to the end to download the full example code.

This tutorial gives an overview of the beamformer method and shows how to reconstruct source activity using an LCMV beamformer.

A beamformer is a spatial filter that reconstructs source activity by scanning through a grid of pre-defined source points and estimating activity at each of those source points independently. A set of weights is constructed for each defined source location which defines the contribution of each sensor to this source.

Beamformers are often used for their focal reconstructions and their ability to reconstruct deeper sources. They can also suppress external noise sources. The beamforming method applied in this tutorial is the linearly constrained minimum variance (LCMV) beamformer [1] operates on time series.

Frequency-resolved data can be reconstructed with the dynamic imaging of coherent sources (DICS) beamforming method [2]. As we will see in the following, the spatial filter is computed from two ingredients: the forward model solution and the covariance matrix of the data.

We will use the sample data set for this tutorial and reconstruct source activity on the trials with left auditory stimulation.

Spatial filters use the data covariance to estimate the filter weights. The data covariance matrix will be inverted during the spatial filter computation, so it is valuable to plot the covariance matrix and its eigenvalues to gauge whether matrix inversion will be possible. Also, because we want to combine different channel types (magnetometers and gradiometers), we need to account for the different amplitude scales of these channel types. To do this we will supply a noise covariance matrix to the beamformer, which will be used for whitening. The data covariance matrix should be estimated from a time window that includes the brain signal of interest, and incorporate enough samples for a stable estimate. A rule of thumb is to use more samples than there are channels in the data set; see [3][4] for more detailed advice on covariance estimation for beamformers. Here, we use a time window incorporating the expected auditory response at around 100 ms post stimulus and extend the period to account for a low number of trials (72) and low sampling rate of 150 Hz.

When looking at the covariance matrix plots, we can see that our data is slightly rank-deficient as the rank is not equal to the number of channels. Thus, we choose to regularize the covariance matrix before inverting it in the beamformer calculation. This can be achieved by setting the parameter reg=0.05 when calculating the spatial filter with make_lcmv(). This corresponds to loading the diagonal of the covariance matrix with 5% of the sensor power. Other ways to deal with rank-deficient covariance matrices are discussed in [4].

The forward model is the other important ingredient for the computation of a spatial filter. Here, we will load the forward model from disk; more information on how to create a forward model can be found in this tutorial: Head model and forward computation. Note that beamformers are usually computed in a volume source space, because estimating only cortical surface activation can misrepresent the data.

The forward model solution is inherently biased toward superficial sources. When analyzing single conditions it is best to mitigate the depth bias somehow. There are several ways to do this:

mne.beamformer.make_lcmv() has a depth parameter that normalizes the forward model prior to computing the spatial filters. See the docstring for details.

Unit-noise gain beamformers handle depth bias by normalizing the weights of the spatial filter. Choose this by setting weight_norm='unit-noise-gain'.

When computing the Neural activity index, the depth bias is handled by normalizing both the weights and the estimated noise (see [1]). Choose this by setting weight_norm='nai'.

Note that when comparing conditions, the depth bias will cancel out and it is possible to set both parameters to None.

Now we can compute the spatial filter. We‚Äôll use a unit-noise gain beamformer to deal with depth bias, and will also optimize the orientation of the sources such that output power is maximized. This is achieved by setting pick_ori='max-power'. This gives us one source estimate per source (i.e., voxel), which is known as a scalar beamformer.

It is also possible to compute a vector beamformer, which gives back three estimates per voxel, corresponding to the three direction components of the source. This can be achieved by setting pick_ori='vector' and will yield a volume vector source estimate. Note that we switch the weight_norm parameter to 'unit-noise-gain-invariant', which is only necessary for the vector unit-noise-gain beamformer. For more in-depth detail, see [4]. We will compute another set of filters using the vector beamformer approach:

The spatial filter can be applied to different data types: raw, epochs, evoked data or the data covariance matrix to gain a static image of power. The function to apply the spatial filter to Evoked data is apply_lcmv() which is what we will use here. The other functions are apply_lcmv_raw(), apply_lcmv_epochs(), and apply_lcmv_cov().

We can visualize the source estimate in different ways, e.g. as a volume rendering, an overlay onto the MRI, or as an overlay onto a glass brain.

The plots for the scalar beamformer show brain activity in the right temporal lobe around 100 ms post stimulus. This is expected given the left-ear auditory stimulation of the experiment.

These plots can also be shown using a volumetric rendering via plot_3d(). Let‚Äôs try visualizing the vector beamformer case. Here we get three source time courses out per voxel (one for each component of the dipole moment: x, y, and z), which appear as small vectors in the visualization (in the 2D plotters, only the magnitude can be shown):

We can also visualize all three components in the peak voxel. For this, we will first find the peak voxel and then plot the time courses of this voxel.

We can also use volumetric morphing to get the data to fsaverage space. This is for example necessary when comparing activity across subjects. Here, we will use the scalar beamformer example. We pass a mne.SourceMorph as the src argument to mne.VolSourceEstimate.plot. To save some computational load when applying the morph, we will crop the stc:

Barry D. Van Veen, Wim van Drongelen, Moshe Yuchtman, and Akifumi Suzuki. Localization of brain electrical activity via linearly constrained minimum variance spatial filtering. IEEE Transactions on Biomedical Engineering, 44(9):867‚Äì880, 1997. doi:10.1109/10.623056.

Joachim Gro√ü, Jan Kujala, Matti S. H√§m√§l√§inen, Lars Timmermann, Alfons Schnitzler, and Riitta Salmelin. Dynamic imaging of coherent sources: studying neural interactions in the human brain. Proceedings of the National Academy of Sciences, 98(2):694‚Äì699, 2001. doi:10.1073/pnas.98.2.694.

Matthew J. Brookes, Jiri Vrba, Stephen E. Robinson, Claire M. Stevenson, Andrew M. Peters, Gareth R. Barnes, Arjan Hillebrand, and Peter G. Morris. Optimising experimental design for MEG beamformer imaging. NeuroImage, 39(4):1788‚Äì1802, 2008. doi:10.1016/j.neuroimage.2007.09.050.

Britta U. Westner, Sarang S. Dalal, Alexandre Gramfort, Vladimir Litvak, John C. Mosher, Robert Oostenveld, and Jan-Mathijs Schoffelen. A unified view on beamformers for M/EEG source reconstruction. NeuroImage, 246:118789, 2022. doi:10.1016/j.neuroimage.2021.118789.

Total running time of the script: (0 minutes 45.135 seconds)

Download Jupyter notebook: 50_beamformer_lcmv.ipynb

Download Python source code: 50_beamformer_lcmv.py

Download zipped: 50_beamformer_lcmv.zip

Gallery generated by Sphinx-Gallery

Computing various MNE solutions

Visualize source time courses (stcs)

---

## Spatiotemporal permutation F-test on full sensor data#

**URL:** https://mne.tools/stable/auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html

**Contents:**
- Spatiotemporal permutation F-test on full sensor data#
- Set parameters#
- Read epochs for the channel of interest#
- Find the FieldTrip neighbor definition to setup sensor adjacency#
- Compute permutation statistic#
- Visualize clusters#
- Permutation statistic for time-frequencies#
- Exercises#
- References#

Go to the end to download the full example code.

Tests for differential evoked responses in at least one condition using a permutation clustering test. The FieldTrip neighbor templates will be used to determine the adjacency between sensors. This serves as a spatial prior to the clustering. Spatiotemporal clusters will then be visualized using custom matplotlib code.

Here, the unit of observation is epochs from a specific study subject. However, the same logic applies when the unit observation is a number of study subject each of whom contribute their own averaged data (i.e., an average of their epochs). This would then be considered an analysis at the ‚Äú2nd level‚Äù.

See the FieldTrip tutorial for a caveat regarding the possible interpretation of ‚Äúsignificant‚Äù clusters.

For more information on cluster-based permutation testing in MNE-Python, see also: Non-parametric 1 sample cluster statistic on single trial power.

How does it work? We use clustering to ‚Äúbind‚Äù together features which are similar. Our features are the magnetic fields measured over our sensor array at different times. This reduces the multiple comparison problem. To compute the actual test-statistic, we first sum all F-values in all clusters. We end up with one statistic for each cluster. Then we generate a distribution from the data by shuffling our conditions between our samples and recomputing our clusters and the test statistics. We test for the significance of a given cluster by computing the probability of observing a cluster of that size [1][2].

Note how we only specified an adjacency for sensors! However, because we used mne.stats.spatio_temporal_cluster_test(), an adjacency for time points was automatically taken into account. That is, at time point N, the time points N - 1 and N + 1 were considered as adjacent (this is also called ‚Äúlattice adjacency‚Äù). This is only possible because we ran the analysis on 2D data (times √ó channels) per observation ‚Ä¶ for 3D data per observation (e.g., times √ó frequencies √ó channels), we will need to use mne.stats.combine_adjacency(), as shown further below.

Note also that the same functions work with source estimates. The only differences are the origin of the data, the size, and the adjacency definition. It can be used for single trials or for groups of subjects.

Let‚Äôs do the same thing with the time-frequency decomposition of the data (see Frequency and time-frequency sensor analysis for a tutorial and Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert) for a comparison of time-frequency methods) to show how cluster permutations can be done on higher-dimensional data.

Remember the note on the adjacency matrix from above: For 3D data, as here, we must use mne.stats.combine_adjacency() to extend the sensor-based adjacency to incorporate the time-frequency plane as well.

Here, the integer inputs are converted into a lattice and combined with the sensor adjacency matrix so that data at similar times and with similar frequencies and at close sensor locations are clustered together.

Now we can run the cluster permutation test, but first we have to set a threshold. This example decimates in time and uses few frequencies so we need to increase the threshold from the default value in order to have differentiated clusters (i.e., so that our algorithm doesn‚Äôt just find one large cluster). For a more principled method of setting this parameter, threshold-free cluster enhancement may be used. See Statistical inference for a discussion.

Finally, we can plot our results. It is difficult to visualize clusters in time-frequency-sensor space; plotting time-frequency spectrograms and plotting topomaps display time-frequency and sensor space respectively but they are difficult to combine. We will plot topomaps with the clustered sensors colored in white adjacent to spectrograms in order to provide a visualization of the results. This is a dimensionally limited view, however. Each sensor has its own significant time-frequencies, but, in order to display a single spectrogram, all the time-frequencies that are significant for any sensor in the cluster are plotted as significant. This is a difficulty inherent to visualizing high-dimensional data and should be taken into consideration when interpreting results.

What is the smallest p-value you can obtain, given the finite number of permutations? You can find the answers in the references [1][2].

Eric Maris and Robert Oostenveld. Nonparametric statistical testing of EEG- and MEG-data. Journal of Neuroscience Methods, 164(1):177‚Äì190, 2007. doi:10.1016/j.jneumeth.2007.03.024.

Jona Sassenhagen and Dejan Draschkow. Cluster-based permutation tests of meg/eeg data do not establish significance of effect latency or location. Psychophysiology, 56(6):e13335, 2019. doi:10.1111/psyp.13335.

Total running time of the script: (0 minutes 22.637 seconds)

Download Jupyter notebook: 75_cluster_ftest_spatiotemporal.ipynb

Download Python source code: 75_cluster_ftest_spatiotemporal.py

Download zipped: 75_cluster_ftest_spatiotemporal.zip

Gallery generated by Sphinx-Gallery

Mass-univariate twoway repeated measures ANOVA on single trial power

Statistical analysis of source estimates

---

## Spectro-temporal receptive field (STRF) estimation on continuous data#

**URL:** https://mne.tools/stable/auto_tutorials/machine-learning/30_strf.html

**Contents:**
- Spectro-temporal receptive field (STRF) estimation on continuous data#
- Load audio data#
- Create a receptive field#
- Simulate a neural response#
- Fit a model to recover this receptive field#
- Visualize the effects of regularization#
- Using different regularization types#
- Compare model performance#
  - References#

Go to the end to download the full example code.

This demonstrates how an encoding model can be fit with multiple continuous inputs. In this case, we simulate the model behind a spectro-temporal receptive field (or STRF). First, we create a linear filter that maps patterns in spectro-temporal space onto an output, representing neural activity. We fit a receptive field model that attempts to recover the original linear filter that was used to create this data.

We‚Äôll read in the audio data from [1] in order to simulate a response.

In addition, we‚Äôll downsample the data along the time dimension in order to speed up computation. Note that depending on the input values, this may not be desired. For example if your input stimulus varies more quickly than 1/2 the sampling rate to which we are downsampling.

We‚Äôll simulate a linear receptive field for a theoretical neural signal. This defines how the signal will respond to power in this receptive field space.

Using this receptive field, we‚Äôll create an artificial neural response to a stimulus.

To do this, we‚Äôll create a time-delayed version of the receptive field, and then calculate the dot product between this and the stimulus. Note that this is effectively doing a convolution between the stimulus and the receptive field. See here for more information.

Finally, we‚Äôll use the mne.decoding.ReceptiveField class to recover the linear receptive field of this signal. Note that properties of the receptive field (e.g. smoothness) will depend on the autocorrelation in the inputs and outputs.

Above we fit a mne.decoding.ReceptiveField model for one of many values for the ridge regularization parameter. Here we will plot the model score as well as the model coefficients for each value, in order to visualize how coefficients change with different levels of regularization. These issues as well as the STRF pipeline are described in detail in [2][3][4].

In addition to the standard ridge regularization, the mne.decoding.TimeDelayingRidge class also exposes Laplacian regularization term as:

This imposes a smoothness constraint of nearby time samples and/or features. Quoting [1] :

Tikhonov [identity] regularization (Equation 5) reduces overfitting by smoothing the TRF estimate in a way that is insensitive to the amplitude of the signal of interest. However, the Laplacian approach (Equation 6) reduces off-sample error whilst preserving signal amplitude (Lalor et al., 2006). As a result, this approach usually leads to an improved estimate of the system‚Äôs response (as indexed by MSE) compared to Tikhonov regularization.

Below we visualize the model performance of each regularization method (ridge vs. Laplacian) for different levels of alpha. As you can see, the Laplacian method performs better in general, because it imposes a smoothness constraint along the time and feature dimensions of the coefficients. This matches the ‚Äútrue‚Äù receptive field structure and results in a better model fit.

Plot the original STRF, and the one that we recovered with modeling.

Michael J. Crosse, Giovanni M. Di Liberto, Adam Bednar, and Edmund C. Lalor. The multivariate temporal response function (mTRF) toolbox: a MATLAB toolbox for relating neural signals to continuous stimuli. Frontiers in Human Neuroscience, 2016. doi:10.3389/fnhum.2016.00604.

Fr√©d√©ric E. Theunissen, Stephen V. David, Nandini C. Singh, Ann Hsu, William E. Vinje, and Jack L. Gallant. Estimating spatio-temporal receptive fields of auditory and visual neurons from their responses to natural stimuli. Network: Computation in Neural Systems, 12(3):289‚Äì316, 2001. doi:10.1080/net.12.3.289.316.

Ben Willmore and Darragh Smyth. Methods for first-order kernel estimation: simple-cell receptive fields from responses to natural scenes. Network: Computation in Neural Systems, 14(3):553‚Äì577, 2003. doi:10.1088/0954-898X_14_3_309.

Christopher R. Holdgraf, Wendy de Heer, Brian Pasley, Jochem Rieger, Nathan Crone, Jack J. Lin, Robert T. Knight, and Fr√©d√©ric E. Theunissen. Rapid tuning shifts in human auditory cortex enhance speech intelligibility. Nature Communications, 2016. doi:10.1038/ncomms13654.

Total running time of the script: (0 minutes 15.867 seconds)

Download Jupyter notebook: 30_strf.ipynb

Download Python source code: 30_strf.py

Download zipped: 30_strf.zip

Gallery generated by Sphinx-Gallery

Machine learning models of neural activity

---

## Statistical analysis of sensor data#

**URL:** https://mne.tools/stable/auto_tutorials/stats-sensor-space/index.html

**Contents:**
- Statistical analysis of sensor data#

These tutorials describe some approaches to statistical analysis of sensor-level data.

Statistical inference

Visualising statistical significance thresholds on EEG data

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

KIT phantom dataset tutorial

Statistical inference

---

## Statistical analysis of source estimates#

**URL:** https://mne.tools/stable/auto_tutorials/stats-source-space/index.html

**Contents:**
- Statistical analysis of source estimates#

These tutorials cover within-subject statistical analysis of source estimates.

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

Spatiotemporal permutation F-test on full sensor data

Permutation t-test on source data with spatio-temporal clustering

---

## Statistical inference#

**URL:** https://mne.tools/stable/auto_tutorials/stats-sensor-space/10_background_stats.html

**Contents:**
- Statistical inference#
- Hypothesis testing#
  - Null hypothesis#
  - Parametric tests#
    - ‚ÄúHat‚Äù variance adjustment#
  - Non-parametric tests#
- Multiple comparisons#
  - Bonferroni correction#
  - False discovery rate (FDR) correction#
  - Non-parametric resampling test with a maximum statistic#

Go to the end to download the full example code.

Here we will briefly cover multiple concepts of inferential statistics in an introductory manner, and demonstrate how to use some MNE statistical functions.

In inferential statistics, a general statement or default position that there is no relationship between two measured phenomena, or no association among groups.

We typically want to reject a null hypothesis with some probability (e.g., p < 0.05). This probability is also called the significance level \(\alpha\). To think about what this means, let‚Äôs follow the illustrative example from [1] and construct a toy dataset consisting of a 40 √ó 40 square with a ‚Äúsignal‚Äù present in the center with white noise added and a Gaussian smoothing kernel applied.

The data averaged over all subjects looks like this:

In this case, a null hypothesis we could test for each voxel is:

There is no difference between the mean value and zero (\(H_0 \colon \mu = 0\)).

The alternative hypothesis, then, is that the voxel has a non-zero mean (\(H_1 \colon \mu \neq 0\)). This is a two-tailed test because the mean could be less than or greater than zero, whereas a one-tailed test would test only one of these possibilities, i.e. \(H_1 \colon \mu \geq 0\) or \(H_1 \colon \mu \leq 0\).

Here we will refer to each spatial location as a ‚Äúvoxel‚Äù. In general, though, it could be any sort of data value, including cortical vertex at a specific time, pixel in a time-frequency decomposition, etc.

Let‚Äôs start with a paired t-test, which is a standard test for differences in paired samples. Mathematically, it is equivalent to a 1-sample t-test on the difference between the samples in each condition. The paired t-test is parametric because it assumes that the underlying sample distribution is Gaussian, and is only valid in this case. This happens to be satisfied by our toy dataset, but is not always satisfied for neuroimaging data.

In the context of our toy dataset, which has many voxels (\(40 \cdot 40 = 1600\)), applying the paired t-test is called a mass-univariate approach as it treats each voxel independently.

The ‚Äúhat‚Äù technique regularizes the variance values used in the t-test calculation [1] to compensate for implausibly small variances.

Instead of assuming an underlying Gaussian distribution, we could instead use a non-parametric resampling method. In the case of a paired t-test between two conditions A and B, which is mathematically equivalent to a one-sample t-test between the difference in the conditions A-B, under the null hypothesis we have the principle of exchangeability. This means that, if the null is true, we can exchange conditions and not change the distribution of the test statistic.

When using a paired t-test, exchangeability thus means that we can flip the signs of the difference between A and B. Therefore, we can construct the null distribution values for each voxel by taking random subsets of samples (subjects), flipping the sign of their difference, and recording the absolute value of the resulting statistic (we record the absolute value because we conduct a two-tailed test). The absolute value of the statistic evaluated on the veridical data can then be compared to this distribution, and the p-value is simply the proportion of null distribution values that are smaller.

In the case of a true one-sample t-test, i.e. analyzing a single condition rather than the difference between two conditions, it is not clear where/how exchangeability applies; see this FieldTrip discussion.

In the case where n_permutations is large enough (or ‚Äúall‚Äù) so that the complete set of unique resampling exchanges can be done (which is \(2^{N_{samp}}-1\) for a one-tailed and \(2^{N_{samp}-1}-1\) for a two-tailed test, not counting the veridical distribution), instead of randomly exchanging conditions the null is formed from using all possible exchanges. This is known as a permutation test (or exact test).

So far, we have done no correction for multiple comparisons. This is potentially problematic for these data because there are \(40 \cdot 40 = 1600\) tests being performed. If we use a threshold p < 0.05 for each individual test, we would expect many voxels to be declared significant even if there were no true effect. In other words, we would make many type I errors (adapted from here):

To see why, consider a standard \(\alpha = 0.05\). For a single test, our probability of making a type I error is 0.05. The probability of making at least one type I error in \(N_{\mathrm{test}}\) independent tests is then given by \(1 - (1 - \alpha)^{N_{\mathrm{test}}}\):

To combat this problem, several methods exist. Typically these provide control over either one of the following two measures:

The probability of making one or more type I errors:

The expected proportion of rejected null hypotheses that are actually true:

We cover some techniques that control FWER and FDR below.

Perhaps the simplest way to deal with multiple comparisons, Bonferroni correction conservatively multiplies the p-values by the number of comparisons to control the FWER.

Typically FDR is performed with the Benjamini-Hochberg procedure, which is less restrictive than Bonferroni correction for large numbers of comparisons (fewer type II errors), but provides less strict control of type I errors.

Non-parametric resampling tests can also be used to correct for multiple comparisons. In its simplest form, we again do permutations using exchangeability under the null hypothesis, but this time we take the maximum statistic across all voxels in each permutation to form the null distribution. The p-value for each voxel from the veridical data is then given by the proportion of null distribution values that were smaller.

This method has two important features:

It is non-parametric. Even though our initial test statistic (here a 1-sample t-test) is parametric, the null distribution for the null hypothesis rejection (the mean value across subjects is indistinguishable from zero) is obtained by permutations. This means that it makes no assumptions of Gaussianity (which do hold for this example, but do not in general for some types of processed neuroimaging data).

Each of the aforementioned multiple comparisons corrections have the disadvantage of not fully incorporating the correlation structure of the data, namely that points close to one another (e.g., in space or time) tend to be correlated. However, by defining the adjacency (or ‚Äúneighbor‚Äù) structure in our data, we can use clustering to compensate.

To use this, we need to rethink our null hypothesis. Instead of thinking about a null hypothesis about means per voxel (with one independent test per voxel), we consider a null hypothesis about sizes of clusters in our data, which could be stated like:

The distribution of spatial cluster sizes observed in two experimental conditions are drawn from the same probability distribution.

Here we only have a single condition and we contrast to zero, which can be thought of as:

The distribution of spatial cluster sizes is independent of the sign of the data.

In this case, we again do permutations with a maximum statistic, but, under each permutation, we:

Compute the test statistic for each voxel individually.

Threshold the test statistic values.

Cluster voxels that exceed this threshold (with the same sign) based on adjacency.

Retain the size of the largest cluster (measured, e.g., by a simple voxel count, or by the sum of voxel t-values within the cluster) to build the null distribution.

After doing these permutations, the cluster sizes in our veridical data are compared to this null distribution. The p-value associated with each cluster is again given by the proportion of smaller null distribution values. This can then be subjected to a standard p-value threshold (e.g., p < 0.05) to reject the null hypothesis (i.e., find an effect of interest).

This reframing to consider cluster sizes rather than individual means maintains the advantages of the standard non-parametric permutation test ‚Äì namely controlling FWER and making no assumptions of parametric data distribution. Critically, though, it also accounts for the correlation structure in the data ‚Äì which in this toy case is spatial but in general can be multidimensional (e.g., spatio-temporal) ‚Äì because the null distribution will be derived from data in a way that preserves these correlations.

For a nice description of how to compute the effect size obtained in a cluster test, see this FieldTrip mailing list discussion.

However, there is a drawback. If a cluster significantly deviates from the null, no further inference on the cluster (e.g., peak location) can be made, as the entire cluster as a whole is used to reject the null. Moreover, because the test statistic concerns the full data, the null hypothesis (and our rejection of it) refers to the structure of the full data. For more information, see also the comprehensive FieldTrip tutorial.

First we need to define our adjacency (sometimes called ‚Äúneighbors‚Äù) matrix. This is a square array (or sparse matrix) of shape (n_src, n_src) that contains zeros and ones to define which spatial points are neighbors, i.e., which voxels are adjacent to each other. In our case this is quite simple, as our data are aligned on a rectangular grid.

Let‚Äôs pretend that our data were smaller ‚Äì a 3 √ó 3 grid. Thinking about each voxel as being connected to the other voxels it touches, we would need a 9 √ó 9 adjacency matrix. The first row of this matrix contains the voxels in the flattened data that the first voxel touches. Since it touches the second element in the first row and the first element in the second row (and is also a neighbor to itself), this would be:

sklearn.feature_extraction provides a convenient function for this:

In general the adjacency between voxels can be more complex, such as those between sensors in 3D space, or time-varying activation at brain vertices on a cortical surface. MNE provides several convenience functions for computing adjacency matrices, for example:

mne.channels.find_ch_adjacency()

mne.stats.combine_adjacency()

See the Statistics API for a full list.

MNE also ships with numerous built-in channel adjacency matrices from the FieldTrip project (called ‚Äúneighbors‚Äù there). You can get an overview of them by using mne.channels.get_builtin_ch_adjacencies():

These built-in channel adjacency matrices can be loaded via mne.channels.read_ch_adjacency().

Here, since our data are on a grid, we can use adjacency=None to trigger optimized grid-based code, and run the clustering algorithm.

This method can also be used in this context to correct for small variances [1]:

TFCE eliminates the free parameter initial threshold value that determines which points are included in clustering by approximating a continuous integration across possible threshold values with a standard Riemann sum [2]. This requires giving a starting threshold start and a step size step, which in MNE is supplied as a dict. The smaller the step and closer to 0 the start value, the better the approximation, but the longer it takes.

A significant advantage of TFCE is that, rather than modifying the statistical null hypothesis under test (from one about individual voxels to one about the distribution of clusters in the data), it modifies the data under test while still controlling for multiple comparisons. The statistical test is then done at the level of individual voxels rather than clusters. This allows for evaluation of each point independently for significance rather than only as cluster groups.

We can also combine TFCE and the ‚Äúhat‚Äù correction:

Let‚Äôs take a look at these statistics. The top row shows each test statistic, and the bottom shows p-values for various statistical tests, with the ones with proper control over FWER or FDR with bold titles.

The first three columns show the parametric and non-parametric statistics that are not corrected for multiple comparisons:

Mass univariate t-tests result in jagged edges.

‚ÄúHat‚Äù variance correction of the t-tests produces less peaky edges, correcting for sharpness in the statistic driven by low-variance voxels.

Non-parametric resampling tests are very similar to t-tests. This is to be expected: the data are drawn from a Gaussian distribution, and thus satisfy parametric assumptions.

The next three columns show multiple comparison corrections of the mass univariate tests (parametric and non-parametric). These too conservatively correct for multiple comparisons because neighboring voxels in our data are correlated:

Bonferroni correction eliminates any significant activity.

FDR correction is less conservative than Bonferroni.

A permutation test with a maximum statistic also eliminates any significant activity.

The final four columns show the non-parametric cluster-based permutation tests with a maximum statistic:

Standard clustering identifies the correct region. However, the whole area must be declared significant, so no peak analysis can be done. Also, the peak is broad.

Clustering with ‚Äúhat‚Äù variance adjustment tightens the estimate of significant activity.

Clustering with TFCE allows analyzing each significant point independently, but still has a broadened estimate.

Clustering with TFCE and ‚Äúhat‚Äù variance adjustment tightens the area declared significant (again FWER corrected).

The complete listing of statistical functions provided by MNE are in the Statistics API list, but we will give a brief overview here.

MNE provides several convenience parametric testing functions that can be used in conjunction with the non-parametric clustering methods. However, the set of functions we provide is not meant to be exhaustive.

If the univariate statistical contrast of interest is not listed here (e.g., interaction term in an unbalanced ANOVA), consider checking out the statsmodels package. It offers many functions for computing statistical contrasts, e.g., statsmodels.stats.anova.anova_lm(). To use these functions in clustering:

Determine which test statistic (e.g., t-value, F-value) you would use in a univariate context to compute your contrast of interest. In other words, if there were only a single output such as reaction times, what test statistic might you compute on the data?

Wrap the call to that function within a function that takes an input of the same shape that is expected by your clustering function, and returns an array of the same shape without the ‚Äúsamples‚Äù dimension (e.g., mne.stats.permutation_cluster_1samp_test() takes an array of shape (n_samples, p, q) and returns an array of shape (p, q)).

Pass this wrapped function to the stat_fun argument to the clustering function.

Set an appropriate threshold value (float or dict) based on the values your statistical contrast function returns.

Paired t-test, optionally with hat adjustment. This is used by default for contrast enhancement in paired cluster tests.

One-way ANOVA for independent samples. This can be used to compute various F-contrasts. It is used by default for contrast enhancement in non-paired cluster tests.

M-way ANOVA for repeated measures and balanced designs. This returns F-statistics and p-values. The associated helper function mne.stats.f_threshold_mway_rm() can be used to determine the F-threshold at a given significance level.

Compute ordinary least square regressions on multiple targets, e.g., sensors, time points across trials (samples). For each regressor it returns the beta value, t-statistic, and uncorrected p-value. While it can be used as a test, it is particularly useful to compute weighted averages or deal with continuous predictors.

Unpaired contrasts with clustering.

Unpaired contrasts with spatio-temporal clustering.

Paired contrast with no clustering.

Paired contrasts with clustering.

Paired contrasts with spatio-temporal clustering.

In most MNE functions, data has shape (..., n_space, n_time), where the spatial dimension can be e.g. sensors or source vertices. But for our spatio-temporal clustering functions, the spatial dimensions need to be last for computational efficiency reasons. For example, for mne.stats.spatio_temporal_cluster_1samp_test(), X needs to be of shape (n_samples, n_time, n_space). You can use numpy.transpose() to transpose axes if necessary.

Gerard R. Ridgway, Vladimir Litvak, Guillaume Flandin, Karl J. Friston, and Will D. Penny. The problem of low variance voxels in statistical parametric mapping; a new hat avoids a ‚Äòhaircut‚Äô. NeuroImage, 59(3):2131‚Äì2141, 2012. doi:10.1016/j.neuroimage.2011.10.027.

Stephen M. Smith and Thomas E. Nichols. Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference. NeuroImage, 44(1):83‚Äì98, 2009. doi:10.1016/j.neuroimage.2008.03.061.

Total running time of the script: (0 minutes 17.332 seconds)

Download Jupyter notebook: 10_background_stats.ipynb

Download Python source code: 10_background_stats.py

Download zipped: 10_background_stats.zip

Gallery generated by Sphinx-Gallery

Statistical analysis of sensor data

Visualising statistical significance thresholds on EEG data

---

## The Epochs data structure: discontinuous data#

**URL:** https://mne.tools/stable/auto_tutorials/epochs/10_epochs_overview.html

**Contents:**
- The Epochs data structure: discontinuous data#
- Creating Epoched data from a Raw object#
  - Basic visualization of Epochs objects#
- Subselecting epochs#
  - Selecting epochs by index#
  - Selecting, dropping, and reordering channels#
  - Changing channel name and type#
  - Selection in the time domain#
  - Extracting data in other forms#
- Loading and saving Epochs objects to disk#

Go to the end to download the full example code.

This tutorial covers the basics of creating and working with epoched data. It introduces the Epochs data structure in detail, including how to load, query, subselect, export, and plot data from an Epochs object. For more information about visualizing Epochs objects, see Visualizing epoched data. For info on creating an Epochs object from (possibly simulated) data in a NumPy array, see Creating MNE-Python data structures from scratch.

As usual we‚Äôll start by importing the modules we need:

Epochs objects are a data structure for representing and analyzing equal-duration chunks of the EEG/MEG signal. Epochs are most often used to represent data that is time-locked to repeated experimental events (such as stimulus onsets or subject button presses), but can also be used for storing sequential or overlapping frames of a continuous signal (e.g., for analysis of resting-state activity; see Making equally-spaced Events arrays). Inside an Epochs object, the data are stored in an array of shape (n_epochs, n_channels, n_times).

Epochs objects have many similarities with Raw objects, including:

They can be loaded from and saved to disk in .fif format, and their data can be exported to a NumPy array through the get_data() method or to a Pandas DataFrame through the to_data_frame() method.

Both Epochs and Raw objects support channel selection by index or name, including pick(), pick_channels() and pick_types() methods.

SSP projector manipulation is possible through add_proj(), del_proj(), and plot_projs_topomap() methods.

Both Epochs and Raw objects have copy(), crop(), time_as_index(), filter(), resample(), and compute_psd() methods.

Both Epochs and Raw objects have times, ch_names, proj, and info attributes.

Both Epochs and Raw objects have built-in plotting methods plot(), and legacy plotting methods plot_psd() and plot_psd_topomap() (in new code, PSD plotting is done via the Spectrum class).

The example dataset we‚Äôve been using thus far doesn‚Äôt include pre-epoched data, so in this section we‚Äôll load the continuous data and create epochs based on the events recorded in the Raw object‚Äôs STIM channels. As we often do in these tutorials, we‚Äôll crop() the Raw data to save memory:

As we saw in the Parsing events from raw data tutorial, we can extract an events array from Raw objects using mne.find_events():

We could also have loaded the events from file, using mne.read_events():

See Reading and writing events from/to a file for more details.

The Raw object and the events array are the bare minimum needed to create an Epochs object, which we create with the mne.Epochs class constructor. However, you will almost surely want to change some of the other default parameters. Here we‚Äôll change tmin and tmax (the time relative to each event at which to start and end each epoch). Note also that the Epochs constructor accepts parameters reject and flat for rejecting individual epochs based on signal amplitude. See the Rejecting Epochs based on peak-to-peak channel amplitude section for examples.

You‚Äôll see from the output that:

all 320 events were used to create epochs

baseline correction was automatically applied (by default, baseline is defined as the time span from tmin to 0, but can be customized with the baseline parameter)

no additional metadata was provided (see Working with Epoch metadata for details)

the projection operators present in the Raw file were copied over to the Epochs object

If we print the Epochs object, we‚Äôll also see a note that the epochs are not copied into memory by default, and a count of the number of epochs created for each integer Event ID.

Notice that the Event IDs are in quotes; since we didn‚Äôt provide an event dictionary, the mne.Epochs constructor created one automatically and used the string representation of the integer Event IDs as the dictionary keys. This is more clear when viewing the event_id attribute:

This time let‚Äôs pass preload=True and provide an event dictionary; our provided dictionary will get stored as the event_id attribute and will make referencing events and pooling across event types easier:

Notice that the output now mentions ‚Äú1 bad epoch dropped‚Äù. In the tutorial section Rejecting Epochs based on peak-to-peak channel amplitude we saw how you can specify channel amplitude criteria for rejecting epochs, but here we haven‚Äôt specified any such criteria. In this case, it turns out that the last event was too close the end of the (cropped) raw file to accommodate our requested tmax of 0.7 seconds, so the final epoch was dropped because it was too short. Here are the drop_log entries for the last 4 epochs (empty lists indicate epochs that were not dropped):

If you forget to provide the event dictionary to the Epochs constructor, you can add it later by assigning to the event_id attribute:

The Epochs object can be visualized (and browsed interactively) using its plot() method:

Notice that the individual epochs are sequentially numbered along the bottom axis and are separated by vertical dashed lines. Epoch plots are interactive (similar to raw.plot()) and have many of the same interactive controls as Raw plots. Horizontal and vertical scrollbars allow browsing through epochs or channels (respectively), and pressing ? when the plot is focused will show a help screen with all the available controls. See Visualizing epoched data for more details (as well as other ways of visualizing epoched data).

Now that we have our Epochs object with our descriptive event labels added, we can subselect epochs easily using square brackets. For example, we can load all the ‚Äúcatch trials‚Äù where the stimulus was a face:

We can also pool across conditions easily, thanks to how MNE-Python handles the / character in epoch labels (using what is sometimes called ‚Äútag-based indexing‚Äù):

You can also pool conditions by passing multiple tags as a list. Note that MNE-Python will not complain if you ask for tags not present in the object, as long as it can find some match: the below example is parsed as (inclusive) 'right' or 'bottom', and you can see from the output that it selects only auditory/right and visual/right.

However, if no match is found, an error is returned:

Epochs objects can also be indexed with integers, slices, or lists of integers. This method of selection ignores event labels, so if you want the first 10 epochs of a particular type, you can select the type first, then use integers or slices:

You can use the pick(), pick_channels(), pick_types(), and drop_channels() methods to modify which channels are included in an Epochs object. You can also use reorder_channels() for this purpose; any channel names not provided to reorder_channels() will be dropped. Note that these channel selection methods modify the object in-place (unlike the square-bracket indexing to select epochs seen above) so in interactive/exploratory sessions you may want to create a copy() first.

You can change the name or type of a channel using rename_channels() or set_channel_types(). Both methods take dictionaries where the keys are existing channel names, and the values are the new name (or type) for that channel. Existing channels that are not in the dictionary will be unchanged.

To change the temporal extent of the Epochs, you can use the crop() method:

Cropping removed part of the baseline. When printing the cropped Epochs, MNE-Python will inform you about the time period that was originally used to perform baseline correction by displaying the string ‚Äúbaseline period cropped after baseline correction‚Äù:

However, if you wanted to expand the time domain of an Epochs object, you would need to go back to the Raw data and recreate the Epochs with different values for tmin and/or tmax.

It is also possible to change the ‚Äúzero point‚Äù that defines the time values in an Epochs object, with the shift_time() method. shift_time() allows shifting times relative to the current values, or specifying a fixed time to set as the new time value of the first sample (deriving the new time values of subsequent samples based on the Epochs object‚Äôs sampling frequency).

Note that although time shifting respects the sampling frequency (the spacing between samples), it does not enforce the assumption that there is a sample occurring at exactly time=0.

The get_data() method returns the epoched data as a NumPy array, of shape (n_epochs, n_channels, n_times); an optional picks parameter selects a subset of channels by index, name, or type:

Note that if your analysis requires repeatedly extracting single epochs from an Epochs object, epochs.get_data(item=2) will be much faster than epochs[2].get_data(), because it avoids the step of subsetting the Epochs object first.

You can also export Epochs data to Pandas DataFrames. Here, the DataFrame index will be constructed by converting the time of each sample into milliseconds and rounding it to the nearest integer, and combining it with the event types and epoch numbers to form a hierarchical MultiIndex. Each channel will appear in a separate column. Then you can use any of Pandas‚Äô tools for grouping and aggregating data; for example, here we select any epochs numbered 10 or less from the auditory/left condition, and extract times between 100 and 107 ms on channels EEG 056 through EEG 058 (note that slice indexing within Pandas‚Äô loc is inclusive of the endpoint):

See the Exporting Epochs to Pandas DataFrames tutorial for many more examples of the to_data_frame() method.

Epochs objects can be loaded and saved in the .fif format just like Raw objects, using the mne.read_epochs() function and the save() method. Functions are also available for loading data that was epoched outside of MNE-Python, such as mne.read_epochs_eeglab() and mne.read_epochs_kit().

The MNE-Python naming convention for epochs files is that the file basename (the part before the .fif or .fif.gz extension) should end with -epo or _epo, and a warning will be issued if the filename you provide does not adhere to that convention.

As a final note, be aware that the class of the epochs object is different when epochs are loaded from disk rather than generated from a Raw object:

In almost all cases this will not require changing anything about your code. However, if you need to do type checking on epochs objects, you can test against the base class that these classes are derived from:

Iterating over an Epochs object will yield arrays rather than single-trial Epochs objects:

If you want to iterate over Epochs objects, you can use an integer index as the iterator:

Total running time of the script: (0 minutes 5.312 seconds)

Download Jupyter notebook: 10_epochs_overview.ipynb

Download Python source code: 10_epochs_overview.py

Download zipped: 10_epochs_overview.zip

Gallery generated by Sphinx-Gallery

Segmenting continuous data into epochs

Regression-based baseline correction

---

## The Evoked data structure: evoked/averaged data#

**URL:** https://mne.tools/stable/auto_tutorials/evoked/10_evoked_overview.html

**Contents:**
- The Evoked data structure: evoked/averaged data#
- Creating Evoked objects from Epochs#
- Basic visualization of Evoked objects#
- Subsetting Evoked data#
  - Selecting, dropping, and reordering channels#
- Similarities among the core data structures#
- Loading and saving Evoked data#
- Combining Evoked objects#
- Other uses of Evoked objects#

Go to the end to download the full example code.

This tutorial covers the basics of creating and working with evoked data. It introduces the Evoked data structure in detail, including how to load, query, subset, export, and plot data from an Evoked object. For details on creating an Evoked object from (possibly simulated) data in a NumPy array, see Creating MNE-Python data structures from scratch.

As usual, we start by importing the modules we need:

Evoked objects typically store EEG or MEG signals that have been averaged over multiple epochs, which is a common technique for estimating stimulus-evoked activity. The data in an Evoked object are stored in an array of shape (n_channels, n_times) (in contrast to an Epochs object, which stores data of shape (n_epochs, n_channels, n_times)). Thus, to create an Evoked object, we‚Äôll start by epoching some raw data, and then averaging together all the epochs from one condition:

You may have noticed that MNE informed us that ‚Äúbaseline correction‚Äù has been applied. This happened automatically during creation of the Epochs object, but may also be initiated (or disabled) manually. We will discuss this in more detail later.

The information about the baseline period of Epochs is transferred to derived Evoked objects to maintain provenance as you process your data:

We can visualize the average evoked response for left-auditory stimuli using the plot() method, which yields a butterfly plot of each channel type:

Like the plot() methods for Raw and Epochs objects, evoked.plot() has many parameters for customizing the plot output, such as color-coding channel traces by scalp location, or plotting the global field power alongside the channel traces. See Visualizing Evoked data for more information on visualizing Evoked objects.

Evokeds are not memory-mapped

Evoked objects use a data attribute rather than a get_data() method; this reflects the fact that the data in Evoked objects are always loaded into memory and never memory-mapped from their location on disk (because they are typically much smaller than Raw or Epochs objects).

Unlike Raw and Epochs objects, Evoked objects do not support selection by square-bracket indexing. Instead, data can be subsetted by indexing the data attribute:

To select based on time in seconds, the time_as_index() method can be useful, although beware that depending on the sampling frequency, the number of samples in a span of given duration may not always be the same (see the Time, sample number, and sample index section of the tutorial on Raw data for details).

By default, when creating Evoked data from an Epochs object, only the primary data channels will be retained: eog, ecg, stim, and misc channel types will be dropped. You can control which channel types are retained via the picks parameter of epochs.average(), by passing 'all' to retain all channels, or by passing a list of integers, channel names, or channel types. See the documentation of average() for details.

If you‚Äôve already created the Evoked object, you can use the pick(), pick_channels(), pick_types(), and drop_channels() methods to modify which channels are included in an Evoked object. You can also use reorder_channels() for this purpose; any channel names not provided to reorder_channels() will be dropped. Note that channel selection methods modify the object in-place, so in interactive/exploratory sessions you may want to create a copy() first.

Evoked objects have many similarities with Raw and Epochs objects, including:

They can be loaded from and saved to disk in .fif format, and their data can be exported to a NumPy array (but through the data attribute instead of a get_data() method). Pandas DataFrame export is also available through the to_data_frame() method.

You can change the name or type of a channel using evoked.rename_channels() or evoked.set_channel_types(). Both methods take dictionaries where the keys are existing channel names, and the values are the new name (or type) for that channel. Existing channels that are not in the dictionary will be unchanged.

SSP projector manipulation is possible through add_proj(), del_proj(), and plot_projs_topomap() methods, and the proj attribute. See Repairing artifacts with SSP for more information on SSP.

Like Raw and Epochs objects, Evoked objects have copy(), crop(), time_as_index(), filter(), and resample() methods.

Like Raw and Epochs objects, Evoked objects have evoked.times, evoked.ch_names, and info attributes.

Single Evoked objects can be saved to disk with the evoked.save() method. One difference between Evoked objects and the other data structures is that multiple Evoked objects can be saved into a single .fif file, using mne.write_evokeds(). The example data includes such a .fif file: the data have already been epoched and averaged, and the file contains separate Evoked objects for each experimental condition:

Notice that mne.read_evokeds() returned a list of Evoked objects, and each one has an evoked.comment attribute describing the experimental condition that was averaged to generate the estimate:

If you want to load only some of the conditions present in a .fif file, read_evokeds() has a condition parameter, which takes either a string (matched against the comment attribute of the evoked objects on disk), or an integer selecting the Evoked object based on the order it is stored in the file. Passing lists of integers or strings is also possible. If only one object is selected, the Evoked object will be returned directly (rather than inside a list of length one):

Previously, when we created an Evoked object by averaging epochs, baseline correction was applied by default when we extracted epochs from the Raw object (the default baseline period is (None, 0), which ensures zero mean for times before the stimulus event). In contrast, if we plot the first Evoked object in the list that was loaded from disk, we‚Äôll see that the data have not been baseline-corrected:

This can be remedied by either passing a baseline parameter to mne.read_evokeds(), or by applying baseline correction after loading, as shown here:

Notice that apply_baseline() operated in-place. Similarly, Evoked objects may have been saved to disk with or without projectors applied; you can pass proj=True to the read_evokeds() function, or use the apply_proj() method after loading.

One way to pool data across multiple conditions when estimating evoked responses is to do so prior to averaging (recall that MNE-Python can select based on partial matching of epoch labels separated by /; see Subselecting epochs for more information):

This approach will weight each epoch equally and create a single Evoked object. Notice that the printed representation includes (average, N=145), indicating that the Evoked object was created by averaging across 145 epochs. In this case, the event types were fairly close in number:

However, this may not always be the case. If for statistical reasons it is important to average the same number of epochs from different conditions, you can use equalize_event_counts() prior to averaging.

Another approach to pooling across conditions is to create separate Evoked objects for each condition, and combine them afterwards. This can be accomplished with the function mne.combine_evoked(), which computes a weighted sum of the Evoked objects given to it. The weights can be manually specified as a list or array of float values, or can be specified using the keyword 'equal' (weight each Evoked object by \(\frac{1}{N}\), where \(N\) is the number of Evoked objects given) or the keyword 'nave' (weight each Evoked object proportional to the number of epochs averaged together to create it):

Note that the nave attribute of the resulting Evoked object will reflect the effective number of averages, and depends on both the nave attributes of the contributing Evoked objects and the weights with which they are combined. Keeping track of effective nave is important for inverse imaging, because nave is used to scale the noise covariance estimate, which in turn affects the magnitude of estimated source activity (see The minimum-norm current estimates for more information, especially the Whitening and scaling section). Note that mne.grand_average() does not adjust nave to reflect the effective number of averaged epochs; it simply sets nave to the number of evokeds that were averaged together. For this reason, it is best to use mne.combine_evoked() rather than mne.grand_average() if you intend to perform inverse imaging on the resulting Evoked object.

Although the most common use of Evoked objects is to store averages of epoched data, there are a few other uses worth noting here. First, the method epochs.standard_error() will create an Evoked object (just like epochs.average() does), but the data in the Evoked object will be the standard error across epochs instead of the average. To indicate this difference, Evoked objects have a kind attribute that takes values 'average' or 'standard error' as appropriate.

Another use of Evoked objects is to represent a single trial or epoch of data, usually when looping through epochs. This can be easily accomplished with the epochs.iter_evoked() method, and can be useful for applications where you want to do something that is only possible for Evoked objects. For example, here we use the get_peak() method (which is not available for Epochs objects) to get the peak response in each trial:

Total running time of the script: (0 minutes 7.839 seconds)

Download Jupyter notebook: 10_evoked_overview.ipynb

Download Python source code: 10_evoked_overview.py

Download zipped: 10_evoked_overview.zip

Gallery generated by Sphinx-Gallery

Estimating evoked responses

Visualizing Evoked data

---

## The Info data structure#

**URL:** https://mne.tools/stable/auto_tutorials/intro/30_info.html

**Contents:**
- The Info data structure#
- Querying the Info object#
- Obtaining subsets of channels#
- Obtaining channel type information#
- Dropping channels from an Info object#

Go to the end to download the full example code.

This tutorial describes the mne.Info data structure, which keeps track of various recording details, and is attached to Raw, Epochs, and Evoked objects.

We will begin by loading the Python modules we need, and loading the same example data we used in the introductory tutorial:

As seen in the introductory tutorial, when a Raw object is loaded, an Info object is created automatically, and stored in the raw.info attribute:

However, it is not strictly necessary to load the Raw object in order to view or edit the Info object; you can extract all the relevant information into a stand-alone Info object using mne.io.read_info():

As you can see, the Info object keeps track of a lot of information about:

the recording system (gantry angle, HPI details, sensor digitizations, channel names, ‚Ä¶)

the experiment (project name and ID, subject information, recording date, experimenter name or ID, ‚Ä¶)

the data (sampling frequency, applied filter frequencies, bad channels, projectors, ‚Ä¶)

The complete list of fields is given in the API documentation.

The fields in a Info object act like Python dictionary keys, using square brackets and strings to access the contents of a field:

Most of the fields contain int, float, or list data, but the chs field bears special mention: it contains a list of dictionaries (one dict per channel) containing everything there is to know about a channel other than the data it recorded. Normally it is not necessary to dig into the details of the chs field ‚Äî various MNE-Python functions can extract the information more cleanly than iterating over the list of dicts yourself ‚Äî but it can be helpful to know what is in there. Here we show the keys for the first channel‚Äôs dict:

It is often useful to convert between channel names and the integer indices identifying rows of the data array where those channels‚Äô measurements are stored. The Info object is useful for this task; two convenience functions that rely on the mne.Info object for picking channels are mne.pick_channels() and mne.pick_types(). pick_channels() minimally takes a list of all channel names and a list of channel names to include; it is also possible to provide an empty list to include and specify which channels to exclude instead:

pick_types() works differently, since channel type cannot always be reliably determined from channel name alone. Consequently, pick_types() needs an Info object instead of just a list of channel names, and has boolean keyword arguments for each channel type. Default behavior is to pick only MEG channels (and MEG reference channels if present) and exclude any channels already marked as ‚Äúbad‚Äù in the bads field of the Info object. Therefore, to get all and only the EEG channel indices (including the ‚Äúbad‚Äù EEG channels) we must pass meg=False and exclude=[]:

Note that the meg and fnirs parameters of pick_types() accept strings as well as boolean values, to allow selecting only magnetometer or gradiometer channels (via meg='mag' or meg='grad') or to pick only oxyhemoglobin or deoxyhemoglobin channels (via fnirs='hbo' or fnirs='hbr', respectively).

A third way to pick channels from an Info object is to apply regular expression matching to the channel names using mne.pick_channels_regexp(). Here the ^ represents the beginning of the string and . character matches any single character, so both EEG and EOG channels will be selected:

pick_channels_regexp() can be especially useful for channels named according to the 10-20 system (e.g., to select all channels ending in ‚Äúz‚Äù to get the midline, or all channels beginning with ‚ÄúO‚Äù to get the occipital channels). Note that pick_channels_regexp() uses the Python standard module re to perform regular expression matching; see the documentation of the re module for implementation details.

Both pick_channels() and pick_channels_regexp() operate on lists of channel names, so they are unaware of which channels (if any) have been marked as ‚Äúbad‚Äù in info['bads']. Use caution to avoid accidentally selecting bad channels.

Sometimes it can be useful to know channel type based on its index in the data array. For this case, use mne.channel_type(), which takes an Info object and a single integer channel index:

To obtain several channel types at once, you could embed channel_type() in a list comprehension, or use the get_channel_types() method of a Raw, Epochs, or Evoked instance:

Alternatively, you can get the indices of all channels of all channel types present in the data, using channel_indices_by_type(), which returns a dict with channel types as keys, and lists of channel indices as values:

If you want to modify an Info object by eliminating some of the channels in it, you can use the mne.pick_info() function to pick the channels you want to keep and omit the rest:

We can also get a nice HTML representation in IPython like this:

By default, pick_info() will make a copy of the original Info object before modifying it; if you want to modify it in-place, include the parameter copy=False.

Total running time of the script: (0 minutes 1.162 seconds)

Download Jupyter notebook: 30_info.ipynb

Download Python source code: 30_info.py

Download zipped: 30_info.zip

Gallery generated by Sphinx-Gallery

Parsing events from raw data

Working with sensor locations

---

## The Raw data structure: continuous data#

**URL:** https://mne.tools/stable/auto_tutorials/raw/10_raw_overview.html

**Contents:**
- The Raw data structure: continuous data#
- Loading continuous data#
- Querying the Raw object#
  - The Raw.info attribute#
  - Time, sample number, and sample index#
- Modifying Raw objects#
  - Selecting, dropping, and reordering channels#
  - Changing channel name and type#
  - Selection in the time domain#
- Extracting data from Raw objects#

Go to the end to download the full example code.

This tutorial covers the basics of working with raw EEG/MEG data in Python. It introduces the Raw data structure in detail, including how to load, query, subselect, export, and plot data from a Raw object. For more info on visualization of Raw objects, see Built-in plotting methods for Raw objects. For info on creating a Raw object from simulated data in a NumPy array, see Creating MNE-Python data structures from scratch.

As usual we‚Äôll start by importing the modules we need:

Datasets in MNE-Python

There are data_path functions for several example datasets in MNE-Python (e.g., mne.datasets.kiloword.data_path(), mne.datasets.spm_face.data_path(), etc). All of them will check the default download location first to see if the dataset is already on your computer, and only download it if necessary. The default download location is also configurable; see the documentation of any of the data_path functions for more information.

As mentioned in the introductory tutorial, MNE-Python data structures are based around the .fif file format from Neuromag. This tutorial uses an example dataset in .fif format, so here we‚Äôll use the function mne.io.read_raw_fif() to load the raw data; there are reader functions for a wide variety of other data formats as well.

There are also several other example datasets that can be downloaded with just a few lines of code. Functions for downloading example datasets are in the mne.datasets submodule; here we‚Äôll use mne.datasets.sample.data_path() to download the ‚ÄúSample‚Äù dataset, which contains EEG, MEG, and structural MRI data from one subject performing an audiovisual experiment. When it‚Äôs done downloading, data_path() will return the folder location where it put the files; you can navigate there with your file browser if you want to examine the files yourself. Once we have the file path, we can load the data with read_raw_fif(). This will return a Raw object, which we‚Äôll store in a variable called raw.

As you can see above, read_raw_fif() automatically displays some information about the file it‚Äôs loading. For example, here it tells us that there are three ‚Äúprojection items‚Äù in the file along with the recorded data; those are SSP projectors calculated to remove environmental noise from the MEG signals, and are discussed in a the tutorial Background on projectors and projections. In addition to the information displayed during loading, you can get a glimpse of the basic details of a Raw object by printing it:

By default, the mne.io.read_raw_* family of functions will not load the data into memory (instead the data on disk are memory-mapped, meaning the data are only read from disk as-needed). Some operations (such as filtering) require that the data be copied into RAM; to do that we could have passed the preload=True parameter to read_raw_fif(), but we can also copy the data into RAM at any time using the load_data() method. However, since this particular tutorial doesn‚Äôt do any serious analysis of the data, we‚Äôll first crop() the Raw object to 60 seconds so it uses less memory and runs more smoothly on our documentation server.

Attributes vs. Methods

Attributes are usually static properties of Python objects ‚Äî things that are pre-computed and stored as part of the object‚Äôs representation in memory. Attributes are accessed with the . operator and do not require parentheses after the attribute name (example: raw.ch_names).

Methods are like specialized functions attached to an object. Usually they require additional user input and/or need some computation to yield a result. Methods always have parentheses at the end; additional arguments (if any) go inside those parentheses (examples: raw.estimate_rank(), raw.drop_channels(['EEG 030', 'MEG 2242'])).

We saw above that printing the Raw object displays some basic information like the total number of channels, the number of time points at which the data were sampled, total duration, and the approximate size in memory. Much more information is available through the various attributes and methods of the Raw class. Some useful attributes of Raw objects include a list of the channel names (ch_names), an array of the sample times in seconds (times), and the total number of samples (n_times); a list of all attributes and methods is given in the documentation of the Raw class.

There is also quite a lot of information stored in the raw.info attribute, which stores an Info object that is similar to a Python dictionary (in that it has fields accessed via named keys). Like Python dictionaries, raw.info has a .keys() method that shows all the available field names; unlike Python dictionaries, printing raw.info will print a nicely-formatted glimpse of each field‚Äôs data. See The Info data structure for more on what is stored in Info objects, and how to interact with them.

Most of the fields of raw.info reflect metadata recorded at acquisition time, and should not be changed by the user. There are a few exceptions (such as raw.info['bads'] and raw.info['projs']), but in most cases there are dedicated MNE-Python functions or methods to update the Info object safely (such as add_proj() to update raw.info['projs']).

Sample numbering in VectorView data

For data from VectorView systems, it is important to distinguish sample number from sample index. See first_samp for more information.

One method of Raw objects that is frequently useful is time_as_index(), which converts a time (in seconds) into the integer index of the sample occurring closest to that time. The method can also take a list or array of times, and will return an array of indices.

It is important to remember that there may not be a data sample at exactly the time requested, so the number of samples between time = 1 second and time = 2 seconds may be different than the number of samples between time = 2 and time = 3:

Although the Raw object underlyingly stores data samples in a NumPy array of shape (n_channels, n_timepoints), the Raw object behaves differently from NumPy arrays with respect to the len() function. len(raw) will return the number of timepoints (length along data axis 1), not the number of channels (length along data axis 0). Hence in this section you‚Äôll see len(raw.ch_names) to get the number of channels.

Raw objects have a number of methods that modify the Raw instance in-place and return a reference to the modified instance. This can be useful for method chaining (e.g., raw.crop(...).pick(...).filter(...).plot()) but it also poses a problem during interactive analysis: if you modify your Raw object for an exploratory plot or analysis (say, by dropping some channels), you will then need to re-load the data (and repeat any earlier processing steps) to undo the channel-dropping and try something else. For that reason, the examples in this section frequently use the copy() method before the other methods being demonstrated, so that the original Raw object is still available in the variable raw for use in later examples.

Altering the channels of a Raw object can be done in several ways. As a first example, we‚Äôll use the pick() method to restrict the Raw object to just the EEG and EOG channels:

In addition, pick() can also be used to pick channels by name, and a corresponding drop_channels() method to remove channels by name:

If you want the channels in a specific order (e.g., for plotting), reorder_channels() works just like pick() but also reorders the channels; for example, here we pick the EOG and frontal EEG channels, putting the EOG first and the EEG in reverse order:

Due to limitations in the .fif file format (which MNE-Python uses to save Raw objects), channel names are limited to a maximum of 15 characters.

You may have noticed that the EEG channel names in the sample data are numbered rather than labelled according to a standard nomenclature such as the 10-20 or 10-05 systems, or perhaps it bothers you that the channel names contain spaces. It is possible to rename channels using the rename_channels() method, which takes a Python dictionary to map old names to new names. You need not rename all channels at once; provide only the dictionary entries for the channels you want to rename. Here‚Äôs a frivolous example:

This next example replaces spaces in the channel names with underscores, using a Python dict comprehension:

If for some reason the channel types in your Raw object are inaccurate, you can change the type of any channel with the set_channel_types() method. The method takes a dictionary mapping channel names to types; allowed types are bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci, eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase, fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp, seeg, stim, syst, temperature (see sensor types for more information about them). A common use case for changing channel type is when using frontal EEG electrodes as makeshift EOG channels:

If you want to limit the time domain of a Raw object, you can use the crop() method, which modifies the Raw object in place (we‚Äôve seen this already at the start of this tutorial, when we cropped the Raw object to 60 seconds to reduce memory demands). crop() takes parameters tmin and tmax, both in seconds (here we‚Äôll again use copy() first to avoid changing the original Raw object):

crop() also modifies the first_samp and times attributes, so that the first sample of the cropped object now corresponds to time = 0. Accordingly, if you wanted to re-crop raw_selection from 11 to 12.5 seconds (instead of 10 to 12.5 as above) then the subsequent call to crop() should get tmin=1 (not tmin=11), and leave tmax unspecified to keep everything from tmin up to the end of the object:

Remember that sample times don‚Äôt always align exactly with requested tmin or tmax values (due to sampling), which is why the max values of the cropped files don‚Äôt exactly match the requested tmax (see Time, sample number, and sample index for further details).

If you need to select discontinuous spans of a Raw object ‚Äî or combine two or more separate Raw objects ‚Äî you can use the append() method:

Be careful when concatenating Raw objects from different recordings, especially when saving: append() only preserves the info attribute of the initial Raw object (the one outside the append() method call).

So far we‚Äôve been looking at ways to modify a Raw object. This section shows how to extract the data from a Raw object into a NumPy array, for analysis or plotting using functions outside of MNE-Python. To select portions of the data, Raw objects can be indexed using square brackets. However, indexing Raw works differently than indexing a NumPy array in two ways:

Along with the requested sample value(s) MNE-Python also returns an array of times (in seconds) corresponding to the requested samples. The data array and the times array are returned together as elements of a tuple.

The data array will always be 2-dimensional even if you request only a single time sample or a single channel.

To illustrate the above two points, let‚Äôs select a couple seconds of data from the first channel:

You can see that it contains 2 arrays. This combination of data and times makes it easy to plot selections of raw data (although note that we‚Äôre transposing the data array so that each channel is a column instead of a row, to match what matplotlib expects when plotting 2-dimensional y against 1-dimensional x):

The Raw object can also be indexed with the names of channels instead of their index numbers. You can pass a single string to get just one channel, or a list of strings to select multiple channels. As with integer indexing, this will return a tuple of (data_array, times_array) that can be easily plotted. Since we‚Äôre plotting 2 channels this time, we‚Äôll add a vertical offset to one channel so it‚Äôs not plotted right on top of the other one:

There are several ways to select all channels of a given type from a Raw object. The safest method is to use mne.pick_types() to obtain the integer indices of the channels you want, then use those indices with the square-bracket indexing method shown above. The pick_types() function uses the Info attribute of the Raw object to determine channel types, and takes boolean or string parameters to indicate which type(s) to retain. The meg parameter defaults to True, and all others default to False, so to get just the EEG channels, we pass eeg=True and meg=False:

Some of the parameters of mne.pick_types() accept string arguments as well as booleans. For example, the meg parameter can take values 'mag', 'grad', 'planar1', or 'planar2' to select only magnetometers, all gradiometers, or a specific type of gradiometer. See the docstring of mne.pick_types() for full details.

If you only want the data (not the corresponding array of times), Raw objects have a get_data() method. Used with no parameters specified, it will extract all data from all channels, in a (n_channels, n_timepoints) NumPy array:

If you want the array of times, get_data() has an optional return_times parameter:

The get_data() method can also be used to extract specific channel(s) and sample ranges, via its picks, start, and stop parameters. The picks parameter accepts integer channel indices, channel names, or channel types, and preserves the requested channel order given as its picks parameter.

The following table summarizes the various ways of extracting data from a Raw object.

NumPy array (n_chans √ó n_samps)

tuple of (data (n_chans √ó n_samps), times (1 √ó n_samps))

raw.get_data(return_times=True)

tuple of (data (1 √ó 1000), times (1 √ó 1000))

raw['MEG 0113', 1000:2000]

raw.get_data(picks=0, start=1000, stop=2000, return_times=True)

raw.get_data(picks='MEG 0113', start=1000, stop=2000, return_times=True)

tuple of (data (2 √ó 1000), times (1 √ó 1000))

raw[[2, 5], 1000:2000]

raw[['EEG 030', 'EOG 061'], 1000:2000]

Raw objects have a built-in save() method, which can be used to write a partially processed Raw object to disk as a .fif file, such that it can be re-loaded later with its various attributes intact (but see Floating-point precision for an important note about numerical precision when saving).

There are a few other ways to export just the sensor data from a Raw object. One is to use indexing or the get_data() method to extract the data, and use numpy.save() to save the data array:

It is also possible to export the data to a Pandas DataFrame object, and use the saving methods that Pandas affords. The Raw object‚Äôs to_data_frame() method is similar to get_data() in that it has a picks parameter for restricting which channels are exported, and start and stop parameters for restricting the time domain. Note that, by default, times will be converted to milliseconds, rounded to the nearest millisecond, and used as the DataFrame index; see the scaling_time parameter in the documentation of to_data_frame() for more details.

When exporting data as a NumPy array or Pandas DataFrame, be sure to properly account for the unit of representation in your subsequent analyses.

Total running time of the script: (0 minutes 1.793 seconds)

Download Jupyter notebook: 10_raw_overview.ipynb

Download Python source code: 10_raw_overview.py

Download zipped: 10_raw_overview.zip

Gallery generated by Sphinx-Gallery

Working with continuous data

---

## The role of dipole orientations in distributed source localization#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/35_dipole_orientations.html

**Contents:**
- The role of dipole orientations in distributed source localization#
- Load data#
- The source space#
- Fixed dipole orientations#
- Loose dipole orientations#
- Limiting orientations, but not fixing them#
- Discarding dipole orientation information#
- References#

Go to the end to download the full example code.

When performing source localization in a distributed manner (i.e., using MNE/dSPM/sLORETA/eLORETA), the source space is defined as a grid of dipoles that spans a large portion of the cortex. These dipoles have both a position and an orientation. In this tutorial, we will look at the various options available to restrict the orientation of the dipoles and the impact on the resulting source estimate.

A common ‚Äúgotcha!‚Äù is that by default, dipole orientation information is discarded in the source estimate. Only the magnitude of the activity is retained. This means that by default, the source-level values are always positive. This has some implications that may not be immediately obvious:

Averaging across source estimated epochs does not produce a source estimated evoked response. Since values are always positive, noise does not ‚Äúcancel out‚Äù. This means the default settings are probably not suitable for things like performing linear regression or computing correlations across epochs in source space.

Oscillatory signals are distorted, as for example a sine wave will become a series of bumps. Hence, frequency analysis in source space is not meaningful when using the default settings.

See Orientation constraints for related information.

Load everything we need to perform source localization on the sample dataset.

Let‚Äôs start by examining the source space as constructed by the mne.setup_source_space() function. Dipoles are placed along fixed intervals on the cortex, determined by the spacing parameter. The source space does not define the orientation for these dipoles.

While the source space defines the position of the dipoles, the inverse operator defines the possible orientations of them. One of the options is to assign a fixed orientation. Since the neural currents from which MEG and EEG signals originate flows mostly perpendicular to the cortex [1], restricting the orientation of the dipoles accordingly places a useful restriction on the source estimate.

By specifying fixed=True when calling mne.minimum_norm.make_inverse_operator(), the dipole orientations are fixed to be orthogonal to the surface of the cortex, pointing outwards. Let‚Äôs visualize this:

Restricting the dipole orientations in this manner leads to the following source estimate for the sample data:

The direction of the estimated current is now restricted to two directions: inward and outward. In the plot, blue areas indicate current flowing inwards and red areas indicate current flowing outwards. Given the curvature of the cortex, groups of dipoles tend to point in the same direction: the direction of the electromagnetic field picked up by the sensors.

Forcing the source dipoles to be strictly orthogonal to the cortex makes the source estimate sensitive to the spacing of the dipoles along the cortex, since the curvature of the cortex changes within each ~10 square mm patch. Furthermore, misalignment of the MEG/EEG and MRI coordinate frames is more critical when the source dipole orientations are strictly constrained [2]. To lift the restriction on the orientation of the dipoles, the inverse operator has the ability to place not one, but three dipoles at each location defined by the source space. These three dipoles are placed orthogonally to form a Cartesian coordinate system. Let‚Äôs visualize this:

When computing the source estimate, the activity at each of the three dipoles is collapsed into the XYZ components of a single vector, which leads to the following source estimate for the sample data:

Often, the best results will be obtained by allowing the dipoles to have somewhat free orientation, but not stray too far from a orientation that is perpendicular to the cortex. The loose parameter of the mne.minimum_norm.make_inverse_operator() allows you to specify a value between 0 (fixed) and 1 (unrestricted or ‚Äúfree‚Äù) to indicate the amount the orientation is allowed to deviate from the surface normal.

Often, further analysis of the data does not need information about the orientation of the dipoles, but rather their magnitudes. The pick_ori parameter of the mne.minimum_norm.apply_inverse() function allows you to specify whether to return the full vector solution ('vector') or rather the magnitude of the vectors (None, the default) or only the activity in the direction perpendicular to the cortex ('normal').

Matti S. H√§m√§l√§inen, Riitta Hari, Risto J. Ilmoniemi, Jukka Knuutila, and Olli V. Lounasmaa. Magnetoencephalography‚Äîtheory, instrumentation, and applications to noninvasive studies of the working human brain. Reviews of Modern Physics, 65(2):413‚Äì497, 1993. doi:10.1103/RevModPhys.65.413.

Fa-Hsuan Lin, John W. Belliveau, Anders M. Dale, and Matti S. H√§m√§l√§inen. Distributed current estimates using cortical orientation constraints. Human Brain Mapping, 27(1):1‚Äì13, 2006. doi:10.1002/hbm.20155.

Total running time of the script: (0 minutes 35.681 seconds)

Download Jupyter notebook: 35_dipole_orientations.ipynb

Download Python source code: 35_dipole_orientations.py

Download zipped: 35_dipole_orientations.zip

Gallery generated by Sphinx-Gallery

Source localization with MNE, dSPM, sLORETA, and eLORETA

Computing various MNE solutions

---

## The SourceEstimate data structure#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/10_stc_class.html

**Contents:**
- The SourceEstimate data structure#
- Load and inspect example data#
- SourceEstimate (stc)#
- Relationship to SourceSpaces (src)#
- Summary#

Go to the end to download the full example code.

Source estimates, commonly referred to as STC (Source Time Courses), are obtained from source localization methods. Source localization method solve the so-called ‚Äòinverse problem‚Äô. MNE provides different methods for solving it: dSPM, sLORETA, LCMV, MxNE etc.

Source localization consists in projecting the EEG/MEG sensor data into a 3-dimensional ‚Äòsource space‚Äô positioned in the individual subject‚Äôs brain anatomy. Hence the data is transformed such that the recorded time series at each sensor location maps to time series at each spatial location of the ‚Äòsource space‚Äô where is defined our source estimates.

An STC object contains the amplitudes of the sources over time. It only stores the amplitudes of activations but not the locations of the sources. To get access to the locations you need to have the source space (often abbreviated src) used to compute the forward operator (often abbreviated fwd).

See Head model and forward computation for more details on forward modeling, and Source localization with MNE, dSPM, sLORETA, and eLORETA for an example of source localization with dSPM, sLORETA or eLORETA.

Source estimates come in different forms:

mne.SourceEstimate: For cortically constrained source spaces.

mne.VolSourceEstimate: For volumetric source spaces

mne.VectorSourceEstimate: For cortically constrained source spaces with vector-valued source activations (strength and orientation)

mne.MixedSourceEstimate: For source spaces formed of a combination of cortically constrained and volumetric sources.

(Vector) SourceEstimate are surface representations mostly used together with FreeSurfer surface representations.

Let‚Äôs get ourselves an idea of what a mne.SourceEstimate really is. We first set up the environment and load some data:

This data set contains source estimation data from an audio visual task. It has been mapped onto the inflated cortical surface representation obtained from FreeSurfer using the dSPM method. It highlights a noticeable peak in the auditory cortices.

Let‚Äôs see how it looks like.

A source estimate contains the time series of a activations at spatial locations defined by the source space. In the context of a FreeSurfer surfaces - which consist of 3D triangulations - we could call each data point on the inflated brain representation a vertex . If every vertex represents the spatial location of a time series, the time series and spatial location can be written into a matrix, where to each vertex (rows) at multiple time points (columns) a value can be assigned. This value is the strength of our signal at a given point in space and time. Exactly this matrix is stored in stc.data.

Let‚Äôs have a look at the shape

We see that stc carries 7498 time series of 25 samples length. Those time series belong to 7498 vertices, which in turn represent locations on the cortical surface. So where do those vertex values come from?

FreeSurfer separates both hemispheres and creates surfaces representation for left and right hemisphere. Indices to surface locations are stored in stc.vertices. This is a list with two arrays of integers, that index a particular vertex of the FreeSurfer mesh. A value of 42 would hence map to the x,y,z coordinates of the mesh with index 42. See next section on how to get access to the positions in a mne.SourceSpaces object.

Since both hemispheres are always represented separately, both attributes introduced above, can also be obtained by selecting the respective hemisphere. This is done by adding the correct prefix (lh or rh).

Since we did not change the time representation, only the selected subset of vertices and hence only the row size of the matrix changed. We can check if the rows of stc.lh_data and stc.rh_data sum up to the value we had before.

Indeed and as the mindful reader already suspected, the same can be said about vertices. stc.lh_vertno thereby maps to the left and stc.rh_vertno to the right inflated surface representation of FreeSurfer.

As mentioned above, src carries the mapping from stc to the surface. The surface is built up from a triangulated mesh for each hemisphere. Each triangle building up a face consists of 3 vertices. Since src is a list of two source spaces (left and right hemisphere), we can access the respective data by selecting the source space first. Faces building up the left hemisphere can be accessed via src[0]['tris'], where the index \(0\) stands for the left and \(1\) for the right hemisphere.

The values in src[0][‚Äòtris‚Äô] refer to row indices in src[0]['rr']. Here we find the actual coordinates of the surface mesh. Hence every index value for vertices will select a coordinate from here. Furthermore src[0]['vertno'] stores the same data as stc.lh_vertno, except when working with sparse solvers such as mne.inverse_sparse.mixed_norm(), as then only a fraction of vertices actually have non-zero activations.

In other words stc.lh_vertno equals src[0]['vertno'], whereas stc.rh_vertno equals src[1]['vertno']. Thus the Nth time series in stc.lh_data corresponds to the Nth value in stc.lh_vertno and src[0][‚Äòvertno‚Äô] respectively, which in turn map the time series to a specific location on the surface, represented as the set of cartesian coordinates stc.lh_vertno[N] in src[0]['rr'].

Let‚Äôs obtain the peak amplitude of the data as vertex and time point index

The first value thereby indicates which vertex and the second which time point index from within stc.lh_vertno or stc.lh_data is used. We can use the respective information to get the index of the surface vertex resembling the peak and its value.

Let‚Äôs visualize this as well, using the same surfer_kwargs as in the beginning.

stc is a class of MNE-Python, representing the transformed time series obtained from source estimation. For both hemispheres the data is stored separately in stc.lh_data and stc.rh_data in form of a \(m \times n\) matrix, where \(m\) is the number of spatial locations belonging to that hemisphere and \(n\) the number of time points.

stc.lh_vertno and stc.rh_vertno correspond to src[0]['vertno'] and src[1]['vertno']. Those are the indices of locations on the surface representation.

The surface‚Äôs mesh coordinates are stored in src[0]['rr'] and src[1]['rr'] for left and right hemisphere. 3D coordinates can be accessed by the above logic:

Total running time of the script: (0 minutes 8.338 seconds)

Download Jupyter notebook: 10_stc_class.ipynb

Download Python source code: 10_stc_class.py

Download zipped: 10_stc_class.zip

Gallery generated by Sphinx-Gallery

Source localization and inverses

Source localization with equivalent current dipole (ECD) fit

---

## The Spectrum and EpochsSpectrum classes: frequency-domain data#

**URL:** https://mne.tools/stable/auto_tutorials/time-freq/10_spectrum_class.html

**Contents:**
- The Spectrum and EpochsSpectrum classes: frequency-domain data#
- Visualizing Spectrum objects#
- Migrating legacy code#
- References#

Go to the end to download the full example code.

This tutorial shows how to create and visualize frequency-domain representations of your data, starting from continuous Raw, discontinuous Epochs, or averaged Evoked data.

As usual we‚Äôll start by importing the modules we need, and loading our sample dataset:

All three sensor-space containers (Raw, Epochs, and Evoked) have a compute_psd() method with the same options.

By default, the spectral estimation method will be the Welch[1] method for continuous data, and the multitaper method [2] for epoched or averaged data. This default can be overridden by passing method='welch' or method='multitaper' to the compute_psd() method.

There are many other options available as well; for example we can compute a spectrum from a given span of times, for a chosen frequency range, and for a subset of the available channels:

You can also pass some parameters to the underlying spectral estimation function, such as the FFT window length and overlap for the Welch method; see the docstrings of mne.time_frequency.Spectrum (esp. its method_kw parameter) and the spectral estimation functions psd_array_welch() and psd_array_multitaper() for details.

For epoched data, the class of the spectral estimate will be mne.time_frequency.EpochsSpectrum instead of mne.time_frequency.Spectrum, but most of the API is the same for the two classes. For example, both have a get_data() method with an option to return the bin frequencies:

Additionally, both Spectrum and EpochsSpectrum have __getitem__ methods, meaning their data can be accessed by square-bracket indexing. For Spectrum objects (computed from Raw or Evoked data), the indexing works similar to a Raw object or a NumPy array:

If the original Epochs object had a metadata dataframe attached, the derived EpochsSpectrum will inherit that metadata and will hence also support subselecting epochs via Pandas query strings.

In contrast, the EpochsSpectrum has indexing similar to Epochs objects: you can use string values to select spectral estimates for specific epochs based on their condition names, and what you get back is a new instance of EpochsSpectrum rather than a NumPy array of the data values. Selection via hierarchical event descriptors (HEDs) is also possible:

Both Spectrum and EpochsSpectrum objects have plotting methods plot() (frequency √ó power), plot_topo() (frequency √ó power separately for each sensor), and plot_topomap() (interpolated scalp topography of power, in specific frequency bands). A few plot options are demonstrated below; see the docstrings for full details.

Below is a quick-reference table of equivalent code from before and after the introduction of the Spectrum and EpochsSpectrum classes.

mne.time_frequency.psd_welch(raw)

raw.compute_psd().get_data(return_freqs=True)

mne.time_frequency.psd_multitaper(raw)

raw.compute_psd(method='multitaper').get_data(return_freqs=True)

raw.plot_psd(fmin, fmax, dB, area_mode='std')

raw.compute_psd(fmin, fmax).plot(dB, ci='std')

raw.plot_psd_topo(n_fft, overlap, axes)

raw.compute_psd(n_fft, overlap).plot_topo(axes)

epochs.plot_psd_topomap(tmax, bands)

epochs.compute_psd(tmax).plot_topomap(bands)

The functions mne.time_frequency.psd_welch and mne.time_frequency.psd_multitaper have been removed; new code should use the Raw.compute_psd(), Epochs.compute_psd(), and Evoked.compute_psd() methods, and pass method='welch' or method='multitaper' as a parameter.

The class methods Raw.plot_psd(), Epochs.plot_psd(), Raw.plot_psd_topo(), and Epochs.plot_psd_topomap() have been kept in the API to support legacy code, but should be avoided when writing new code.

Peter D. Welch. The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms. IEEE Transactions on Audio and Electroacoustics, 15(2):70‚Äì73, 1967. doi:10.1109/TAU.1967.1161901.

David S. Slepian. Prolate spheroidal wave functions, fourier analysis, and uncertainty-V: the discrete case. Bell System Technical Journal, 57(5):1371‚Äì1430, 1978. doi:10.1002/j.1538-7305.1978.tb02104.x.

Total running time of the script: (0 minutes 15.229 seconds)

Download Jupyter notebook: 10_spectrum_class.ipynb

Download Python source code: 10_spectrum_class.py

Download zipped: 10_spectrum_class.zip

Gallery generated by Sphinx-Gallery

Time-frequency analysis

Frequency and time-frequency sensor analysis

---

## Time-frequency analysis#

**URL:** https://mne.tools/stable/auto_tutorials/time-freq/index.html

**Contents:**
- Time-frequency analysis#

These tutorials cover frequency and time-frequency analysis of neural signals.

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency and time-frequency sensor analysis

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

Plotting whitened data

The Spectrum and EpochsSpectrum classes: frequency-domain data

---

## Transform EEG data using current source density (CSD)#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/eeg_csd.html

**Contents:**
- Transform EEG data using current source density (CSD)#
- References#

Go to the end to download the full example code.

This script shows an example of how to use CSD [1][2][3][4]. CSD takes the spatial Laplacian of the sensor signal (derivative in both x and y). It does what a planar gradiometer does in MEG. Computing these spatial derivatives reduces point spread. CSD transformed data have a sharper or more distinct topography, reducing the negative impact of volume conduction.

Load sample subject data

Plot the raw data and CSD-transformed raw data:

Also look at the power spectral densities:

CSD can also be computed on Evoked (averaged) data. Here we epoch and average the data so we can demonstrate that.

First let‚Äôs look at how CSD affects scalp topography:

CSD has parameters stiffness and lambda2 affecting smoothing and spline flexibility, respectively. Let‚Äôs see how they affect the solution:

F. Perrin, O. Bertrand, and J. Pernier. Scalp Current Density Mapping: Value and Estimation from Potential Data. IEEE Transactions on Biomedical Engineering, BME-34(4):283‚Äì288, 1987. doi:10.1109/TBME.1987.326089.

Fran√ßois M. Perrin, Jacques Pernier, Olivier M. Bertrand, and Jean Franƒáois Echallier. Spherical splines for scalp potential and current density mapping. Electroencephalography and Clinical Neurophysiology, 72(2):184‚Äì187, 1989. doi:10.1016/0013-4694(89)90180-6.

Mike X. Cohen. Analyzing Neural Time Series Data: Theory and Practice. MIT Press, 2014.

J√ºrgen Kayser and Craig E. Tenke. On the benefits of using surface Laplacian (Current Source Density) methodology in electrophysiology. International journal of psychophysiology : official journal of the International Organization of Psychophysiology, 97(3):171‚Äì173, 2015. doi:10.1016/j.ijpsycho.2015.06.001.

Total running time of the script: (0 minutes 17.942 seconds)

Download Jupyter notebook: eeg_csd.ipynb

Download Python source code: eeg_csd.py

Download zipped: eeg_csd.zip

Gallery generated by Sphinx-Gallery

Identify EEG Electrodes Bridged by too much Gel

Show EOG artifact timing

---

## Tutorials#

**URL:** https://mne.tools/stable/auto_tutorials/index.html

**Contents:**
- Tutorials#
- Introductory tutorials#
- Reading data for different recording systems#
- Working with continuous data#
- Preprocessing#
- Segmenting continuous data into epochs#
- Estimating evoked responses#
- Time-frequency analysis#
- Forward models and source spaces#
- Source localization and inverses#

These tutorials provide narrative explanations, sample code, and expected output for the most common MNE-Python analysis tasks. The emphasis here is on thorough explanations that get you up to speed quickly, at the expense of covering only a limited number of topics. The sections and tutorials are arranged in a fixed order, so in theory a new user should be able to progress through in order without encountering any cases where background knowledge is assumed and unexplained. More experienced users (i.e., those with significant experience analyzing EEG/MEG signals with different software) can probably skip around to just the topics they need without too much trouble.

If tutorial-scripts contain plots and are run locally, using the interactive flag with python -i tutorial_script.py keeps them open.

These tutorials cover the basic EEG/MEG pipeline for event-related analysis, introduce the mne.Info, events, and mne.Annotations data structures, discuss how sensor locations are handled, and introduce some of the configuration options available.

Overview of MEG/EEG analysis with MNE-Python

Modifying data in-place

Parsing events from raw data

The Info data structure

Working with sensor locations

Configuring MNE-Python

Getting started with mne.Report

These tutorials cover the basics of loading EEG/MEG data into MNE-Python for various recording devices.

Importing data from MEG devices

Importing data from EEG devices

Importing data from fNIRS devices

Working with CTF data: the Brainstorm auditory dataset

Importing Data from Eyetracking devices

These tutorials cover the basics of loading EEG/MEG data into MNE-Python, and how to query, manipulate, annotate, plot, and export continuous data in the Raw format.

The Raw data structure: continuous data

Annotating continuous data

Built-in plotting methods for Raw objects

These tutorials cover various preprocessing techniques for continuous data, as well as some diagnostic plotting methods.

Overview of artifact detection

Handling bad channels

Rejecting bad data spans and breaks

Background information on filtering

Filtering and resampling data

Repairing artifacts with regression

Repairing artifacts with ICA

Background on projectors and projections

Repairing artifacts with SSP

Setting the EEG reference

Extracting and visualizing subject head movement

Signal-space separation (SSS) and Maxwell filtering

Preprocessing functional near-infrared spectroscopy (fNIRS) data

Preprocessing optically pumped magnetometer (OPM) MEG data

Working with eye tracker data in MNE-Python

These tutorials cover epoched data, and how it differs from working with continuous data.

The Epochs data structure: discontinuous data

Regression-based baseline correction

Visualizing epoched data

Working with Epoch metadata

Auto-generating Epochs metadata

Exporting Epochs to Pandas DataFrames

Divide continuous data into equally-spaced epochs

These tutorials cover estimates of evoked responses (i.e., averages across several repetitions of an experimental condition).

The Evoked data structure: evoked/averaged data

Visualizing Evoked data

EEG analysis - Event-Related Potentials (ERPs)

Plotting whitened data

These tutorials cover frequency and time-frequency analysis of neural signals.

The Spectrum and EpochsSpectrum classes: frequency-domain data

Frequency and time-frequency sensor analysis

Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset

These tutorials cover how the cortical source locations (source spaces) and forward models (AKA leadfield matrices) are defined.

FreeSurfer MRI reconstruction

Source alignment and coordinate frames

Using an automated approach to coregistration

Head model and forward computation

EEG forward operator with a template MRI

How MNE uses FreeSurfer‚Äôs outputs

Fixing BEM and head surfaces

Computing a covariance matrix

These tutorials cover estimation of cortical activity from sensor recordings.

The SourceEstimate data structure

Source localization with equivalent current dipole (ECD) fit

Source localization with MNE, dSPM, sLORETA, and eLORETA

The role of dipole orientations in distributed source localization

Computing various MNE solutions

Source reconstruction using an LCMV beamformer

Visualize source time courses (stcs)

EEG source localization given electrode locations on an MRI

Brainstorm Elekta phantom dataset tutorial

Brainstorm CTF phantom dataset tutorial

4D Neuroimaging/BTi phantom dataset tutorial

KIT phantom dataset tutorial

These tutorials describe some approaches to statistical analysis of sensor-level data.

Statistical inference

Visualising statistical significance thresholds on EEG data

Non-parametric 1 sample cluster statistic on single trial power

Non-parametric between conditions cluster statistic on single trial power

Mass-univariate twoway repeated measures ANOVA on single trial power

Spatiotemporal permutation F-test on full sensor data

These tutorials cover within-subject statistical analysis of source estimates.

Permutation t-test on source data with spatio-temporal clustering

2 samples permutation test on source data with spatio-temporal clustering

Repeated measures ANOVA on source data with spatio-temporal clustering

These tutorials cover some of the machine learning methods available in MNE-Python.

Spectro-temporal receptive field (STRF) estimation on continuous data

These tutorials illustrate some clinical use cases.

The mne_gui_addons package supports some clinical use cases:

Locating intracranial electrode contacts

MNE-Python also supports some clinical use cases directly:

Working with sEEG data

Working with ECoG data

Sleep stage classification from polysomnography (PSG) data

These tutorials describe how to populate MNE-Python data structures with arbitrary data, using the array-based constructors and the simulation submodule.

Creating MNE-Python data structures from scratch

Corrupt known signal with point spread

DICS for power mapping

These tutorials cover the more advanced visualization options provided by MNE-Python, such as how to produce publication-quality figures or how to make plots more interactive.

Make figures more publication ready

Using the event system to link figures

Download all examples in Python source code: auto_tutorials_python.zip

Download all examples in Jupyter notebooks: auto_tutorials_jupyter.zip

Gallery generated by Sphinx-Gallery

Documentation overview

Introductory tutorials

---

## Using an automated approach to coregistration#

**URL:** https://mne.tools/stable/auto_tutorials/forward/25_automated_coreg.html

**Contents:**
- Using an automated approach to coregistration#
- Set up the coregistration model#
- Initial fit with fiducials#
- Refining with ICP#
- Omitting bad points#
- Final coregistration fit#
- References#

Go to the end to download the full example code.

This example shows how to use the coregistration functions to perform an automated MEG-MRI coregistration via scripting. Generally the results of this approach are consistent with those obtained from manual coregistration [1].

The quality of the coregistration depends heavily upon the quality of the head shape points (HSP) collected during subject prepration and the quality of your T1-weighted MRI. Use with caution and check the coregistration error.

Do first a coregistration fit using only 3 fiducial points. This allows to find a good initial solution before further optimization using head shape points. This can also be useful to detect outlier head shape points which are too far from the skin surface. One can see for example that on this dataset there is one such point and we will omit it from the subsequent fit.

Next we refine the transformation using a few iteration of the Iterative Closest Point (ICP) algorithm. As the initial fiducials are obtained from fsaverage and not from precise manual picking in the GUI we do a fit with reduced weight for the nasion.

It is now very clear that we have one point that is an outlier and that should be removed.

Don‚Äôt forget to save the resulting trans matrix!

The mne.coreg.Coregistration class has the ability to compute MRI scale factors using set_scale_mode() that is useful for creating surrogate MRI subjects, i.e., using a template MRI (such as one from mne.datasets.fetch_infant_template()) matched to a subject‚Äôs head digitization. When scaling is desired, a scaled surrogate MRI should be created using mne.scale_mri().

Jon M. Houck and Eric D. Claus. A comparison of automated and manual co-registration for magnetoencephalography. PLOS ONE, 15:e0232100, 2020. doi:10.1371/journal.pone.0232100.

Total running time of the script: (0 minutes 49.530 seconds)

Download Jupyter notebook: 25_automated_coreg.ipynb

Download Python source code: 25_automated_coreg.py

Download zipped: 25_automated_coreg.zip

Gallery generated by Sphinx-Gallery

Source alignment and coordinate frames

Head model and forward computation

---

## Using contralateral referencing for EEG#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/contralateral_referencing.html

**Contents:**
- Using contralateral referencing for EEG#

Go to the end to download the full example code.

Instead of using a single reference electrode for all channels, some researchers reference the EEG electrodes in each hemisphere to an electrode in the contralateral hemisphere (often an electrode over the mastoid bone; this is common in sleep research for example). Here we demonstrate how to set a contralateral EEG reference.

The electrodes TP9 and TP10 are near the mastoids so we‚Äôll use them as our contralateral reference channels. Then we‚Äôll create our hemisphere groups.

Finally we do the referencing. For the midline channels we‚Äôll reference them to the mean of the two mastoid channels; the left and right hemispheres we‚Äôll reference to the single contralateral mastoid channel.

Make sure the channel locations still look right:

Total running time of the script: (0 minutes 1.002 seconds)

Download Jupyter notebook: contralateral_referencing.ipynb

Download Python source code: contralateral_referencing.py

Download zipped: contralateral_referencing.zip

Gallery generated by Sphinx-Gallery

Cortical Signal Suppression (CSS) for removal of cortical signals

---

## Using the event system to link figures#

**URL:** https://mne.tools/stable/auto_tutorials/visualization/20_ui_events.html

**Contents:**
- Using the event system to link figures#
- Linking interactive plots#
- Overlaying one figure over another#
- Hooking a custom plot into the event system#

Go to the end to download the full example code.

Many of MNE-Python‚Äôs figures are interactive. For example, you can select channels or scroll through time. The event system allows you to link figures together so that interacting with one figure will simultaneously update another figure.

In this example, we‚Äôll be looking at linking a topomap plot with a source estimate plot, such that selecting the time in one will also update the time in the other, as well as hooking our own custom plot into MNE-Python‚Äôs event system.

Since the figures on our website don‚Äôt have any interaction capabilities, this example will only work properly when run in an interactive environment.

We load sensor-level and source-level data for the MNE-Sample dataset and create two plots that have sliders controlling the time-point that is shown. By default, both figures are independent, but we will link the event channels of the figures together, so that moving the slider in one figure will also move the slider in the other.

A common scenario in which the UI event system comes in handy is when plotting multiple things in the same figure. For example, if we want to draw the magnetic fieldlines on top of a source estimate, we can link the UI event channels together, so that when a different time is selected, both the source estimate and the fieldlines are updated together.

In MNE-Python, each figure has an associated event channel. Drawing routines can publish events on the channel and receive events by subscribe-ing to the channel. When subscribing to an event on a channel, you specify a callback function to be called whenever a drawing routine publishes that event on the event channel.

The events are modeled after matplotlib‚Äôs event system. Each event has a string name (the snake-case version of its class name) and a list of relevant values. For example, the ‚Äútime_change‚Äù event should have the new time as a value. Values can be any python object. When publishing an event, the publisher creates a new instance of the event‚Äôs class. When subscribing to an event, having to dig up and import the correct class is a bit of a hassle. Following matplotlib‚Äôs example, subscribers use the string name of the event to refer to it.

Below, we create a custom plot and then make it publish and subscribe to TimeChange events so it can work together with the plots we created earlier.

Total running time of the script: (0 minutes 12.601 seconds)

Download Jupyter notebook: 20_ui_events.ipynb

Download Python source code: 20_ui_events.py

Download zipped: 20_ui_events.zip

Gallery generated by Sphinx-Gallery

Make figures more publication ready

---

## Visualise NIRS artifact correction methods#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/fnirs_artifact_removal.html

**Contents:**
- Visualise NIRS artifact correction methods#
- Import data#
- Add artificial artifacts to data#
- Apply temporal derivative distribution repair#
- References#

Go to the end to download the full example code.

Here we artificially introduce several fNIRS artifacts and observe how artifact correction techniques attempt to correct the data.

Here we will work with the fNIRS motor data. We resample the data to make indexing exact times more convenient. We then convert the data to optical density to perform corrections on and plot these signals.

We can see some small artifacts in the above data from movement around 40, 190 and 240 seconds. However, this data is relatively clean so we will add some additional artifacts below.

Two common types of artifacts in NIRS data are spikes and baseline shifts. Spikes often occur when a person moves and the optode moves relative to the scalp and then returns to its original position. Baseline shifts occur if the optode moves relative to the scalp and does not return to its original position. We add a spike type artifact at 100 seconds and a baseline shift at 200 seconds to the data.

This approach corrects baseline shift and spike artifacts without the need for any user-supplied parameters [1].

We can see in the data above that the introduced spikes and shifts are largely removed, but some residual smaller artifact remains. The same can be said for the artifacts in the original data.

Frank A Fishburn, Ruth S Ludlum, Chandan J Vaidya, and Andrei V Medvedev. Temporal derivative distribution repair (tddr): a motion correction method for fNIRS. NeuroImage, 184:171‚Äì179, 2019. doi:10.1016/j.neuroimage.2018.09.025.

Total running time of the script: (0 minutes 6.256 seconds)

Download Jupyter notebook: fnirs_artifact_removal.ipynb

Download Python source code: fnirs_artifact_removal.py

Download zipped: fnirs_artifact_removal.zip

Gallery generated by Sphinx-Gallery

Find MEG reference channel artifacts

Compare the different ICA algorithms in MNE

---

## Visualising statistical significance thresholds on EEG data#

**URL:** https://mne.tools/stable/auto_tutorials/stats-sensor-space/20_erp_stats.html

**Contents:**
- Visualising statistical significance thresholds on EEG data#
- References#

Go to the end to download the full example code.

MNE-Python provides a range of tools for statistical hypothesis testing and the visualisation of the results. Here, we show a few options for exploratory and confirmatory tests - e.g., targeted t-tests, cluster-based permutation approaches (here with Threshold-Free Cluster Enhancement); and how to visualise the results.

The underlying data comes from [1]; we contrast long vs. short words. TFCE is described in [2].

If we have a specific point in space and time we wish to test, it can be convenient to convert the data into Pandas Dataframe format. In this case, the mne.Epochs object has a convenient mne.Epochs.to_data_frame() method, which returns a dataframe. This dataframe can then be queried for specific time windows and sensors. The extracted data can be submitted to standard statistical tests. Here, we conduct t-tests on the difference between long and short words.

Absent specific hypotheses, we can also conduct an exploratory mass-univariate analysis at all sensors and time points. This requires correcting for multiple tests. MNE offers various methods for this; amongst them, cluster-based permutation methods allow deriving power from the spatio-temoral correlation structure of the data. Here, we use TFCE.

The results of these mass univariate analyses can be visualised by plotting mne.Evoked objects as images (via mne.Evoked.plot_image) and masking points for significance. Here, we group channels by Regions of Interest to facilitate localising effects on the head.

St√©phane Dufau, Jonathan Grainger, Katherine J. Midgley, and Phillip J. Holcomb. A thousand words are worth a picture: snapshots of printed-word processing in an event-related potential megastudy. Psychological Science, 26(12):1887‚Äì1897, 2015. doi:10.1177/0956797615603934.

Stephen M. Smith and Thomas E. Nichols. Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference. NeuroImage, 44(1):83‚Äì98, 2009. doi:10.1016/j.neuroimage.2008.03.061.

Total running time of the script: (0 minutes 9.651 seconds)

Download Jupyter notebook: 20_erp_stats.ipynb

Download Python source code: 20_erp_stats.py

Download zipped: 20_erp_stats.zip

Gallery generated by Sphinx-Gallery

Statistical inference

Non-parametric 1 sample cluster statistic on single trial power

---

## Visualization#

**URL:** https://mne.tools/stable/auto_examples/visualization/index.html

**Contents:**
- Visualization#

Looking at data and processing output.

How to convert 3D electrode positions to a 2D image

Plotting with mne.viz.Brain

Visualize channel over epochs as an image

Plotting EEG sensors on the scalp

Plotting topographic arrowmaps of evoked data

Plotting topographic maps of evoked data

Whitening evoked data with a noise covariance

Plotting eye-tracking heatmaps in MNE-Python

Plotting sensor layouts of MEG systems

Plot the MNE brain and helmet

Plotting sensor layouts of EEG systems

Plot a cortical parcellation

Plot single trial activity, grouped by ROI and sorted by RT

Sensitivity map of SSP projections

Compare evoked responses for different conditions

Plot custom topographies for MEG sensors

Cross-hemisphere comparison

How to convert 3D electrode positions to a 2D image

---

## Visualization tutorials#

**URL:** https://mne.tools/stable/auto_tutorials/visualization/index.html

**Contents:**
- Visualization tutorials#

These tutorials cover the more advanced visualization options provided by MNE-Python, such as how to produce publication-quality figures or how to make plots more interactive.

Make figures more publication ready

Using the event system to link figures

DICS for power mapping

Make figures more publication ready

---

## Visualize channel over epochs as an image#

**URL:** https://mne.tools/stable/auto_examples/visualization/channel_epochs_image.html

**Contents:**
- Visualize channel over epochs as an image#
- References#

Go to the end to download the full example code.

This will produce what is sometimes called an event related potential / field (ERP/ERF) image.

Two images are produced, one with a good channel and one with a channel that does not show any evoked field.

It is also demonstrated how to reorder the epochs using a 1D spectral embedding as described in [1].

Show event-related fields images

Alexandre Gramfort, Renaud Keriven, and Maureen Clerc. Graph-based variability estimation in single-trial event-related neural responses. IEEE Transactions on Biomedical Engineering, 57(5):1051‚Äì1061, 2010. doi:10.1109/tbme.2009.2037139.

Total running time of the script: (0 minutes 2.896 seconds)

Download Jupyter notebook: channel_epochs_image.ipynb

Download Python source code: channel_epochs_image.py

Download zipped: channel_epochs_image.zip

Gallery generated by Sphinx-Gallery

Plotting with mne.viz.Brain

Plotting EEG sensors on the scalp

---

## Visualize source time courses (stcs)#

**URL:** https://mne.tools/stable/auto_tutorials/inverse/60_visualize_stc.html

**Contents:**
- Visualize source time courses (stcs)#
- Surface Source Estimates#
- Volume Source Estimates#
- Vector Source Estimates#
- Dipole fits#

Go to the end to download the full example code.

This tutorial focuses on visualization of source estimates.

First, we get the paths for the evoked data and the source time courses (stcs).

Then, we read the stc from file.

This is a SourceEstimate object.

The SourceEstimate object is in fact a surface source estimate. MNE also supports volume-based source estimates but more on that later.

We can plot the source estimate using the stc.plot just as in other MNE objects. Note that for this visualization to work, you must have PyVista installed on your machine.

You can also morph it to fsaverage and visualize it using a flatmap.

Note that here we used initial_time=0.1, but we can also browse through time using time_viewer=True.

In case PyVista is not available, we also offer a matplotlib backend. Here we use verbose=‚Äôerror‚Äô to ignore a warning that not all vertices were used in plotting.

We can also visualize volume source estimates (used for deep structures).

Let us load the sensor-level evoked data. We select the MEG channels to keep things simple.

Then, we can load the precomputed inverse operator from a file.

The source estimate is computed using the inverse operator and the sensor-space data.

This time, we have a different container (VolSourceEstimate) for the source time course.

This too comes with a convenient plot method.

For this visualization, nilearn must be installed. This visualization is interactive. Click on any of the anatomical slices to explore the time series. Clicking on any time point will bring up the corresponding anatomical map.

We could visualize the source estimate on a glass brain. Unlike the previous visualization, a glass brain does not show us one slice but what we would see if the brain was transparent like glass, and maximum intensity projection) is used:

You can also extract label time courses using volumetric atlases. Here we‚Äôll use the built-in aparc+aseg.mgz:

We can plot several labels with the most activation in their time course for a more fine-grained view of the anatomical loci of activation.

And we can project these label time courses back to their original locations and see how the plot has been smoothed:

If we choose to use pick_ori='vector' in apply_inverse

For computing a dipole fit, we need to load the noise covariance, the BEM solution, and the coregistration transformation files. Note that for the other methods, these were already used to generate the inverse operator.

Dipoles are fit independently for each time point, so let us crop our time series to visualize the dipole fit for the time point of interest.

Finally, we can visualize the dipole.

Total running time of the script: (1 minutes 15.146 seconds)

Download Jupyter notebook: 60_visualize_stc.ipynb

Download Python source code: 60_visualize_stc.py

Download zipped: 60_visualize_stc.zip

Gallery generated by Sphinx-Gallery

Source reconstruction using an LCMV beamformer

EEG source localization given electrode locations on an MRI

---

## Visualizing epoched data#

**URL:** https://mne.tools/stable/auto_tutorials/epochs/20_visualize_epochs.html

**Contents:**
- Visualizing epoched data#
- Plotting Epochs as time series#
- Plotting projectors from an Epochs object#
- Plotting sensor locations#
- Plotting the power spectrum of Epochs#
- Plotting Epochs as an image map#

Go to the end to download the full example code.

This tutorial shows how to plot epoched data as time series, how to plot the spectral density of epoched data, how to plot epochs as an imagemap, and how to plot the sensor locations and projectors stored in Epochs objects.

We‚Äôll start by importing the modules we need, loading the continuous (raw) sample data, and cropping it to save memory:

To create the Epochs data structure, we‚Äôll extract the event IDs stored in the stim channel, map those integer event IDs to more descriptive condition labels using an event dictionary, and pass those to the Epochs constructor, along with the Raw data and the desired temporal limits of our epochs, tmin and tmax (for a detailed explanation of these steps, see The Epochs data structure: discontinuous data).

Interactivity in pipelines and scripts

To use the interactive features of the plot method when running your code non-interactively, pass the block=True parameter, which halts the Python interpreter until the figure window is closed. That way, any channels or epochs that you mark as ‚Äúbad‚Äù will be taken into account in subsequent processing steps.

To visualize epoched data as time series (one time series per channel), the mne.Epochs.plot method is available. It creates an interactive window where you can scroll through epochs and channels, enable/disable any unapplied SSP projectors to see how they affect the signal, and even manually mark bad channels (by clicking the channel name) or bad epochs (by clicking the data) for later dropping. Channels marked ‚Äúbad‚Äù will be shown in light grey color and will be added to epochs.info['bads']; epochs marked as bad will be indicated as 'USER' in epochs.drop_log.

Here we‚Äôll plot only the ‚Äúcatch‚Äù trials from the sample dataset, and pass in our events array so that the button press responses also get marked (we‚Äôll plot them in red, and plot the ‚Äúface‚Äù events defining time zero for each epoch in blue). We also need to pass in our event_dict so that the plot method will know what we mean by ‚Äúbutton‚Äù ‚Äî this is because subsetting the conditions by calling epochs['face'] automatically purges the dropped entries from epochs.event_id:

To see all sensors at once, we can use butterfly mode and group by selection:

In the plot above we can see heartbeat artifacts in the magnetometer channels, so before we continue let‚Äôs load ECG projectors from disk and apply them to the data:

Just as we saw in the Plotting projectors from Raw objects section, we can plot the projectors present in an Epochs object using the same plot_projs_topomap method. Since the original three empty-room magnetometer projectors were inherited from the Raw file, and we added two ECG projectors for each sensor type, we should see nine projector topomaps:

Note that these field maps illustrate aspects of the signal that have already been removed (because projectors in Raw data are applied by default when epoching, and because we called apply_proj after adding additional ECG projectors from file). You can check this by examining the 'active' field of the projectors:

Just like Raw objects, Epochs objects keep track of sensor locations, which can be visualized with the plot_sensors method:

Again, just like Raw objects, Epochs objects can be converted to spectral density via compute_psd(), which can then be plotted using the EpochsSpectrum‚Äôs plot() method.

It is also possible to plot spectral power estimates across sensors as a scalp topography, using the EpochsSpectrum‚Äôs plot_topomap() method. The default parameters will plot five frequency bands (Œ¥, Œ∏, Œ±, Œ≤, Œ≥), will compute power based on magnetometer channels (if present), and will plot the power estimates on a dB-like log-scale:

Prior to the addition of the EpochsSpectrum class, the above plots were possible via:

The plot_psd() and plot_psd_topomap methods of Epochs objects are still provided to support legacy analysis scripts, but new code should instead use the EpochsSpectrum object API.

Just like plot_projs_topomap, EpochsSpectrum.plot_topomap() has a vlim='joint' option for fixing the colorbar limits jointly across all subplots, to give a better sense of the relative magnitude in each frequency band. You can change which channel type is used via the ch_type parameter, and if you want to view different frequency bands than the defaults, the bands parameter takes a dict, with keys providing a subplot title and values providing either single frequency bins to plot, or lower/upper frequency band edges:

If you prefer untransformed power estimates, you can pass dB=False. It is also possible to normalize the power estimates by dividing by the total power across all frequencies, by passing normalize=True. See the docstring of plot_topomap for details.

A convenient way to visualize many epochs simultaneously is to plot them as an image map, with each row of pixels in the image representing a single epoch, the horizontal axis representing time, and each pixel‚Äôs color representing the signal value at that time sample for that epoch. Of course, this requires either a separate image map for each channel, or some way of combining information across channels. The latter is possible using the plot_image method; the former can be achieved with the plot_image method (one channel at a time) or with the plot_topo_image method (all sensors at once).

By default, the image map generated by plot_image will be accompanied by a scalebar indicating the range of the colormap, and a time series showing the average signal across epochs and a bootstrapped 95% confidence band around the mean. plot_image is a highly customizable method with many parameters, including customization of the auxiliary colorbar and averaged time series subplots. See the docstrings of plot_image and mne.viz.plot_compare_evokeds (which is used to plot the average time series) for full details. Here we‚Äôll show the mean across magnetometers for all epochs with an auditory stimulus:

To plot image maps for individual sensors or a small group of sensors, use the picks parameter. Passing combine=None (the default) will yield separate plots for each sensor in picks; passing combine='gfp' will plot the global field power (useful for combining sensors that respond with opposite polarity).

To plot an image map for all sensors, use plot_topo_image, which is optimized for plotting a large number of image maps simultaneously, and (in interactive sessions) allows you to click on each small image map to pop open a separate figure with the full-sized image plot (as if you had called plot_image on just that sensor). At the small scale shown in this tutorial it‚Äôs hard to see much useful detail in these plots; it‚Äôs often best when plotting interactively to maximize the topo image plots to fullscreen. The default is a figure with black background, so here we specify a white background and black foreground text. By default plot_topo_image will show magnetometers and gradiometers on the same plot (and hence not show a colorbar, since the sensors are on different scales) so we‚Äôll also pass a Layout restricting each plot to one channel type. First, however, we‚Äôll also drop any epochs that have unusually high signal levels, because they can cause the colormap limits to be too extreme and therefore mask smaller signal fluctuations of interest.

To plot image maps for all EEG sensors, pass an EEG layout as the layout parameter of plot_topo_image. Note also here the use of the sigma parameter, which smooths each image map along the vertical dimension (across epochs) which can make it easier to see patterns across the small image maps (by smearing noisy epochs onto their neighbors, while reinforcing parts of the image where adjacent epochs are similar). However, sigma can also disguise epochs that have persistent extreme values and maybe should have been excluded, so it should be used with caution.

Total running time of the script: (0 minutes 30.417 seconds)

Download Jupyter notebook: 20_visualize_epochs.ipynb

Download Python source code: 20_visualize_epochs.py

Download zipped: 20_visualize_epochs.zip

Gallery generated by Sphinx-Gallery

Regression-based baseline correction

Working with Epoch metadata

---

## Visualizing Evoked data#

**URL:** https://mne.tools/stable/auto_tutorials/evoked/20_visualize_evoked.html

**Contents:**
- Visualizing Evoked data#
- Plotting signal traces#
- Plotting scalp topographies#
- Arrow maps#
- Joint plots#
- Comparing Evoked objects#
- Image plots#
- Topographical subplots#
- 3D Field Maps#

Go to the end to download the full example code.

This tutorial shows the different visualization methods for Evoked objects.

As usual we‚Äôll start by importing the modules we need:

Instead of creating the Evoked object from an Epochs object, we‚Äôll load an existing Evoked object from disk. Remember, the .fif format can store multiple Evoked objects, so we‚Äôll end up with a list of Evoked objects after loading. Recall also from the Loading and saving Evoked data section of the introductory Evoked tutorial that the sample Evoked objects have not been baseline-corrected and have unapplied projectors, so we‚Äôll take care of that when loading:

To make our life easier, let‚Äôs convert that list of Evoked objects into a dictionary. We‚Äôll use /-separated dictionary keys to encode the conditions (like is often done when epoching) because some of the plotting methods can take advantage of that style of coding.

Plots of superimposed sensor timeseries are called ‚Äúbutterfly plots‚Äù because the positive- and negative-going traces can resemble butterfly wings.

The most basic plot of Evoked objects is a butterfly plot of each channel type, generated by the evoked.plot() method. By default, channels marked as ‚Äúbad‚Äù are suppressed, but you can control this by passing an empty list to the exclude parameter (default is exclude='bads'):

Notice the completely flat EEG channel and the noisy gradiometer channel plotted in red color. Like many MNE-Python plotting functions, evoked.plot() has a picks parameter that can select channels to plot by name, index, or type. In the next plot, we‚Äôll show only magnetometer channels and also color-code the channel traces by their location by passing spatial_colors=True. Finally, we‚Äôll superimpose a trace of the root mean square (RMS) of the signal across channels by passing gfp=True. This parameter is called gfp for historical reasons and behaves correctly for all supported channel types: for MEG data, it will plot the RMS; while for EEG, it would plot the global field power (an average-referenced RMS), hence its name:

Interesting time periods can be highlighted via the highlight parameter.

In an interactive session, the butterfly plots seen above can be click-dragged to select a time region, which will pop up a map of the average field distribution over the scalp for the selected time span. You can also generate scalp topographies at specific times or time spans using the plot_topomap() method:

It is also possible to pass different time durations to average over for each time point. Passing a value of None will disable averaging for that time point:

Additional examples of plotting scalp topographies can be found in Plotting topographic maps of evoked data.

Scalp topographies at a given time point can be augmented with arrows to show the estimated magnitude and direction of the magnetic field, using the function mne.viz.plot_arrowmap():

Joint plots combine butterfly plots with scalp topographies, and provide an excellent first-look at evoked data; by default, topographies will be automatically placed based on peak finding. Here we plot the right-visual-field condition; if no picks are specified we get a separate figure for each channel type:

Like plot_topomap(), you can specify the times at which you want the scalp topographies calculated, and you can customize the plot in various other ways as well. See mne.Evoked.plot_joint() for details.

To compare Evoked objects from different experimental conditions, the function mne.viz.plot_compare_evokeds() can take a list or dict of Evoked objects and plot them all on the same axes. Like most MNE-Python visualization functions, it has a picks parameter for selecting channels, but by default will generate one figure for each channel type, and combine information across channels of the same type by calculating the global field power. Information may be combined across channels in other ways too; support for combining via mean, median, or standard deviation are built-in, and custom callable functions may also be used, as shown here:

One nice feature of plot_compare_evokeds() is that when passing evokeds in a dictionary, it allows specifying plot styles based on /-separated substrings of the dictionary keys (similar to epoch selection; see Subselecting epochs). Here, we specify colors for ‚Äúaud‚Äù and ‚Äúvis‚Äù conditions, and linestyles for ‚Äúleft‚Äù and ‚Äúright‚Äù conditions, and the traces and legend are styled accordingly. Here we also show the time_unit='ms' parameter in action.

The legends generated by plot_compare_evokeds() above used the dictionary keys provided by the evks variable. If instead you pass a list or tuple of Evoked objects, the legend keys will be generated automatically from the comment attribute of the Evoked objects (or, as sequential integers if the comment attribute is empty or ambiguous). To illustrate this, we‚Äôll make a list of five Evoked objects: two with identical comments, two with empty comments (either an empty string or None), and one with a unique non-empty comment:

Like Epochs, Evoked objects also have a plot_image() method, but unlike epochs.plot_image(), evoked.plot_image() shows one channel per row instead of one epoch per row. Again, a picks parameter is available, as well as several other customization options; see plot_image() for details.

For sensor-level analyses, it can be useful to plot the response at each sensor in a topographical layout. The plot_compare_evokeds() function can do this if you pass axes='topo', but it can be quite slow if the number of sensors is too large, so here we‚Äôll plot only the EEG channels:

For a larger number of sensors, the method evoked.plot_topo() and the function mne.viz.plot_evoked_topo() can both be used. The plot_topo() method will plot only a single condition, while the plot_evoked_topo() function can plot one or more conditions on the same axes, if passed a list of Evoked objects. The legend entries will be automatically drawn from the Evoked objects‚Äô comment attribute:

By default, plot_evoked_topo() will plot all MEG sensors (if present), so to get EEG sensors you would need to modify the evoked objects first (e.g., using mne.pick_types).

In interactive sessions, both approaches to topographical plotting allow you to click one of the sensor subplots to open a larger version of the evoked plot at that sensor.

The scalp topographies above were all projected into two-dimensional overhead views of the field, but it is also possible to plot field maps in 3D. This requires a trans file to transform locations between the coordinate systems of the MEG device and the head surface (based on the MRI). You can compute 3D field maps without a trans file, but it will only work for calculating the field on the MEG helmet from the MEG sensors.

By default, MEG sensors will be used to estimate the field on the helmet surface, while EEG sensors will be used to estimate the field on the scalp. Once the maps are computed, you can plot them with evoked.plot_field():

You can also use MEG sensors to estimate the scalp field by passing meg_surf='head'. By selecting each sensor type in turn, you can compare the scalp field estimates from each.

Total running time of the script: (0 minutes 31.720 seconds)

Download Jupyter notebook: 20_visualize_evoked.ipynb

Download Python source code: 20_visualize_evoked.py

Download zipped: 20_visualize_evoked.zip

Gallery generated by Sphinx-Gallery

The Evoked data structure: evoked/averaged data

EEG analysis - Event-Related Potentials (ERPs)

---

## Whitening evoked data with a noise covariance#

**URL:** https://mne.tools/stable/auto_examples/visualization/evoked_whitening.html

**Contents:**
- Whitening evoked data with a noise covariance#
- References#

Go to the end to download the full example code.

Evoked data are loaded and then whitened using a given noise covariance matrix. It‚Äôs an excellent quality check to see if baseline signals match the assumption of Gaussian white noise during the baseline period.

Covariance estimation and diagnostic plots are based on [1].

Denis A. Engemann and Alexandre Gramfort. Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals. NeuroImage, 108:328‚Äì342, 2015. doi:10.1016/j.neuroimage.2014.12.040.

Compute covariance using automated regularization

Show the evoked data:

We can then show whitening for our various noise covariance estimates.

Here we should look to see if baseline signals match the assumption of Gaussian white noise. we expect values centered at 0 within 2 standard deviations for 95% of the time points.

For the Global field power we expect a value of 1.

Total running time of the script: (0 minutes 16.536 seconds)

Download Jupyter notebook: evoked_whitening.ipynb

Download Python source code: evoked_whitening.py

Download zipped: evoked_whitening.zip

Gallery generated by Sphinx-Gallery

Plotting topographic maps of evoked data

Plotting eye-tracking heatmaps in MNE-Python

---

## Working with continuous data#

**URL:** https://mne.tools/stable/auto_tutorials/raw/index.html

**Contents:**
- Working with continuous data#

These tutorials cover the basics of loading EEG/MEG data into MNE-Python, and how to query, manipulate, annotate, plot, and export continuous data in the Raw format.

The Raw data structure: continuous data

Annotating continuous data

Built-in plotting methods for Raw objects

Importing Data from Eyetracking devices

The Raw data structure: continuous data

---

## Working with CTF data: the Brainstorm auditory dataset#

**URL:** https://mne.tools/stable/auto_tutorials/io/60_ctf_bst_auditory.html

**Contents:**
- Working with CTF data: the Brainstorm auditory dataset#
- References#

Go to the end to download the full example code.

Here we compute the evoked from raw for the auditory Brainstorm tutorial dataset. For comparison, see [1] and the associated brainstorm site.

One subject, 2 acquisition runs 6 minutes each.

Each run contains 200 regular beeps and 40 easy deviant beeps.

Random ISI: between 0.7s and 1.7s seconds, uniformly distributed.

Button pressed when detecting a deviant with the right index finger.

To reduce memory consumption and running time, some of the steps are precomputed. To run everything from scratch change use_precomputed to False. With use_precomputed = False running time of this script can be several minutes even on a fast computer.

The data was collected with a CTF 275 system at 2400 Hz and low-pass filtered at 600 Hz. Here the data and empty room data files are read to construct instances of mne.io.Raw.

In the memory saving mode we use preload=False and use the memory efficient IO which loads the data on demand. However, filtering and some other functions require the data to be preloaded into memory.

The data array consists of 274 MEG axial gradiometers, 26 MEG reference sensors and 2 EEG electrodes (Cz and Pz). In addition:

1 stim channel for marking presentation times for the stimuli

1 audio channel for the sent signal

1 response channel for recording the button presses

2 EOG bipolar (vertical and horizontal)

12 head tracking channels

Notice also that the digitized electrode positions (stored in a .pos file) were automatically loaded and added to the Raw object.

The head tracking channels and the unused channels are marked as misc channels. Here we define the EOG and ECG channels.

For noise reduction, a set of bad segments have been identified and stored in csv files. The bad segments are later used to reject epochs that overlap with them. The file for the second run also contains some saccades. The saccades are removed by using SSP. We use pandas to read the data from the csv files. You can also view the files with your favorite text editor.

Here we compute the saccade and EOG projectors for magnetometers and add them to the raw data. The projectors are added to both runs.

Visually inspect the effects of projections. Click on ‚Äòproj‚Äô button at the bottom right corner to toggle the projectors on/off. EOG events can be plotted by adding the event list as a keyword argument. As the bad segments and saccades were added as annotations to the raw data, they are plotted as well.

Typical preprocessing step is the removal of power line artifact (50 Hz or 60 Hz). Here we notch filter the data at 60, 120 and 180 to remove the original 60 Hz artifact and the harmonics. The power spectra are plotted before and after the filtering to show the effect. The drop after 600 Hz appears because the data was filtered during the acquisition. In memory saving mode we do the filtering at evoked stage, which is not something you usually would do.

We also lowpass filter the data at 100 Hz to remove the hf components.

Epoching and averaging. First some parameters are defined and events extracted from the stimulus channel (UPPT001). The rejection thresholds are defined as peak-to-peak values and are in T / m for gradiometers, T for magnetometers and V for EOG and EEG channels.

The event timing is adjusted by comparing the trigger times on detected sound onsets on channel UADC001-4408.

We mark a set of bad channels that seem noisier than others. This can also be done interactively with raw.plot by clicking the channel name (or the line). The marked channels are added as bad when the browser window is closed.

The epochs (trials) are created for MEG channels. First we find the picks for MEG and EOG channels. Then the epochs are constructed using these picks. The epochs overlapping with annotated bad segments are also rejected by default. To turn off rejection by bad segments (as was done earlier with saccades) you can use keyword reject_by_annotation=False.

We only use first 40 good epochs from each run. Since we first drop the bad epochs, the indices of the epochs are no longer same as in the original epochs collection. Investigation of the event timings reveals that first epoch from the second run corresponds to index 182.

The averages for each conditions are computed.

Typical preprocessing step is the removal of power line artifact (50 Hz or 60 Hz). Here we lowpass filter the data at 40 Hz, which will remove all line artifacts (and high frequency information). Normally this would be done to raw data (with mne.io.Raw.filter()), but to reduce memory consumption of this tutorial, we do it at evoked stage. (At the raw stage, you could alternatively notch filter with mne.io.Raw.notch_filter().)

Here we plot the ERF of standard and deviant conditions. In both conditions we can see the P50 and N100 responses. The mismatch negativity is visible only in the deviant condition around 100-200 ms. P200 is also visible around 170 ms in both conditions but much stronger in the standard condition. P300 is visible in deviant condition only (decision making in preparation of the button press). You can view the topographies from a certain time span by painting an area with clicking and holding the left mouse button.

Show activations as topography figures.

We can see the MMN effect more clearly by looking at the difference between the two conditions. P50 and N100 are no longer visible, but MMN/P200 and P300 are emphasised.

Source estimation. We compute the noise covariance matrix from the empty room measurement and use it for the other runs.

The transformation is read from a file:

To save time and memory, the forward solution is read from a file. Set use_precomputed=False in the beginning of this script to build the forward solution from scratch. The head surfaces for constructing a BEM solution are read from a file. Since the data only contains MEG channels, we only need the inner skull surface for making the forward solution. For more information: Cortical surface reconstruction with FreeSurfer, mne.setup_source_space(), The Boundary Element Model (BEM), mne.bem.make_watershed_bem().

The sources are computed using dSPM method and plotted on an inflated brain surface. For interactive controls over the image, use keyword time_viewer=True. Standard condition.

Fran√ßois Tadel, Sylvain Baillet, John C. Mosher, Dimitrios Pantazis, and Richard M. Leahy. Brainstorm: a user-friendly application for MEG/EEG analysis. Computational Intelligence and Neuroscience, 2011:1‚Äì13, 2011. doi:10.1155/2011/879716.

Total running time of the script: (0 minutes 43.910 seconds)

Download Jupyter notebook: 60_ctf_bst_auditory.ipynb

Download Python source code: 60_ctf_bst_auditory.py

Download zipped: 60_ctf_bst_auditory.zip

Gallery generated by Sphinx-Gallery

Importing data from fNIRS devices

Importing Data from Eyetracking devices

---

## Working with ECoG data#

**URL:** https://mne.tools/stable/auto_tutorials/clinical/30_ecog.html

**Contents:**
- Working with ECoG data#
- Load in data and perform basic preprocessing#
- Explore the electrodes on a template brain#
- Compute frequency features of the data#
- Plot Gamma Power on cortical sensors#
- Visualize the time-evolution of the gamma power on the brain#

Go to the end to download the full example code.

MNE supports working with more than just MEG and EEG data. Here we show some of the functions that can be used to facilitate working with electrocorticography (ECoG) data.

This example shows how to use:

ECoG data (available here) from an epilepsy patient during a seizure

channel locations in FreeSurfer‚Äôs fsaverage MRI space

projection onto a pial surface

For a complementary example that involves sEEG data, channel locations in MNI space, or projection into a volume, see Working with sEEG data.

Please note that this tutorial requires 3D plotting dependencies (see Install via pip or conda) as well as mne-bids which can be installed using pip.

Let‚Äôs load some ECoG electrode data with MNE-BIDS.

Downsampling is just to save execution time in this example, you should not need to do this in general!

Our electrodes are shown after being morphed to fsaverage brain so we‚Äôll use this fsaverage brain to plot the locations of our electrodes. We‚Äôll use snapshot_brain_montage() to save the plot as image data (along with xy positions of each electrode in the image), so that later we can plot frequency band power on top of it.

Next, we‚Äôll compute the signal power in the gamma (30-90 Hz) band, downsampling the result to 10 Hz (to save time).

We will now use evoked gamma power to plot on the cortical surface. Therefore we extract the evoked time sample at 15s and normalize it in a range of 0 to 1 in order to map it using a matplotlib colormap.

Say we want to visualize the evolution of the power in the gamma band, instead of just plotting the average. We can use matplotlib.animation.FuncAnimation to create an animation and apply this to the brain figure.

We can project gamma power from the sensor data to the nearest locations on the pial surface and visualize that:

As shown in the plot, the epileptiform activity starts in the temporal lobe, progressing posteriorly. The seizure becomes generalized eventually, after this example short time section. This dataset is available using mne.datasets.epilepsy_ecog.data_path() for you to examine.

Total running time of the script: (0 minutes 9.595 seconds)

Download Jupyter notebook: 30_ecog.ipynb

Download Python source code: 30_ecog.py

Download zipped: 30_ecog.zip

Gallery generated by Sphinx-Gallery

Working with sEEG data

Sleep stage classification from polysomnography (PSG) data

---

## Working with Epoch metadata#

**URL:** https://mne.tools/stable/auto_tutorials/epochs/30_epochs_metadata.html

**Contents:**
- Working with Epoch metadata#
- Viewing Epochs metadata#
- Modifying the metadata#
- Selecting epochs using metadata queries#
- Adding metadata to an Epochs object#

Go to the end to download the full example code.

This tutorial shows how to add metadata to Epochs objects, and how to use Pandas query strings to select and plot epochs based on metadata properties.

For this tutorial we‚Äôll use a different dataset than usual: the Kiloword dataset, which contains EEG data averaged across 75 subjects who were performing a lexical decision (word/non-word) task. The data is in Epochs format, with each epoch representing the response to a different stimulus (word). As usual we‚Äôll start by importing the modules we need and loading the data:

Restrictions on metadata DataFrames

Metadata dataframes are less flexible than typical Pandas DataFrames. For example, the allowed data types are restricted to strings, floats, integers, or booleans; and the row labels are always integers corresponding to epoch numbers. Other capabilities of DataFrames such as hierarchical indexing are possible while the Epochs object is in memory, but will not survive saving and reloading the Epochs object to/from disk.

The metadata attached to Epochs objects is stored as a pandas.DataFrame:

Each row corresponds to one epoch. The columns can contain just about any information you want to store about each epoch; in this case, the metadata encodes information about the stimulus seen on each trial, including properties of the visual word form itself (e.g., NumberOfLetters, VisualComplexity) as well as properties of what the word means (e.g., its Concreteness) and its prominence in the English lexicon (e.g., WordFrequency). Here are all the variables; note that in a Jupyter notebook, viewing a pandas.DataFrame gets rendered as an HTML table instead of the normal Python output block:

Viewing the metadata values for a given epoch and metadata variable is done using any of the Pandas indexing methods such as loc, iloc, at, and iat. Because the index of the dataframe is the integer epoch number, the name- and index-based selection methods will work similarly for selecting rows, except that name-based selection (with loc) is inclusive of the endpoint:

Like any pandas.DataFrame, you can modify the data or add columns as needed. Here we convert the NumberOfLetters column from float to integer data type, and add a boolean column that arbitrarily divides the variable VisualComplexity into high and low groups.

All Epochs objects can be subselected by event name, index, or slice (see Subselecting epochs). But Epochs objects with metadata can also be queried using Pandas query strings by passing the query string just as you would normally pass an event name. For example:

This capability uses the pandas.DataFrame.query() method under the hood, so you can check out the documentation of that method to learn how to format query strings. Here‚Äôs another example:

Note also that traditional epochs subselection by condition name still works; MNE-Python will try the traditional method first before falling back on rich metadata querying.

One use of the Pandas query string approach is to select specific words for plotting:

Notice that in this dataset, each ‚Äúcondition‚Äù (A.K.A., each word) occurs only once, whereas with the Sample dataset each condition (e.g., ‚Äúauditory/left‚Äù, ‚Äúvisual/right‚Äù, etc) occurred dozens of times. This makes the Pandas querying methods especially useful when you want to aggregate epochs that have different condition names but that share similar stimulus properties. For example, here we group epochs based on the number of letters in the stimulus word, and compare the average signal at electrode Pz for each group:

Metadata can also be useful for sorting the epochs in an image plot. For example, here we order the epochs based on word frequency to see if there‚Äôs a pattern to the latency or intensity of the response:

Although there‚Äôs no obvious relationship in this case, such analyses may be useful for metadata variables that more directly index the time course of stimulus processing (such as reaction time).

You can add a metadata DataFrame to any Epochs object (or replace existing metadata) simply by assigning to the metadata attribute:

You can remove metadata from an Epochs object by setting its metadata to None:

Total running time of the script: (0 minutes 6.146 seconds)

Download Jupyter notebook: 30_epochs_metadata.ipynb

Download Python source code: 30_epochs_metadata.py

Download zipped: 30_epochs_metadata.zip

Gallery generated by Sphinx-Gallery

Visualizing epoched data

Auto-generating Epochs metadata

---

## Working with events#

**URL:** https://mne.tools/stable/auto_tutorials/raw/20_event_arrays.html

**Contents:**
- Working with events#
- Reading and writing events from/to a file#
- Subselecting and combining events#
- Mapping Event IDs to trial descriptors#
- Plotting events#
  - Plotting events and raw data together#
- Making equally-spaced Events arrays#

Go to the end to download the full example code.

This tutorial describes event representation and how event arrays are used to subselect data.

As usual we‚Äôll start by importing the modules we need, loading some example data, and cropping the Raw object to just 60 seconds before loading it into RAM to save memory:

The tutorial Parsing events from raw data describes in detail the different ways of obtaining an Events array from a Raw object (see the section Detecting experimental events for details). Since the sample dataset includes experimental events recorded on stim channel STI 014, we‚Äôll start this tutorial by parsing the events from that channel using mne.find_events():

Event arrays are NumPy array objects, so they could be saved to disk as binary .npy files using numpy.save(). However, MNE-Python provides convenience functions mne.read_events() and mne.write_events() for reading and writing event arrays as either text files (common file extensions are .eve, .lst, and .txt) or binary .fif files. The example dataset includes the results of mne.find_events(raw) in a .fif file. Since we‚Äôve truncated our Raw object, it will have fewer events than the events file loaded from disk (which contains events for the entire recording), but the events should match for the first 60 seconds anyway:

When writing event arrays to disk, the format will be inferred from the file extension you provide. By convention, MNE-Python expects events files to either have an .eve extension or to have a file basename ending in -eve or _eve (e.g., my_experiment_eve.fif), and will issue a warning if this convention is not respected.

The output of find_events() above (repeated here) told us the number of events that were found, and the unique integer event IDs present:

Including/excluding events

Just like pick_events, read_events also has include and exclude parameters.

If some of those events are not of interest, you can easily subselect events using mne.pick_events(), which has parameters include and exclude. For example, in the sample data Event ID 32 corresponds to a subject button press, which could be excluded as:

It is also possible to combine two Event IDs using mne.merge_events(); the following example will combine Event IDs 1, 2 and 3 into a single event labelled 1:

Note, however, that merging events is not necessary if you simply want to pool trial types for analysis; the next section describes how MNE-Python uses event dictionaries to map integer Event IDs to more descriptive label strings.

So far in this tutorial we‚Äôve only been dealing with integer Event IDs, which were assigned based on DC voltage pulse magnitude (which is ultimately determined by the experimenter‚Äôs choices about what signals to send to the STIM channels). Keeping track of which Event ID corresponds to which experimental condition can be cumbersome, and it is often desirable to pool experimental conditions during analysis. You may recall that the mapping of integer Event IDs to meaningful descriptions for the sample dataset is given in this table in the introductory tutorial. Here we simply reproduce that mapping as an event dictionary:

Event dictionaries like this one are used when extracting epochs from continuous data, and the resulting Epochs object allows pooling by requesting partial trial descriptors. For example, if we wanted to pool all auditory trials, instead of merging Event IDs 1 and 2 using the merge_events() function, we can make use of the fact that the keys of event_dict contain multiple trial descriptors separated by / characters: requesting 'auditory' trials will select all epochs with Event IDs 1 and 2; requesting 'left' trials will select all epochs with Event IDs 1 and 3. An example of this is shown later, in the Subselecting epochs section of the tutorial The Epochs data structure: discontinuous data.

Another use of event dictionaries is when plotting events, which can serve as a useful check that your event signals were properly sent to the STIM channel(s) and that MNE-Python has successfully found them. The function mne.viz.plot_events() will plot each event versus its sample number (or, if you provide the sampling frequency, it will plot them versus time in seconds). It can also account for the offset between sample number and sample index in Neuromag systems, with the first_samp parameter. If an event dictionary is provided, it will be used to generate a legend:

Events can also be plotted alongside the Raw object they were extracted from, by passing the Event array as the events parameter of raw.plot:

For some experiments (such as those intending to analyze resting-state activity) there may not be any experimental events included in the raw recording. In such cases, an Events array of equally-spaced events can be generated using mne.make_fixed_length_events():

By default, the events will all be given the integer Event ID of 1, but you can change that with the id parameter. It is also possible to specify an overlap duration ‚Äî i.e., if you ultimately want epochs that are 2.5 seconds long, but you want them to overlap by 0.5 seconds, you can specify duration=2.5, overlap=0.5 in the call to make_fixed_length_events() (this will yield the same spacing of events as duration=2, overlap=0).

Total running time of the script: (0 minutes 2.074 seconds)

Download Jupyter notebook: 20_event_arrays.ipynb

Download Python source code: 20_event_arrays.py

Download zipped: 20_event_arrays.zip

Gallery generated by Sphinx-Gallery

The Raw data structure: continuous data

Annotating continuous data

---

## Working with eye tracker data in MNE-Python#

**URL:** https://mne.tools/stable/auto_tutorials/preprocessing/90_eyetracking_data.html

**Contents:**
- Working with eye tracker data in MNE-Python#
- Data loading#
- Ocular annotations#
- Checking the calibration#
- Standardizing eyetracking data to SI units#
- Plot the raw eye-tracking data#
- Handling blink artifacts#
- Extract common stimulus events from the data#
- Align the eye-tracking data with EEG data#
- Showing the pupillary light reflex#

Go to the end to download the full example code.

In this tutorial we will explore simultaneously recorded eye-tracking and EEG data from a pupillary light reflex task. We will combine the eye-tracking and EEG data, and plot the ERP and pupil response to the light flashes (i.e. the pupillary light reflex).

As usual we start by importing the modules we need and loading some example data: eye-tracking data recorded from SR research‚Äôs '.asc' file format, and EEG data recorded from EGI‚Äôs '.mff' file format. We‚Äôll pass create_annotations=["blinks"] to read_raw_eyelink() so that only blinks annotations are created (by default, annotations are created for blinks, saccades, fixations, and experiment messages).

Importing Data from Eyetracking devices

The info structure of the eye-tracking data tells us we loaded a monocular recording with 2 eyegaze channels (x- and y-coordinate positions), 1 pupil channel, 1 stim channel, and 3 channels for the head distance and position (since this data was collected using EyeLink‚Äôs Remote mode).

By default, EyeLink files will output ocular events (blinks, saccades, and fixations), and experiment messages. MNE will store these events as mne.Annotations. Ocular annotations contain channel information in the 'ch_names' key. This means that we can see which eye an ocular event occurred in, which can be useful for binocular recordings:

EyeLink .asc files can also include calibration information. MNE-Python can load and visualize those eye-tracking calibrations, which is a useful first step in assessing the quality of the eye-tracking data. read_eyelink_calibration() will return a list of Calibration instances, one for each calibration. We can index that list to access a specific calibration.

Calibrations have dict-like attribute access; in addition to the attributes shown in the output above, additional attributes are 'positions' (the x and y coordinates of each calibration point), 'gaze' (the x and y coordinates of the actual gaze position to each calibration point), and 'offsets' (the offset in visual degrees between the calibration position and the actual gaze position for each calibration point). Below is an example of how to access these data:

Let‚Äôs plot the calibration to get a better look. Below we see the location that each calibration point was displayed (gray dots), the positions of the actual gaze (red), and the offsets (in visual degrees) between the calibration position and the actual gaze position of each calibration point.

EyeLink stores eyegaze positions in pixels, and pupil size in arbitrary units. MNE-Python expects eyegaze positions to be in radians of visual angle, and pupil size to be in meters. We can convert the eyegaze positions to radians using convert_units(). We‚Äôll pass the calibration object we created above, after specifying the screen resolution, screen size, and screen distance.

Let‚Äôs plot the raw eye-tracking data. Since we did not convert the pupil size to meters, we‚Äôll pass a custom dict into the scalings argument to make the pupil size traces legible when plotting.

Naturally, there are blinks in our data, which occur within "BAD_blink" annotations. During blink periods, eyegaze coordinates are not reported, and pupil size data are 0. We don‚Äôt want these blink artifacts biasing our analysis, so we have two options: Drop the blink periods from our data during epoching, or interpolate the missing data during the blink periods. For this tutorial, let‚Äôs interpolate the blink samples. We‚Äôll pass (0.05, 0.2) to interpolate_blinks(), expanding the interpolation window 50 ms before and 200 ms after the blink, so that the noisy data surrounding the blink is also interpolated.

By default, interpolate_blinks(), will only interpolate blinks in pupil channels. Passing interpolate_gaze=True will also interpolate the blink periods of the eyegaze channels. Be aware, however, that eye movements can occur during blinks which makes the gaze data less suitable for interpolation.

In this experiment, a photodiode attached to the display screen was connected to both the EEG and eye-tracking systems. The photodiode was triggered by the the light flash stimuli, causing a signal to be sent to both systems simultaneously, signifying the onset of the flash. The photodiode signal was recorded as a digital input channel in the EEG and eye-tracking data. MNE loads these data as a stim channel.

We‚Äôll extract the flash event onsets from both the EEG and eye-tracking data, as they are necessary for aligning the data from the two recordings.

The output above shows us that both the EEG and EyeLink data used event ID 2 for the flash events, so we‚Äôll create a dictionary to use later when plotting to label those events.

In this dataset, eye-tracking and EEG data were recorded simultaneously, but on different systems, so we‚Äôll need to align the data before we can analyze them together. We can do this using the realign_raw() function, which will align the data based on the timing of the shared events that are present in both Raw objects. We‚Äôll use the shared photodiode events we extracted above, but first we need to convert the event onsets from samples to seconds. Once the data have been aligned, we‚Äôll add the EEG channels to the eye-tracking raw object.

Now let‚Äôs extract epochs around our flash events. We should see a clear pupil constriction response to the flashes.

For this experiment, the participant was instructed to fixate on a crosshair in the center of the screen. Let‚Äôs plot the gaze position data to confirm that the participant primarily kept their gaze fixated at the center of the screen.

Plotting eye-tracking heatmaps in MNE-Python

Finally, let‚Äôs plot the evoked responses to the light flashes to get a sense of the average pupillary light response, and the associated ERP in the EEG data.

Total running time of the script: (0 minutes 16.160 seconds)

Download Jupyter notebook: 90_eyetracking_data.ipynb

Download Python source code: 90_eyetracking_data.py

Download zipped: 90_eyetracking_data.zip

Gallery generated by Sphinx-Gallery

Preprocessing optically pumped magnetometer (OPM) MEG data

Segmenting continuous data into epochs

---

## Working with sEEG data#

**URL:** https://mne.tools/stable/auto_tutorials/clinical/20_seeg.html

**Contents:**
- Working with sEEG data#

Go to the end to download the full example code.

MNE-Python supports working with more than just MEG and EEG data. Here we show some of the functions that can be used to facilitate working with stereoelectroencephalography (sEEG) data.

This example shows how to use:

channel locations in MNI space

projection into a volume

Note that our sample sEEG electrodes are already assumed to be in MNI space. If you want to map positions from your subject MRI space to MNI fsaverage space, you must apply the FreeSurfer‚Äôs talairach.xfm transform for your dataset. You can take a look at How MNE uses FreeSurfer‚Äôs outputs for more information.

For an example that involves ECoG data, channel locations in a subject-specific MRI, or projection into a surface, see Working with ECoG data. In the ECoG example, we show how to visualize surface grid channels on the brain.

Please note that this tutorial requires 3D plotting dependencies, see Install via pip or conda.

Let‚Äôs load some sEEG data with channel locations and make epochs.

Let use the Talairach transform computed in the Freesurfer recon-all to apply the Freesurfer surface RAS (‚Äòmri‚Äô) to MNI (‚Äòmni_tal‚Äô) transform.

Let‚Äôs check to make sure everything is aligned.

The most rostral electrode in the temporal lobe is outside the fsaverage template brain. This is not ideal but it is the best that the linear Talairach transform can accomplish. A more complex transform is necessary for more accurate warping, see Locating intracranial electrode contacts.

Now, let‚Äôs project onto the inflated brain surface for visualization. This video may be helpful for understanding the how the annotations on the pial surface translate to the inflated brain and flat map:

Let‚Äôs also show the sensors on a flat brain.

Let‚Äôs also look at which regions of interest are nearby our electrode contacts.

Now, let‚Äôs the electrodes and a few regions of interest that the contacts of the electrode are proximal to.

Next, we‚Äôll get the epoch data and plot its amplitude over time.

We can visualize this raw data on the fsaverage brain (in MNI space) as a heatmap. This works by first creating an Evoked data structure from the data of interest (in this example, it is just the raw LFP). Then one should generate a stc data structure, which will be able to visualize source activity on the brain in various different formats.

Plot 3D source (brain region) visualization:

By default, stc.plot_3d() will show a time course of the source with the largest absolute value across any time point. In this example, it is simply the source with the largest raw signal value. Its location is marked on the brain by a small blue sphere.

In this tutorial, we used a BEM surface for the fsaverage subject from FreeSurfer.

For additional common analyses of interest, see the following:

For volumetric plotting options, including limiting to a specific area of the volume specified by say an atlas, or plotting different types of source visualizations see: Visualize source time courses (stcs).

For extracting activation within a specific FreeSurfer volume and using different FreeSurfer volumes, see: How MNE uses FreeSurfer‚Äôs outputs.

For working with BEM surfaces and using FreeSurfer, or MNE to generate them, see: Head model and forward computation.

Total running time of the script: (0 minutes 44.593 seconds)

Download Jupyter notebook: 20_seeg.ipynb

Download Python source code: 20_seeg.py

Download zipped: 20_seeg.zip

Gallery generated by Sphinx-Gallery

Clinical applications

Working with ECoG data

---

## Working with sensor locations#

**URL:** https://mne.tools/stable/auto_tutorials/intro/40_sensor_locations.html

**Contents:**
- Working with sensor locations#
- About montages and layouts#
- Working with built-in montages#
- Plotting 2D sensor locations like EEGLAB#
- Manually controlling 2D channel projection#
- Reading sensor digitization files#
- Visualizing sensors in 3D surface renderings#
- Working with layout files#

Go to the end to download the full example code.

This tutorial describes how to read and plot sensor locations, and how MNE-Python handles physical locations of sensors. As usual we‚Äôll start by importing the modules we need:

Montages contain sensor positions in 3D (x, y, z in meters), which can be assigned to existing EEG/MEG data. By specifying the locations of sensors relative to the brain, Montages play an important role in computing the forward solution and inverse estimates.

In contrast, Layouts are idealized 2D representations of sensor positions. They are primarily used for arranging individual sensor subplots in a topoplot or for showing the approximate relative arrangement of sensors as seen from above.

If you‚Äôre working with EEG data exclusively, you‚Äôll want to use Montages, not layouts. Idealized montages (e.g., those provided by the manufacturer, or the ones shipping with MNE-Python mentioned below) are typically referred to as template montages.

Computing sensor locations

If you are interested in how standard (idealized) EEG sensor positions are computed on a spherical head model, make sure to check out the eeg_positions repository.

The 3D coordinates of MEG sensors are included in the raw recordings from MEG systems. They are automatically stored in the info attribute of the Raw object upon loading. EEG electrode locations are much more variable because of differences in head shape. Idealized montages (‚Äùtemplate montages‚Äù) for many EEG systems are included in MNE-Python, and you can get an overview of them by using mne.channels.get_builtin_montages():

These built-in EEG montages can be loaded with mne.channels.make_standard_montage:

Montage objects have a plot method for visualizing the sensor locations in 2D or 3D:

Once loaded, a montage can be applied to data with the set_montage method, for example raw.set_montage(), epochs.set_montage(), or evoked.set_montage(). This will only work with data whose EEG channel names correspond to those in the montage. (Therefore, we‚Äôre loading some EEG data below, and not the usual MNE ‚Äúsample‚Äù dataset.)

You can then visualize the sensor locations via the plot_sensors() method.

It is also possible to skip the manual montage loading step by passing the montage name directly to the set_montage() method.

You may have noticed that the figures created via plot_sensors() contain fewer sensors than the result of easycap_montage.plot(). This is because the montage contains all channels defined for that EEG system; but not all recordings will necessarily use all possible channels. Thus when applying a montage to an actual EEG dataset, information about sensors that are not actually present in the data is removed.

The sphere keyword is available in many places!

All MNE plotting functions for EEG topographies and sensor locations support the sphere keyword argument, and therefore allow for adjustment of the way the sensors are projected onto the head circle.

In MNE-Python, by default the head center is calculated using fiducial points. This means that the head circle represents the head circumference at the nasion and ear level, and not where it is commonly measured in the 10‚Äì20 EEG system (i.e., above the nasion at T4/T8, T3/T7, Oz, and Fpz).

If you prefer to draw the head circle using 10‚Äì20 conventions (which are also used by EEGLAB), you can pass sphere='eeglab':

Because the data we‚Äôre using here doesn‚Äôt contain an Fpz channel, its putative location was approximated automatically.

Channel positions in 2D space are obtained by projecting their actual 3D positions onto a sphere, then projecting the sphere onto a plane. By default, a sphere with origin at (0, 0, 0) (x, y, z coordinates) and radius of 0.095 meters (9.5 cm) is used. You can use a different sphere radius by passing a single value as the sphere argument in any function that plots channels in 2D (like plot that we use here, but also for example mne.viz.plot_topomap):

To change not only the radius, but also the sphere origin, pass a (x, y, z, radius) tuple as the sphere argument:

In the sample data, the sensor positions are already available in the info attribute of the Raw object (see the documentation of the reading functions and set_montage() for details on how that works). Therefore, we can plot sensor locations directly from the Raw object using plot_sensors(), which provides similar functionality to montage.plot(). In addition, plot_sensors() supports channel selection by type, color-coding channels in various ways (by default, channels listed in raw.info['bads'] will be plotted in red), and drawing in an existing Matplotlib Axes object (so the channel positions can easily be added as a subplot in a multi-panel figure):

The previous 2D topomap reveals irregularities in the EEG sensor positions in the sample dataset ‚Äî this is because the sensor positions in that dataset are digitizations of actual sensor positions on the head rather than idealized sensor positions based on a spherical head model. Depending on the digitization device (e.g., a Polhemus Fastrak digitizer), you need to use different montage reading functions (see Supported formats for digitized 3D locations). The resulting montage can then be added to Raw objects by passing it as an argument to the set_montage() method (just as we did before with the name of the predefined 'standard_1020' montage). Once loaded, locations can be plotted with the plot() method and saved with the save() method of the montage object.

When setting a montage with set_montage(), the measurement info is updated in two places (both chs and dig entries are updated) ‚Äì see The Info data structure for more details. Note that dig may contain HPI, fiducial, or head shape points in addition to electrode locations.

It is also possible to render an image of an MEG sensor helmet using 3D surface rendering instead of matplotlib. This works by calling mne.viz.plot_alignment():

Note that plot_alignment() requires an Info object, and can also render MRI surfaces of the scalp, skull, and brain (by passing a dict with keys like 'head', 'outer_skull' or 'brain' to the surfaces parameter). This makes the function useful for assessing coordinate frame transformations. For examples of various uses of plot_alignment(), see Plotting sensor layouts of EEG systems, Plotting EEG sensors on the scalp, and Plotting sensor layouts of MEG systems.

Similar to montages, many layout files are included with MNE-Python. They are stored in the mne/channels/data/layouts folder:

To load a layout file, use the mne.channels.read_layout function. You can then visualize the layout using its plot method:

Similar to the picks argument for selecting channels from Raw objects, the plot() method of Layout objects also has a picks argument. However, because layouts only contain information about sensor name and location (not sensor type), the plot() method only supports picking channels by index (not by name or by type). In the following example, we find the desired indices using numpy.where(); selection by name or type is possible with mne.pick_channels() or mne.pick_types().

If you have a Raw object that contains sensor positions, you can create a Layout object with either mne.channels.make_eeg_layout() or mne.channels.find_layout().

There is no corresponding make_meg_layout() function because sensor locations are fixed in an MEG system (unlike in EEG, where sensor caps deform to fit snugly on a specific head). Therefore, MEG layouts are consistent (constant) for a given system and you can simply load them with mne.channels.read_layout() or use mne.channels.find_layout() with the ch_type parameter (as previously demonstrated for EEG).

All Layout objects have a save method that writes layouts to disk as either .lout or .lay formats (inferred from the file extension contained in the fname argument). The choice between .lout and .lay format only matters if you need to load the layout file in some other application (MNE-Python can read both formats).

Total running time of the script: (0 minutes 9.279 seconds)

Download Jupyter notebook: 40_sensor_locations.ipynb

Download Python source code: 40_sensor_locations.py

Download zipped: 40_sensor_locations.zip

Gallery generated by Sphinx-Gallery

The Info data structure

Configuring MNE-Python

---

## XDAWN Denoising#

**URL:** https://mne.tools/stable/auto_examples/preprocessing/xdawn_denoising.html

**Contents:**
- XDAWN Denoising#
- References#

Go to the end to download the full example code.

XDAWN filters are trained from epochs, signal is projected in the sources space and then projected back in the sensor space using only the first two XDAWN components. The process is similar to an ICA, but is supervised in order to maximize the signal to signal + noise ratio of the evoked response [1][2].

As this denoising method exploits the known events to maximize SNR of the contrast between conditions it can lead to overfitting. To avoid a statistical analysis problem you should split epochs used in fit with the ones used in apply method.

Set parameters and read data

Now, we estimate a set of xDAWN filters for the epochs (which contain only the vis_r class).

Epochs are denoised by calling apply, which by default keeps only the signal subspace corresponding to the first n_components specified in the Xdawn constructor above.

Bertrand Rivet, Antoine Souloumiac, Virginie Attina, and Guillaume Gibert. xDAWN algorithm to enhance evoked potentials: application to brain‚Äìcomputer interface. IEEE Transactions on Biomedical Engineering, 56(8):2035‚Äì2043, 2009. doi:10.1109/TBME.2009.2012869.

Bertrand Rivet, Hubert Cecotti, Antoine Souloumiac, Emmanuel Maby, and J√©r√©mie Mattout. Theoretical analysis of xDAWN algorithm: application to an efficient sensor selection in a P300 BCI. In Proceedings of EUSIPCO-2011, 1382‚Äì1386. Barcelona, 2011. IEEE. URL: https://ieeexplore.ieee.org/document/7073970.

Total running time of the script: (0 minutes 5.887 seconds)

Download Jupyter notebook: xdawn_denoising.ipynb

Download Python source code: xdawn_denoising.py

Download zipped: xdawn_denoising.zip

Gallery generated by Sphinx-Gallery

Remap MEG channel types

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_parse_folder_raw_psd_projs.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_inverse_op.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_add_html.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_inverse_sol.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_forward_sol.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_epochs.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_custom_figure_sections.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_coregistration.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_ica.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_custom_figure.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_parse_folder_mri_bem.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_tags.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_cov.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_parse_folder_basic.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_raw.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_mri_and_bem.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_projs.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_code.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_custom_image.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_custom_figures.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_parse_folder_evoked.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_events.html

---

## 

**URL:** https://mne.tools/stable/auto_tutorials/intro/report_evoked.html

---
