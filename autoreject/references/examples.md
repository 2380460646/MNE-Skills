# Autoreject - Examples

**Pages:** 8

---

## Automatically repair epochs#

**URL:** https://autoreject.github.io/stable/auto_examples/plot_auto_repair.html

**Contents:**
- Automatically repair epochs#

Go to the end to download the full example code

This example demonstrates how to use autoreject to automatically repair epochs.

Let us first define the parameters. n_interpolates are the \(\rho\) values that we would like autoreject to try and consensus_percs are the \(\kappa\) values that autoreject will try (see the autoreject paper) for more information on these parameters).

Epochs with more than \(\kappa * N\) sensors (\(N\) total sensors) bad are dropped. For the rest of the epochs, the worst \(\rho\) bad sensors (as determined by channel-level thresholds) are interpolated. The exact values of these parameters are not preselected but learned from the data. If the number of bad sensors for a particular trial is less than \(\rho\), all the bad sensors are interpolated.

For the purposes of this example, we shall use the MNE sample dataset. Therefore, let us make some MNE related imports.

Now, we can import the class required for rejecting and repairing bad epochs. autoreject.compute_thresholds() is a callable which must be provided to the autoreject.AutoReject class for computing the channel-level thresholds.

Let us now read in the raw fif file for MNE sample dataset.

We can then read in the events

And pick MEG channels for repairing. Currently, autoreject can repair only one channel type at a time.

Now, we can create epochs. The reject params will be set to None because we do not want epochs to be dropped when instantiating mne.Epochs.

autoreject.AutoReject internally does cross-validation to determine the optimal values \(\rho^{*}\) and \(\kappa^{*}\)

Note that autoreject.AutoReject by design supports multiple channels. If no picks are passed, separate solutions will be computed for each channel type and internally combined. This then readily supports cleaning unseen epochs from the different channel types used during fit. Here we only use a subset of channels to save time.

Now, we will manually mark the bad channels just for plotting.

Let us plot the results.

To top things up, we can also visualize the bad sensors for each trial using a heatmap.

Total running time of the script: ( 1 minutes 47.137 seconds)

Download Python source code: plot_auto_repair.py

Download Jupyter notebook: plot_auto_repair.ipynb

Gallery generated by Sphinx-Gallery

Plot channel-level thresholds

Plotting the cross-validation curve

---

## Detect bad sensors using RANSAC#

**URL:** https://autoreject.github.io/stable/auto_examples/plot_ransac.html

**Contents:**
- Detect bad sensors using RANSAC#
- References#

Go to the end to download the full example code

This example demonstrates how to use RANSAC [1] from the PREP pipeline to detect bad sensors and repair them. Note that this implementation in autoreject [2] is an extension of the original implementation and works for MEG sensors as well.

Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., & Robbins, K. A. (2015). The PREP pipeline: standardized preprocessing for large-scale EEG analysis. Frontiers in neuroinformatics, 9, 16.

Jas, M., Engemann, D. A., Bekhti, Y., Raimondo, F., & Gramfort, A. (2017). Autoreject: Automated artifact rejection for MEG and EEG data. NeuroImage, 159, 417-429.

For the purposes of this example, we shall use the MNE sample dataset. Therefore, let us make some MNE related imports.

Let us now read in the raw fif file for MNE sample dataset.

We can then read in the events

And pick MEG channels for repairing. Currently, autoreject can repair only one channel type at a time.

Now, we can create epochs. The reject params will be set to None because we do not want epochs to be dropped when instantiating mne.Epochs.

We import Ransac and run the familiar fit_transform method.

We can also get the list of bad channels computed by Ransac.

Then we compute the evoked before and after interpolation.

We will manually mark the bad channels just for plotting.

Let us plot the results.

To top things up, we can also visualize the bad sensors for each trial using a heatmap.

Total running time of the script: ( 1 minutes 36.666 seconds)

Download Python source code: plot_ransac.py

Download Jupyter notebook: plot_ransac.ipynb

Gallery generated by Sphinx-Gallery

Plotting the cross-validation curve

Preprocessing workflow with autoreject and ICA

---

## Examples Gallery#

**URL:** https://autoreject.github.io/stable/auto_examples/index.html

**Contents:**
- Examples Gallery#

This section of the documentation is learning-oriented and shows off some of the basic functionality of autoreject.

Find global rejection threshold

Plot channel-level thresholds

Automatically repair epochs

Plotting the cross-validation curve

Detect bad sensors using RANSAC

Preprocessing workflow with autoreject and ICA

Visualize bad sensors per trial

Download all examples in Python source code: auto_examples_python.zip

Download all examples in Jupyter notebooks: auto_examples_jupyter.zip

Gallery generated by Sphinx-Gallery

Find global rejection threshold

---

## Find global rejection threshold#

**URL:** https://autoreject.github.io/stable/auto_examples/plot_estimate_global_reject.html

**Contents:**
- Find global rejection threshold#

Go to the end to download the full example code

This example demonstrates how to use autoreject to find global rejection thresholds.

Let us import the data using MNE-Python and epoch it.

Now we get the rejection dictionary

Finally, the cleaned epochs

Total running time of the script: ( 0 minutes 2.828 seconds)

Download Python source code: plot_estimate_global_reject.py

Download Jupyter notebook: plot_estimate_global_reject.ipynb

Gallery generated by Sphinx-Gallery

Plot channel-level thresholds

---

## Plotting the cross-validation curve#

**URL:** https://autoreject.github.io/stable/auto_examples/plot_global_reject.html

**Contents:**
- Plotting the cross-validation curve#

Go to the end to download the full example code

This example demonstrates how to use autoreject to plot the cross-validation curve that is used to estimate the global rejection thresholds.

Let us import the data using MNE-Python and epoch it.

Let us define a range of candidate thresholds which we would like to try. In this particular case, we try from \(40{\mu}V\) to \(200{\mu}V\)

Next, we can use autoreject.validation_curve() to compute the Root Mean Squared (RMSE) values at the candidate thresholds. Under the hood, this is using autoreject._GlobalAutoReject to find global (i.e., for all channels) peak-to-peak thresholds.

We can also get the best threshold more efficiently using Bayesian optimization

Now let us plot the RMSE values against the candidate thresholds.

Total running time of the script: ( 0 minutes 2.494 seconds)

Download Python source code: plot_global_reject.py

Download Jupyter notebook: plot_global_reject.ipynb

Gallery generated by Sphinx-Gallery

Automatically repair epochs

Detect bad sensors using RANSAC

---

## Plot channel-level thresholds#

**URL:** https://autoreject.github.io/stable/auto_examples/plot_channel_thresholds.html

**Contents:**
- Plot channel-level thresholds#

Go to the end to download the full example code

This example demonstrates how to use autoreject to find channel-wise thresholds.

Let us first load the raw data using mne.io.read_raw_fif().

We can extract the events (or triggers) for epoching our signal.

Now that we have the events, we can extract the trials for the selection of channels defined by picks.

Now, we compute the channel-level thresholds using autoreject.compute_thresholds(). The method parameter will determine how we will search for thresholds over a range of potential candidates.

Finally, let us plot a histogram of the channel-level thresholds to verify that the thresholds are indeed different for different sensors.

Total running time of the script: ( 0 minutes 18.849 seconds)

Download Python source code: plot_channel_thresholds.py

Download Jupyter notebook: plot_channel_thresholds.ipynb

Gallery generated by Sphinx-Gallery

Find global rejection threshold

Automatically repair epochs

---

## Preprocessing workflow with autoreject and ICA#

**URL:** https://autoreject.github.io/stable/auto_examples/plot_autoreject_workflow.html

**Contents:**
- Preprocessing workflow with autoreject and ICA#
- Autoreject without any other preprocessing#
- Autoreject with high-pass filter#
- ICA#
- Autoreject with highpass filter and ICA#

Go to the end to download the full example code

This example demonstrates how to visualize data when preprocessing with autoreject and discusses decisions about when and which other preprocessing steps to use in combination.

tldr: We recommend that you first highpass filter the data, then run autoreject (local) and supply the bad epochs detected by it to the ICA algorithm for a robust fit, and finally run autoreject (local) again.

Autoreject without any other preprocessing

Autoreject with high-pass filter

Autoreject with highpass filter and ICA

First, we download resting-state EEG data from a Parkinson’s patient from OpenNeuro. We will do this using openneuro-py which can be installed with the command pip install openneuro-py.

We will now load in the raw data from the bdf file downloaded from OpenNeuro and, since this is resting-state data without any events, make regularly spaced events with which to epoch the raw data. In the averaged plot, we can see that there may be some eyeblink artifact contamination but, overall, the data is typical of resting-state EEG.

Now, we’ll naively apply autoreject as our first preprocessing step.

As we can see in the plot of the rejected epochs, there are many eyeblinks that caused the epoch to be dropped. This resulted in a lot of the data being lost.

The data looks fairly clean already and we don’t want to interpolate more than a few sensors since we only have 32 to start, so the number of channels to interpolate was set to check some low numbers

visualize the dropped epochs

The data may be very valuable and the time for the experiment limited and so we may want to take steps to reduce the number of epochs dropped by first using other steps to preprocess the data. We will use a high-pass filter first to remove slow drift that could cause epochs to be dropped.

When making this decision to filter the data, we do want to be careful because filtering can spread sharp, high-frequency transients and distort the phase of the signal. Most evoked response potential analyses use filtering since the interest is in the time series, but if you are doing a frequency based analysis, filtering before the Fourier transform could potentially be avoided by detrending instead.

visualize the dropped epochs

and the reject log. As we can see in the plot, high-pass filtering reduced the number of epochs marked as bad by autoreject substantially.

Finally, we can apply independent components analysis (ICA) to remove eyeblinks from the data. If our analysis were to be very dependent on sensors at the front of the head, we could skip ICA and use the previous result. However, ICA can increase the amount of usable data by applying a spatial filter that downscales the data in sensors most affected by eyeblink artifacts.

Note that ICA works best if bad segments of the data are removed Hence, we will remove the bad segments from the previous run of autoreject for the benefit of the ICA algorithm.

We can see in the plots below that ICA effectively removed eyeblink artifact.

plot source components to see which is made up of blinks

plot with and without eyeblink component

We can see in this section that preprocessing, especially ICA, can be made to do a lot of the heavy lifting. There isn’t a huge difference when viewing the averaged data because the ICA effectively limited the number of epochs that had to be dropped. However, there are still artifacts such as non-stereotypical blinks that weren’t able to be removed by ICA, channel “pops” (sharp transients with exponential RC decay), muscle artifact such as jaw clenches and gross movement artifact that could still impact analyses.

These are the basic steps for a workflow with decisions that must be made based on what the data is being used for. Following this may help you optimize your use of autoreject in preprocessing.

We will do a few more visualizations to see that removing the bad epochs found by autoreject is still important even with preprocessing first. This is especially important if your analyses include trial-level statistics such as looking for bursting activity. We’ll visualize why autoreject excluded these epochs and the effect that including these bad epochs would have on the data.

First, we will visualize the reject log

Next, we will visualize the cleaned average data and compare it against the bad segments.

As a last optional step, we can do inspect the reject_log and make manual corrections to the reject_log. For instance, if data is limited, we may not want to drop epochs but retain the list of bad epochs for quality assurance metrics.

The modified reject log can be applied to the data as follows.

Finally, don’t forget that we are working with resting state data here. Here we used long epochs of 3 seconds so that frequency-domain analysis was possible with the epochs. However, this could also lead to longer segments of the data being rejected. If you want more fine-grained control over the artifacts, you can construct shorter epochs and use the autoreject log to mark annotations in MNE that can be used to reject the data during doing time-frequency analysis. We want to emphasize that there is no subsitute for visual inspection. Irrespective of the rejection method used, we highly recommend users to inspect their preprocessed data before further analyses.

Total running time of the script: ( 1 minutes 29.369 seconds)

Download Python source code: plot_autoreject_workflow.py

Download Jupyter notebook: plot_autoreject_workflow.ipynb

Gallery generated by Sphinx-Gallery

Detect bad sensors using RANSAC

Visualize bad sensors per trial

---

## Visualize bad sensors per trial#

**URL:** https://autoreject.github.io/stable/auto_examples/plot_visualize_bad_epochs.html

**Contents:**
- Visualize bad sensors per trial#

Go to the end to download the full example code

This example demonstrates how to use autoreject to visualize the bad sensors in each trial

First, we download the data from OpenfMRI which is hosted on OpenNeuro. We will do this using openneuro-py which can be installed using pip (pip install openneuro-py).

We will create epochs with data starting 200 ms before trigger onset and continuing up to 800 ms after that. The data contains visual stimuli for famous faces, unfamiliar faces, as well as scrambled faces.

Let us now load all the epochs into memory and concatenate them

Now, we apply autoreject

Note that autoreject.AutoReject by design supports multiple channels. If no picks are passed separate solutions will be computed for each channel type and internally combines. This then readily supports cleaning unseen epochs from the different channel types used during fit. Here we only use a subset of channels to save time.

Also note that once the parameters are learned, any data can be repaired that contains channels that were used during fit. This also means that time may be saved by fitting autoreject.AutoReject on a representative subsample of the data.

We can visualize the cross validation curve over two variables

… and visualize the bad epochs and sensors. Bad sensors which have been interpolated are in blue. Bad sensors which are not interpolated are in red. Bad trials are also in red.

… and the epochs after cleaning with autoreject

The epochs dropped by autoreject are also stored in epochs.drop_log

Finally, the evoked before and after autoreject, for sanity check. We use the spatial_colors argument from MNE as it allows us to see that the eyeblinks have not yet been cleaned but the bad channels have been repaired.

Total running time of the script: ( 1 minutes 58.656 seconds)

Download Python source code: plot_visualize_bad_epochs.py

Download Jupyter notebook: plot_visualize_bad_epochs.ipynb

Gallery generated by Sphinx-Gallery

Preprocessing workflow with autoreject and ICA

---
